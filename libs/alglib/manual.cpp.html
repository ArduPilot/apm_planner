<html>
<head>
<style type="text/css">
h1              { background-color: #808080; padding: 0.2em; }
h2              { background-color: #B0B0B0; padding: 0.2em; }
h3              { background-color: #E0E0E0; padding: 0.2em; }
sheader         { }
.inlineheader   { background-color: #E8E8E8; padding: 0.1em; font-weight:bold; }
.pagecontent    { font-family: Arial; font-size: 10pt; width: 770px; text-align: justify; }
.pageheader     { width: 770px; }
.source         { font-family: "Courier New"; font-size: 10pt; }

.p_example      { margin-left: 4em; }
.p_note         { margin-left: 50px; width: 720px; font-size: 80%; }
.p_code         { margin-left: 50px; margin-top: 50px; margin-bottom: 50px; width: 720px; font-family: "Courier New", monospace; background-color: #F0F0F0; }
.s_code         { font-family: "Courier New"; background-color: #F0F0F0; }
.s_str          { font-family: "Courier New"; color: blue; font-weight: bold; }
.s_comment      { color: navy; font-style: italic; }
.s_preprocessor { color: green; }

a               { color:#000077; text-decoration: underline; }
a:visited       { color:#000077; text-decoration: underline;}
a:hover         { color:#000077; text-decoration: underline; }

a.toc           { color:#000077; text-decoration: none; }
a.toc:visited   { color:#000077; text-decoration: none;}
a.toc:hover     { color:#000077; text-decoration: underline; }

a.nav           { color:#000077; font-weight:bold; text-decoration: none; }
a.nav:visited   { color:#000077; font-weight:bold; text-decoration: none;}
a.nav:hover     { color:#000077; font-weight:bold; text-decoration: underline; }

.cond           { color:blue; }
.const          { color:#222222; }
.func           { color:#111111; }
</style>
</head>
<body>
<pre>
<a href='#int_main'>1 Introduction</a>
    <a href='#int_license'>1.1 ALGLIB license</a>
    <a href='#int_doc_license'>1.2 Documentation license</a>
    <a href='#gs_guide'>1.3 Reference Manual and User Guide</a>
    <a href='#int_ack'>1.4 Acknowledgements</a>
<a href='#gs_main'>2 Getting started with ALGLIB</a>
    <a href='#gs_structure'>2.1 ALGLIB structure</a>
        <a href='#gs_packages'>2.1.1 Packages</a>
        <a href='#gs_subpackages'>2.1.2 Subpackages</a>
        <a href='#gs_osscomm'>2.1.3 Open Source and Commercial versions</a>
    <a href='#gs_compatibility'>2.2 Compatibility</a>
        <a href='#gs_compatibility_cpu'>2.2.1 CPU</a>
        <a href='#gs_compatibility_os'>2.2.2 OS</a>
        <a href='#gs_compatibility_compiler'>2.2.3 Compiler</a>
        <a href='#gs_compatibility_opt'>2.2.4 Optimization settings</a>
    <a href='#gs_compiling'>2.3 Compiling ALGLIB</a>
        <a href='#gs_attaching'>2.3.1 Adding to your project</a>
        <a href='#gs_configuring'>2.3.2 Configuring for your compiler</a>
        <a href='#gs_configuring2'>2.3.3 Improving performance (CPU-specific and OS-specific optimizations)</a>
    <a href='#gs_comm'>2.4 Working with commercial version</a>
        <a href='#gs_comm_benefits'>2.4.1 Benefits of commercial version</a>
        <a href='#gs_comm_sse'>2.4.2 Working with SSE support (Intel/AMD users)</a>
        <a href='#gs_comm_smp'>2.4.3 Using multithreading</a>
        <a href='#gs_comm_smp'>2.4.4 SMT (CMT/hyper-threading) issues</a>
    <a href='#gs_using'>2.5 Using ALGLIB</a>
        <a href='#gs_using_threadsafety'>2.5.1 Thread-safety</a>
        <a href='#gs_global'>2.5.2 Global definitions</a>
        <a href='#gs_datatypes'>2.5.3 Datatypes</a>
        <a href='#gs_constants'>2.5.4 Constants</a>
        <a href='#gs_stdfunctions'>2.5.5 Functions</a>
        <a href='#gs_vecmat'>2.5.6 Working with vectors and matrices</a>
        <a href='#gs_functions'>2.5.7 Using functions: 'expert' and 'friendly' interfaces</a>
        <a href='#gs_errors'>2.5.8 Handling errors</a>
        <a href='#gs_blas'>2.5.9 Working with Level 1 BLAS functions</a>
    <a href='#gs_advanced'>2.6 Advanced topics</a>
        <a href='#gs_testing'>2.6.1 Testing ALGLIB</a>
<a href='#alglib_main'>3 ALGLIB reference manual</a>

</pre>
<div class=pagecontent>
<a name='int_main' class='sheader'></a><h1>1 Introduction</h1>

<a name='int_license' class='sheader'></a><h2>1.1 ALGLIB license</h2>

<p align=justify>
ALGLIB is a free software which uses dual licensing. You can either use it under GPL license (version 2 or at your option any later version)
or buy commercial license without copyleft requirement.
A copy of the GNU General Public License is available at <a href='http://www.fsf.org/licensing/licenses'>http://www.fsf.org/licensing/licenses</a>
A copy of the commercial license can be found at <a href='http://www.alglib.net/commercial.php'>http://www.alglib.net/commercial.php</a>
</p>

<a name='int_doc_license' class='sheader'></a><h2>1.2 Documentation license</h2>

<div style='width: 640px;'>
<p>
<U>This reference manual is licensed under BSD-like documentation license</U>:
</p>

<p>
Copyright 1994-2009 Sergey Bochkanov, ALGLIB Project. All rights reserved.
</p>

<p>
Redistribution and use of this document (ALGLIB Reference Manual) with or without modification,
are permitted provided that such redistributions will retain the above copyright notice,
this condition and the following disclaimer as the first (or last) lines of this file.
</p>

<p>
THIS DOCUMENTATION IS PROVIDED BY THE ALGLIB PROJECT "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES,
INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE ALGLIB PROJECT BE LIABLE FOR ANY DIRECT, INDIRECT,
INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT
OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS DOCUMENTATION, EVEN IF ADVISED
OF THE POSSIBILITY OF SUCH DAMAGE.
</p>
</div>

<a name='gs_guide' class='sheader'></a><h2>1.3 Reference Manual and User Guide</h2>

<p>
ALGLIB Project provides two sources of information: ALGLIB Reference Manual (this document) and <a href="http://www.alglib.net/#book">ALGLIB User Guide</a>.
</p>

<p>
ALGLIB Reference Manual contains full description of all publicly accessible ALGLIB units accompanied with examples.
Reference Manual is focused on the source code: it documents units, functions, structures and so on.
If you want to know what unit <code>YYY</code> can do or what subroutines unit <code>ZZZ</code> contains Reference Manual is a place to go.
Free software needs free documentation - that's why ALGLIB Reference Manual is licensed under BSD-like documentation license.
</p>

<p>
Additionally to the Reference Manual we provide you <a href="http://www.alglib.net/#book">User Guide</a>.
User Guide is focused on more general questions: how fast ALGLIB is? how reliable it is? what are the strong and weak sides of the algorithms used?
We aim to make ALGLIB User Guide an important source of information both about ALGLIB and numerical analysis algorithms in general.
We want it to be a book about algorithms, not just software documentation.
And we want it to be unique - that's why ALGLIB User Guide is distributed under less-permissive <a href="http://alglib.net.localhost/#guide_license">personal-use-only license</a>.
</p>

<a name='int_ack' class='sheader'></a><h2>1.4 Acknowledgements</h2>

<p>
ALGLIB was not possible without contribution of the next open source projects:
</p>

<ul>
<li><a href="http://www.netlib.org/lapack/">LAPACK</a></li>
<li><a href="http://www.moshier.net/">Cephes</a></li>
<li><a href="http://gmplib.org/">GNU MP</a></li>
<li><a href="http://www.mpfr.org/">MPFR</a></li>
</ul>




<a name='gs_main' class='sheader'></a><h1>2 Getting started with ALGLIB</h1>



<a name='gs_structure' class='sheader'></a><h2>2.1 ALGLIB structure</h2>

<a name='gs_packages' class='sheader'></a><h3>2.1.1 Packages</h3>

<p>
ALGLIB is a C++ interface to the computational core written in C.
Both C library and C++ wrapper are automatically generated by code generation tools developed within ALGLIB project.
Pre-3.0 versions of ALGLIB included more than 100 units, but it was difficult to work with such large number of files.
Since ALGLIB 3.0 all units are merged into 11 <i>packages</i> and two support units:
</p>

<ul>
<li><b>alglibmisc.cpp</b>&nbsp;-&nbsp;contains different algorithms which are hard to classify</li>
<li><b>dataanalysis.cpp</b>&nbsp;-&nbsp;contains data mining algorithms</li>
<li><b>diffequations.cpp</b>&nbsp;-&nbsp;contains differential equation solvers</li>
<li><b>fasttransforms.cpp</b>&nbsp;-&nbsp;contains FFT and other related algorithms</li>
<li><b>integration.cpp</b>&nbsp;-&nbsp;contains numerical integration algorithms</li>
<li><b>interpolation.cpp</b>&nbsp;-&nbsp;contains interpolation algorithms</li>
<li><b>linalg.cpp</b>&nbsp;-&nbsp;contains linear algebra algorithms</li>
<li><b>optimization.cpp</b>&nbsp;-&nbsp;contains optimization algorithms</li>
<li><b>solvers.cpp</b>&nbsp;-&nbsp;contains linear and nonlinear solvers</li>
<li><b>specialfunctions.cpp</b>&nbsp;-&nbsp;contains special functions</li>
<li><b>statistics.cpp</b>&nbsp;-&nbsp;statistics</li>
<li><i>alglibinternal.cpp</i>&nbsp;-&nbsp;contains internal functions which are used by other packages, but not exposed to the external world</li>
<li><i>ap.cpp</i>&nbsp;-&nbsp;contains publicly accessible vector/matrix classes, most important and general functions and other "basic" functionality</li>
</ul>

<p>
One package may rely on other ones, but we have tried to reduce number of dependencies.
Every package relies on <code>ap.cpp</code> and many packages rely on <code>alglibinternal.cpp</code>.
But many packages require only these two to work, and many other packages need significantly less than 13 packages.
For example, <code>statistics.cpp</code> requires two packages mentioned above and only one additional package - <code>specialfunctions.cpp</code>.
</p>

<a name='gs_subpackages' class='sheader'></a><h3>2.1.2 Subpackages</h3>

<p>
There is one more concept to learn - <i>subpackages</i>.
Every package was created from several source files.
For example (as of ALGLIB 3.0.0), <code>linalg.cpp</code> was created by merging together 14 .cpp files (C++ interface) and 14 .c files (computational core).
These files provide different functionality: one of them calculates triangular factorizations, another generates random matrices, and so on.
We've merged source code, but what to do with their documentation?
</p>

<p>
Of course, we can merge their documentation (as we've merged units) in one big list of functions and data structures, but such list will be hard to read.
Instead, we have decided to merge <i>source code</i>, but leave <i>documentation</i> separate.
</p>

<p>
If you look at the <a href='#alglib_packages'>list of ALGLIB packages</a>, you will see that each package includes several subpackages.
For example, <code>linalg.cpp</code> includes <code>trfac</code>, <code>svd</code>, <code>evd</code> and other subpackages.
These subpackages do no exist as separate files, namespaces or other entities.
They are just subsets of one large unit which provide significantly different functionality.
They have separate documentation sections, but if you want to use <code>svd</code> subpackage, you have to include <code>linalg.h</code>, not <code>svd.h</code>.
</p>


<a name='gs_osscomm' class='sheader'></a><h3>2.1.3 Open Source and Commercial versions</h3>

<p>
ALGLIB comes in two versions - open source (GPL-licensed) and commercial (closed source) one.
Both versions have same <i>functionality</i>, i.e. may solve same set of problems.
However, commercial version differs from open source one in following aspects:
</p>

<ul>
<li>
<b>License</b>.
Commercial ALGLIB is licensed under non-copyleft license which is friendly to commercial users.
</li>
<li>
<b>Performance</b>.
Many algorithms in commercial ALGLIB are multi-threaded and SSE-optimized (when used on Intel systems).
Open source ALGLIB is single-threaded and can not efficiently use modern multicore CPU's.<br>
You have to study comments on specific functions if you want to know whether they have multithreaded versions or not.
</li>
</ul>

<p>
This documentation applies to both versions of ALGLIB.
Detailed description of commercial version can be found <a href='#gs_comm'>below</a>.
</p>


<a name='gs_compatibility' class='sheader'></a><h2>2.2 Compatibility</h2>

<a name='gs_compatibility_cpu' class='sheader'></a><h3>2.2.1 CPU</h3>

<p>
ALGLIB is compatible with any CPU which:
</p>

<ul>
<li>supports double precision arithmetics</li>
<li>complies with IEEE 754 floating point standard (especially in its handling of IEEE special values)</li>
<li>either big-endian or little-endian (but not mixed-endian)</li>
</ul>

<p>
Most mainstream CPU's (in particular, x86, x86_64 and SPARC) satisfy these requirements.
</p>

<p class='p_note'>
As for Intel architecture, ALGLIB works with both FPU-based and SSE-based implementations of floating point math.
80-bit internal representation used by Intel FPU is not a problem for ALGLIB.
</p>

<a name='gs_compatibility_os' class='sheader'></a><h3>2.2.2 OS</h3>

<p>
ALGLIB for C++ (both open source and commercial versions) can be compiled in OS-agnostic mode (no OS-specific preprocessor definitions),
when it is compatible with any OS which supports C++98 standard library.
In particular, it will work under any POSIX-compatible OS and under Windows.
</p>

<p>
If you want to use multithreaded capabilities of <i>commercial</i> version of ALGLIB,
you should compile it in OS-specific mode by #defining either <code>AE_OS=AE_WINDOWS</code>
or <code>AE_OS=AE_POSIX</code> at compile time, depending on OS being used.
Former corresponds to any modern OS (32/64-bit Windows XP and later) from Windows family,
while latter means almost any POSIX-compatible OS.
It applies only to commercial version of ALGLIB.
Open source version is always OS-agnostic, even in the presence of OS-specific definitions.
</p>

<a name='gs_compatibility_compiler' class='sheader'></a><h3>2.2.3 Compiler</h3>

<p>
ALGLIB is compatible with any C++ compiler which:
</p>

<ul>
<li>supports 32-bit and 64-bit signed integer datatypes</li>
<li>emits code which handles <i>comparisons</i> with IEEE special values without raising exception.
We don't require that <code>x/0</code> will return <code>INF</code>.
But at least we must be able to <i>compare</i> double precision value with infinity or NAN without raising exception.</li>
</ul>

<p>
All modern compilers (in particular, reasonably new versions of MSVC, GCC and Sun Studio) satisfy these requirements.
</p>

<p>
However, some <i>very</i> old compilers (ten years old version of Borland C++ Builder, for example) may emit code which does not correctly work with IEEE special values.
If you use one of these old compilers, we recommend you to run ALGLIB test suite to ensure that library works.
</p>

<a name='gs_compatibility_opt' class='sheader'></a><h3>2.2.4 Optimization settings</h3>

<p>
ALGLIB is compatible with any kind of optimizing compiler as long as:
</p>

<ul>
<li><b>volatile</b> modifier is correctly handled (i.e. compiler does <b>not</b> optimize volatile reads/writes)</li>
<li>optimized code correctly handles IEEE special values</li>
</ul>

<p>
Generally, all kinds of optimization that were marked by compiler vendor as "safe" are possible. For example, ALGLIB can be compiled:
</p>

<ul>
<li>under MSVC: with /O1, /O2, /Og, /Os, /Ox, /Ot, /Oy, /fp:precise, /fp:except, /fp:strict</li>
<li>under GCC: with -O1, -O2, -O3, -Os</li>
</ul>

<p>
From the other side, following "unsafe" optimizations will break ALGLIB:
</p>

<ul>
<li>under MSVC:  /fp:fast</li>
<li>under GCC: -Ofast, -ffast-math</li>
</ul>

<a name='gs_compiling' class='sheader'></a><h2>2.3 Compiling ALGLIB</h2>

<a name='gs_attaching' class='sheader'></a><h3>2.3.1 Adding to your project</h3>

<p>
Adding ALGLIB to your project is easy - just pick packages you need and... add them to your project!
Under most used compilers (GCC, MSVC, Sun Studio) it will work without any additional settings.
In other cases you will need to define several preprocessor definitions (this topic will be detailed below), but everything will still be simple.
</p>

<p style='margin-left: 30px; font-size: 90%;'>
By "adding to your project" we mean that you should a) <i>compile</i> .cpp files with the rest of your project, and b) <i>include</i> .h files you need.
<u>Do not include .cpp files</u> - these files must be compiled separately, not as part of some larger source file.
The only files you should include are .h files, stored in the /src folder of the ALGLIB distribution.
</p>

<p>
As you see, ALGLIB has no project files or makefiles. Why? There are several reasons:
</p>

<ul>
<li>first, because many ALGLIB users don't need separate static library (which will be created by invoking makefile) - they prefer to integrate source code in their projects.
We have provided script-based build system before, but majority of our users prefer to build ALGLIB themselves.
</li>
<li>
second, because we want ALGLIB to be usable in any programming environment, whether it is Visual Studio, GNU build system or something else.
The best solution is to write package which doesn't depend on any particular programming environment.
</li>
</ul>

<p>
In any case, compiling ALGLIB is so simple that even without project file you can do it in several minutes.
</p>

<a name='gs_configuring' class='sheader'></a><h3>2.3.2 Configuring for your compiler</h3>

<p>
If you use modern versions of MSVC, GCC or Sun Studio, you don't need to configure ALGLIB at all.
But if you use outdated versions of these compilers (or something else), then you may need to tune definitions of several data types:
</p>

<ul>
<li><b>alglib_impl::ae_int32_t</b>&nbsp;-&nbsp;signed integer which is 32 bits wide</li>
<li><b>alglib_impl::ae_int64_t</b>&nbsp;-&nbsp;signed integer which is 64 bits wide</li>
<li><b>alglib_impl::ae_int_t</b>&nbsp;-&nbsp;signed integer which has same width as pointer</li>
</ul>

<p>
ALGLIB tries to autodetect your compiler and to define these types in compiler-specific manner:
</p>

<ul>
<li><code>ae_int32_t</code> is defined as <code>int</code>, because this type is 32 bits wide in all modern compilers.</li>
<li><code>ae_int64_t</code> is defined as <code>_int64</code> (MSVC) or as <code>signed long long</code> (GCC, Sun Studio).</li>
<li><code>ae_int_t</code> is defined as <code>ptrdiff_t</code>.</li>
</ul>

<p>
In most cases, it is enough. But if anything goes wrong, you have several options:
</p>

<ul>
<li>if your compiler provides <code>stdint.h</code>, you can define <code>AE_HAVE_STDINT</code> conditional symbol</li>
<li>alternatively, you can manually define <code>AE_INT32_T</code> and/or <code>AE_INT64_T</code> and/or <code>AE_INT_T</code> symbols.
Just assign datatype name to them, and ALGLIB will automatically use your definition. You can define only one or two types (those which are not defined automatically).</li>
</ul>


<a name='gs_configuring2' class='sheader'></a><h3>2.3.3 Improving performance (CPU-specific and OS-specific optimizations)</h3>

<p>
You can improve performance of ALGLIB in a several ways:
</p>

<ul>
<li>by compiling with advanced optimization turned on</li>
<li>by telling ALGLIB about CPU it will run on</li>
</ul>

<p>
ALGLIB has two-layered structure: some set of basic performance-critical primitives is implemented using optimized code,
and the rest of the library is built on top of these primitives.
By default, ALGLIB uses generic C code to implement these primitives (matrix multiplication, decompositions, etc.).
This code works everywhere from Intel to SPARC.
However, you can tell ALGLIB that it will work under particular architecture by defining appropriate macro at the global level:
</p>

<ul>
<li>defining <code>AE_CPU=AE_INTEL</code> - to tell ALGLIB that it will work under Intel</li>
</ul>

<p>
When <code>AE_CPU</code> macro is defined and equals to the <code>AE_INTEL</code>, it enables SSE2 support.
ALGLIB will use <code>cpuid</code> instruction to determine SSE2 presence at run-time and - in case we have SSE2 - to use SSE2-capable code.
ALGLIB uses SSE2 intrinsics which are portable across different compilers and efficient enough for most practical purposes. 
As of ALGLIB 3.4, SSE2 support is available for MSVC, GCC and Sun Studio users only.
</p>

<a name='gs_comm' class='sheader'></a><h2>2.4 Working with commercial version</h2>

<a name='gs_comm_benefits' class='sheader'></a><h3>2.4.1 Benefits of commercial version</h3>

<p>
Commercial version of ALGLIB for C++ features three important improvements over open source one:
</p>

<ul>
<li>
<b>License</b>.
Commercial license used by ALGLIB is friendly to closed source applications.
Unlike GPL, it does not require you to open source your application.
Thus, almost any commercial software developer is interested in obtaining commercial license.
</li>
<li>
<b>Low-level optimizations</b>.
Commercial version of ALGLIB includes SSE-optimized versions of many computationally intensive functions.
In particular, commercial version of neural networks outperforms open source one with 2-3x increase in speed -
even without multithreading!
It allows to increase performance on Intel/AMD platforms while still being able to use software under non-x86 CPU's.
</li>
<li>
<b>Multithreading</b>.
Commercial version of ALGLIB can utilize multicore capabilities of modern CPU's.
Large computational problems can be automatically split between different cores.
ALGLIB uses its own multithreading framework which <b>does not</b> depend on vendor/compiler support for technologies like OpenMP/MPI/...
It gives ALGLIB unprecedented portability across operating systems and compilers.
</li>
</ul>

<a name='gs_comm_sse' class='sheader'></a><h3>2.4.2 Working with SSE support (Intel/AMD users)</h3>

<p>
ALGLIB for C++ can utilize SSE2 set of instructions supported by all modern Intel and AMD x86 processors.
This feature is optional and must be explicitly turned on during compile-time.
If you do not activate it, ALGLIB will use generic C code, without <b>any</b> processor-specific assembly/intrinsics.
</p>

<p>
Thus, if you turn on this feature, your code will run faster on x86_32 and x86_64 processors,
but will be unportable to non-x86 platforms (<i>and Intel MIC platform, which is not exactly x86 and does not support SSE!</i>).
From the other side, if you do not activate this feature, your code will be portable to almost any modern CPU (SPARC, ARM, ...).
</p>

<p>
In order to turn on x86-specific optimizations,
you should define <code>AE_CPU=AE_INTEL</code> preprocessor definition at global level.
It will tell ALGLIB to use SSE intrinsics supported by GCC, MSVC and Intel compilers.
Additionally you should tell compiler to generate SSE-capable code.
It can be done in the project settings of your IDE or in the command line:
</p>

<pre class='p_code'>

<span style='color: navy; font-weight: bold;'>GCC example:</span>
> g++ <span style='color: red;'>-msse2</span> -I. <span style='color: red;'>-DAE_CPU=AE_INTEL</span> *.cpp -lm

<span style='color: navy; font-weight: bold;'>MSVC example:</span>
> cl /I. /EHsc <span style='color: red;'>/DAE_CPU=AE_INTEL</span> *.cpp

</pre>

<a name='gs_comm_smp' class='sheader'></a><h3>2.4.4 2.4.3 Using multithreading</h3>

<p>
Commercial version of ALGLIB includes out-of-the-box support for multithreading.
Many (<i>not all</i>) computationally intensive problems can be solved in multithreaded mode.
You should read comments on specific ALGLIB functions to determine what can be multithreaded and what can not.
</p>

<p>
ALGLIB <b>does not</b> depend on vendor/compiler support for technologies like OpenMP/MPI/...
Under Windows ALGLIB uses OS threads and custom synchronization framework.
Under POSIX-compatible OS (Solaris, Linux, FreeBSD, NetBSD, OpenBSD, ...) ALGLIB uses POSIX Threads
(<i>standard *nix library which is shipped with any POSIX system</i>)
with its threading and synchronization primitives.
It gives ALGLIB unprecedented portability across operating systems and compilers.
ALGLIB does not depend on presence of <b>any</b> custom multithreading library
or compiler support for <b>any</b> multithreading technology.
</p>

<p>
If you want to use multithreaded capabilities of ALGLIB, you should:
</p>

<ol>
<li>compile it in OS-specific mode (ALGLIB have to know what OS it is running on)</li>
<li>tell ALGLIB about number of worker threads to use</li>
<li>call multithreaded versions of computational functions</li>
</ol>

<p>
Let explain it in more details...
</p>

<p>
<b>1</b>.
You should compile ALGLIB in OS-specific mode by #defining either
<code>AE_OS=AE_WINDOWS</code> or <code>AE_OS=AE_POSIX</code> at compile time, depending on OS being used.
Former corresponds to any modern OS (32/64-bit Windows XP and later) from Windows family,
while latter means almost any POSIX-compatible OS.
When compiling on POSIX, do not forget to link ALGLIB with <code>libpthread</code> library.
</p>

<p>
<b>2</b>.
ALGLIB automatically determines number of cores on application startup.
On Windows it is done using <code>GetSystemInfo()</code> call.
On POSIX systems ALGLIB performs <code>sysconf(_SC_NPROCESSORS_ONLN)</code> system call.
This system call is supported by all modern POSIX-compatible systems: Solaris, Linux, FreeBSD, NetBSD, OpenBSD.
</p>

<p>
By default, ALGLIB uses all available cores except for one.
Say, on 4-core system it will use three cores - unless being told to use more or less.
It will keep your system responsive during lengthy computations.
Such behavior may be changed with <code>setnworkers()</code> call:
</p>

<ul>
<li><code>alglib::setnworkers(0)</code>  = use all cores</li>
<li><code>alglib::setnworkers(-1)</code> = leave one core unused</li>
<li><code>alglib::setnworkers(-2)</code> = leave two cores unused</li>
<li><code>alglib::setnworkers(+2)</code> = use 2 cores (even if you have more)</li>
</ul>

<p>
You may want to specify maximum number of worker threads during compile time
by means of preprocessor definition <code>AE_NWORKERS=N</code>.
You can add this definition to compiler command line or change corresponding project settings in your IDE.
Here N can be any positive number.
ALGLIB will use exactly N worker threads, unless being told to use less by <code>setnworkers()</code> call.
</p>

<p class='p_note'>
Some old POSIX-compatible operating systems do not support <code>sysconf(_SC_NPROCESSORS_ONLN)</code> system call
which is required in order to automatically determine number of active cores.
On these systems you should specify number of cores manually at compile time.
Without it ALGLIB will run in single-threaded mode.
</p>

<p>
<b>3</b>.
When you use commercial edition of ALGLIB,
you may choose between serial and multithreaded versions of SMP-capable functions:
</p>
<ul>
<li>serial version works as usual, in the context of the calling thread</li>
<li>multithreaded version (with <code>smp_</code> prefix in its name) creates (or wakes up) worker threads,
inserts task in the worker queue, and waits for completion of the task.
All processing is done in context of worker thread(s).</li>
</ul>
<p>
You should carefully decide what version of function to use.
Starting/stopping worker thread costs tens of thousands of CPU cycles.
Thus you won't get multithreading speedup on small computational problems.
</p>

<a name='gs_comm_smp' class='sheader'></a><h3>2.4.4 2.4.3 SMT (CMT/hyper-threading) issues</h3>

<p>
<i>Simultaneous multithreading (SMT)</i> also known as <i>Hyper-threading</i> (Intel)
and <i>Cluster-based Multithreading</i> (AMD)
is a CPU design where several (usually two) <i>logical</i> cores share resources of one <i>physical</i> core.
Say, on dual-core system with 2x HT scale factor you will see 4 logical cores.
Each pair of these 4 cores, however, share same hardware resources.
Thus, you may get only marginal speedup when running highly optimized software which fully utilizes CPU resources.
</p>

<p>
Say, if one thread occupies floating-point unit,
another thread on the same physical core may work with integer numbers at the same time without any performance penalties.
In this case you may get some speedup due to having additional cores.
But if both threads keep FPU unit 100% busy, they won't get <i>any</i> multithreaded speedup.
</p>

<p>
So, if 2 math-intensive threads are dispatched by OS scheduler to different physical cores,
you will get 2x speedup due to use of multithreading.
But if these threads are dispatched to different logical cores - but same physical core - you won't get any speedup at all!
One physical core will be 100% busy, and another one will be 100% idle.
From the other side, if you start four threads instead of two, your system will be 100% utilized independently of thread scheduling details.
</p>

<p>
Let we stress it one more time - multithreading speedup on SMT systems is highly dependent on number of threads you are running and decisions made by OS scheduler.
<b>It is not 100% deterministic!</b>
With "true SMP" when you run 2 threads, you get 2x speedup (or 1.95, or 1.80 - it depends on algorithm, but this factor is always same).
With SMT when you run 2 threads you may get your 2x speedup - or no speedup at all.
Modern OS schedulers do a good job on single-socket hardware,
but even in this "simple" case they give no guarantees of fair distribution of hardware resources.
And things become a bit tricky when you work with multi-socket hardware.
<b>On SMT systems the only guaranteed way to 100% utilize your CPU is to create as many worker threads as there are logical cores</b>.
In this case OS scheduler has no chance to make its work in a wrong way.
</p>

<a name='gs_using' class='sheader'></a><h2>2.5 Using ALGLIB</h2>

<a name='gs_using_threadsafety' class='sheader'></a><h3>2.5.1 Thread-safety</h3>

<p>
Both open source and commercial versions of ALGLIB are 100% thread-safe
<b>as long as different user threads work with different instances of objects/arrays</b>.
Thread-safety is guaranteed by having no global shared variables.
</p>

<p>
However, <b>any kind</b> of sharing ALGLIB objects/arrays between different threads is potentially hazardous.
Even when this object is <b>seemingly</b> used in read-only mode!
</p>

<p class='p_note'>
Say, you use ALGLIB neural network <i>NET</i> to process two input vectors <i>X0</i> and <i>X1</i>,
and get two output vectors <i>Y0</i> and <i>Y1</i>.
You may decide that neural network is used in read-only mode which does not change state of <i>NET</i>,
because output is written to distinct arrays <i>Y</i>.
Thus, you may want to process these vectors from parallel threads.
<br><br>
But it is <b>not</b> read-only operation, even if it looks like this!
Neural network object <i>NET</i> allocates internal temporary buffers, which are modified by neural processing functions.
Thus, sharing one instance of neural network between two threads is thread-unsafe!
</p>

<a name='gs_global' class='sheader'></a><h3>2.5.2 Global definitions</h3>

<p>
ALGLIB defines several conditional symbols (all start with "AE_" which means "<b>A</b>LGLIB <b>e</b>nvironment") and two namespaces:
<code>alglib_impl</code> (contains computational core) and <code>alglib</code> (contains C++ interface).
</p>

<p>
Although this manual mentions both <code>alglib_impl</code> and <code>alglib</code> namespaces, only <code>alglib</code> namespace should be used by you.
It contains user-friendly C++ interface with automatic memory management, exception handling and all other nice features.
<code>alglib_impl</code> is less user-friendly, is less documented, and it is too easy to crash your system or cause memory leak if you use it directly.
</p>

<a name='gs_datatypes' class='sheader'></a><h3>2.5.3 Datatypes</h3>

<p>
ALGLIB (<code>ap.h</code> header) defines several "basic" datatypes (types which are used by all packages) and many package-specific datatypes. "Basic" datatypes are:
</p>

<ul>
<li><code>alglib::ae_int_t</code>&nbsp;-&nbsp;signed integer type used by library</li>
<li><code>alglib::complex</code>&nbsp;-&nbsp;double precision complex datatype, safer replacement for <code>std::complex</code></li>
<li><code>alglib::ap_error</code>&nbsp;-&nbsp;exception which is thrown by library</li>
<li><code>boolean_1d_array</code>&nbsp;-&nbsp;1-dimensional boolean array</li>
<li><code>integer_1d_array</code>&nbsp;-&nbsp;1-dimensional integer array</li>
<li><code>real_1d_array</code>&nbsp;-&nbsp;1-dimensional real (double precision) array</li>
<li><code>complex_1d_array</code>&nbsp;-&nbsp;1-dimensional complex array</li>
<li><code>boolean_2d_array</code>&nbsp;-&nbsp;2-dimensional boolean array</li>
<li><code>integer_2d_array</code>&nbsp;-&nbsp;2-dimensional integer array</li>
<li><code>real_2d_array</code>&nbsp;-&nbsp;2-dimensional real (double precision) array</li>
<li><code>complex_2d_array</code>&nbsp;-&nbsp;2-dimensional complex array</li>
</ul>

<p>
Package-specific datatypes are classes which can be divided into two distinct groups:
</p>

<ul>
<li>"struct-like" classes with public fields which you can access directly.</li>
<li>"object-like" classes which have no public fields. You should use ALGLIB functions to work with them.</li>
</ul>

<a name='gs_constants' class='sheader'></a><h3>2.5.4 Constants</h3>

<p>
The most important constants (defined in the <code>ap.h</code> header) from ALGLIB namespace are:
</p>

<ul>
<li><code>alglib::machineepsilon</code>&nbsp;-&nbsp;small number which is <i>close</i> to the double precision &eps;, but is slightly larger</li>
<li><code>alglib::maxrealnumber</code>&nbsp;-&nbsp;very large number which is <i>close</i> to the maximum real number, but is slightly smaller </li>
<li><code>alglib::minrealnumber</code>&nbsp;-&nbsp;very small number which is <i>close</i> to the minimum nonzero real number, but is slightly larger</li>
<li><code>alglib::fp_nan</code>&nbsp;-&nbsp;NAN (non-signalling under most platforms except for PA-RISC, where it is signalling;
but when PA-RISC CPU is in its default state, it is silently converted to the quiet NAN)</li>
<li><code>alglib::fp_posinf</code>&nbsp;-&nbsp;positive infinity</li>
<li><code>alglib::fp_neginf</code>&nbsp;-&nbsp;negative infinity</li>
</ul>

<a name='gs_stdfunctions' class='sheader'></a><h3>2.5.5 Functions</h3>

<p>
The most important "basic" functions from ALGLIB namespace (<code>ap.h</code> header) are:
</p>

<ul>
<li><code>alglib::randomreal()</code>&nbsp;-&nbsp;returns random real number from [0,1)</li>
<li><code>alglib::randominteger(mx)</code>&nbsp;-&nbsp;returns random integer number from [0,nx); <i>mx</i> must be less than RAND_MAX</li>
<li><code>alglib::fp_eq(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.
If numbers are represented with greater precision than specified by IEEE 754 (as with Intel 80-bit FPU), this functions converts them to 64 bits before comparing.</li>
<li><code>alglib::fp_neq(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.</li>
<li><code>alglib::fp_less(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.</li>
<li><code>alglib::fp_less_eq(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.</li>
<li><code>alglib::fp_greater(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.</li>
<li><code>alglib::fp_greater_eq(v1,v2)</code>&nbsp;-&nbsp;makes IEEE-compliant comparison of two double precision numbers.</li>
<li><code>alglib::fp_isnan</code>&nbsp;-&nbsp;checks whether number is NAN</li>
<li><code>alglib::fp_isposinf</code>&nbsp;-&nbsp;checks whether number is +INF</li>
<li><code>alglib::fp_isneginf</code>&nbsp;-&nbsp;checks whether number is -INF</li>
<li><code>alglib::fp_isinf</code>&nbsp;-&nbsp;checks whether number is +INF or -INF</li>
<li><code>alglib::fp_isfinite</code>&nbsp;-&nbsp;checks whether number is finite value (possibly subnormalized)</li>
</ul>

<a name='gs_vecmat' class='sheader'></a><h3>2.5.6 Working with vectors and matrices</h3>

<p>
ALGLIB (<code>ap.h</code> header) supports matrixes and vectors (one-dimensional and two-dimensional arrays) of variable size, with numeration starting from zero.
</p>

<p>
Everything starts from array creation.
You should distinguish the creation of array class instance and the memory allocation for the array.
When creating the class instance, you can use constructor without any parameters, that creates an empty array without any elements.
An attempt to address them may cause the program failure.
</p>

<p>
You can use copy and assignment constructors that copy one array into another.
If, during the copy operation, the source array has no memory allocated for the array elements, destination array will contain no elements either.
If the source array has memory allocated for its elements, destination array will allocate the same amount of memory and copy the elements there.
That is, the copy operation yields into two independent arrays with indentical contents.
</p>

<p>
You can also create array from formatted string like
    <span class='s_str'>"[]"</span>,
    <span class='s_str'>"[true,FALSE,tRUe]"</span>,
    <span class='s_str'>"[[]]]"</span> or
    <span class='s_str'>"[[1,2],[3.2,4],[5.2]]"</span> (note: <span class='s_str'>'.'</span> is used as decimal point independently from locale settings).
</p>

<pre class='p_example'>
alglib::boolean_1d_array b1;
b1 = <span class='s_str'>"[true]"</span>;

alglib::real_2d_array r2(<span class='s_str'>"[[2,3],[3,4]]"</span>);
alglib::real_2d_array r2_1(<span class='s_str'>"[[]]"</span>);
alglib::real_2d_array r2_2(r2);
r2_1 = r2;

alglib::complex_1d_array c2;
c2 = <span class='s_str'>"[]"</span>;
c2 = <span class='s_str'>"[0]"</span>;
c2 = <span class='s_str'>"[1,2i]"</span>;
c2 = <span class='s_str'>"[+1-2i,-1+5i]"</span>;
c2 = <span class='s_str'>"[ 4i-2,  8i+2]"</span>;
c2 = <span class='s_str'>"[+4i-2, +8i+2]"</span>;
c2 = <span class='s_str'>"[-4i-2, -8i+2]"</span>;
</pre>

<p>
After an empty array has been created, you can allocate memory for its elements, using the <code>setlength()</code> method.
The content of the created array elements is not defined.
If the <code>setlength</code> method is called for the array with already allocated memory, then, after changing its parameters,
the newly allocated elements also become undefined and the old content is destroyed.
</p>

<pre class='p_example'>
alglib::boolean_1d_array b1;
b1.setlength(2);

alglib::integer_2d_array r2;
r2.setlength(4,3);
</pre>

<p>
Another way to initialize array is to call <code>setcontent()</code> method.
This method accepts pointer to data which are copied into newly allocated array.
Vectors are stored in contiguous order, matrices are stored row by row.
</p>

<pre class='p_example'>
alglib::real_1d_array r1;
double _r1[] = {2, 3};
r1.setcontent(2,_r1);

alglib::real_2d_array r2;
double _r2[] = {11, 12, 13, 21, 22, 23};
r2.setcontent(2,3,_r2);
</pre>

<p>
To access the array elements, an overloaded <code>operator()</code> or <code>operator[]</code> can used.
That is, the code addressing the element of array <code>a</code> with indexes <code>[i,j]</code> can look like <code>a(i,j)</code> or <code>a[i][j]</code>. 
</p>

<pre class='p_example'>
alglib::integer_1d_array a(<span class='s_str'>"[1,2,3]"</span>);
alglib::integer_1d_array b(<span class='s_str'>"[3,9,27]"</span>);
a[0] = b(0);

alglib::integer_2d_array c(<span class='s_str'>"[[1,2,3],[9,9,9]]"</span>);
alglib::integer_2d_array d(<span class='s_str'>"[[3,9,27],[8,8,8]]"</span>);
d[1][1] = c(0,0);
</pre>

<p>
You can access contents of 1-dimensional array by calling <code>getcontent()</code> method which returns pointer to the array memory.
For historical reasons 2-dimensional arrays do not provide <code>getcontent()</code> method, but you can use create reference to any element of array.
2-dimensional arrays store data in row-major order with aligned rows (i.e. generally distance between rows is not equal to number of columns).
You can get stride (distance between consequtive elements in different rows) with <code>getstride()</code> call.
</p>

<pre class='p_example'>
alglib::integer_1d_array a(<span class='s_str'>"[1,2]"</span>);
alglib::real_2d_array b(<span class='s_str'>"[[0,1],[10,11]]"</span>);

alglib::ae_int_t *a_row = a.getcontent();

<span class='s_comment'>// all three pointers point to the same location</span>
double *b_row0 = &amp;b[0][0];
double *b_row0_2 = &amp;b(0,0);
double *b_row0_3 = b[0];

<span class='s_comment'>// advancing to the next row of 2-dimensional array</span>
double *b_row1 = b_row0 + b.getstride();
</pre>

<p>
Finally, you can get array size with <code>length()</code>, <code>rows()</code> or <code>cols()</code> methods:
</p>

<pre class='p_example'>
alglib::integer_1d_array a(<span class='s_str'>"[1,2]"</span>);
alglib::real_2d_array b(<span class='s_str'>"[[0,1],[10,11]]"</span>);

printf(<span class='s_str'>"%ld\n"</span>, (long)a.length());
printf(<span class='s_str'>"%ld\n"</span>, (long)b.rows());
printf(<span class='s_str'>"%ld\n"</span>, (long)b.cols());
</pre>

<a name='gs_functions' class='sheader'></a><h3>2.5.7 Using functions: 'expert' and 'friendly' interfaces</h3>

<p>
Most ALGLIB functions provide two interfaces: 'expert' and 'friendly'. What is the difference between two? When you use 'friendly' interface, ALGLIB:
</p>

<ul>
<li>tries to automatically determine size of input arguments</li>
<li>throws an exception when arguments have inconsistent size (for example, square matrix is expected, but non-square is passed;
another example - two parameters must have same size, but have different size)</li>
<li>if semantics of input parameter assumes that it is symmetric/Hermitian matrix,
checks that lower triangle is equal to upper triangle (conjugate of upper triangle) and throws an exception otherwise</li>
<li>if semantics of output parameter assumes that it is symmetric/Hermitian matrix,
returns full matrix (both upper and lower triangles)</li>
</ul>

<p>
When you use 'expert' interface, ALGLIB:
</p>

<ul>
<li>requires caller to explicitly specify size of input arguments.
If vector/matrix is larger than size being specified (say, N), only N leading elements are used</li>
<li>if semantics of input parameter assumes that it is symmetric/Hermitian matrix,
uses <i>only upper or lower triangle</i> of input matrix and requires caller <i>to specify what triangle to use</i></li>
<li>if semantics of output parameter assumes that it is symmetric/Hermitian matrix, returns only upper or lower triangle
(when you look at specific function, it is clear what triangle is returned)</li>
</ul>

<p>
Here are several examples of 'friendly' and 'expert' interfaces:
</p>

<pre class='p_example'>
<span class='s_preprocessor'>#include "interpolation.h"</span>

<span style='color: gray;'>...</span>

alglib::real_1d_array    x(<span class='s_str'>"[0,1,2,3]"</span>);
alglib::real_1d_array    y(<span class='s_str'>"[1,5,3,9]"</span>);
alglib::real_1d_array   y2(<span class='s_str'>"[1,5,3,9,0]"</span>);
alglib::spline1dinterpolant s;

alglib::spline1dbuildlinear(x, y, 4, s);  <span class='s_comment'>// 'expert' interface is used</span>
alglib::spline1dbuildlinear(x, y, s);     <span class='s_comment'>// 'friendly' interface - input size is</span>
                                          <span class='s_comment'>// automatically determined</span>

alglib::spline1dbuildlinear(x, y2, 4, s); <span class='s_comment'>// y2.length() is 5, but it will work</span>

alglib::spline1dbuildlinear(x, y2, s);    <span class='s_comment'>// it won't work because sizes of x and y2</span>
                                          <span class='s_comment'>// are inconsistent</span>
</pre>

<p>
'Friendly' interface - matrix semantics:
</p>

<pre class='p_example'>
<span class='s_preprocessor'>#include "linalg.h"</span>

<span style='color: gray;'>...</span>

alglib::real_2d_array a;
alglib::matinvreport  rep;
alglib::ae_int_t      info;

<span class='s_comment'>// </span>
<span class='s_comment'>// 'Friendly' interface: spdmatrixinverse() accepts and returns symmetric matrix</span>
<span class='s_comment'>// </span>

<span class='s_comment'>// symmetric positive definite matrix</span>
a = <span class='s_str'>"[[2,1],[1,2]]"</span>;

<span class='s_comment'>// after this line A will contain [[0.66,-0.33],[-0.33,0.66]]</span>
<span class='s_comment'>// which is symmetric too</span>
alglib::spdmatrixinverse(a, info, rep); 

<span class='s_comment'>// you may try to pass nonsymmetric matrix</span>
a = <span class='s_str'>"[[2,1],[0,2]]"</span>;

<span class='s_comment'>// but exception will be thrown in such case</span>
alglib::spdmatrixinverse(a, info, rep); 
</pre>

<p>
Same function but with 'expert' interface:
</p>

<pre class='p_example'>
<span class='s_preprocessor'>#include "linalg.h"</span>

<span style='color: gray;'>...</span>

alglib::real_2d_array a;
alglib::matinvreport  rep;
alglib::ae_int_t      info;

<span class='s_comment'>// </span>
<span class='s_comment'>// 'Expert' interface, spdmatrixinverse()</span>
<span class='s_comment'>// </span>

<span class='s_comment'>// only upper triangle is used; a[1][0] is initialized by NAN,</span>
<span class='s_comment'>// but it can be arbitrary number</span>
a = <span class='s_str'>"[[2,1],[NAN,2]]"</span>;

<span class='s_comment'>// after this line A will contain [[0.66,-0.33],[NAN,0.66]]</span>
<span class='s_comment'>// only upper triangle is modified</span>
alglib::spdmatrixinverse(a, 2 <span class='s_comment'>/* N */</span>, true <span class='s_comment'>/* upper triangle is used */</span>, info, rep); 
</pre>


<a name='gs_errors' class='sheader'></a><h3>2.5.8 Handling errors</h3>

<p>
ALGLIB uses two error handling strategies:
</p>

<ul>
<li>returning error code</li>
<li>throwing exception</li>
</ul>

<p>
What is actually done depends on function being used and error being reported:
</p>

<ol>
<li>if function returns some error code <b>and</b> has corresponding value for this kind of error, ALLGIB returns error code</li>
<li>if function does not return error code (or returns error code, but there is no code for error being reported), ALGLIB throws <code>alglib::ap_error</code> exception.
Exception object has <code>msg</code> parameter which contains short description of error.</li>
</ol>

<p>
To make things clear we consider several examples of error handling.
</p>

<p>
<u>Example 1</u>. <a href="#sub_mincgcreate">mincgreate</a> function creates nonlinear CG optimizer. It accepts problem size <code>N</code> and initial point <code>X</code>.
Several things can go wrong - you may pass array which is too short, filled by NAN's, or otherwise pass incorrect data.
However, this function returns no error code - so it throws an exception in case something goes wrong.
There is no other way to tell caller that something went wrong.
</p>

<p>
<u>Example 2</u>. <a href="#sub_rmatrixinverse">rmatrixinverse</a> function calculates inverse matrix.
It returns error code, which is set to <code>+1</code> when problem is solved and is set to <code>-3</code> if singular matrix was passed to the function.
However, there is no error code for matrix which is non-square or contains infinities.
Well, we could have created corresponding error codes - but we didn't.
So if you pass singular matrix to <code>rmatrixinverse</code>, you will get completion code <code>-3</code>.
But if you pass matrix which contains INF in one of its elements, <code>alglib::ap_error</code> will be thrown.
</p>

<p>
First error handling strategy (error codes) is used to report "frequent" errors, which can occur during normal execution of user program.
Second error handling strategy (exceptions) is used to report "rare" errors which are result of serious flaws in your program (or ALGLIB) - 
infinities/NAN's in the inputs, inconsistent inputs, etc.
</p>


<a name='gs_blas' class='sheader'></a><h3>2.5.9 Working with Level 1 BLAS functions</h3>

<p>
ALGLIB (<code>ap.h</code> header) includes following Level 1 BLAS functions:
</p>

<ul>
<li><code>alglib::vdotproduct()</code> family, which allows to calculate dot product of two real or complex vectors</li>
<li><code>alglib::vmove()</code> family, which allows to copy real/complex vector to another location with optimal multiplication by real/complex value</li>
<li><code>alglib::vmoveneg()</code> family, which allows to copy real/complex vector to another location with multiplication by -1</li>
<li><code>alglib::vadd()</code> and <code>alglib::vsub()</code> families, which allows to add or subtract two real/complex vectors with optimal multiplication by real/complex value</li>
<li><code>alglib::vmul()</code> family, which implements in-place multiplication of real/complex vector by real/complex value</li>
</ul>

<p>
Each Level 1 BLAS function accepts input stride and output stride, which are expected to be positive.
Input and output vectors should not overlap.
Functions operating with complex vectors accept additional parameter <code>conj_src</code>, which specifies whether input vector is conjugated or not.
</p>

<p>
For each real/complex function there exists "simple" companion which accepts no stride or conjugation modifier.
"Simple" function assumes that input/output stride is +1, and no input conjugation is required.
</p>

<pre class='p_example'>
alglib::real_1d_array    rvec(<span class='s_str'>"[0,1,2,3]"</span>);
alglib::real_2d_array    rmat(<span class='s_str'>"[[1,2],[3,4]]"</span>);
alglib::complex_1d_array cvec(<span class='s_str'>"[0+1i,1+2i,2-1i,3-2i]"</span>);
alglib::complex_2d_array cmat(<span class='s_str'>"[[3i,1],[9,2i]]"</span>);

alglib::vmove(&amp;rvec[0],  1, &amp;rmat[0][0], rmat.getstride(), 2); // now rvec is [1,3,2,3]

alglib::vmove(&amp;cvec[0],  1, &amp;cmat[0][0], rmat.getstride(), "No conj", 2); // now cvec is [3i, 9, 2-1i, 3-2i]
alglib::vmove(&amp;cvec[2],  1, &amp;cmat[0][0], 1,                "Conj", 2);    // now cvec is [3i, 9, -3i,  1]
</pre>

<p>
Here is full list of Level 1 BLAS functions implemented in ALGLIB:
</p>

<pre>
<b>double</b> vdotproduct(
    <b>const</b> <b>double</b> *v0,
     ae_int_t stride0,
     <b>const</b> <b>double</b> *v1,
     ae_int_t stride1,
     ae_int_t n);
<b>double</b> vdotproduct(
    <b>const</b> <b>double</b> *v1,
     <b>const</b> <b>double</b> *v2,
     ae_int_t N);

alglib::complex vdotproduct(
    <b>const</b> alglib::complex *v0,
     ae_int_t stride0,
     <b>const</b> char *conj0,
     <b>const</b> alglib::complex *v1,
     ae_int_t stride1,
     <b>const</b> char *conj1,
     ae_int_t n);
alglib::complex vdotproduct(
    <b>const</b> alglib::complex *v1,
     <b>const</b> alglib::complex *v2,
     ae_int_t N);

<b>void</b> vmove(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b>* vsrc,
      ae_int_t stride_src,
     ae_int_t n);
<b>void</b> vmove(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b>* vsrc,
     ae_int_t N);

<b>void</b> vmove(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex* vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n);
<b>void</b> vmove(
    alglib::complex *vdst,
     <b>const</b> alglib::complex* vsrc,
     ae_int_t N);

<b>void</b> vmoveneg(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b>* vsrc,
      ae_int_t stride_src,
     ae_int_t n);
<b>void</b> vmoveneg(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N);

<b>void</b> vmoveneg(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex* vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n);
<b>void</b> vmoveneg(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N);

<b>void</b> vmove(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b>* vsrc,
      ae_int_t stride_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vmove(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vmove(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex* vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vmove(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vmove(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex* vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     alglib::complex alpha);
<b>void</b> vmove(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     alglib::complex alpha);

<b>void</b> vadd(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b> *vsrc,
      ae_int_t stride_src,
     ae_int_t n);
<b>void</b> vadd(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N);

<b>void</b> vadd(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n);
<b>void</b> vadd(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N);

<b>void</b> vadd(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b> *vsrc,
      ae_int_t stride_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vadd(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vadd(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vadd(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vadd(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     alglib::complex alpha);
<b>void</b> vadd(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     alglib::complex alpha);

<b>void</b> vsub(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b> *vsrc,
      ae_int_t stride_src,
     ae_int_t n);
<b>void</b> vsub(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N);

<b>void</b> vsub(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n);
<b>void</b> vsub(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N);

<b>void</b> vsub(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     <b>const</b> <b>double</b> *vsrc,
      ae_int_t stride_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vsub(
    <b>double</b> *vdst,
     <b>const</b> <b>double</b> *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vsub(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vsub(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vsub(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t stride_src,
     <b>const</b> char *conj_src,
     ae_int_t n,
     alglib::complex alpha);
<b>void</b> vsub(
    alglib::complex *vdst,
     <b>const</b> alglib::complex *vsrc,
     ae_int_t N,
     alglib::complex alpha);

<b>void</b> vmul(
    <b>double</b> *vdst,
      ae_int_t stride_dst,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vmul(
    <b>double</b> *vdst,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vmul(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     ae_int_t n,
     <b>double</b> alpha);
<b>void</b> vmul(
    alglib::complex *vdst,
     ae_int_t N,
     <b>double</b> alpha);

<b>void</b> vmul(
    alglib::complex *vdst,
     ae_int_t stride_dst,
     ae_int_t n,
     alglib::complex alpha);
<b>void</b> vmul(
    alglib::complex *vdst,
     ae_int_t N,
     alglib::complex alpha);
</pre>

<a name='gs_advanced' class='sheader'></a><h2>2.6 Advanced topics</h2>

<a name='gs_testing' class='sheader'></a><h3>2.6.1 Testing ALGLIB</h3>

<p>
There are two test suites in ALGLIB: computational tests and interface tests.
Computational tests are located in <code>/tests/test_c.cpp</code>.
They are focused on numerical properties of algorithms, stress testing and "deep" tests (large automatically generated problems).
They require significant amount of time to finish (tens of minutes).
</p>

<p>
Interface tests are located in <code>/tests/test_i.cpp</code>.
These tests are focused on ability to correctly pass data between computational core and caller, ability to detect simple problems in inputs,
and on ability to at least compile ALGLIB with your compiler.
They are very fast (about a minute to finish including compilation time).
</p>

<p>
Running test suite is easy - just
</p>

<ol>
<li>compile one of these files (<code>test_c.cpp</code> or <code>test_i.cpp</code>) along with the rest of the library</li>
<li>launch executable you will get. It may take from several seconds (interface tests) to several minutes (computational tests) to get final results</li>
</ol>

<p>
If you want to be sure that ALGLIB will work with some sophisticated optimization settings, set corresponding flags during compile time.
If your compiler/system are not in the list of supported ones, we recommend you to run both test suites. But if you are running out of time, run at least <code>test_i.cpp</code>.
</p>



</div>
<a name='alglib_main' class='sheader'></a><h1>3 ALGLIB reference manual</h1>
<a name='alglib_packages'></a><h2>Packages and subpackages</h2>
<table border=0 cellspacing=0>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>AlglibMisc</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_hqrnd' class=toc>hqrnd</a></td><td width=15>&nbsp;</td><td>High quality random numbers generator</td></tr>
<tr align=left valign=top><td><a href='#unit_nearestneighbor' class=toc>nearestneighbor</a></td><td width=15>&nbsp;</td><td>Nearest neighbor search: approximate and exact</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>DataAnalysis</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_bdss' class=toc>bdss</a></td><td width=15>&nbsp;</td><td>Basic dataset functions</td></tr>
<tr align=left valign=top><td><a href='#unit_clustering' class=toc>clustering</a></td><td width=15>&nbsp;</td><td>Clustering functions (hierarchical, k-means++)</td></tr>
<tr align=left valign=top><td><a href='#unit_datacomp' class=toc>datacomp</a></td><td width=15>&nbsp;</td><td>Backward compatibility functions</td></tr>
<tr align=left valign=top><td><a href='#unit_dforest' class=toc>dforest</a></td><td width=15>&nbsp;</td><td>Decision forest classifier (regression model)</td></tr>
<tr align=left valign=top><td><a href='#unit_filters' class=toc>filters</a></td><td width=15>&nbsp;</td><td>Different filters used in data analysis</td></tr>
<tr align=left valign=top><td><a href='#unit_lda' class=toc>lda</a></td><td width=15>&nbsp;</td><td>Linear discriminant analysis</td></tr>
<tr align=left valign=top><td><a href='#unit_linreg' class=toc>linreg</a></td><td width=15>&nbsp;</td><td>Linear models</td></tr>
<tr align=left valign=top><td><a href='#unit_logit' class=toc>logit</a></td><td width=15>&nbsp;</td><td>Logit models</td></tr>
<tr align=left valign=top><td><a href='#unit_mcpd' class=toc>mcpd</a></td><td width=15>&nbsp;</td><td>Markov Chains for Population/proportional Data</td></tr>
<tr align=left valign=top><td><a href='#unit_mlpbase' class=toc>mlpbase</a></td><td width=15>&nbsp;</td><td>Basic functions for neural networks</td></tr>
<tr align=left valign=top><td><a href='#unit_mlpe' class=toc>mlpe</a></td><td width=15>&nbsp;</td><td>Basic functions for neural ensemble models</td></tr>
<tr align=left valign=top><td><a href='#unit_mlptrain' class=toc>mlptrain</a></td><td width=15>&nbsp;</td><td>Neural network training</td></tr>
<tr align=left valign=top><td><a href='#unit_pca' class=toc>pca</a></td><td width=15>&nbsp;</td><td>Principal component analysis</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>DiffEquations</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_odesolver' class=toc>odesolver</a></td><td width=15>&nbsp;</td><td>Ordinary differential equation solver</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>FastTransforms</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_conv' class=toc>conv</a></td><td width=15>&nbsp;</td><td>Fast real/complex convolution</td></tr>
<tr align=left valign=top><td><a href='#unit_corr' class=toc>corr</a></td><td width=15>&nbsp;</td><td>Fast real/complex cross-correlation</td></tr>
<tr align=left valign=top><td><a href='#unit_fft' class=toc>fft</a></td><td width=15>&nbsp;</td><td>Real/complex FFT</td></tr>
<tr align=left valign=top><td><a href='#unit_fht' class=toc>fht</a></td><td width=15>&nbsp;</td><td>Real Fast Hartley Transform</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>Integration</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_autogk' class=toc>autogk</a></td><td width=15>&nbsp;</td><td>Adaptive 1-dimensional integration</td></tr>
<tr align=left valign=top><td><a href='#unit_gkq' class=toc>gkq</a></td><td width=15>&nbsp;</td><td>Gauss-Kronrod quadrature generator</td></tr>
<tr align=left valign=top><td><a href='#unit_gq' class=toc>gq</a></td><td width=15>&nbsp;</td><td>Gaussian quadrature generator</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>Interpolation</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_idwint' class=toc>idwint</a></td><td width=15>&nbsp;</td><td>Inverse distance weighting: interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_lsfit' class=toc>lsfit</a></td><td width=15>&nbsp;</td><td>Linear and nonlinear least-squares solvers</td></tr>
<tr align=left valign=top><td><a href='#unit_polint' class=toc>polint</a></td><td width=15>&nbsp;</td><td>Polynomial interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_pspline' class=toc>pspline</a></td><td width=15>&nbsp;</td><td>Parametric spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#unit_ratint' class=toc>ratint</a></td><td width=15>&nbsp;</td><td>Rational interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_rbf' class=toc>rbf</a></td><td width=15>&nbsp;</td><td>Scattered 2/3-dimensional interpolation with RBF models</td></tr>
<tr align=left valign=top><td><a href='#unit_spline1d' class=toc>spline1d</a></td><td width=15>&nbsp;</td><td>1D spline interpolation/fitting</td></tr>
<tr align=left valign=top><td><a href='#unit_spline2d' class=toc>spline2d</a></td><td width=15>&nbsp;</td><td>2D spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#unit_spline3d' class=toc>spline3d</a></td><td width=15>&nbsp;</td><td>3D spline interpolation</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>LinAlg</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_ablas' class=toc>ablas</a></td><td width=15>&nbsp;</td><td>Level 2 and Level 3 BLAS operations</td></tr>
<tr align=left valign=top><td><a href='#unit_bdsvd' class=toc>bdsvd</a></td><td width=15>&nbsp;</td><td>Bidiagonal SVD</td></tr>
<tr align=left valign=top><td><a href='#unit_evd' class=toc>evd</a></td><td width=15>&nbsp;</td><td>Eigensolvers</td></tr>
<tr align=left valign=top><td><a href='#unit_inverseupdate' class=toc>inverseupdate</a></td><td width=15>&nbsp;</td><td>Sherman-Morrison update of the inverse matrix</td></tr>
<tr align=left valign=top><td><a href='#unit_matdet' class=toc>matdet</a></td><td width=15>&nbsp;</td><td>Determinant calculation</td></tr>
<tr align=left valign=top><td><a href='#unit_matgen' class=toc>matgen</a></td><td width=15>&nbsp;</td><td>Random matrix generation</td></tr>
<tr align=left valign=top><td><a href='#unit_matinv' class=toc>matinv</a></td><td width=15>&nbsp;</td><td>Matrix inverse</td></tr>
<tr align=left valign=top><td><a href='#unit_normestimator' class=toc>normestimator</a></td><td width=15>&nbsp;</td><td>Estimates norm of the sparse matrix (from below)</td></tr>
<tr align=left valign=top><td><a href='#unit_ortfac' class=toc>ortfac</a></td><td width=15>&nbsp;</td><td>Real/complex QR/LQ, bi(tri)diagonal, Hessenberg decompositions</td></tr>
<tr align=left valign=top><td><a href='#unit_rcond' class=toc>rcond</a></td><td width=15>&nbsp;</td><td>Condition number estimate</td></tr>
<tr align=left valign=top><td><a href='#unit_schur' class=toc>schur</a></td><td width=15>&nbsp;</td><td>Schur decomposition</td></tr>
<tr align=left valign=top><td><a href='#unit_sparse' class=toc>sparse</a></td><td width=15>&nbsp;</td><td>Sparse matrices</td></tr>
<tr align=left valign=top><td><a href='#unit_spdgevd' class=toc>spdgevd</a></td><td width=15>&nbsp;</td><td>Generalized symmetric eigensolver</td></tr>
<tr align=left valign=top><td><a href='#unit_svd' class=toc>svd</a></td><td width=15>&nbsp;</td><td>Singular value decomposition</td></tr>
<tr align=left valign=top><td><a href='#unit_trfac' class=toc>trfac</a></td><td width=15>&nbsp;</td><td>LU and Cholesky decompositions</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>Optimization</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_minbleic' class=toc>minbleic</a></td><td width=15>&nbsp;</td><td>Bound constrained optimizer with additional linear equality/inequality constraints </td></tr>
<tr align=left valign=top><td><a href='#unit_mincg' class=toc>mincg</a></td><td width=15>&nbsp;</td><td>Conjugate gradient optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_mincomp' class=toc>mincomp</a></td><td width=15>&nbsp;</td><td>Backward compatibility functions</td></tr>
<tr align=left valign=top><td><a href='#unit_minlbfgs' class=toc>minlbfgs</a></td><td width=15>&nbsp;</td><td>Limited memory BFGS optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_minlm' class=toc>minlm</a></td><td width=15>&nbsp;</td><td>Improved Levenberg-Marquardt optimizer</td></tr>
<tr align=left valign=top><td><a href='#unit_minqp' class=toc>minqp</a></td><td width=15>&nbsp;</td><td>Quadratic programming with bound and linear equality/inequality constraints </td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>Solvers</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_densesolver' class=toc>densesolver</a></td><td width=15>&nbsp;</td><td>Dense linear system solver</td></tr>
<tr align=left valign=top><td><a href='#unit_lincg' class=toc>lincg</a></td><td width=15>&nbsp;</td><td>Sparse linear CG solver</td></tr>
<tr align=left valign=top><td><a href='#unit_linlsqr' class=toc>linlsqr</a></td><td width=15>&nbsp;</td><td>Sparse linear LSQR solver</td></tr>
<tr align=left valign=top><td><a href='#unit_nleq' class=toc>nleq</a></td><td width=15>&nbsp;</td><td>Solvers for nonlinear equations</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>SpecialFunctions</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_airyf' class=toc>airyf</a></td><td width=15>&nbsp;</td><td>Airy functions</td></tr>
<tr align=left valign=top><td><a href='#unit_bessel' class=toc>bessel</a></td><td width=15>&nbsp;</td><td>Bessel functions</td></tr>
<tr align=left valign=top><td><a href='#unit_betaf' class=toc>betaf</a></td><td width=15>&nbsp;</td><td>Beta function</td></tr>
<tr align=left valign=top><td><a href='#unit_binomialdistr' class=toc>binomialdistr</a></td><td width=15>&nbsp;</td><td>Binomial distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_chebyshev' class=toc>chebyshev</a></td><td width=15>&nbsp;</td><td>Chebyshev polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_chisquaredistr' class=toc>chisquaredistr</a></td><td width=15>&nbsp;</td><td>Chi-Square distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_dawson' class=toc>dawson</a></td><td width=15>&nbsp;</td><td>Dawson integral</td></tr>
<tr align=left valign=top><td><a href='#unit_elliptic' class=toc>elliptic</a></td><td width=15>&nbsp;</td><td>Elliptic integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_expintegrals' class=toc>expintegrals</a></td><td width=15>&nbsp;</td><td>Exponential integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_fdistr' class=toc>fdistr</a></td><td width=15>&nbsp;</td><td>F-distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_fresnel' class=toc>fresnel</a></td><td width=15>&nbsp;</td><td>Fresnel integrals</td></tr>
<tr align=left valign=top><td><a href='#unit_gammafunc' class=toc>gammafunc</a></td><td width=15>&nbsp;</td><td>Gamma function</td></tr>
<tr align=left valign=top><td><a href='#unit_hermite' class=toc>hermite</a></td><td width=15>&nbsp;</td><td>Hermite polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_ibetaf' class=toc>ibetaf</a></td><td width=15>&nbsp;</td><td>Incomplete beta function</td></tr>
<tr align=left valign=top><td><a href='#unit_igammaf' class=toc>igammaf</a></td><td width=15>&nbsp;</td><td>Incomplete gamma function</td></tr>
<tr align=left valign=top><td><a href='#unit_jacobianelliptic' class=toc>jacobianelliptic</a></td><td width=15>&nbsp;</td><td>Jacobian elliptic functions</td></tr>
<tr align=left valign=top><td><a href='#unit_laguerre' class=toc>laguerre</a></td><td width=15>&nbsp;</td><td>Laguerre polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_legendre' class=toc>legendre</a></td><td width=15>&nbsp;</td><td>Legendre polynomials</td></tr>
<tr align=left valign=top><td><a href='#unit_normaldistr' class=toc>normaldistr</a></td><td width=15>&nbsp;</td><td>Normal distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_poissondistr' class=toc>poissondistr</a></td><td width=15>&nbsp;</td><td>Poisson distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_psif' class=toc>psif</a></td><td width=15>&nbsp;</td><td>Psi function</td></tr>
<tr align=left valign=top><td><a href='#unit_studenttdistr' class=toc>studenttdistr</a></td><td width=15>&nbsp;</td><td>Student's t-distribution</td></tr>
<tr align=left valign=top><td><a href='#unit_trigintegrals' class=toc>trigintegrals</a></td><td width=15>&nbsp;</td><td>Trigonometric integrals</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
<tr align=left valign=top><td colspan=3 bgcolor=#E8E8E8><b><code>Statistics</code> package</b></td></tr>
<tr align=left valign=top><td><a href='#unit_basestat' class=toc>basestat</a></td><td width=15>&nbsp;</td><td>Mean, variance, covariance, correlation, etc.</td></tr>
<tr align=left valign=top><td><a href='#unit_correlationtests' class=toc>correlationtests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: correlation tests</td></tr>
<tr align=left valign=top><td><a href='#unit_jarquebera' class=toc>jarquebera</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Jarque-Bera test</td></tr>
<tr align=left valign=top><td><a href='#unit_mannwhitneyu' class=toc>mannwhitneyu</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Mann-Whitney-U test</td></tr>
<tr align=left valign=top><td><a href='#unit_stest' class=toc>stest</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: sign test</td></tr>
<tr align=left valign=top><td><a href='#unit_studentttests' class=toc>studentttests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Student's t-test</td></tr>
<tr align=left valign=top><td><a href='#unit_variancetests' class=toc>variancetests</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: F-test and one-sample variance test</td></tr>
<tr align=left valign=top><td><a href='#unit_wsr' class=toc>wsr</a></td><td width=15>&nbsp;</td><td>Hypothesis testing: Wilcoxon signed rank test</td></tr>
<tr align=left valign=top><td colspan=2>&nbsp;</td></tr>
</table>
<a name=unit_ablas></a><h2 class=pageheader><code>ablas</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixcopy' class=toc>cmatrixcopy</a><br>
<a href='#sub_cmatrixgemm' class=toc>cmatrixgemm</a><br>
<a href='#sub_cmatrixlefttrsm' class=toc>cmatrixlefttrsm</a><br>
<a href='#sub_cmatrixmv' class=toc>cmatrixmv</a><br>
<a href='#sub_cmatrixrank1' class=toc>cmatrixrank1</a><br>
<a href='#sub_cmatrixrighttrsm' class=toc>cmatrixrighttrsm</a><br>
<a href='#sub_cmatrixsyrk' class=toc>cmatrixsyrk</a><br>
<a href='#sub_cmatrixtranspose' class=toc>cmatrixtranspose</a><br>
<a href='#sub_rmatrixcopy' class=toc>rmatrixcopy</a><br>
<a href='#sub_rmatrixenforcesymmetricity' class=toc>rmatrixenforcesymmetricity</a><br>
<a href='#sub_rmatrixgemm' class=toc>rmatrixgemm</a><br>
<a href='#sub_rmatrixlefttrsm' class=toc>rmatrixlefttrsm</a><br>
<a href='#sub_rmatrixmv' class=toc>rmatrixmv</a><br>
<a href='#sub_rmatrixrank1' class=toc>rmatrixrank1</a><br>
<a href='#sub_rmatrixrighttrsm' class=toc>rmatrixrighttrsm</a><br>
<a href='#sub_rmatrixsyrk' class=toc>rmatrixsyrk</a><br>
<a href='#sub_rmatrixtranspose' class=toc>rmatrixtranspose</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_ablas_d_gemm' class=toc>ablas_d_gemm</a></td><td width=15>&nbsp;</td><td>Matrix multiplication (single-threaded)</td></tr>
<tr align=left valign=top><td><a href='#example_ablas_d_syrk' class=toc>ablas_d_syrk</a></td><td width=15>&nbsp;</td><td>Symmetric rank-K update (single-threaded)</td></tr>
<tr align=left valign=top><td><a href='#example_ablas_smp_gemm' class=toc>ablas_smp_gemm</a></td><td width=15>&nbsp;</td><td>Matrix multiplication (multithreaded)</td></tr>
<tr align=left valign=top><td><a href='#example_ablas_smp_syrk' class=toc>ablas_smp_syrk</a></td><td width=15>&nbsp;</td><td>Symmetric rank-K update (multithreaded)</td></tr>
</table></div>
<a name='sub_cmatrixcopy'></a><h3 class=pageheader><code>cmatrixcopy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Copy

Input parameters:
    M   -   number of rows
    N   -   number of columns
    A   -   source matrix, MxN submatrix is copied and transposed
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    B   -   destination matrix, must be large enough to store result
    IB  -   submatrix offset (row index)
    JB  -   submatrix offset (column index)
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixcopy(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    complex_2d_array&amp; b,
    ae_int_t ib,
    ae_int_t jb);

</div></pre>
<a name='sub_cmatrixgemm'></a><h3 class=pageheader><code>cmatrixgemm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixgemm(
    ae_int_t m,
    ae_int_t n,
    ae_int_t k,
    alglib::complex alpha,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    complex_2d_array b,
    ae_int_t ib,
    ae_int_t jb,
    ae_int_t optypeb,
    alglib::complex beta,
    complex_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc);
<b>void</b> alglib::smp_cmatrixgemm(
    ae_int_t m,
    ae_int_t n,
    ae_int_t k,
    alglib::smp_complex alpha,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    complex_2d_array b,
    ae_int_t ib,
    ae_int_t jb,
    ae_int_t optypeb,
    alglib::smp_complex beta,
    complex_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_ablas_d_gemm' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_ablas_smp_gemm' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_cmatrixlefttrsm'></a><h3 class=pageheader><code>cmatrixlefttrsm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlefttrsm(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    complex_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);
<b>void</b> alglib::smp_cmatrixlefttrsm(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    complex_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);

</div></pre>
<a name='sub_cmatrixmv'></a><h3 class=pageheader><code>cmatrixmv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Matrix-vector product: y := op(A)*x

INPUT PARAMETERS:
    M   -   number of rows of op(A)
            M&gt;=0
    N   -   number of columns of op(A)
            N&gt;=0
    A   -   target matrix
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    OpA -   operation type:
            * OpA=0     =&gt;  op(A) = A
            * OpA=1     =&gt;  op(A) = A^T
            * OpA=2     =&gt;  op(A) = A^H
    X   -   input vector
    IX  -   subvector offset
    IY  -   subvector offset
    Y   -   preallocated matrix, must be large enough to store result

OUTPUT PARAMETERS:
    Y   -   vector which stores result

if M=0, then subroutine does nothing.
if N=0, Y is filled by zeros.


  -- ALGLIB routine --

     28.01.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixmv(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t opa,
    complex_1d_array x,
    ae_int_t ix,
    complex_1d_array&amp; y,
    ae_int_t iy);

</div></pre>
<a name='sub_cmatrixrank1'></a><h3 class=pageheader><code>cmatrixrank1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rank-1 correction: A := A + u*v'

INPUT PARAMETERS:
    M   -   number of rows
    N   -   number of columns
    A   -   target matrix, MxN submatrix is updated
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    U   -   vector #1
    IU  -   subvector offset
    V   -   vector #2
    IV  -   subvector offset
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrank1(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array&amp; a,
    ae_int_t ia,
    ae_int_t ja,
    complex_1d_array&amp; u,
    ae_int_t iu,
    complex_1d_array&amp; v,
    ae_int_t iv);

</div></pre>
<a name='sub_cmatrixrighttrsm'></a><h3 class=pageheader><code>cmatrixrighttrsm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrighttrsm(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    complex_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);
<b>void</b> alglib::smp_cmatrixrighttrsm(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    complex_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);

</div></pre>
<a name='sub_cmatrixsyrk'></a><h3 class=pageheader><code>cmatrixsyrk</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixsyrk(
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    <b>double</b> beta,
    complex_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc,
    <b>bool</b> isupper);
<b>void</b> alglib::smp_cmatrixsyrk(
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    <b>double</b> beta,
    complex_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc,
    <b>bool</b> isupper);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_ablas_d_syrk' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_ablas_smp_syrk' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_cmatrixtranspose'></a><h3 class=pageheader><code>cmatrixtranspose</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cache-oblivous complex &quot;copy-and-transpose&quot;

Input parameters:
    M   -   number of rows
    N   -   number of columns
    A   -   source matrix, MxN submatrix is copied and transposed
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    B   -   destination matrix, must be large enough to store result
    IB  -   submatrix offset (row index)
    JB  -   submatrix offset (column index)
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixtranspose(
    ae_int_t m,
    ae_int_t n,
    complex_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    complex_2d_array&amp; b,
    ae_int_t ib,
    ae_int_t jb);

</div></pre>
<a name='sub_rmatrixcopy'></a><h3 class=pageheader><code>rmatrixcopy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Copy

Input parameters:
    M   -   number of rows
    N   -   number of columns
    A   -   source matrix, MxN submatrix is copied and transposed
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    B   -   destination matrix, must be large enough to store result
    IB  -   submatrix offset (row index)
    JB  -   submatrix offset (column index)
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixcopy(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    real_2d_array&amp; b,
    ae_int_t ib,
    ae_int_t jb);

</div></pre>
<a name='sub_rmatrixenforcesymmetricity'></a><h3 class=pageheader><code>rmatrixenforcesymmetricity</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This code enforces symmetricy of the matrix by copying Upper part to lower
one (or vice versa).

INPUT PARAMETERS:
    A   -   matrix
    N   -   number of rows/columns
    IsUpper - whether we want to copy upper triangle to lower one (True)
            or vice versa (False).
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixenforcesymmetricity(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_rmatrixgemm'></a><h3 class=pageheader><code>rmatrixgemm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixgemm(
    ae_int_t m,
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    real_2d_array b,
    ae_int_t ib,
    ae_int_t jb,
    ae_int_t optypeb,
    <b>double</b> beta,
    real_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc);
<b>void</b> alglib::smp_rmatrixgemm(
    ae_int_t m,
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    real_2d_array b,
    ae_int_t ib,
    ae_int_t jb,
    ae_int_t optypeb,
    <b>double</b> beta,
    real_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_ablas_d_gemm' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_ablas_smp_gemm' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_rmatrixlefttrsm'></a><h3 class=pageheader><code>rmatrixlefttrsm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlefttrsm(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    real_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);
<b>void</b> alglib::smp_rmatrixlefttrsm(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    real_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);

</div></pre>
<a name='sub_rmatrixmv'></a><h3 class=pageheader><code>rmatrixmv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Matrix-vector product: y := op(A)*x

INPUT PARAMETERS:
    M   -   number of rows of op(A)
    N   -   number of columns of op(A)
    A   -   target matrix
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    OpA -   operation type:
            * OpA=0     =&gt;  op(A) = A
            * OpA=1     =&gt;  op(A) = A^T
    X   -   input vector
    IX  -   subvector offset
    IY  -   subvector offset
    Y   -   preallocated matrix, must be large enough to store result

OUTPUT PARAMETERS:
    Y   -   vector which stores result

if M=0, then subroutine does nothing.
if N=0, Y is filled by zeros.


  -- ALGLIB routine --

     28.01.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixmv(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t opa,
    real_1d_array x,
    ae_int_t ix,
    real_1d_array&amp; y,
    ae_int_t iy);

</div></pre>
<a name='sub_rmatrixrank1'></a><h3 class=pageheader><code>rmatrixrank1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rank-1 correction: A := A + u*v'

INPUT PARAMETERS:
    M   -   number of rows
    N   -   number of columns
    A   -   target matrix, MxN submatrix is updated
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    U   -   vector #1
    IU  -   subvector offset
    V   -   vector #2
    IV  -   subvector offset
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrank1(
    ae_int_t m,
    ae_int_t n,
    real_2d_array&amp; a,
    ae_int_t ia,
    ae_int_t ja,
    real_1d_array&amp; u,
    ae_int_t iu,
    real_1d_array&amp; v,
    ae_int_t iv);

</div></pre>
<a name='sub_rmatrixrighttrsm'></a><h3 class=pageheader><code>rmatrixrighttrsm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrighttrsm(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    real_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);
<b>void</b> alglib::smp_rmatrixrighttrsm(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t i1,
    ae_int_t j1,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t optype,
    real_2d_array&amp; x,
    ae_int_t i2,
    ae_int_t j2);

</div></pre>
<a name='sub_rmatrixsyrk'></a><h3 class=pageheader><code>rmatrixsyrk</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixsyrk(
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    <b>double</b> beta,
    real_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc,
    <b>bool</b> isupper);
<b>void</b> alglib::smp_rmatrixsyrk(
    ae_int_t n,
    ae_int_t k,
    <b>double</b> alpha,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    ae_int_t optypea,
    <b>double</b> beta,
    real_2d_array&amp; c,
    ae_int_t ic,
    ae_int_t jc,
    <b>bool</b> isupper);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_ablas_d_syrk' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_ablas_smp_syrk' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_rmatrixtranspose'></a><h3 class=pageheader><code>rmatrixtranspose</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cache-oblivous real &quot;copy-and-transpose&quot;

Input parameters:
    M   -   number of rows
    N   -   number of columns
    A   -   source matrix, MxN submatrix is copied and transposed
    IA  -   submatrix offset (row index)
    JA  -   submatrix offset (column index)
    B   -   destination matrix, must be large enough to store result
    IB  -   submatrix offset (row index)
    JB  -   submatrix offset (column index)
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixtranspose(
    ae_int_t m,
    ae_int_t n,
    real_2d_array a,
    ae_int_t ia,
    ae_int_t ja,
    real_2d_array&amp; b,
    ae_int_t ib,
    ae_int_t jb);

</div></pre>
<a name='example_ablas_d_gemm'></a><h3 class=pageheader>ablas_d_gemm example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array a = <font color=blue><b>&quot;[[2,1],[1,3]]&quot;</b></font>;
    real_2d_array b = <font color=blue><b>&quot;[[2,1],[0,1]]&quot;</b></font>;
    real_2d_array c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// rmatrixgemm() function allows us to calculate matrix product C:=A*B or</font>
    <font color=navy>// to perform more general operation, C:=alpha*op1(A)*op2(B)+beta*C,</font>
    <font color=navy>// where A, B, C are rectangular matrices, op(X) can be X or X^T,</font>
    <font color=navy>// alpha and beta are scalars.</font>
    <font color=navy>//</font>
    <font color=navy>// This function:</font>
    <font color=navy>// * can apply transposition and/or multiplication by scalar to operands</font>
    <font color=navy>// * can use arbitrary part of matrices A/B (given by submatrix offset)</font>
    <font color=navy>// * can store result into arbitrary part of C</font>
    <font color=navy>// * <b>for</b> performance reasons requires C to be preallocated</font>
    <font color=navy>//</font>
    <font color=navy>// Parameters of this function are:</font>
    <font color=navy>// * M, N, K            -   sizes of op1(A) (which is MxK), op2(B) (which</font>
    <font color=navy>//                          is KxN) and C (which is MxN)</font>
    <font color=navy>// * Alpha              -   coefficient before A*B</font>
    <font color=navy>// * A, IA, JA          -   matrix A and offset of the submatrix</font>
    <font color=navy>// * OpTypeA            -   transformation type:</font>
    <font color=navy>//                          0 - no transformation</font>
    <font color=navy>//                          1 - transposition</font>
    <font color=navy>// * B, IB, JB          -   matrix B and offset of the submatrix</font>
    <font color=navy>// * OpTypeB            -   transformation type:</font>
    <font color=navy>//                          0 - no transformation</font>
    <font color=navy>//                          1 - transposition</font>
    <font color=navy>// * Beta               -   coefficient before C</font>
    <font color=navy>// * C, IC, JC          -   preallocated matrix C and offset of the submatrix</font>
    <font color=navy>//</font>
    <font color=navy>// Below we perform simple product C:=A*B (alpha=1, beta=0)</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this function works with preallocated C, which must be large</font>
    <font color=navy>//            enough to store multiplication result.</font>
    <font color=navy>//</font>
    ae_int_t m = 2;
    ae_int_t n = 2;
    ae_int_t k = 2;
    <b>double</b> alpha = 1.0;
    ae_int_t ia = 0;
    ae_int_t ja = 0;
    ae_int_t optypea = 0;
    ae_int_t ib = 0;
    ae_int_t jb = 0;
    ae_int_t optypeb = 0;
    <b>double</b> beta = 0.0;
    ae_int_t ic = 0;
    ae_int_t jc = 0;
    rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[4,3],[2,4]]</font>

    <font color=navy>//</font>
    <font color=navy>// Now we try to apply some simple transformation to operands: C:=A*B^T</font>
    <font color=navy>//</font>
    optypeb = 1;
    rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[5,1],[5,3]]</font>
    <b>return</b> 0;
}


</pre><a name='example_ablas_d_syrk'></a><h3 class=pageheader>ablas_d_syrk example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// rmatrixsyrk() function allows us to calculate symmetric rank-K update</font>
    <font color=navy>// C := beta*C + alpha*A'*A, where C is square N*N matrix, A is square K*N</font>
    <font color=navy>// matrix, alpha and beta are scalars. It is also possible to update by</font>
    <font color=navy>// adding A*A' instead of A'*A.</font>
    <font color=navy>//</font>
    <font color=navy>// Parameters of this function are:</font>
    <font color=navy>// * N, K       -   matrix size</font>
    <font color=navy>// * Alpha      -   coefficient before A</font>
    <font color=navy>// * A, IA, JA  -   matrix and submatrix offsets</font>
    <font color=navy>// * OpTypeA    -   multiplication type:</font>
    <font color=navy>//                  * 0 - A*A^T is calculated</font>
    <font color=navy>//                  * 2 - A^T*A is calculated</font>
    <font color=navy>// * Beta       -   coefficient before C</font>
    <font color=navy>// * C, IC, JC  -   preallocated input/output matrix and submatrix offsets</font>
    <font color=navy>// * IsUpper    -   whether upper or lower triangle of C is updated;</font>
    <font color=navy>//                  this function updates only one half of C, leaving</font>
    <font color=navy>//                  other half unchanged (not referenced at all).</font>
    <font color=navy>//</font>
    <font color=navy>// Below we will show how to calculate simple product C:=A'*A</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: beta=0 and we <b>do</b> not use previous value of C, but still it</font>
    <font color=navy>//       MUST be preallocated.</font>
    <font color=navy>//</font>
    ae_int_t n = 2;
    ae_int_t k = 1;
    <b>double</b> alpha = 1.0;
    ae_int_t ia = 0;
    ae_int_t ja = 0;
    ae_int_t optypea = 2;
    <b>double</b> beta = 0.0;
    ae_int_t ic = 0;
    ae_int_t jc = 0;
    <b>bool</b> isupper = true;
    real_2d_array a = <font color=blue><b>&quot;[[1,2]]&quot;</b></font>;

    <font color=navy>// preallocate space to store result</font>
    real_2d_array c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;

    <font color=navy>// calculate product, store result into upper part of c</font>
    rmatrixsyrk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper);

    <font color=navy>// output result.</font>
    <font color=navy>// IMPORTANT: lower triangle of C was NOT updated!</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[1,2],[0,4]]</font>
    <b>return</b> 0;
}


</pre><a name='example_ablas_smp_gemm'></a><h3 class=pageheader>ablas_smp_gemm example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we assume that you already know how to work with</font>
    <font color=navy>// rmatrixgemm() function. Below we concentrate on its multithreading</font>
    <font color=navy>// capabilities.</font>
    <font color=navy>//</font>
    <font color=navy>// SMP edition of ALGLIB includes smp_rmatrixgemm() - multithreaded</font>
    <font color=navy>// version of rmatrixgemm() function. In the basic edition of ALGLIB</font>
    <font color=navy>// (GPL edition or commercial version without SMP support) this function</font>
    <font color=navy>// just calls single-threaded stub. So, you may call this function from</font>
    <font color=navy>// ANY edition of ALGLIB, but only in SMP edition it will work in really</font>
    <font color=navy>// multithreaded mode.</font>
    <font color=navy>//</font>
    <font color=navy>// In order to use multithreading, you have to:</font>
    <font color=navy>// 1) Install SMP edition of ALGLIB.</font>
    <font color=navy>// 2) This step is specific <b>for</b> C++ users: you should activate OS-specific</font>
    <font color=navy>//    capabilities of ALGLIB by defining AE_OS=AE_POSIX (<b>for</b> *nix systems)</font>
    <font color=navy>//    or AE_OS=AE_WINDOWS (<b>for</b> Windows systems).</font>
    <font color=navy>//    C# users <b>do</b> not have to perform this step because C# programs are</font>
    <font color=navy>//    portable across different systems without OS-specific tuning.</font>
    <font color=navy>// 3) Allow ALGLIB to know about number of worker threads to use:</font>
    <font color=navy>//    a) autodetection (C++, C#):</font>
    <font color=navy>//          ALGLIB will automatically determine number of CPU cores and</font>
    <font color=navy>//          (by default) will use all cores except <b>for</b> one. Say, on 4-core</font>
    <font color=navy>//          system it will use three cores - unless you manually told it</font>
    <font color=navy>//          to use more or less. It will keep your system responsive during</font>
    <font color=navy>//          lengthy computations.</font>
    <font color=navy>//          Such behavior may be changed with setnworkers() call:</font>
    <font color=navy>//          * alglib::setnworkers(0)  = use all cores</font>
    <font color=navy>//          * alglib::setnworkers(-1) = leave one core unused</font>
    <font color=navy>//          * alglib::setnworkers(-2) = leave two cores unused</font>
    <font color=navy>//          * alglib::setnworkers(+2) = use 2 cores (even <b>if</b> you have more)</font>
    <font color=navy>//    b) manual specification (C++, C#):</font>
    <font color=navy>//          You may want to specify maximum number of worker threads during</font>
    <font color=navy>//          compile time by means of preprocessor definition AE_NWORKERS.</font>
    <font color=navy>//          For C++ it will be <font color=blue><b>&quot;AE_NWORKERS=X&quot;</b></font> where X can be any positive number.</font>
    <font color=navy>//          For C# it is <font color=blue><b>&quot;AE_NWORKERSX&quot;</b></font>, where X should be replaced by number of</font>
    <font color=navy>//          workers (AE_NWORKERS2, AE_NWORKERS3, AE_NWORKERS4, ...).</font>
    <font color=navy>//          You can add this definition to compiler command line or change</font>
    <font color=navy>//          corresponding project settings in your IDE.</font>
    <font color=navy>//</font>
    <font color=navy>// After you installed and configured SMP edition of ALGLIB, you may choose</font>
    <font color=navy>// between serial and multithreaded versions of SMP-capable functions:</font>
    <font color=navy>// * serial version works as usual, in the context of the calling thread</font>
    <font color=navy>// * multithreaded version (with <font color=blue><b>&quot;smp_&quot;</b></font> prefix) creates (or wakes up) worker</font>
    <font color=navy>//   threads, inserts task in the worker queue, and waits <b>for</b> completion of</font>
    <font color=navy>//   the task. All processing is done in context of worker thread(s).</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: because starting/stopping worker threads costs thousands of CPU cycles,</font>
    <font color=navy>//       you should not use multithreading <b>for</b> lightweight computational problems.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: some old POSIX-compatible operating systems <b>do</b> not support</font>
    <font color=navy>//       sysconf(_SC_NPROCESSORS_ONLN) system call which is required in order</font>
    <font color=navy>//       to automatically determine number of active cores. On these systems</font>
    <font color=navy>//       you should specify number of cores manually at compile time.</font>
    <font color=navy>//       Without it ALGLIB will run in single-threaded mode.</font>
    <font color=navy>//</font>
    <font color=navy>// Now, back to our example. In this example we will show you:</font>
    <font color=navy>// * how to call SMP version of rmatrixgemm(). Because we work with tiny 2x2</font>
    <font color=navy>//   matrices, we won't expect to see ANY speedup from using multithreading.</font>
    <font color=navy>//   The only purpose of this demo is to show how to call SMP functions.</font>
    <font color=navy>// * how to modify number of worker threads used by ALGLIB</font>
    <font color=navy>//</font>
    real_2d_array a = <font color=blue><b>&quot;[[2,1],[1,3]]&quot;</b></font>;
    real_2d_array b = <font color=blue><b>&quot;[[2,1],[0,1]]&quot;</b></font>;
    real_2d_array c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    ae_int_t m = 2;
    ae_int_t n = 2;
    ae_int_t k = 2;
    <b>double</b> alpha = 1.0;
    ae_int_t ia = 0;
    ae_int_t ja = 0;
    ae_int_t optypea = 0;
    ae_int_t ib = 0;
    ae_int_t jb = 0;
    ae_int_t optypeb = 0;
    <b>double</b> beta = 0.0;
    ae_int_t ic = 0;
    ae_int_t jc = 0;

    <font color=navy>// serial code</font>
    c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc);

    <font color=navy>// SMP code with default number of worker threads</font>
    c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    smp_rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[4,3],[2,4]]</font>

    <font color=navy>// override number of worker threads - use two cores</font>
    alglib::setnworkers(+2);
    c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    smp_rmatrixgemm(m, n, k, alpha, a, ia, ja, optypea, b, ib, jb, optypeb, beta, c, ic, jc);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[4,3],[2,4]]</font>
    <b>return</b> 0;
}


</pre><a name='example_ablas_smp_syrk'></a><h3 class=pageheader>ablas_smp_syrk example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we assume that you already know how to work with</font>
    <font color=navy>// rmatrixsyrk() function. Below we concentrate on its multithreading</font>
    <font color=navy>// capabilities.</font>
    <font color=navy>//</font>
    <font color=navy>// SMP edition of ALGLIB includes smp_rmatrixsyrk() - multithreaded</font>
    <font color=navy>// version of rmatrixsyrk() function. In the basic edition of ALGLIB</font>
    <font color=navy>// (GPL edition or commercial version without SMP support) this function</font>
    <font color=navy>// just calls single-threaded stub. So, you may call this function from</font>
    <font color=navy>// ANY edition of ALGLIB, but only in SMP edition it will work in really</font>
    <font color=navy>// multithreaded mode.</font>
    <font color=navy>//</font>
    <font color=navy>// In order to use multithreading, you have to:</font>
    <font color=navy>// 1) Install SMP edition of ALGLIB.</font>
    <font color=navy>// 2) This step is specific <b>for</b> C++ users: you should activate OS-specific</font>
    <font color=navy>//    capabilities of ALGLIB by defining AE_OS=AE_POSIX (<b>for</b> *nix systems)</font>
    <font color=navy>//    or AE_OS=AE_WINDOWS (<b>for</b> Windows systems).</font>
    <font color=navy>//    C# users <b>do</b> not have to perform this step because C# programs are</font>
    <font color=navy>//    portable across different systems without OS-specific tuning.</font>
    <font color=navy>// 3) Allow ALGLIB to know about number of worker threads to use:</font>
    <font color=navy>//    a) autodetection (C++, C#):</font>
    <font color=navy>//          ALGLIB will automatically determine number of CPU cores and</font>
    <font color=navy>//          (by default) will use all cores except <b>for</b> one. Say, on 4-core</font>
    <font color=navy>//          system it will use three cores - unless you manually told it</font>
    <font color=navy>//          to use more or less. It will keep your system responsive during</font>
    <font color=navy>//          lengthy computations.</font>
    <font color=navy>//          Such behavior may be changed with setnworkers() call:</font>
    <font color=navy>//          * alglib::setnworkers(0)  = use all cores</font>
    <font color=navy>//          * alglib::setnworkers(-1) = leave one core unused</font>
    <font color=navy>//          * alglib::setnworkers(-2) = leave two cores unused</font>
    <font color=navy>//          * alglib::setnworkers(+2) = use 2 cores (even <b>if</b> you have more)</font>
    <font color=navy>//    b) manual specification (C++, C#):</font>
    <font color=navy>//          You may want to specify maximum number of worker threads during</font>
    <font color=navy>//          compile time by means of preprocessor definition AE_NWORKERS.</font>
    <font color=navy>//          For C++ it will be <font color=blue><b>&quot;AE_NWORKERS=X&quot;</b></font> where X can be any positive number.</font>
    <font color=navy>//          For C# it is <font color=blue><b>&quot;AE_NWORKERSX&quot;</b></font>, where X should be replaced by number of</font>
    <font color=navy>//          workers (AE_NWORKERS2, AE_NWORKERS3, AE_NWORKERS4, ...).</font>
    <font color=navy>//          You can add this definition to compiler command line or change</font>
    <font color=navy>//          corresponding project settings in your IDE.</font>
    <font color=navy>//</font>
    <font color=navy>// After you installed and configured SMP edition of ALGLIB, you may choose</font>
    <font color=navy>// between serial and multithreaded versions of SMP-capable functions:</font>
    <font color=navy>// * serial version works as usual, in the context of the calling thread</font>
    <font color=navy>// * multithreaded version (with <font color=blue><b>&quot;smp_&quot;</b></font> prefix) creates (or wakes up) worker</font>
    <font color=navy>//   threads, inserts task in the worker queue, and waits <b>for</b> completion of</font>
    <font color=navy>//   the task. All processing is done in context of worker thread(s).</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: because starting/stopping worker threads costs thousands of CPU cycles,</font>
    <font color=navy>//       you should not use multithreading <b>for</b> lightweight computational problems.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: some old POSIX-compatible operating systems <b>do</b> not support</font>
    <font color=navy>//       sysconf(_SC_NPROCESSORS_ONLN) system call which is required in order</font>
    <font color=navy>//       to automatically determine number of active cores. On these systems</font>
    <font color=navy>//       you should specify number of cores manually at compile time.</font>
    <font color=navy>//       Without it ALGLIB will run in single-threaded mode.</font>
    <font color=navy>//</font>
    <font color=navy>// Now, back to our example. In this example we will show you:</font>
    <font color=navy>// * how to call SMP version of rmatrixsyrk(). Because we work with tiny 2x2</font>
    <font color=navy>//   matrices, we won't expect to see ANY speedup from using multithreading.</font>
    <font color=navy>//   The only purpose of this demo is to show how to call SMP functions.</font>
    <font color=navy>// * how to modify number of worker threads used by ALGLIB</font>
    <font color=navy>//</font>
    ae_int_t n = 2;
    ae_int_t k = 1;
    <b>double</b> alpha = 1.0;
    ae_int_t ia = 0;
    ae_int_t ja = 0;
    ae_int_t optypea = 2;
    <b>double</b> beta = 0.0;
    ae_int_t ic = 0;
    ae_int_t jc = 0;
    <b>bool</b> isupper = true;
    real_2d_array a = <font color=blue><b>&quot;[[1,2]]&quot;</b></font>;
    real_2d_array c = <font color=blue><b>&quot;[[]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Default number of worker threads.</font>
    <font color=navy>// Preallocate space to store result, call multithreaded version, test.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: this function updates only one triangular part of C. In our</font>
    <font color=navy>//       example we choose to update upper triangle.</font>
    <font color=navy>//</font>
    c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    smp_rmatrixsyrk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[1,2],[0,4]]</font>

    <font color=navy>//</font>
    <font color=navy>// Override default number of worker threads (set to 2).</font>
    <font color=navy>// Preallocate space to store result, call multithreaded version, test.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: this function updates only one triangular part of C. In our</font>
    <font color=navy>//       example we choose to update upper triangle.</font>
    <font color=navy>//</font>
    alglib::setnworkers(+2);
    c = <font color=blue><b>&quot;[[0,0],[0,0]]&quot;</b></font>;
    smp_rmatrixsyrk(n, k, alpha, a, ia, ja, optypea, beta, c, ic, jc, isupper);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [[1,2],[0,4]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_airyf></a><h2 class=pageheader><code>airyf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_airy' class=toc>airy</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_airy'></a><h3 class=pageheader><code>airy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Airy function

Solution of the differential equation

y&quot;(x) = xy.

The function returns the two independent solutions Ai, Bi
and their first derivatives Ai'(x), Bi'(x).

Evaluation is by power series summation for small x,
by rational minimax approximations for large x.



ACCURACY:
Error criterion is absolute when function &lt;= 1, relative
when function &gt; 1, except * denotes relative error criterion.
For large negative x, the absolute error increases as x^1.5.
For large positive x, the relative error increases as x^1.5.

Arithmetic  domain   function  # trials      peak         rms
IEEE        -10, 0     Ai        10000       1.6e-15     2.7e-16
IEEE          0, 10    Ai        10000       2.3e-14*    1.8e-15*
IEEE        -10, 0     Ai'       10000       4.6e-15     7.6e-16
IEEE          0, 10    Ai'       10000       1.8e-14*    1.5e-15*
IEEE        -10, 10    Bi        30000       4.2e-15     5.3e-16
IEEE        -10, 10    Bi'       30000       4.9e-15     7.3e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::airy(
    <b>double</b> x,
    <b>double</b>&amp; ai,
    <b>double</b>&amp; aip,
    <b>double</b>&amp; bi,
    <b>double</b>&amp; bip);

</div></pre>
<a name=unit_autogk></a><h2 class=pageheader><code>autogk</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_autogkreport' class=toc>autogkreport</a><br>
<a href='#struct_autogkstate' class=toc>autogkstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_autogkintegrate' class=toc>autogkintegrate</a><br>
<a href='#sub_autogkresults' class=toc>autogkresults</a><br>
<a href='#sub_autogksingular' class=toc>autogksingular</a><br>
<a href='#sub_autogksmooth' class=toc>autogksmooth</a><br>
<a href='#sub_autogksmoothw' class=toc>autogksmoothw</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_autogk_d1' class=toc>autogk_d1</a></td><td width=15>&nbsp;</td><td>Integrating f=exp(x) by adaptive integrator</td></tr>
</table></div>
<a name='struct_autogkreport'></a><h3 class=pageheader><code>autogkreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Integration report:
* TerminationType = completetion code:
    * -5    non-convergence of Gauss-Kronrod nodes
            calculation subroutine.
    * -1    incorrect parameters were specified
    *  1    OK
* Rep.NFEV countains number of function calculations
* Rep.NIntervals contains number of intervals [a,b]
  was partitioned into.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> autogkreport
{
    ae_int_t             terminationtype;
    ae_int_t             nfev;
    ae_int_t             nintervals;
};

</div></pre>
<a name='struct_autogkstate'></a><h3 class=pageheader><code>autogkstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure stores state of the integration algorithm.

Although this class has public fields,  they are not intended for external
use. You should use ALGLIB functions to work with this class:
* autogksmooth()/AutoGKSmoothW()/... to create objects
* autogkintegrate() to begin integration
* autogkresults() to get results
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> autogkstate
{
};

</div></pre>
<a name='sub_autogkintegrate'></a><h3 class=pageheader><code>autogkintegrate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to launcn iterations of ODE solver

It accepts following parameters:
    diff    -   callback which calculates dy/dx for given y and x
    obj     -   optional object which is passed to diff; can be NULL


  -- ALGLIB --
     Copyright 07.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> autogkintegrate(autogkstate &amp;state,
    <b>void</b> (*func)(<b>double</b> x, <b>double</b> xminusa, <b>double</b> bminusx, <b>double</b> &amp;y, <b>void</b> *ptr),
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_autogk_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_autogkresults'></a><h3 class=pageheader><code>autogkresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Adaptive integration results

Called after AutoGKIteration returned False.

Input parameters:
    State   -   algorithm state (used by AutoGKIteration).

Output parameters:
    V       -   integral(f(x)dx,a,b)
    Rep     -   optimization report (see AutoGKReport description)

  -- ALGLIB --
     Copyright 14.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::autogkresults(
    autogkstate state,
    <b>double</b>&amp; v,
    autogkreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_autogk_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_autogksingular'></a><h3 class=pageheader><code>autogksingular</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Integration on a finite interval [A,B].
Integrand have integrable singularities at A/B.

F(X) must diverge as &quot;(x-A)^alpha&quot; at A, as &quot;(B-x)^beta&quot; at B,  with known
alpha/beta (alpha&gt;-1, beta&gt;-1).  If alpha/beta  are  not known,  estimates
from below can be used (but these estimates should be greater than -1 too).

One  of  alpha/beta variables (or even both alpha/beta) may be equal to 0,
which means than function F(x) is non-singular at A/B. Anyway (singular at
bounds or not), function F(x) is supposed to be continuous on (A,B).

Fast-convergent algorithm based on a Gauss-Kronrod formula is used. Result
is calculated with accuracy close to the machine precision.

INPUT PARAMETERS:
    A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)
    Alpha   -   power-law coefficient of the F(x) at A,
                Alpha&gt;-1
    Beta    -   power-law coefficient of the F(x) at B,
                Beta&gt;-1

OUTPUT PARAMETERS
    State   -   structure which stores algorithm state

SEE ALSO
    AutoGKSmooth, AutoGKSmoothW, AutoGKResults.


  -- ALGLIB --
     Copyright 06.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::autogksingular(
    <b>double</b> a,
    <b>double</b> b,
    <b>double</b> alpha,
    <b>double</b> beta,
    autogkstate&amp; state);

</div></pre>
<a name='sub_autogksmooth'></a><h3 class=pageheader><code>autogksmooth</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Integration of a smooth function F(x) on a finite interval [a,b].

Fast-convergent algorithm based on a Gauss-Kronrod formula is used. Result
is calculated with accuracy close to the machine precision.

Algorithm works well only with smooth integrands.  It  may  be  used  with
continuous non-smooth integrands, but with  less  performance.

It should never be used with integrands which have integrable singularities
at lower or upper limits - algorithm may crash. Use AutoGKSingular in such
cases.

INPUT PARAMETERS:
    A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)

OUTPUT PARAMETERS
    State   -   structure which stores algorithm state

SEE ALSO
    AutoGKSmoothW, AutoGKSingular, AutoGKResults.


  -- ALGLIB --
     Copyright 06.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::autogksmooth(<b>double</b> a, <b>double</b> b, autogkstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_autogk_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_autogksmoothw'></a><h3 class=pageheader><code>autogksmoothw</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Integration of a smooth function F(x) on a finite interval [a,b].

This subroutine is same as AutoGKSmooth(), but it guarantees that interval
[a,b] is partitioned into subintervals which have width at most XWidth.

Subroutine  can  be  used  when  integrating nearly-constant function with
narrow &quot;bumps&quot; (about XWidth wide). If &quot;bumps&quot; are too narrow, AutoGKSmooth
subroutine can overlook them.

INPUT PARAMETERS:
    A, B    -   interval boundaries (A&lt;B, A=B or A&gt;B)

OUTPUT PARAMETERS
    State   -   structure which stores algorithm state

SEE ALSO
    AutoGKSmooth, AutoGKSingular, AutoGKResults.


  -- ALGLIB --
     Copyright 06.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::autogksmoothw(
    <b>double</b> a,
    <b>double</b> b,
    <b>double</b> xwidth,
    autogkstate&amp; state);

</div></pre>
<a name='example_autogk_d1'></a><h3 class=pageheader>autogk_d1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;integration.h&quot;</b></font>

using namespace alglib;
<b>void</b> int_function_1_func(<b>double</b> x, <b>double</b> xminusa, <b>double</b> bminusx, <b>double</b> &amp;y, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(x)=exp(x)</font>
    y = exp(x);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates integration of f=exp(x) on [0,1]:</font>
    <font color=navy>// * first, autogkstate is initialized</font>
    <font color=navy>// * then we call integration function</font>
    <font color=navy>// * and finally we obtain results with autogkresults() call</font>
    <font color=navy>//</font>
    <b>double</b> a = 0;
    <b>double</b> b = 1;
    autogkstate s;
    <b>double</b> v;
    autogkreport rep;

    autogksmooth(a, b, s);
    alglib::autogkintegrate(s, int_function_1_func);
    autogkresults(s, v, rep);

    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.7182</font>
    <b>return</b> 0;
}


</pre><a name=unit_basestat></a><h2 class=pageheader><code>basestat</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cov2' class=toc>cov2</a><br>
<a href='#sub_covm' class=toc>covm</a><br>
<a href='#sub_covm2' class=toc>covm2</a><br>
<a href='#sub_pearsoncorr2' class=toc>pearsoncorr2</a><br>
<a href='#sub_pearsoncorrelation' class=toc>pearsoncorrelation</a><br>
<a href='#sub_pearsoncorrm' class=toc>pearsoncorrm</a><br>
<a href='#sub_pearsoncorrm2' class=toc>pearsoncorrm2</a><br>
<a href='#sub_rankdata' class=toc>rankdata</a><br>
<a href='#sub_rankdatacentered' class=toc>rankdatacentered</a><br>
<a href='#sub_sampleadev' class=toc>sampleadev</a><br>
<a href='#sub_samplekurtosis' class=toc>samplekurtosis</a><br>
<a href='#sub_samplemean' class=toc>samplemean</a><br>
<a href='#sub_samplemedian' class=toc>samplemedian</a><br>
<a href='#sub_samplemoments' class=toc>samplemoments</a><br>
<a href='#sub_samplepercentile' class=toc>samplepercentile</a><br>
<a href='#sub_sampleskewness' class=toc>sampleskewness</a><br>
<a href='#sub_samplevariance' class=toc>samplevariance</a><br>
<a href='#sub_spearmancorr2' class=toc>spearmancorr2</a><br>
<a href='#sub_spearmancorrm' class=toc>spearmancorrm</a><br>
<a href='#sub_spearmancorrm2' class=toc>spearmancorrm2</a><br>
<a href='#sub_spearmanrankcorrelation' class=toc>spearmanrankcorrelation</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_basestat_d_base' class=toc>basestat_d_base</a></td><td width=15>&nbsp;</td><td>Basic functionality (moments, adev, median, percentile)</td></tr>
<tr align=left valign=top><td><a href='#example_basestat_d_c2' class=toc>basestat_d_c2</a></td><td width=15>&nbsp;</td><td>Correlation (covariance) between two random variables</td></tr>
<tr align=left valign=top><td><a href='#example_basestat_d_cm' class=toc>basestat_d_cm</a></td><td width=15>&nbsp;</td><td>Correlation (covariance) between components of random vector</td></tr>
<tr align=left valign=top><td><a href='#example_basestat_d_cm2' class=toc>basestat_d_cm2</a></td><td width=15>&nbsp;</td><td>Correlation (covariance) between two random vectors</td></tr>
</table></div>
<a name='sub_cov2'></a><h3 class=pageheader><code>cov2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
2-sample covariance

Input parameters:
    X       -   sample 1 (array indexes: [0..N-1])
    Y       -   sample 2 (array indexes: [0..N-1])
    N       -   N&gt;=0, sample size:
                * if given, only N leading elements of X/Y are processed
                * if not given, automatically determined from input sizes

Result:
    covariance (zero for N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cov2(real_1d_array x, real_1d_array y);
<b>double</b> alglib::cov2(real_1d_array x, real_1d_array y, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_c2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_covm'></a><h3 class=pageheader><code>covm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Covariance matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with covariance matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X are used
            * if not given, automatically determined from input size
    M   -   M&gt;0, number of variables:
            * if given, only leading M columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M,M], covariance matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::covm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::covm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_covm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::smp_covm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_covm2'></a><h3 class=pageheader><code>covm2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cross-covariance matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with covariance matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M1], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    Y   -   array[N,M2], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X/Y are used
            * if not given, automatically determined from input sizes
    M1  -   M1&gt;0, number of variables in X:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size
    M2  -   M2&gt;0, number of variables in Y:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M1,M2], cross-covariance matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::covm2(real_2d_array x, real_2d_array y, real_2d_array&amp; c);
<b>void</b> alglib::covm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_covm2(real_2d_array x, real_2d_array y, real_2d_array&amp; c);
<b>void</b> alglib::smp_covm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_pearsoncorr2'></a><h3 class=pageheader><code>pearsoncorr2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Pearson product-moment correlation coefficient

Input parameters:
    X       -   sample 1 (array indexes: [0..N-1])
    Y       -   sample 2 (array indexes: [0..N-1])
    N       -   N&gt;=0, sample size:
                * if given, only N leading elements of X/Y are processed
                * if not given, automatically determined from input sizes

Result:
    Pearson product-moment correlation coefficient
    (zero for N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::pearsoncorr2(real_1d_array x, real_1d_array y);
<b>double</b> alglib::pearsoncorr2(real_1d_array x, real_1d_array y, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_c2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_pearsoncorrelation'></a><h3 class=pageheader><code>pearsoncorrelation</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete function, we recommend to use PearsonCorr2().

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::pearsoncorrelation(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n);

</div></pre>
<a name='sub_pearsoncorrm'></a><h3 class=pageheader><code>pearsoncorrm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Pearson product-moment correlation matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with correlation matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X are used
            * if not given, automatically determined from input size
    M   -   M&gt;0, number of variables:
            * if given, only leading M columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M,M], correlation matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pearsoncorrm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::pearsoncorrm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_pearsoncorrm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::smp_pearsoncorrm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_pearsoncorrm2'></a><h3 class=pageheader><code>pearsoncorrm2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Pearson product-moment cross-correlation matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with correlation matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M1], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    Y   -   array[N,M2], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X/Y are used
            * if not given, automatically determined from input sizes
    M1  -   M1&gt;0, number of variables in X:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size
    M2  -   M2&gt;0, number of variables in Y:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M1,M2], cross-correlation matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pearsoncorrm2(
    real_2d_array x,
    real_2d_array y,
    real_2d_array&amp; c);
<b>void</b> alglib::pearsoncorrm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_pearsoncorrm2(
    real_2d_array x,
    real_2d_array y,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_pearsoncorrm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rankdata'></a><h3 class=pageheader><code>rankdata</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rankdata(real_2d_array&amp; xy);
<b>void</b> alglib::rankdata(
    real_2d_array&amp; xy,
    ae_int_t npoints,
    ae_int_t nfeatures);
<b>void</b> alglib::smp_rankdata(real_2d_array&amp; xy);
<b>void</b> alglib::smp_rankdata(
    real_2d_array&amp; xy,
    ae_int_t npoints,
    ae_int_t nfeatures);

</div></pre>
<a name='sub_rankdatacentered'></a><h3 class=pageheader><code>rankdatacentered</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rankdatacentered(real_2d_array&amp; xy);
<b>void</b> alglib::rankdatacentered(
    real_2d_array&amp; xy,
    ae_int_t npoints,
    ae_int_t nfeatures);
<b>void</b> alglib::smp_rankdatacentered(real_2d_array&amp; xy);
<b>void</b> alglib::smp_rankdatacentered(
    real_2d_array&amp; xy,
    ae_int_t npoints,
    ae_int_t nfeatures);

</div></pre>
<a name='sub_sampleadev'></a><h3 class=pageheader><code>sampleadev</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
ADev

Input parameters:
    X   -   sample
    N   -   N&gt;=0, sample size:
            * if given, only leading N elements of X are processed
            * if not given, automatically determined from size of X

Output parameters:
    ADev-   ADev

  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sampleadev(real_1d_array x, <b>double</b>&amp; adev);
<b>void</b> alglib::sampleadev(real_1d_array x, ae_int_t n, <b>double</b>&amp; adev);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_base' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_samplekurtosis'></a><h3 class=pageheader><code>samplekurtosis</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the kurtosis.

INPUT PARAMETERS:
    X       -   sample
    N       -   N&gt;=0, sample size:
                * if given, only leading N elements of X are processed
                * if not given, automatically determined from size of X

NOTE:

This function return result  which calculated by 'SampleMoments' function
and stored at 'Kurtosis' variable.


  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::samplekurtosis(real_1d_array x);
<b>double</b> alglib::samplekurtosis(real_1d_array x, ae_int_t n);

</div></pre>
<a name='sub_samplemean'></a><h3 class=pageheader><code>samplemean</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the mean.

INPUT PARAMETERS:
    X       -   sample
    N       -   N&gt;=0, sample size:
                * if given, only leading N elements of X are processed
                * if not given, automatically determined from size of X

NOTE:

This function return result  which calculated by 'SampleMoments' function
and stored at 'Mean' variable.


  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::samplemean(real_1d_array x);
<b>double</b> alglib::samplemean(real_1d_array x, ae_int_t n);

</div></pre>
<a name='sub_samplemedian'></a><h3 class=pageheader><code>samplemedian</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Median calculation.

Input parameters:
    X   -   sample (array indexes: [0..N-1])
    N   -   N&gt;=0, sample size:
            * if given, only leading N elements of X are processed
            * if not given, automatically determined from size of X

Output parameters:
    Median

  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::samplemedian(real_1d_array x, <b>double</b>&amp; median);
<b>void</b> alglib::samplemedian(real_1d_array x, ae_int_t n, <b>double</b>&amp; median);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_base' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_samplemoments'></a><h3 class=pageheader><code>samplemoments</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the distribution moments: mean, variance, skewness, kurtosis.

INPUT PARAMETERS:
    X       -   sample
    N       -   N&gt;=0, sample size:
                * if given, only leading N elements of X are processed
                * if not given, automatically determined from size of X

OUTPUT PARAMETERS
    Mean    -   mean.
    Variance-   variance.
    Skewness-   skewness (if variance&lt;&gt;0; zero otherwise).
    Kurtosis-   kurtosis (if variance&lt;&gt;0; zero otherwise).


  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::samplemoments(
    real_1d_array x,
    <b>double</b>&amp; mean,
    <b>double</b>&amp; variance,
    <b>double</b>&amp; skewness,
    <b>double</b>&amp; kurtosis);
<b>void</b> alglib::samplemoments(
    real_1d_array x,
    ae_int_t n,
    <b>double</b>&amp; mean,
    <b>double</b>&amp; variance,
    <b>double</b>&amp; skewness,
    <b>double</b>&amp; kurtosis);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_base' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_samplepercentile'></a><h3 class=pageheader><code>samplepercentile</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Percentile calculation.

Input parameters:
    X   -   sample (array indexes: [0..N-1])
    N   -   N&gt;=0, sample size:
            * if given, only leading N elements of X are processed
            * if not given, automatically determined from size of X
    P   -   percentile (0&lt;=P&lt;=1)

Output parameters:
    V   -   percentile

  -- ALGLIB --
     Copyright 01.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::samplepercentile(real_1d_array x, <b>double</b> p, <b>double</b>&amp; v);
<b>void</b> alglib::samplepercentile(
    real_1d_array x,
    ae_int_t n,
    <b>double</b> p,
    <b>double</b>&amp; v);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_base' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_sampleskewness'></a><h3 class=pageheader><code>sampleskewness</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the skewness.

INPUT PARAMETERS:
    X       -   sample
    N       -   N&gt;=0, sample size:
                * if given, only leading N elements of X are processed
                * if not given, automatically determined from size of X

NOTE:

This function return result  which calculated by 'SampleMoments' function
and stored at 'Skewness' variable.


  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::sampleskewness(real_1d_array x);
<b>double</b> alglib::sampleskewness(real_1d_array x, ae_int_t n);

</div></pre>
<a name='sub_samplevariance'></a><h3 class=pageheader><code>samplevariance</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the variance.

INPUT PARAMETERS:
    X       -   sample
    N       -   N&gt;=0, sample size:
                * if given, only leading N elements of X are processed
                * if not given, automatically determined from size of X

NOTE:

This function return result  which calculated by 'SampleMoments' function
and stored at 'Variance' variable.


  -- ALGLIB --
     Copyright 06.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::samplevariance(real_1d_array x);
<b>double</b> alglib::samplevariance(real_1d_array x, ae_int_t n);

</div></pre>
<a name='sub_spearmancorr2'></a><h3 class=pageheader><code>spearmancorr2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Spearman's rank correlation coefficient

Input parameters:
    X       -   sample 1 (array indexes: [0..N-1])
    Y       -   sample 2 (array indexes: [0..N-1])
    N       -   N&gt;=0, sample size:
                * if given, only N leading elements of X/Y are processed
                * if not given, automatically determined from input sizes

Result:
    Spearman's rank correlation coefficient
    (zero for N=0 or N=1)

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spearmancorr2(real_1d_array x, real_1d_array y);
<b>double</b> alglib::spearmancorr2(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_c2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spearmancorrm'></a><h3 class=pageheader><code>spearmancorrm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Spearman's rank correlation matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with correlation matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X are used
            * if not given, automatically determined from input size
    M   -   M&gt;0, number of variables:
            * if given, only leading M columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M,M], correlation matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spearmancorrm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::spearmancorrm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_spearmancorrm(real_2d_array x, real_2d_array&amp; c);
<b>void</b> alglib::smp_spearmancorrm(
    real_2d_array x,
    ae_int_t n,
    ae_int_t m,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spearmancorrm2'></a><h3 class=pageheader><code>spearmancorrm2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Spearman's rank cross-correlation matrix

SMP EDITION OF ALGLIB:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero cost. Although  multicore  version  is  pretty  efficient on
  ! large problems, we do not recommend you to use it on small problems -
  ! with correlation matrices smaller than 128*128.

INPUT PARAMETERS:
    X   -   array[N,M1], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    Y   -   array[N,M2], sample matrix:
            * J-th column corresponds to J-th variable
            * I-th row corresponds to I-th observation
    N   -   N&gt;=0, number of observations:
            * if given, only leading N rows of X/Y are used
            * if not given, automatically determined from input sizes
    M1  -   M1&gt;0, number of variables in X:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size
    M2  -   M2&gt;0, number of variables in Y:
            * if given, only leading M1 columns of X are used
            * if not given, automatically determined from input size

OUTPUT PARAMETERS:
    C   -   array[M1,M2], cross-correlation matrix (zero if N=0 or N=1)

  -- ALGLIB --
     Copyright 28.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spearmancorrm2(
    real_2d_array x,
    real_2d_array y,
    real_2d_array&amp; c);
<b>void</b> alglib::spearmancorrm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_spearmancorrm2(
    real_2d_array x,
    real_2d_array y,
    real_2d_array&amp; c);
<b>void</b> alglib::smp_spearmancorrm2(
    real_2d_array x,
    real_2d_array y,
    ae_int_t n,
    ae_int_t m1,
    ae_int_t m2,
    real_2d_array&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_basestat_d_cm2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spearmanrankcorrelation'></a><h3 class=pageheader><code>spearmanrankcorrelation</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete function, we recommend to use SpearmanCorr2().

    -- ALGLIB --
    Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spearmanrankcorrelation(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n);

</div></pre>
<a name='example_basestat_d_base'></a><h3 class=pageheader>basestat_d_base example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;statistics.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_1d_array x = <font color=blue><b>&quot;[0,1,4,9,16,25,36,49,64,81]&quot;</b></font>;
    <b>double</b> mean;
    <b>double</b> variance;
    <b>double</b> skewness;
    <b>double</b> kurtosis;
    <b>double</b> adev;
    <b>double</b> p;
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate calculation of sample moments</font>
    <font color=navy>// (mean, variance, skewness, kurtosis)</font>
    <font color=navy>//</font>
    samplemoments(x, mean, variance, skewness, kurtosis);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(mean)); <font color=navy>// EXPECTED: 28.5</font>
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(variance)); <font color=navy>// EXPECTED: 801.1667</font>
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(skewness)); <font color=navy>// EXPECTED: 0.5751</font>
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(kurtosis)); <font color=navy>// EXPECTED: -1.2666</font>

    <font color=navy>//</font>
    <font color=navy>// Average deviation</font>
    <font color=navy>//</font>
    sampleadev(x, adev);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(adev)); <font color=navy>// EXPECTED: 23.2</font>

    <font color=navy>//</font>
    <font color=navy>// Median and percentile</font>
    <font color=navy>//</font>
    samplemedian(x, v);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 20.5</font>
    p = 0.5;
    samplepercentile(x, p, v);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 20.5</font>
    <b>return</b> 0;
}


</pre><a name='example_basestat_d_c2'></a><h3 class=pageheader>basestat_d_c2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;statistics.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We have two samples - x and y, and want to measure dependency between them</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,1,4,9,16,25,36,49,64,81]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,1,2,3,4,5,6,7,8,9]&quot;</b></font>;
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// Three dependency measures are calculated:</font>
    <font color=navy>// * covariation</font>
    <font color=navy>// * Pearson correlation</font>
    <font color=navy>// * Spearman rank correlation</font>
    <font color=navy>//</font>
    v = cov2(x, y);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 82.5</font>
    v = pearsoncorr2(x, y);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.9627</font>
    v = spearmancorr2(x, y);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.000</font>
    <b>return</b> 0;
}


</pre><a name='example_basestat_d_cm'></a><h3 class=pageheader>basestat_d_cm example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;statistics.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// X is a sample matrix:</font>
    <font color=navy>// * I-th row corresponds to I-th observation</font>
    <font color=navy>// * J-th column corresponds to J-th variable</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[1,0,1],[1,1,0],[-1,1,0],[-2,-1,1],[-1,0,9]]&quot;</b></font>;
    real_2d_array c;

    <font color=navy>//</font>
    <font color=navy>// Three dependency measures are calculated:</font>
    <font color=navy>// * covariation</font>
    <font color=navy>// * Pearson correlation</font>
    <font color=navy>// * Spearman rank correlation</font>
    <font color=navy>//</font>
    <font color=navy>// Result is stored into C, with C[i,j] equal to correlation</font>
    <font color=navy>// (covariance) between I-th and J-th variables of X.</font>
    <font color=navy>//</font>
    covm(x, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[1.80,0.60,-1.40],[0.60,0.70,-0.80],[-1.40,-0.80,14.70]]</font>
    pearsoncorrm(x, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[1.000,0.535,-0.272],[0.535,1.000,-0.249],[-0.272,-0.249,1.000]]</font>
    spearmancorrm(x, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[1.000,0.556,-0.306],[0.556,1.000,-0.750],[-0.306,-0.750,1.000]]</font>
    <b>return</b> 0;
}


</pre><a name='example_basestat_d_cm2'></a><h3 class=pageheader>basestat_d_cm2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;statistics.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// X and Y are sample matrices:</font>
    <font color=navy>// * I-th row corresponds to I-th observation</font>
    <font color=navy>// * J-th column corresponds to J-th variable</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[1,0,1],[1,1,0],[-1,1,0],[-2,-1,1],[-1,0,9]]&quot;</b></font>;
    real_2d_array y = <font color=blue><b>&quot;[[2,3],[2,1],[-1,6],[-9,9],[7,1]]&quot;</b></font>;
    real_2d_array c;

    <font color=navy>//</font>
    <font color=navy>// Three dependency measures are calculated:</font>
    <font color=navy>// * covariation</font>
    <font color=navy>// * Pearson correlation</font>
    <font color=navy>// * Spearman rank correlation</font>
    <font color=navy>//</font>
    <font color=navy>// Result is stored into C, with C[i,j] equal to correlation</font>
    <font color=navy>// (covariance) between I-th variable of X and J-th variable of Y.</font>
    <font color=navy>//</font>
    covm2(x, y, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[4.100,-3.250],[2.450,-1.500],[13.450,-5.750]]</font>
    pearsoncorrm2(x, y, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[0.519,-0.699],[0.497,-0.518],[0.596,-0.433]]</font>
    spearmancorrm2(x, y, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [[0.541,-0.649],[0.216,-0.433],[0.433,-0.135]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_bdss></a><h2 class=pageheader><code>bdss</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dsoptimalsplit2' class=toc>dsoptimalsplit2</a><br>
<a href='#sub_dsoptimalsplit2fast' class=toc>dsoptimalsplit2fast</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_dsoptimalsplit2'></a><h3 class=pageheader><code>dsoptimalsplit2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Optimal binary classification

Algorithms finds optimal (=with minimal cross-entropy) binary partition.
Internal subroutine.

INPUT PARAMETERS:
    A       -   array[0..N-1], variable
    C       -   array[0..N-1], class numbers (0 or 1).
    N       -   array size

OUTPUT PARAMETERS:
    Info    -   completetion code:
                * -3, all values of A[] are same (partition is impossible)
                * -2, one of C[] is incorrect (&lt;0, &gt;1)
                * -1, incorrect pararemets were passed (N&lt;=0).
                *  1, OK
    Threshold-  partiton boundary. Left part contains values which are
                strictly less than Threshold. Right part contains values
                which are greater than or equal to Threshold.
    PAL, PBL-   probabilities P(0|v&lt;Threshold) and P(1|v&lt;Threshold)
    PAR, PBR-   probabilities P(0|v&gt;=Threshold) and P(1|v&gt;=Threshold)
    CVE     -   cross-validation estimate of cross-entropy

  -- ALGLIB --
     Copyright 22.05.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dsoptimalsplit2(
    real_1d_array a,
    integer_1d_array c,
    ae_int_t n,
    ae_int_t&amp; info,
    <b>double</b>&amp; threshold,
    <b>double</b>&amp; pal,
    <b>double</b>&amp; pbl,
    <b>double</b>&amp; par,
    <b>double</b>&amp; pbr,
    <b>double</b>&amp; cve);

</div></pre>
<a name='sub_dsoptimalsplit2fast'></a><h3 class=pageheader><code>dsoptimalsplit2fast</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Optimal partition, internal subroutine. Fast version.

Accepts:
    A       array[0..N-1]       array of attributes     array[0..N-1]
    C       array[0..N-1]       array of class labels
    TiesBuf array[0..N]         temporaries (ties)
    CntBuf  array[0..2*NC-1]    temporaries (counts)
    Alpha                       centering factor (0&lt;=alpha&lt;=1, recommended value - 0.05)
    BufR    array[0..N-1]       temporaries
    BufI    array[0..N-1]       temporaries

Output:
    Info    error code (&quot;&gt;0&quot;=OK, &quot;&lt;0&quot;=bad)
    RMS     training set RMS error
    CVRMS   leave-one-out RMS error

Note:
    content of all arrays is changed by subroutine;
    it doesn't allocate temporaries.

  -- ALGLIB --
     Copyright 11.12.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dsoptimalsplit2fast(
    real_1d_array&amp; a,
    integer_1d_array&amp; c,
    integer_1d_array&amp; tiesbuf,
    integer_1d_array&amp; cntbuf,
    real_1d_array&amp; bufr,
    integer_1d_array&amp; bufi,
    ae_int_t n,
    ae_int_t nc,
    <b>double</b> alpha,
    ae_int_t&amp; info,
    <b>double</b>&amp; threshold,
    <b>double</b>&amp; rms,
    <b>double</b>&amp; cvrms);

</div></pre>
<a name=unit_bdsvd></a><h2 class=pageheader><code>bdsvd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixbdsvd' class=toc>rmatrixbdsvd</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixbdsvd'></a><h3 class=pageheader><code>rmatrixbdsvd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Singular value decomposition of a bidiagonal matrix (extended algorithm)

The algorithm performs the singular value decomposition  of  a  bidiagonal
matrix B (upper or lower) representing it as B = Q*S*P^T, where Q and  P -
orthogonal matrices, S - diagonal matrix with non-negative elements on the
main diagonal, in descending order.

The  algorithm  finds  singular  values.  In  addition,  the algorithm can
calculate  matrices  Q  and P (more precisely, not the matrices, but their
product  with  given  matrices U and VT - U*Q and (P^T)*VT)).  Of  course,
matrices U and VT can be of any type, including identity. Furthermore, the
algorithm can calculate Q'*C (this product is calculated more  effectively
than U*Q,  because  this calculation operates with rows instead  of matrix
columns).

The feature of the algorithm is its ability to find  all  singular  values
including those which are arbitrarily close to 0  with  relative  accuracy
close to  machine precision. If the parameter IsFractionalAccuracyRequired
is set to True, all singular values will have high relative accuracy close
to machine precision. If the parameter is set to False, only  the  biggest
singular value will have relative accuracy  close  to  machine  precision.
The absolute error of other singular values is equal to the absolute error
of the biggest singular value.

Input parameters:
    D       -   main diagonal of matrix B.
                Array whose index ranges within [0..N-1].
    E       -   superdiagonal (or subdiagonal) of matrix B.
                Array whose index ranges within [0..N-2].
    N       -   size of matrix B.
    IsUpper -   True, if the matrix is upper bidiagonal.
    IsFractionalAccuracyRequired -
                THIS PARAMETER IS IGNORED SINCE ALGLIB 3.5.0
                SINGULAR VALUES ARE ALWAYS SEARCHED WITH HIGH ACCURACY.
    U       -   matrix to be multiplied by Q.
                Array whose indexes range within [0..NRU-1, 0..N-1].
                The matrix can be bigger, in that case only the  submatrix
                [0..NRU-1, 0..N-1] will be multiplied by Q.
    NRU     -   number of rows in matrix U.
    C       -   matrix to be multiplied by Q'.
                Array whose indexes range within [0..N-1, 0..NCC-1].
                The matrix can be bigger, in that case only the  submatrix
                [0..N-1, 0..NCC-1] will be multiplied by Q'.
    NCC     -   number of columns in matrix C.
    VT      -   matrix to be multiplied by P^T.
                Array whose indexes range within [0..N-1, 0..NCVT-1].
                The matrix can be bigger, in that case only the  submatrix
                [0..N-1, 0..NCVT-1] will be multiplied by P^T.
    NCVT    -   number of columns in matrix VT.

Output parameters:
    D       -   singular values of matrix B in descending order.
    U       -   if NRU&gt;0, contains matrix U*Q.
    VT      -   if NCVT&gt;0, contains matrix (P^T)*VT.
    C       -   if NCC&gt;0, contains matrix Q'*C.

Result:
    True, if the algorithm has converged.
    False, if the algorithm hasn't converged (rare case).

Additional information:
    The type of convergence is controlled by the internal  parameter  TOL.
    If the parameter is greater than 0, the singular values will have
    relative accuracy TOL. If TOL&lt;0, the singular values will have
    absolute accuracy ABS(TOL)*norm(B).
    By default, |TOL| falls within the range of 10*Epsilon and 100*Epsilon,
    where Epsilon is the machine precision. It is not  recommended  to  use
    TOL less than 10*Epsilon since this will  considerably  slow  down  the
    algorithm and may not lead to error decreasing.
History:
    * 31 March, 2007.
        changed MAXITR from 6 to 12.

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     October 31, 1999.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::rmatrixbdsvd(
    real_1d_array&amp; d,
    real_1d_array e,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isfractionalaccuracyrequired,
    real_2d_array&amp; u,
    ae_int_t nru,
    real_2d_array&amp; c,
    ae_int_t ncc,
    real_2d_array&amp; vt,
    ae_int_t ncvt);

</div></pre>
<a name=unit_bessel></a><h2 class=pageheader><code>bessel</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_besseli0' class=toc>besseli0</a><br>
<a href='#sub_besseli1' class=toc>besseli1</a><br>
<a href='#sub_besselj0' class=toc>besselj0</a><br>
<a href='#sub_besselj1' class=toc>besselj1</a><br>
<a href='#sub_besseljn' class=toc>besseljn</a><br>
<a href='#sub_besselk0' class=toc>besselk0</a><br>
<a href='#sub_besselk1' class=toc>besselk1</a><br>
<a href='#sub_besselkn' class=toc>besselkn</a><br>
<a href='#sub_bessely0' class=toc>bessely0</a><br>
<a href='#sub_bessely1' class=toc>bessely1</a><br>
<a href='#sub_besselyn' class=toc>besselyn</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_besseli0'></a><h3 class=pageheader><code>besseli0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modified Bessel function of order zero

Returns modified Bessel function of order zero of the
argument.

The function is defined as i0(x) = j0( ix ).

The range is partitioned into the two intervals [0,8] and
(8, infinity).  Chebyshev polynomial expansions are employed
in each interval.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,30        30000       5.8e-16     1.4e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besseli0(<b>double</b> x);

</div></pre>
<a name='sub_besseli1'></a><h3 class=pageheader><code>besseli1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modified Bessel function of order one

Returns modified Bessel function of order one of the
argument.

The function is defined as i1(x) = -i j1( ix ).

The range is partitioned into the two intervals [0,8] and
(8, infinity).  Chebyshev polynomial expansions are employed
in each interval.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       30000       1.9e-15     2.1e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1985, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besseli1(<b>double</b> x);

</div></pre>
<a name='sub_besselj0'></a><h3 class=pageheader><code>besselj0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of order zero

Returns Bessel function of order zero of the argument.

The domain is divided into the intervals [0, 5] and
(5, infinity). In the first interval the following rational
approximation is used:


       2         2
(w - r  ) (w - r  ) P (w) / Q (w)
      1         2    3       8

           2
where w = x  and the two r's are zeros of the function.

In the second interval, the Hankel asymptotic expansion
is employed with two rational functions of degree 6/6
and 7/7.

ACCURACY:

                     Absolute error:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       60000       4.2e-16     1.1e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselj0(<b>double</b> x);

</div></pre>
<a name='sub_besselj1'></a><h3 class=pageheader><code>besselj1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of order one

Returns Bessel function of order one of the argument.

The domain is divided into the intervals [0, 8] and
(8, infinity). In the first interval a 24 term Chebyshev
expansion is used. In the second, the asymptotic
trigonometric representation is employed using two
rational functions of degree 5/5.

ACCURACY:

                     Absolute error:
arithmetic   domain      # trials      peak         rms
   IEEE      0, 30       30000       2.6e-16     1.1e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselj1(<b>double</b> x);

</div></pre>
<a name='sub_besseljn'></a><h3 class=pageheader><code>besseljn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of integer order

Returns Bessel function of order n, where n is a
(possibly negative) integer.

The ratio of jn(x) to j0(x) is computed by backward
recurrence.  First the ratio jn/jn-1 is found by a
continued fraction expansion.  Then the recurrence
relating successive orders is applied until j0 or j1 is
reached.

If n = 0 or 1 the routine for j0 or j1 is called
directly.

ACCURACY:

                     Absolute error:
arithmetic   range      # trials      peak         rms
   IEEE      0, 30        5000       4.4e-16     7.9e-17


Not suitable for large n or x. Use jv() (fractional order) instead.

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besseljn(ae_int_t n, <b>double</b> x);

</div></pre>
<a name='sub_besselk0'></a><h3 class=pageheader><code>besselk0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modified Bessel function, second kind, order zero

Returns modified Bessel function of the second kind
of order zero of the argument.

The range is partitioned into the two intervals [0,8] and
(8, infinity).  Chebyshev polynomial expansions are employed
in each interval.

ACCURACY:

Tested at 2000 random points between 0 and 8.  Peak absolute
error (relative when K0 &gt; 1) was 1.46e-14; rms, 4.26e-15.
                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       30000       1.2e-15     1.6e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselk0(<b>double</b> x);

</div></pre>
<a name='sub_besselk1'></a><h3 class=pageheader><code>besselk1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modified Bessel function, second kind, order one

Computes the modified Bessel function of the second kind
of order one of the argument.

The range is partitioned into the two intervals [0,2] and
(2, infinity).  Chebyshev polynomial expansions are employed
in each interval.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       30000       1.2e-15     1.6e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselk1(<b>double</b> x);

</div></pre>
<a name='sub_besselkn'></a><h3 class=pageheader><code>besselkn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modified Bessel function, second kind, integer order

Returns modified Bessel function of the second kind
of order n of the argument.

The range is partitioned into the two intervals [0,9.55] and
(9.55, infinity).  An ascending power series is used in the
low range, and an asymptotic expansion in the high range.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,30        90000       1.8e-8      3.0e-10

Error is high only near the crossover point x = 9.55
between the two expansions used.

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselkn(ae_int_t nn, <b>double</b> x);

</div></pre>
<a name='sub_bessely0'></a><h3 class=pageheader><code>bessely0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of the second kind, order zero

Returns Bessel function of the second kind, of order
zero, of the argument.

The domain is divided into the intervals [0, 5] and
(5, infinity). In the first interval a rational approximation
R(x) is employed to compute
  y0(x)  = R(x)  +   2 * log(x) * j0(x) / PI.
Thus a call to j0() is required.

In the second interval, the Hankel asymptotic expansion
is employed with two rational functions of degree 6/6
and 7/7.



ACCURACY:

 Absolute error, when y0(x) &lt; 1; else relative error:

arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       30000       1.3e-15     1.6e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::bessely0(<b>double</b> x);

</div></pre>
<a name='sub_bessely1'></a><h3 class=pageheader><code>bessely1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of second kind of order one

Returns Bessel function of the second kind of order one
of the argument.

The domain is divided into the intervals [0, 8] and
(8, infinity). In the first interval a 25 term Chebyshev
expansion is used, and a call to j1() is required.
In the second, the asymptotic trigonometric representation
is employed using two rational functions of degree 5/5.

ACCURACY:

                     Absolute error:
arithmetic   domain      # trials      peak         rms
   IEEE      0, 30       30000       1.0e-15     1.3e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::bessely1(<b>double</b> x);

</div></pre>
<a name='sub_besselyn'></a><h3 class=pageheader><code>besselyn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bessel function of second kind of integer order

Returns Bessel function of order n, where n is a
(possibly negative) integer.

The function is evaluated by forward recurrence on
n, starting with values computed by the routines
y0() and y1().

If n = 0 or 1 the routine for y0 or y1 is called
directly.

ACCURACY:
                     Absolute error, except relative
                     when y &gt; 1:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       30000       3.4e-15     4.3e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::besselyn(ae_int_t n, <b>double</b> x);

</div></pre>
<a name=unit_betaf></a><h2 class=pageheader><code>betaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_beta' class=toc>beta</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_beta'></a><h3 class=pageheader><code>beta</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Beta function


                  -     -
                 | (a) | (b)
beta( a, b )  =  -----------.
                    -
                   | (a+b)

For large arguments the logarithm of the function is
evaluated using lgam(), then exponentiated.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE       0,30       30000       8.1e-14     1.1e-14

Cephes Math Library Release 2.0:  April, 1987
Copyright 1984, 1987 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::beta(<b>double</b> a, <b>double</b> b);

</div></pre>
<a name=unit_binomialdistr></a><h2 class=pageheader><code>binomialdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_binomialcdistribution' class=toc>binomialcdistribution</a><br>
<a href='#sub_binomialdistribution' class=toc>binomialdistribution</a><br>
<a href='#sub_invbinomialdistribution' class=toc>invbinomialdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_binomialcdistribution'></a><h3 class=pageheader><code>binomialcdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complemented binomial distribution

Returns the sum of the terms k+1 through n of the Binomial
probability density:

  n
  --  ( n )   j      n-j
  &gt;   (   )  p  (1-p)
  --  ( j )
 j=k+1

The terms are not summed directly; instead the incomplete
beta integral is employed, according to the formula

y = bdtrc( k, n, p ) = incbet( k+1, n-k, p ).

The arguments must be positive, with p ranging from 0 to 1.

ACCURACY:

Tested at random points (a,b,p).

              a,b                     Relative error:
arithmetic  domain     # trials      peak         rms
 For p between 0.001 and 1:
   IEEE     0,100       100000      6.7e-15     8.2e-16
 For p between 0 and .001:
   IEEE     0,100       100000      1.5e-13     2.7e-15

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::binomialcdistribution(ae_int_t k, ae_int_t n, <b>double</b> p);

</div></pre>
<a name='sub_binomialdistribution'></a><h3 class=pageheader><code>binomialdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Binomial distribution

Returns the sum of the terms 0 through k of the Binomial
probability density:

  k
  --  ( n )   j      n-j
  &gt;   (   )  p  (1-p)
  --  ( j )
 j=0

The terms are not summed directly; instead the incomplete
beta integral is employed, according to the formula

y = bdtr( k, n, p ) = incbet( n-k, k+1, 1-p ).

The arguments must be positive, with p ranging from 0 to 1.

ACCURACY:

Tested at random points (a,b,p), with p between 0 and 1.

              a,b                     Relative error:
arithmetic  domain     # trials      peak         rms
 For p between 0.001 and 1:
   IEEE     0,100       100000      4.3e-15     2.6e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::binomialdistribution(ae_int_t k, ae_int_t n, <b>double</b> p);

</div></pre>
<a name='sub_invbinomialdistribution'></a><h3 class=pageheader><code>invbinomialdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse binomial distribution

Finds the event probability p such that the sum of the
terms 0 through k of the Binomial probability density
is equal to the given cumulative probability y.

This is accomplished using the inverse beta integral
function and the relation

1 - p = incbi( n-k, k+1, y ).

ACCURACY:

Tested at random points (a,b,p).

              a,b                     Relative error:
arithmetic  domain     # trials      peak         rms
 For p between 0.001 and 1:
   IEEE     0,100       100000      2.3e-14     6.4e-16
   IEEE     0,10000     100000      6.6e-12     1.2e-13
 For p between 10^-6 and 0.001:
   IEEE     0,100       100000      2.0e-12     1.3e-14
   IEEE     0,10000     100000      1.5e-12     3.2e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invbinomialdistribution(ae_int_t k, ae_int_t n, <b>double</b> y);

</div></pre>
<a name=unit_chebyshev></a><h2 class=pageheader><code>chebyshev</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_chebyshevcalculate' class=toc>chebyshevcalculate</a><br>
<a href='#sub_chebyshevcoefficients' class=toc>chebyshevcoefficients</a><br>
<a href='#sub_chebyshevsum' class=toc>chebyshevsum</a><br>
<a href='#sub_fromchebyshev' class=toc>fromchebyshev</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_chebyshevcalculate'></a><h3 class=pageheader><code>chebyshevcalculate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the value of the Chebyshev polynomials of the
first and second kinds.

Parameters:
    r   -   polynomial kind, either 1 or 2.
    n   -   degree, n&gt;=0
    x   -   argument, -1 &lt;= x &lt;= 1

Result:
    the value of the Chebyshev polynomial at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::chebyshevcalculate(ae_int_t r, ae_int_t n, <b>double</b> x);

</div></pre>
<a name='sub_chebyshevcoefficients'></a><h3 class=pageheader><code>chebyshevcoefficients</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Representation of Tn as C[0] + C[1]*X + ... + C[N]*X^N

Input parameters:
    N   -   polynomial degree, n&gt;=0

Output parameters:
    C   -   coefficients
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::chebyshevcoefficients(ae_int_t n, real_1d_array&amp; c);

</div></pre>
<a name='sub_chebyshevsum'></a><h3 class=pageheader><code>chebyshevsum</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Summation of Chebyshev polynomials using Clenshaws recurrence formula.

This routine calculates
    c[0]*T0(x) + c[1]*T1(x) + ... + c[N]*TN(x)
or
    c[0]*U0(x) + c[1]*U1(x) + ... + c[N]*UN(x)
depending on the R.

Parameters:
    r   -   polynomial kind, either 1 or 2.
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Chebyshev polynomial at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::chebyshevsum(
    real_1d_array c,
    ae_int_t r,
    ae_int_t n,
    <b>double</b> x);

</div></pre>
<a name='sub_fromchebyshev'></a><h3 class=pageheader><code>fromchebyshev</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conversion of a series of Chebyshev polynomials to a power series.

Represents A[0]*T0(x) + A[1]*T1(x) + ... + A[N]*Tn(x) as
B[0] + B[1]*X + ... + B[N]*X^N.

Input parameters:
    A   -   Chebyshev series coefficients
    N   -   degree, N&gt;=0

Output parameters
    B   -   power series coefficients
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fromchebyshev(real_1d_array a, ae_int_t n, real_1d_array&amp; b);

</div></pre>
<a name=unit_chisquaredistr></a><h2 class=pageheader><code>chisquaredistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_chisquarecdistribution' class=toc>chisquarecdistribution</a><br>
<a href='#sub_chisquaredistribution' class=toc>chisquaredistribution</a><br>
<a href='#sub_invchisquaredistribution' class=toc>invchisquaredistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_chisquarecdistribution'></a><h3 class=pageheader><code>chisquarecdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complemented Chi-square distribution

Returns the area under the right hand tail (from x to
infinity) of the Chi square probability density function
with v degrees of freedom:

                                 inf.
                                   -
                       1          | |  v/2-1  -t/2
 P( x | v )   =   -----------     |   t      e     dt
                   v/2  -       | |
                  2    | (v/2)   -
                                  x

where x is the Chi-square variable.

The incomplete gamma integral is used, according to the
formula

y = chdtr( v, x ) = igamc( v/2.0, x/2.0 ).

The arguments must both be positive.

ACCURACY:

See incomplete gamma function

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::chisquarecdistribution(<b>double</b> v, <b>double</b> x);

</div></pre>
<a name='sub_chisquaredistribution'></a><h3 class=pageheader><code>chisquaredistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Chi-square distribution

Returns the area under the left hand tail (from 0 to x)
of the Chi square probability density function with
v degrees of freedom.


                                  x
                                   -
                       1          | |  v/2-1  -t/2
 P( x | v )   =   -----------     |   t      e     dt
                   v/2  -       | |
                  2    | (v/2)   -
                                  0

where x is the Chi-square variable.

The incomplete gamma integral is used, according to the
formula

y = chdtr( v, x ) = igam( v/2.0, x/2.0 ).

The arguments must both be positive.

ACCURACY:

See incomplete gamma function


Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::chisquaredistribution(<b>double</b> v, <b>double</b> x);

</div></pre>
<a name='sub_invchisquaredistribution'></a><h3 class=pageheader><code>invchisquaredistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of complemented Chi-square distribution

Finds the Chi-square argument x such that the integral
from x to infinity of the Chi-square density is equal
to the given cumulative probability y.

This is accomplished using the inverse gamma integral
function and the relation

   x/2 = igami( df/2, y );

ACCURACY:

See inverse incomplete gamma function


Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invchisquaredistribution(<b>double</b> v, <b>double</b> y);

</div></pre>
<a name=unit_clustering></a><h2 class=pageheader><code>clustering</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_ahcreport' class=toc>ahcreport</a><br>
<a href='#struct_clusterizerstate' class=toc>clusterizerstate</a><br>
<a href='#struct_kmeansreport' class=toc>kmeansreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_clusterizercreate' class=toc>clusterizercreate</a><br>
<a href='#sub_clusterizergetdistances' class=toc>clusterizergetdistances</a><br>
<a href='#sub_clusterizergetkclusters' class=toc>clusterizergetkclusters</a><br>
<a href='#sub_clusterizerrunahc' class=toc>clusterizerrunahc</a><br>
<a href='#sub_clusterizerrunkmeans' class=toc>clusterizerrunkmeans</a><br>
<a href='#sub_clusterizerseparatedbycorr' class=toc>clusterizerseparatedbycorr</a><br>
<a href='#sub_clusterizerseparatedbydist' class=toc>clusterizerseparatedbydist</a><br>
<a href='#sub_clusterizersetahcalgo' class=toc>clusterizersetahcalgo</a><br>
<a href='#sub_clusterizersetdistances' class=toc>clusterizersetdistances</a><br>
<a href='#sub_clusterizersetkmeanslimits' class=toc>clusterizersetkmeanslimits</a><br>
<a href='#sub_clusterizersetpoints' class=toc>clusterizersetpoints</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_clst_ahc' class=toc>clst_ahc</a></td><td width=15>&nbsp;</td><td>Simple hierarchical clusterization with Euclidean distance function</td></tr>
<tr align=left valign=top><td><a href='#example_clst_distance' class=toc>clst_distance</a></td><td width=15>&nbsp;</td><td>Clusterization with different metric types</td></tr>
<tr align=left valign=top><td><a href='#example_clst_kclusters' class=toc>clst_kclusters</a></td><td width=15>&nbsp;</td><td>Obtaining K top clusters from clusterization tree</td></tr>
<tr align=left valign=top><td><a href='#example_clst_kmeans' class=toc>clst_kmeans</a></td><td width=15>&nbsp;</td><td>Simple k-means clusterization</td></tr>
<tr align=left valign=top><td><a href='#example_clst_linkage' class=toc>clst_linkage</a></td><td width=15>&nbsp;</td><td>Clusterization with different linkage types</td></tr>
</table></div>
<a name='struct_ahcreport'></a><h3 class=pageheader><code>ahcreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure  is used to store results of the agglomerative hierarchical
clustering (AHC).

Following information is returned:

* NPoints contains number of points in the original dataset

* Z contains information about merges performed  (see below).  Z  contains
  indexes from the original (unsorted) dataset and it can be used when you
  need to know what points were merged. However, it is not convenient when
  you want to build a dendrograd (see below).

* if  you  want  to  build  dendrogram, you  can use Z, but it is not good
  option, because Z contains  indexes from  unsorted  dataset.  Dendrogram
  built from such dataset is likely to have intersections. So, you have to
  reorder you points before building dendrogram.
  Permutation which reorders point is returned in P. Another representation
  of  merges,  which  is  more  convenient for dendorgram construction, is
  returned in PM.

* more information on format of Z, P and PM can be found below and in the
  examples from ALGLIB Reference Manual.

FORMAL DESCRIPTION OF FIELDS:
    NPoints         number of points
    Z               array[NPoints-1,2],  contains   indexes   of  clusters
                    linked in pairs to  form  clustering  tree.  I-th  row
                    corresponds to I-th merge:
                    * Z[I,0] - index of the first cluster to merge
                    * Z[I,1] - index of the second cluster to merge
                    * Z[I,0]&lt;Z[I,1]
                    * clusters are  numbered  from 0 to 2*NPoints-2,  with
                      indexes from 0 to NPoints-1 corresponding to  points
                      of the original dataset, and indexes from NPoints to
                      2*NPoints-2  correspond  to  clusters  generated  by
                      subsequent  merges  (I-th  row  of Z creates cluster
                      with index NPoints+I).

                    IMPORTANT: indexes in Z[] are indexes in the ORIGINAL,
                    unsorted dataset. In addition to  Z algorithm  outputs
                    permutation which rearranges points in such  way  that
                    subsequent merges are  performed  on  adjacent  points
                    (such order is needed if you want to build dendrogram).
                    However,  indexes  in  Z  are  related  to   original,
                    unrearranged sequence of points.

    P               array[NPoints], permutation which reorders points  for
                    dendrogram  construction.  P[i] contains  index of the
                    position  where  we  should  move  I-th  point  of the
                    original dataset in order to apply merges PZ/PM.

    PZ              same as Z, but for permutation of points given  by  P.
                    The  only  thing  which  changed  are  indexes  of the
                    original points; indexes of clusters remained same.

    MergeDist       array[NPoints-1], contains distances between  clusters
                    being merged (MergeDist[i] correspond to merge  stored
                    in Z[i,...]).

    PM              array[NPoints-1,6], another representation of  merges,
                    which is suited for dendrogram construction. It  deals
                    with rearranged points (permutation P is applied)  and
                    represents merges in a form which different  from  one
                    used by Z.
                    For each I from 0 to NPoints-2, I-th row of PM represents
                    merge performed on two clusters C0 and C1. Here:
                    * C0 contains points with indexes PM[I,0]...PM[I,1]
                    * C1 contains points with indexes PM[I,2]...PM[I,3]
                    * indexes stored in PM are given for dataset sorted
                      according to permutation P
                    * PM[I,1]=PM[I,2]-1 (only adjacent clusters are merged)
                    * PM[I,0]&lt;=PM[I,1], PM[I,2]&lt;=PM[I,3], i.e. both
                      clusters contain at least one point
                    * heights of &quot;subdendrograms&quot; corresponding  to  C0/C1
                      are stored in PM[I,4]  and  PM[I,5].  Subdendrograms
                      corresponding   to   single-point   clusters    have
                      height=0. Dendrogram of the merge result has  height
                      H=max(H0,H1)+1.

NOTE: there is one-to-one correspondence between merges described by Z and
      PM. I-th row of Z describes same merge of clusters as I-th row of PM,
      with &quot;left&quot; cluster from Z corresponding to the &quot;left&quot; one from PM.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> ahcreport
{
    ae_int_t             npoints;
    integer_1d_array     p;
    integer_2d_array     z;
    integer_2d_array     pz;
    integer_2d_array     pm;
    real_1d_array        mergedist;
};

</div></pre>
<a name='struct_clusterizerstate'></a><h3 class=pageheader><code>clusterizerstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure is a clusterization engine.

You should not try to access its fields directly.
Use ALGLIB functions in order to work with this object.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> clusterizerstate
{
};

</div></pre>
<a name='struct_kmeansreport'></a><h3 class=pageheader><code>kmeansreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  structure   is  used  to  store  results of the k-means++ clustering
algorithm.

Following information is always returned:
* NPoints contains number of points in the original dataset
* TerminationType contains completion code, negative on failure, positive
  on success
* K contains number of clusters

For positive TerminationType we return:
* NFeatures contains number of variables in the original dataset
* C, which contains centers found by algorithm
* CIdx, which maps points of the original dataset to clusters

FORMAL DESCRIPTION OF FIELDS:
    NPoints         number of points, &gt;=0
    NFeatures       number of variables, &gt;=1
    TerminationType completion code:
                    * -5 if  distance  type  is  anything  different  from
                         Euclidean metric
                    * -3 for degenerate dataset: a) less  than  K  distinct
                         points, b) K=0 for non-empty dataset.
                    * +1 for successful completion
    K               number of clusters
    C               array[K,NFeatures], rows of the array store centers
    CIdx            array[NPoints], which contains cluster indexes

  -- ALGLIB --
     Copyright 27.11.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> kmeansreport
{
    ae_int_t             npoints;
    ae_int_t             nfeatures;
    ae_int_t             terminationtype;
    ae_int_t             k;
    real_2d_array        c;
    integer_1d_array     cidx;
};

</div></pre>
<a name='sub_clusterizercreate'></a><h3 class=pageheader><code>clusterizercreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function initializes clusterizer object. Newly initialized object  is
empty, i.e. it does not contain dataset. You should use it as follows:
1. creation
2. dataset is added with ClusterizerSetPoints()
3. additional parameters are set
3. clusterization is performed with one of the clustering functions

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizercreate(clusterizerstate&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_ahc' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_clst_kmeans' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_clst_linkage' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_clst_distance' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_clst_kclusters' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_clusterizergetdistances'></a><h3 class=pageheader><code>clusterizergetdistances</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns distance matrix for dataset

FOR USERS OF SMP EDITION:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero  cost.  Multicore  version  is  pretty  efficient  on  large
  ! problems  which  need  more  than  1.000.000 operations to be solved,
  ! gives  moderate  speed-up in mid-range (from 100.000 to 1.000.000 CPU
  ! cycles), but gives no speed-up for small problems (less than  100.000
  ! operations).

INPUT PARAMETERS:
    XY      -   array[NPoints,NFeatures], dataset
    NPoints -   number of points, &gt;=0
    NFeatures-  number of features, &gt;=1
    DistType-   distance function:
                *  0    Chebyshev distance  (L-inf norm)
                *  1    city block distance (L1 norm)
                *  2    Euclidean distance  (L2 norm)
                * 10    Pearson correlation:
                        dist(a,b) = 1-corr(a,b)
                * 11    Absolute Pearson correlation:
                        dist(a,b) = 1-|corr(a,b)|
                * 12    Uncentered Pearson correlation (cosine of the angle):
                        dist(a,b) = a'*b/(|a|*|b|)
                * 13    Absolute uncentered Pearson correlation
                        dist(a,b) = |a'*b|/(|a|*|b|)
                * 20    Spearman rank correlation:
                        dist(a,b) = 1-rankcorr(a,b)
                * 21    Absolute Spearman rank correlation
                        dist(a,b) = 1-|rankcorr(a,b)|

OUTPUT PARAMETERS:
    D       -   array[NPoints,NPoints], distance matrix
                (full matrix is returned, with lower and upper triangles)

NOTES: different distance functions have different performance penalty:
       * Euclidean or Pearson correlation distances are the fastest ones
       * Spearman correlation distance function is a bit slower
       * city block and Chebyshev distances are order of magnitude slower

       The reason behing difference in performance is that correlation-based
       distance functions are computed using optimized linear algebra kernels,
       while Chebyshev and city block distance functions are computed using
       simple nested loops with two branches at each iteration.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizergetdistances(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nfeatures,
    ae_int_t disttype,
    real_2d_array&amp; d);
<b>void</b> alglib::smp_clusterizergetdistances(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nfeatures,
    ae_int_t disttype,
    real_2d_array&amp; d);

</div></pre>
<a name='sub_clusterizergetkclusters'></a><h3 class=pageheader><code>clusterizergetkclusters</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function takes as input clusterization report Rep,  desired  clusters
count K, and builds top K clusters from hierarchical clusterization  tree.
It returns assignment of points to clusters (array of cluster indexes).

INPUT PARAMETERS:
    Rep     -   report from ClusterizerRunAHC() performed on XY
    K       -   desired number of clusters, 1&lt;=K&lt;=NPoints.
                K can be zero only when NPoints=0.

OUTPUT PARAMETERS:
    CIdx    -   array[NPoints], I-th element contains cluster index  (from
                0 to K-1) for I-th point of the dataset.
    CZ      -   array[K]. This array allows  to  convert  cluster  indexes
                returned by this function to indexes used by  Rep.Z.  J-th
                cluster returned by this function corresponds to  CZ[J]-th
                cluster stored in Rep.Z/PZ/PM.
                It is guaranteed that CZ[I]&lt;CZ[I+1].

NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
      Although  they  were  obtained  by  manipulation with top K nodes of
      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
      function does not return information about hierarchy.  Each  of  the
      clusters stand on its own.

NOTE: Cluster indexes returned by this function  does  not  correspond  to
      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
      representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
      representation returned by this function.  Each  of  representations
      has its own clusters indexing system (former uses [0, 2*NPoints-2]),
      while latter uses [0..K-1]), although  it  is  possible  to  perform
      conversion from one system to another by means of CZ array, returned
      by this function, which allows you to convert indexes stored in CIdx
      to the numeration system used by Rep.Z.

NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
      it will perform many times faster than  for  K=100.  Its  worst-case
      performance is O(N*K), although in average case  it  perform  better
      (up to O(N*log(K))).

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizergetkclusters(
    ahcreport rep,
    ae_int_t k,
    integer_1d_array&amp; cidx,
    integer_1d_array&amp; cz);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_linkage' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_clst_kclusters' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_clusterizerrunahc'></a><h3 class=pageheader><code>clusterizerrunahc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function performs agglomerative hierarchical clustering

FOR USERS OF SMP EDITION:

  ! This function can utilize multicore capabilities of  your system.  In
  ! order to do this you have to call version with &quot;smp_&quot; prefix,   which
  ! indicates that multicore code will be used.
  !
  ! This note is given for users of SMP edition; if you use GPL  edition,
  ! or commercial edition of ALGLIB without SMP support, you  still  will
  ! be able to call smp-version of this function,  but  all  computations
  ! will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.
  !
  ! You should remember that starting/stopping worker thread always  have
  ! non-zero  cost.  Multicore  version  is  pretty  efficient  on  large
  ! problems  which  need  more  than  1.000.000 operations to be solved,
  ! gives  moderate  speed-up in mid-range (from 100.000 to 1.000.000 CPU
  ! cycles), but gives no speed-up for small problems (less than  100.000
  ! operations).

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()

OUTPUT PARAMETERS:
    Rep     -   clustering results; see description of AHCReport
                structure for more information.

NOTE 1: hierarchical clustering algorithms require large amounts of memory.
        In particular, this implementation needs  sizeof(double)*NPoints^2
        bytes, which are used to store distance matrix. In  case  we  work
        with user-supplied matrix, this amount is multiplied by 2 (we have
        to store original matrix and to work with its copy).

        For example, problem with 10000 points  would require 800M of RAM,
        even when working in a 1-dimensional space.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizerrunahc(clusterizerstate s, ahcreport&amp; rep);
<b>void</b> alglib::smp_clusterizerrunahc(clusterizerstate s, ahcreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_ahc' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_clst_kmeans' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_clst_linkage' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_clst_distance' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_clst_kclusters' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_clusterizerrunkmeans'></a><h3 class=pageheader><code>clusterizerrunkmeans</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function performs clustering by k-means++ algorithm.

You may change algorithm properties like number of restarts or  iterations
limit by calling ClusterizerSetKMeansLimits() functions.

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()
    K       -   number of clusters, K&gt;=0.
                K  can  be  zero only when algorithm is called  for  empty
                dataset,  in   this   case   completion  code  is  set  to
                success (+1).
                If  K=0  and  dataset  size  is  non-zero,  we   can   not
                meaningfully assign points to some center  (there  are  no
                centers because K=0) and  return  -3  as  completion  code
                (failure).

OUTPUT PARAMETERS:
    Rep     -   clustering results; see description of KMeansReport
                structure for more information.

NOTE 1: k-means  clustering  can  be  performed  only  for  datasets  with
        Euclidean  distance  function.  Algorithm  will  return   negative
        completion code in Rep.TerminationType in case dataset  was  added
        to clusterizer with DistType other than Euclidean (or dataset  was
        specified by distance matrix instead of explicitly given points).

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizerrunkmeans(
    clusterizerstate s,
    ae_int_t k,
    kmeansreport&amp; rep);

</div></pre>
<a name='sub_clusterizerseparatedbycorr'></a><h3 class=pageheader><code>clusterizerseparatedbycorr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  accepts  AHC  report  Rep,  desired  maximum  intercluster
correlation and returns top clusters from hierarchical clusterization tree
which are separated by correlation R or LOWER.

It returns assignment of points to clusters (array of cluster indexes).

There is one more function with similar name - ClusterizerSeparatedByDist,
which returns clusters with intercluster distance equal  to  R  or  HIGHER
(note: higher for distance, lower for correlation).

INPUT PARAMETERS:
    Rep     -   report from ClusterizerRunAHC() performed on XY
    R       -   desired maximum intercluster correlation, -1&lt;=R&lt;=+1

OUTPUT PARAMETERS:
    K       -   number of clusters, 1&lt;=K&lt;=NPoints
    CIdx    -   array[NPoints], I-th element contains cluster index  (from
                0 to K-1) for I-th point of the dataset.
    CZ      -   array[K]. This array allows  to  convert  cluster  indexes
                returned by this function to indexes used by  Rep.Z.  J-th
                cluster returned by this function corresponds to  CZ[J]-th
                cluster stored in Rep.Z/PZ/PM.
                It is guaranteed that CZ[I]&lt;CZ[I+1].

NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
      Although  they  were  obtained  by  manipulation with top K nodes of
      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
      function does not return information about hierarchy.  Each  of  the
      clusters stand on its own.

NOTE: Cluster indexes returned by this function  does  not  correspond  to
      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
      representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
      representation returned by this function.  Each  of  representations
      has its own clusters indexing system (former uses [0, 2*NPoints-2]),
      while latter uses [0..K-1]), although  it  is  possible  to  perform
      conversion from one system to another by means of CZ array, returned
      by this function, which allows you to convert indexes stored in CIdx
      to the numeration system used by Rep.Z.

NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
      it will perform many times faster than  for  K=100.  Its  worst-case
      performance is O(N*K), although in average case  it  perform  better
      (up to O(N*log(K))).

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizerseparatedbycorr(
    ahcreport rep,
    <b>double</b> r,
    ae_int_t&amp; k,
    integer_1d_array&amp; cidx,
    integer_1d_array&amp; cz);

</div></pre>
<a name='sub_clusterizerseparatedbydist'></a><h3 class=pageheader><code>clusterizerseparatedbydist</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  accepts  AHC  report  Rep,  desired  minimum  intercluster
distance and returns top clusters from  hierarchical  clusterization  tree
which are separated by distance R or HIGHER.

It returns assignment of points to clusters (array of cluster indexes).

There is one more function with similar name - ClusterizerSeparatedByCorr,
which returns clusters with intercluster correlation equal to R  or  LOWER
(note: higher for distance, lower for correlation).

INPUT PARAMETERS:
    Rep     -   report from ClusterizerRunAHC() performed on XY
    R       -   desired minimum intercluster distance, R&gt;=0

OUTPUT PARAMETERS:
    K       -   number of clusters, 1&lt;=K&lt;=NPoints
    CIdx    -   array[NPoints], I-th element contains cluster index  (from
                0 to K-1) for I-th point of the dataset.
    CZ      -   array[K]. This array allows  to  convert  cluster  indexes
                returned by this function to indexes used by  Rep.Z.  J-th
                cluster returned by this function corresponds to  CZ[J]-th
                cluster stored in Rep.Z/PZ/PM.
                It is guaranteed that CZ[I]&lt;CZ[I+1].

NOTE: K clusters built by this subroutine are assumed to have no hierarchy.
      Although  they  were  obtained  by  manipulation with top K nodes of
      dendrogram  (i.e.  hierarchical  decomposition  of  dataset),   this
      function does not return information about hierarchy.  Each  of  the
      clusters stand on its own.

NOTE: Cluster indexes returned by this function  does  not  correspond  to
      indexes returned in Rep.Z/PZ/PM. Either you work  with  hierarchical
      representation of the dataset (dendrogram), or you work with  &quot;flat&quot;
      representation returned by this function.  Each  of  representations
      has its own clusters indexing system (former uses [0, 2*NPoints-2]),
      while latter uses [0..K-1]), although  it  is  possible  to  perform
      conversion from one system to another by means of CZ array, returned
      by this function, which allows you to convert indexes stored in CIdx
      to the numeration system used by Rep.Z.

NOTE: this subroutine is optimized for moderate values of K. Say, for  K=5
      it will perform many times faster than  for  K=100.  Its  worst-case
      performance is O(N*K), although in average case  it  perform  better
      (up to O(N*log(K))).

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizerseparatedbydist(
    ahcreport rep,
    <b>double</b> r,
    ae_int_t&amp; k,
    integer_1d_array&amp; cidx,
    integer_1d_array&amp; cz);

</div></pre>
<a name='sub_clusterizersetahcalgo'></a><h3 class=pageheader><code>clusterizersetahcalgo</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets agglomerative hierarchical clustering algorithm

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()
    Algo    -   algorithm type:
                * 0     complete linkage (default algorithm)
                * 1     single linkage
                * 2     unweighted average linkage
                * 3     weighted average linkage

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizersetahcalgo(clusterizerstate s, ae_int_t algo);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_ahc' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_clst_kmeans' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_clst_linkage' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_clst_distance' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_clst_kclusters' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_clusterizersetdistances'></a><h3 class=pageheader><code>clusterizersetdistances</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function adds dataset given by distance  matrix  to  the  clusterizer
structure. It is important that dataset is not  given  explicitly  -  only
distance matrix is given.

This function overrides all previous calls  of  ClusterizerSetPoints()  or
ClusterizerSetDistances().

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()
    D       -   array[NPoints,NPoints], distance matrix given by its upper
                or lower triangle (main diagonal is  ignored  because  its
                entries are expected to be zero).
    NPoints -   number of points
    IsUpper -   whether upper or lower triangle of D is given.

NOTE 1: different clustering algorithms have different limitations:
        * agglomerative hierarchical clustering algorithms may be used with
          any kind of distance metric, including one  which  is  given  by
          distance matrix
        * k-means++ clustering algorithm may be used only  with  Euclidean
          distance function and explicitly given points - it  can  not  be
          used with dataset given by distance matrix
        Thus, if you call this function, you will be unable to use k-means
        clustering algorithm to process your problem.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizersetdistances(
    clusterizerstate s,
    real_2d_array d,
    <b>bool</b> isupper);
<b>void</b> alglib::clusterizersetdistances(
    clusterizerstate s,
    real_2d_array d,
    ae_int_t npoints,
    <b>bool</b> isupper);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_distance' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_clusterizersetkmeanslimits'></a><h3 class=pageheader><code>clusterizersetkmeanslimits</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets k-means++ properties : number of restarts and maximum
number of iterations per one run.

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()
    Restarts-   restarts count, &gt;=1.
                k-means++ algorithm performs several restarts and  chooses
                best set of centers (one with minimum squared distance).
    MaxIts  -   maximum number of k-means iterations performed during  one
                run. &gt;=0, zero value means that algorithm performs unlimited
                number of iterations.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizersetkmeanslimits(
    clusterizerstate s,
    ae_int_t restarts,
    ae_int_t maxits);

</div></pre>
<a name='sub_clusterizersetpoints'></a><h3 class=pageheader><code>clusterizersetpoints</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function adds dataset to the clusterizer structure.

This function overrides all previous calls  of  ClusterizerSetPoints()  or
ClusterizerSetDistances().

INPUT PARAMETERS:
    S       -   clusterizer state, initialized by ClusterizerCreate()
    XY      -   array[NPoints,NFeatures], dataset
    NPoints -   number of points, &gt;=0
    NFeatures-  number of features, &gt;=1
    DistType-   distance function:
                *  0    Chebyshev distance  (L-inf norm)
                *  1    city block distance (L1 norm)
                *  2    Euclidean distance  (L2 norm)
                * 10    Pearson correlation:
                        dist(a,b) = 1-corr(a,b)
                * 11    Absolute Pearson correlation:
                        dist(a,b) = 1-|corr(a,b)|
                * 12    Uncentered Pearson correlation (cosine of the angle):
                        dist(a,b) = a'*b/(|a|*|b|)
                * 13    Absolute uncentered Pearson correlation
                        dist(a,b) = |a'*b|/(|a|*|b|)
                * 20    Spearman rank correlation:
                        dist(a,b) = 1-rankcorr(a,b)
                * 21    Absolute Spearman rank correlation
                        dist(a,b) = 1-|rankcorr(a,b)|

NOTE 1: different distance functions have different performance penalty:
        * Euclidean or Pearson correlation distances are the fastest ones
        * Spearman correlation distance function is a bit slower
        * city block and Chebyshev distances are order of magnitude slower

        The reason behing difference in performance is that correlation-based
        distance functions are computed using optimized linear algebra kernels,
        while Chebyshev and city block distance functions are computed using
        simple nested loops with two branches at each iteration.

NOTE 2: different clustering algorithms have different limitations:
        * agglomerative hierarchical clustering algorithms may be used with
          any kind of distance metric
        * k-means++ clustering algorithm may be used only  with  Euclidean
          distance function
        Thus, list of specific clustering algorithms you may  use  depends
        on distance function you specify when you set your dataset.

  -- ALGLIB --
     Copyright 10.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::clusterizersetpoints(
    clusterizerstate s,
    real_2d_array xy,
    ae_int_t disttype);
<b>void</b> alglib::clusterizersetpoints(
    clusterizerstate s,
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nfeatures,
    ae_int_t disttype);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_clst_ahc' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_clst_kmeans' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_clst_linkage' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_clst_distance' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_clst_kclusters' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='example_clst_ahc'></a><h3 class=pageheader>clst_ahc example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// The very simple clusterization example</font>
    <font color=navy>//</font>
    <font color=navy>// We have a set of points in 2D space:</font>
    <font color=navy>//     (P0,P1,P2,P3,P4) = ((1,1),(1,2),(4,1),(2,3),(4,1.5))</font>
    <font color=navy>//</font>
    <font color=navy>//  |</font>
    <font color=navy>//  |     P3</font>
    <font color=navy>//  |</font>
    <font color=navy>//  | P1          </font>
    <font color=navy>//  |             P4</font>
    <font color=navy>//  | P0          P2</font>
    <font color=navy>//  |-------------------------</font>
    <font color=navy>//</font>
    <font color=navy>// We want to perform Agglomerative Hierarchic Clusterization (AHC),</font>
    <font color=navy>// using complete linkage (default algorithm) and Euclidean distance</font>
    <font color=navy>// (default metric).</font>
    <font color=navy>//</font>
    <font color=navy>// In order to <b>do</b> that, we:</font>
    <font color=navy>// * create clusterizer with clusterizercreate()</font>
    <font color=navy>// * set points XY and metric (2=Euclidean) with clusterizersetpoints()</font>
    <font color=navy>// * run AHC algorithm with clusterizerrunahc</font>
    <font color=navy>//</font>
    <font color=navy>// You may see that clusterization itself is a minor part of the example,</font>
    <font color=navy>// most of which is dominated by comments :)</font>
    <font color=navy>//</font>
    clusterizerstate s;
    ahcreport rep;
    real_2d_array xy = <font color=blue><b>&quot;[[1,1],[1,2],[4,1],[2,3],[4,1.5]]&quot;</b></font>;

    clusterizercreate(s);
    clusterizersetpoints(s, xy, 2);
    clusterizerrunahc(s, rep);

    <font color=navy>//</font>
    <font color=navy>// Now we've built our clusterization tree. Rep.z contains information which</font>
    <font color=navy>// is required to build dendrogram. I-th row of rep.z represents one merge</font>
    <font color=navy>// operation, with first cluster to merge having index rep.z[I,0] and second</font>
    <font color=navy>// one having index rep.z[I,1]. Merge result has index NPoints+I.</font>
    <font color=navy>//</font>
    <font color=navy>// Clusters with indexes less than NPoints are single-point initial clusters,</font>
    <font color=navy>// <b>while</b> ones with indexes from NPoints to 2*NPoints-2 are multi-point</font>
    <font color=navy>// clusters created during merges.</font>
    <font color=navy>//</font>
    <font color=navy>// In our example, Z=[[2,4], [0,1], [3,6], [5,7]]</font>
    <font color=navy>//</font>
    <font color=navy>// It means that:</font>
    <font color=navy>// * first, we merge C2=(P2) and C4=(P4),    and create C5=(P2,P4)</font>
    <font color=navy>// * then, we merge  C2=(P0) and C1=(P1),    and create C6=(P0,P1)</font>
    <font color=navy>// * then, we merge  C3=(P3) and C6=(P0,P1), and create C7=(P0,P1,P3)</font>
    <font color=navy>// * finally, we merge C5 and C7 and create C8=(P0,P1,P2,P3,P4)</font>
    <font color=navy>//</font>
    <font color=navy>// Thus, we have following dendrogram:</font>
    <font color=navy>//  </font>
    <font color=navy>//      ------8-----</font>
    <font color=navy>//      |          |</font>
    <font color=navy>//      |      ----7----</font>
    <font color=navy>//      |      |       |</font>
    <font color=navy>//   ---5---   |    ---6---</font>
    <font color=navy>//   |     |   |    |     |</font>
    <font color=navy>//   P2   P4   P3   P0   P1</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.z.tostring().c_str()); <font color=navy>// EXPECTED: [[2,4],[0,1],[3,6],[5,7]]</font>

    <font color=navy>//</font>
    <font color=navy>// We've built dendrogram above by reordering our dataset.</font>
    <font color=navy>//</font>
    <font color=navy>// Without such reordering it would be impossible to build dendrogram without</font>
    <font color=navy>// intersections. Luckily, ahcreport structure contains two additional fields</font>
    <font color=navy>// which help to build dendrogram from your data:</font>
    <font color=navy>// * rep.p, which contains permutation applied to dataset</font>
    <font color=navy>// * rep.pm, which contains another representation of merges </font>
    <font color=navy>//</font>
    <font color=navy>// In our example we have:</font>
    <font color=navy>// * P=[3,4,0,2,1]</font>
    <font color=navy>// * PZ=[[0,0,1,1,0,0],[3,3,4,4,0,0],[2,2,3,4,0,1],[0,1,2,4,1,2]]</font>
    <font color=navy>//</font>
    <font color=navy>// Permutation array P tells us that P0 should be moved to position 3,</font>
    <font color=navy>// P1 moved to position 4, P2 moved to position 0 and so on:</font>
    <font color=navy>//</font>
    <font color=navy>//   (P0 P1 P2 P3 P4) =&gt; (P2 P4 P3 P0 P1)</font>
    <font color=navy>//</font>
    <font color=navy>// Merges array PZ tells us how to perform merges on the sorted dataset.</font>
    <font color=navy>// One row of PZ corresponds to one merge operations, with first pair of</font>
    <font color=navy>// elements denoting first of the clusters to merge (start index, end</font>
    <font color=navy>// index) and next pair of elements denoting second of the clusters to</font>
    <font color=navy>// merge. Clusters being merged are always adjacent, with first one on</font>
    <font color=navy>// the left and second one on the right.</font>
    <font color=navy>//</font>
    <font color=navy>// For example, first row of PZ tells us that clusters [0,0] and [1,1] are</font>
    <font color=navy>// merged (single-point clusters, with first one containing P2 and second</font>
    <font color=navy>// one containing P4). Third row of PZ tells us that we merge one single-</font>
    <font color=navy>// point cluster [2,2] with one two-point cluster [3,4].</font>
    <font color=navy>//</font>
    <font color=navy>// There are two more elements in each row of PZ. These are the helper</font>
    <font color=navy>// elements, which denote HEIGHT (not size) of left and right subdendrograms.</font>
    <font color=navy>// For example, according to PZ, first two merges are performed on clusterization</font>
    <font color=navy>// trees of height 0, <b>while</b> next two merges are performed on 0-1 and 1-2</font>
    <font color=navy>// pairs of trees correspondingly.</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.p.tostring().c_str()); <font color=navy>// EXPECTED: [3,4,0,2,1]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.pm.tostring().c_str()); <font color=navy>// EXPECTED: [[0,0,1,1,0,0],[3,3,4,4,0,0],[2,2,3,4,0,1],[0,1,2,4,1,2]]</font>
    <b>return</b> 0;
}


</pre><a name='example_clst_distance'></a><h3 class=pageheader>clst_distance example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We have three points in 4D space:</font>
    <font color=navy>//     (P0,P1,P2) = ((1, 2, 1, 2), (6, 7, 6, 7), (7, 6, 7, 6))</font>
    <font color=navy>//</font>
    <font color=navy>// We want to try clustering them with different distance functions.</font>
    <font color=navy>// Distance function is chosen when we add dataset to the clusterizer.</font>
    <font color=navy>// We can choose several distance types - Euclidean, city block, Chebyshev,</font>
    <font color=navy>// several correlation measures or user-supplied distance matrix.</font>
    <font color=navy>//</font>
    <font color=navy>// Here we'll try three distances: Euclidean, Pearson correlation,</font>
    <font color=navy>// user-supplied distance matrix. Different distance functions lead</font>
    <font color=navy>// to different choices being made by algorithm during clustering.</font>
    <font color=navy>//</font>
    clusterizerstate s;
    ahcreport rep;
    ae_int_t disttype;
    real_2d_array xy = <font color=blue><b>&quot;[[1, 2, 1, 2], [6, 7, 6, 7], [7, 6, 7, 6]]&quot;</b></font>;
    clusterizercreate(s);

    <font color=navy>// With Euclidean distance function (disttype=2) two closest points</font>
    <font color=navy>// are P1 and P2, thus:</font>
    <font color=navy>// * first, we merge P1 and P2 to form C3=[P1,P2]</font>
    <font color=navy>// * second, we merge P0 and C3 to form C4=[P0,P1,P2]</font>
    disttype = 2;
    clusterizersetpoints(s, xy, disttype);
    clusterizerrunahc(s, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.z.tostring().c_str()); <font color=navy>// EXPECTED: [[1,2],[0,3]]</font>

    <font color=navy>// With Pearson correlation distance function (disttype=10) situation</font>
    <font color=navy>// is different - distance between P0 and P1 is zero, thus:</font>
    <font color=navy>// * first, we merge P0 and P1 to form C3=[P0,P1]</font>
    <font color=navy>// * second, we merge P2 and C3 to form C4=[P0,P1,P2]</font>
    disttype = 10;
    clusterizersetpoints(s, xy, disttype);
    clusterizerrunahc(s, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.z.tostring().c_str()); <font color=navy>// EXPECTED: [[0,1],[2,3]]</font>

    <font color=navy>// Finally, we try clustering with user-supplied distance matrix:</font>
    <font color=navy>//     [ 0 3 1 ]</font>
    <font color=navy>// P = [ 3 0 3 ], where P[i,j] = dist(Pi,Pj)</font>
    <font color=navy>//     [ 1 3 0 ]</font>
    <font color=navy>//</font>
    <font color=navy>// * first, we merge P0 and P2 to form C3=[P0,P2]</font>
    <font color=navy>// * second, we merge P1 and C3 to form C4=[P0,P1,P2]</font>
    real_2d_array d = <font color=blue><b>&quot;[[0,3,1],[3,0,3],[1,3,0]]&quot;</b></font>;
    clusterizersetdistances(s, d, true);
    clusterizerrunahc(s, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, rep.z.tostring().c_str()); <font color=navy>// EXPECTED: [[0,2],[1,3]]</font>
    <b>return</b> 0;
}


</pre><a name='example_clst_kclusters'></a><h3 class=pageheader>clst_kclusters example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We have a set of points in 2D space:</font>
    <font color=navy>//     (P0,P1,P2,P3,P4) = ((1,1),(1,2),(4,1),(2,3),(4,1.5))</font>
    <font color=navy>//</font>
    <font color=navy>//  |</font>
    <font color=navy>//  |     P3</font>
    <font color=navy>//  |</font>
    <font color=navy>//  | P1          </font>
    <font color=navy>//  |             P4</font>
    <font color=navy>//  | P0          P2</font>
    <font color=navy>//  |-------------------------</font>
    <font color=navy>//</font>
    <font color=navy>// We perform Agglomerative Hierarchic Clusterization (AHC) and we want</font>
    <font color=navy>// to get top K clusters from clusterization tree <b>for</b> different K.</font>
    <font color=navy>//</font>
    clusterizerstate s;
    ahcreport rep;
    real_2d_array xy = <font color=blue><b>&quot;[[1,1],[1,2],[4,1],[2,3],[4,1.5]]&quot;</b></font>;
    integer_1d_array cidx;
    integer_1d_array cz;

    clusterizercreate(s);
    clusterizersetpoints(s, xy, 2);
    clusterizerrunahc(s, rep);

    <font color=navy>// with K=5, every points is assigned to its own cluster:</font>
    <font color=navy>// C0=P0, C1=P1 and so on...</font>
    clusterizergetkclusters(rep, 5, cidx, cz);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, cidx.tostring().c_str()); <font color=navy>// EXPECTED: [0,1,2,3,4]</font>

    <font color=navy>// with K=1 we have one large cluster C0=[P0,P1,P2,P3,P4,P5]</font>
    clusterizergetkclusters(rep, 1, cidx, cz);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, cidx.tostring().c_str()); <font color=navy>// EXPECTED: [0,0,0,0,0]</font>

    <font color=navy>// with K=3 we have three clusters C0=[P3], C1=[P2,P4], C2=[P0,P1]</font>
    clusterizergetkclusters(rep, 3, cidx, cz);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, cidx.tostring().c_str()); <font color=navy>// EXPECTED: [2,2,1,0,1]</font>
    <b>return</b> 0;
}


</pre><a name='example_clst_kmeans'></a><h3 class=pageheader>clst_kmeans example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// The very simple clusterization example</font>
    <font color=navy>//</font>
    <font color=navy>// We have a set of points in 2D space:</font>
    <font color=navy>//     (P0,P1,P2,P3,P4) = ((1,1),(1,2),(4,1),(2,3),(4,1.5))</font>
    <font color=navy>//</font>
    <font color=navy>//  |</font>
    <font color=navy>//  |     P3</font>
    <font color=navy>//  |</font>
    <font color=navy>//  | P1          </font>
    <font color=navy>//  |             P4</font>
    <font color=navy>//  | P0          P2</font>
    <font color=navy>//  |-------------------------</font>
    <font color=navy>//</font>
    <font color=navy>// We want to perform k-means++ clustering with K=2.</font>
    <font color=navy>//</font>
    <font color=navy>// In order to <b>do</b> that, we:</font>
    <font color=navy>// * create clusterizer with clusterizercreate()</font>
    <font color=navy>// * set points XY and metric (must be Euclidean, distype=2) with clusterizersetpoints()</font>
    <font color=navy>// * (optional) set number of restarts from random positions to 5</font>
    <font color=navy>// * run k-means algorithm with clusterizerrunkmeans()</font>
    <font color=navy>//</font>
    <font color=navy>// You may see that clusterization itself is a minor part of the example,</font>
    <font color=navy>// most of which is dominated by comments :)</font>
    <font color=navy>//</font>
    clusterizerstate s;
    kmeansreport rep;
    real_2d_array xy = <font color=blue><b>&quot;[[1,1],[1,2],[4,1],[2,3],[4,1.5]]&quot;</b></font>;

    clusterizercreate(s);
    clusterizersetpoints(s, xy, 2);
    clusterizersetkmeanslimits(s, 5, 0);
    clusterizerrunkmeans(s, 2, rep);

    <font color=navy>//</font>
    <font color=navy>// We've performed clusterization, and it succeeded (completion code is +1).</font>
    <font color=navy>//</font>
    <font color=navy>// Now first center is stored in the first row of rep.c, second one is stored</font>
    <font color=navy>// in the second row. rep.cidx can be used to determine which center is</font>
    <font color=navy>// closest to some specific point of the dataset.</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>

    <font color=navy>// We called clusterizersetpoints() with disttype=2 because k-means++</font>
    <font color=navy>// algorithm does NOT support metrics other than Euclidean. But what <b>if</b> we</font>
    <font color=navy>// try to use some other metric?</font>
    <font color=navy>//</font>
    <font color=navy>// We change metric type by calling clusterizersetpoints() one more time,</font>
    <font color=navy>// and try to run k-means algo again. It fails.</font>
    <font color=navy>//</font>
    clusterizersetpoints(s, xy, 0);
    clusterizerrunkmeans(s, 2, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: -5</font>
    <b>return</b> 0;
}


</pre><a name='example_clst_linkage'></a><h3 class=pageheader>clst_linkage example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We have a set of points in 1D space:</font>
    <font color=navy>//     (P0,P1,P2,P3,P4) = (1, 3, 10, 16, 20)</font>
    <font color=navy>//</font>
    <font color=navy>// We want to perform Agglomerative Hierarchic Clusterization (AHC),</font>
    <font color=navy>// using either complete or single linkage and Euclidean distance</font>
    <font color=navy>// (default metric).</font>
    <font color=navy>//</font>
    <font color=navy>// First two steps merge P0/P1 and P3/P4 independently of the linkage type.</font>
    <font color=navy>// However, third step depends on linkage type being used:</font>
    <font color=navy>// * in case of complete linkage P2=10 is merged with [P0,P1]</font>
    <font color=navy>// * in case of single linkage P2=10 is merged with [P3,P4]</font>
    <font color=navy>//</font>
    clusterizerstate s;
    ahcreport rep;
    real_2d_array xy = <font color=blue><b>&quot;[[1],[3],[10],[16],[20]]&quot;</b></font>;
    integer_1d_array cidx;
    integer_1d_array cz;

    clusterizercreate(s);
    clusterizersetpoints(s, xy, 2);

    <font color=navy>// use complete linkage, reduce set down to 2 clusters.</font>
    <font color=navy>// print clusterization with clusterizergetkclusters(2).</font>
    <font color=navy>// P2 must belong to [P0,P1]</font>
    clusterizersetahcalgo(s, 0);
    clusterizerrunahc(s, rep);
    clusterizergetkclusters(rep, 2, cidx, cz);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, cidx.tostring().c_str()); <font color=navy>// EXPECTED: [1,1,1,0,0]</font>

    <font color=navy>// use single linkage, reduce set down to 2 clusters.</font>
    <font color=navy>// print clusterization with clusterizergetkclusters(2).</font>
    <font color=navy>// P2 must belong to [P2,P3]</font>
    clusterizersetahcalgo(s, 1);
    clusterizerrunahc(s, rep);
    clusterizergetkclusters(rep, 2, cidx, cz);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, cidx.tostring().c_str()); <font color=navy>// EXPECTED: [0,0,1,1,1]</font>
    <b>return</b> 0;
}


</pre><a name=unit_conv></a><h2 class=pageheader><code>conv</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_convc1d' class=toc>convc1d</a><br>
<a href='#sub_convc1dcircular' class=toc>convc1dcircular</a><br>
<a href='#sub_convc1dcircularinv' class=toc>convc1dcircularinv</a><br>
<a href='#sub_convc1dinv' class=toc>convc1dinv</a><br>
<a href='#sub_convr1d' class=toc>convr1d</a><br>
<a href='#sub_convr1dcircular' class=toc>convr1dcircular</a><br>
<a href='#sub_convr1dcircularinv' class=toc>convr1dcircularinv</a><br>
<a href='#sub_convr1dinv' class=toc>convr1dinv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_convc1d'></a><h3 class=pageheader><code>convc1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex convolution.

For given A/B returns conv(A,B) (non-circular). Subroutine can automatically
choose between three implementations: straightforward O(M*N)  formula  for
very small N (or M), overlap-add algorithm for  cases  where  max(M,N)  is
significantly larger than min(M,N), but O(M*N) algorithm is too slow,  and
general FFT-based formula for cases where two previois algorithms are  too
slow.

Algorithm has max(M,N)*log(max(M,N)) complexity for any M/N.

INPUT PARAMETERS
    A   -   array[0..M-1] - complex function to be transformed
    M   -   problem size
    B   -   array[0..N-1] - complex function to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..N+M-2].

NOTE:
    It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
functions have non-zero values at negative T's, you  can  still  use  this
subroutine - just shift its result correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convc1d(
    complex_1d_array a,
    ae_int_t m,
    complex_1d_array b,
    ae_int_t n,
    complex_1d_array&amp; r);

</div></pre>
<a name='sub_convc1dcircular'></a><h3 class=pageheader><code>convc1dcircular</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional circular complex convolution.

For given S/R returns conv(S,R) (circular). Algorithm has linearithmic
complexity for any M/N.

IMPORTANT:  normal convolution is commutative,  i.e.   it  is symmetric  -
conv(A,B)=conv(B,A).  Cyclic convolution IS NOT.  One function - S - is  a
signal,  periodic function, and another - R - is a response,  non-periodic
function with limited length.

INPUT PARAMETERS
    S   -   array[0..M-1] - complex periodic signal
    M   -   problem size
    B   -   array[0..N-1] - complex non-periodic response
    N   -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..M-1].

NOTE:
    It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
negative T's, you can still use this subroutine - just  shift  its  result
correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convc1dcircular(
    complex_1d_array s,
    ae_int_t m,
    complex_1d_array r,
    ae_int_t n,
    complex_1d_array&amp; c);

</div></pre>
<a name='sub_convc1dcircularinv'></a><h3 class=pageheader><code>convc1dcircularinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional circular complex deconvolution (inverse of ConvC1DCircular()).

Algorithm has M*log(M)) complexity for any M (composite or prime).

INPUT PARAMETERS
    A   -   array[0..M-1] - convolved periodic signal, A = conv(R, B)
    M   -   convolved signal length
    B   -   array[0..N-1] - non-periodic response
    N   -   response length

OUTPUT PARAMETERS
    R   -   deconvolved signal. array[0..M-1].

NOTE:
    deconvolution is unstable process and may result in division  by  zero
(if your response function is degenerate, i.e. has zero Fourier coefficient).

NOTE:
    It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
negative T's, you can still use this subroutine - just  shift  its  result
correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convc1dcircularinv(
    complex_1d_array a,
    ae_int_t m,
    complex_1d_array b,
    ae_int_t n,
    complex_1d_array&amp; r);

</div></pre>
<a name='sub_convc1dinv'></a><h3 class=pageheader><code>convc1dinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex non-circular deconvolution (inverse of ConvC1D()).

Algorithm has M*log(M)) complexity for any M (composite or prime).

INPUT PARAMETERS
    A   -   array[0..M-1] - convolved signal, A = conv(R, B)
    M   -   convolved signal length
    B   -   array[0..N-1] - response
    N   -   response length, N&lt;=M

OUTPUT PARAMETERS
    R   -   deconvolved signal. array[0..M-N].

NOTE:
    deconvolution is unstable process and may result in division  by  zero
(if your response function is degenerate, i.e. has zero Fourier coefficient).

NOTE:
    It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
functions have non-zero values at negative T's, you  can  still  use  this
subroutine - just shift its result correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convc1dinv(
    complex_1d_array a,
    ae_int_t m,
    complex_1d_array b,
    ae_int_t n,
    complex_1d_array&amp; r);

</div></pre>
<a name='sub_convr1d'></a><h3 class=pageheader><code>convr1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional real convolution.

Analogous to ConvC1D(), see ConvC1D() comments for more details.

INPUT PARAMETERS
    A   -   array[0..M-1] - real function to be transformed
    M   -   problem size
    B   -   array[0..N-1] - real function to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..N+M-2].

NOTE:
    It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
functions have non-zero values at negative T's, you  can  still  use  this
subroutine - just shift its result correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convr1d(
    real_1d_array a,
    ae_int_t m,
    real_1d_array b,
    ae_int_t n,
    real_1d_array&amp; r);

</div></pre>
<a name='sub_convr1dcircular'></a><h3 class=pageheader><code>convr1dcircular</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional circular real convolution.

Analogous to ConvC1DCircular(), see ConvC1DCircular() comments for more details.

INPUT PARAMETERS
    S   -   array[0..M-1] - real signal
    M   -   problem size
    B   -   array[0..N-1] - real response
    N   -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..M-1].

NOTE:
    It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
negative T's, you can still use this subroutine - just  shift  its  result
correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convr1dcircular(
    real_1d_array s,
    ae_int_t m,
    real_1d_array r,
    ae_int_t n,
    real_1d_array&amp; c);

</div></pre>
<a name='sub_convr1dcircularinv'></a><h3 class=pageheader><code>convr1dcircularinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex deconvolution (inverse of ConvC1D()).

Algorithm has M*log(M)) complexity for any M (composite or prime).

INPUT PARAMETERS
    A   -   array[0..M-1] - convolved signal, A = conv(R, B)
    M   -   convolved signal length
    B   -   array[0..N-1] - response
    N   -   response length

OUTPUT PARAMETERS
    R   -   deconvolved signal. array[0..M-N].

NOTE:
    deconvolution is unstable process and may result in division  by  zero
(if your response function is degenerate, i.e. has zero Fourier coefficient).

NOTE:
    It is assumed that B is zero at T&lt;0. If  it  has  non-zero  values  at
negative T's, you can still use this subroutine - just  shift  its  result
correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convr1dcircularinv(
    real_1d_array a,
    ae_int_t m,
    real_1d_array b,
    ae_int_t n,
    real_1d_array&amp; r);

</div></pre>
<a name='sub_convr1dinv'></a><h3 class=pageheader><code>convr1dinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional real deconvolution (inverse of ConvC1D()).

Algorithm has M*log(M)) complexity for any M (composite or prime).

INPUT PARAMETERS
    A   -   array[0..M-1] - convolved signal, A = conv(R, B)
    M   -   convolved signal length
    B   -   array[0..N-1] - response
    N   -   response length, N&lt;=M

OUTPUT PARAMETERS
    R   -   deconvolved signal. array[0..M-N].

NOTE:
    deconvolution is unstable process and may result in division  by  zero
(if your response function is degenerate, i.e. has zero Fourier coefficient).

NOTE:
    It is assumed that A is zero at T&lt;0, B is zero too.  If  one  or  both
functions have non-zero values at negative T's, you  can  still  use  this
subroutine - just shift its result correspondingly.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::convr1dinv(
    real_1d_array a,
    ae_int_t m,
    real_1d_array b,
    ae_int_t n,
    real_1d_array&amp; r);

</div></pre>
<a name=unit_corr></a><h2 class=pageheader><code>corr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_corrc1d' class=toc>corrc1d</a><br>
<a href='#sub_corrc1dcircular' class=toc>corrc1dcircular</a><br>
<a href='#sub_corrr1d' class=toc>corrr1d</a><br>
<a href='#sub_corrr1dcircular' class=toc>corrr1dcircular</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_corrc1d'></a><h3 class=pageheader><code>corrc1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex cross-correlation.

For given Pattern/Signal returns corr(Pattern,Signal) (non-circular).

Correlation is calculated using reduction to  convolution.  Algorithm with
max(N,N)*log(max(N,N)) complexity is used (see  ConvC1D()  for  more  info
about performance).

IMPORTANT:
    for  historical reasons subroutine accepts its parameters in  reversed
    order: CorrC1D(Signal, Pattern) = Pattern x Signal (using  traditional
    definition of cross-correlation, denoting cross-correlation as &quot;x&quot;).

INPUT PARAMETERS
    Signal  -   array[0..N-1] - complex function to be transformed,
                signal containing pattern
    N       -   problem size
    Pattern -   array[0..M-1] - complex function to be transformed,
                pattern to search withing signal
    M       -   problem size

OUTPUT PARAMETERS
    R       -   cross-correlation, array[0..N+M-2]:
                * positive lags are stored in R[0..N-1],
                  R[i] = sum(conj(pattern[j])*signal[i+j]
                * negative lags are stored in R[N..N+M-2],
                  R[N+M-1-i] = sum(conj(pattern[j])*signal[-i+j]

NOTE:
    It is assumed that pattern domain is [0..M-1].  If Pattern is non-zero
on [-K..M-1],  you can still use this subroutine, just shift result by K.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::corrc1d(
    complex_1d_array signal,
    ae_int_t n,
    complex_1d_array pattern,
    ae_int_t m,
    complex_1d_array&amp; r);

</div></pre>
<a name='sub_corrc1dcircular'></a><h3 class=pageheader><code>corrc1dcircular</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional circular complex cross-correlation.

For given Pattern/Signal returns corr(Pattern,Signal) (circular).
Algorithm has linearithmic complexity for any M/N.

IMPORTANT:
    for  historical reasons subroutine accepts its parameters in  reversed
    order:   CorrC1DCircular(Signal, Pattern) = Pattern x Signal    (using
    traditional definition of cross-correlation, denoting cross-correlation
    as &quot;x&quot;).

INPUT PARAMETERS
    Signal  -   array[0..N-1] - complex function to be transformed,
                periodic signal containing pattern
    N       -   problem size
    Pattern -   array[0..M-1] - complex function to be transformed,
                non-periodic pattern to search withing signal
    M       -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..M-1].


  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::corrc1dcircular(
    complex_1d_array signal,
    ae_int_t m,
    complex_1d_array pattern,
    ae_int_t n,
    complex_1d_array&amp; c);

</div></pre>
<a name='sub_corrr1d'></a><h3 class=pageheader><code>corrr1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional real cross-correlation.

For given Pattern/Signal returns corr(Pattern,Signal) (non-circular).

Correlation is calculated using reduction to  convolution.  Algorithm with
max(N,N)*log(max(N,N)) complexity is used (see  ConvC1D()  for  more  info
about performance).

IMPORTANT:
    for  historical reasons subroutine accepts its parameters in  reversed
    order: CorrR1D(Signal, Pattern) = Pattern x Signal (using  traditional
    definition of cross-correlation, denoting cross-correlation as &quot;x&quot;).

INPUT PARAMETERS
    Signal  -   array[0..N-1] - real function to be transformed,
                signal containing pattern
    N       -   problem size
    Pattern -   array[0..M-1] - real function to be transformed,
                pattern to search withing signal
    M       -   problem size

OUTPUT PARAMETERS
    R       -   cross-correlation, array[0..N+M-2]:
                * positive lags are stored in R[0..N-1],
                  R[i] = sum(pattern[j]*signal[i+j]
                * negative lags are stored in R[N..N+M-2],
                  R[N+M-1-i] = sum(pattern[j]*signal[-i+j]

NOTE:
    It is assumed that pattern domain is [0..M-1].  If Pattern is non-zero
on [-K..M-1],  you can still use this subroutine, just shift result by K.

  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::corrr1d(
    real_1d_array signal,
    ae_int_t n,
    real_1d_array pattern,
    ae_int_t m,
    real_1d_array&amp; r);

</div></pre>
<a name='sub_corrr1dcircular'></a><h3 class=pageheader><code>corrr1dcircular</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional circular real cross-correlation.

For given Pattern/Signal returns corr(Pattern,Signal) (circular).
Algorithm has linearithmic complexity for any M/N.

IMPORTANT:
    for  historical reasons subroutine accepts its parameters in  reversed
    order:   CorrR1DCircular(Signal, Pattern) = Pattern x Signal    (using
    traditional definition of cross-correlation, denoting cross-correlation
    as &quot;x&quot;).

INPUT PARAMETERS
    Signal  -   array[0..N-1] - real function to be transformed,
                periodic signal containing pattern
    N       -   problem size
    Pattern -   array[0..M-1] - real function to be transformed,
                non-periodic pattern to search withing signal
    M       -   problem size

OUTPUT PARAMETERS
    R   -   convolution: A*B. array[0..M-1].


  -- ALGLIB --
     Copyright 21.07.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::corrr1dcircular(
    real_1d_array signal,
    ae_int_t m,
    real_1d_array pattern,
    ae_int_t n,
    real_1d_array&amp; c);

</div></pre>
<a name=unit_correlationtests></a><h2 class=pageheader><code>correlationtests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_pearsoncorrelationsignificance' class=toc>pearsoncorrelationsignificance</a><br>
<a href='#sub_spearmanrankcorrelationsignificance' class=toc>spearmanrankcorrelationsignificance</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_pearsoncorrelationsignificance'></a><h3 class=pageheader><code>pearsoncorrelationsignificance</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Pearson's correlation coefficient significance test

This test checks hypotheses about whether X  and  Y  are  samples  of  two
continuous  distributions  having  zero  correlation  or   whether   their
correlation is non-zero.

The following tests are performed:
    * two-tailed test (null hypothesis - X and Y have zero correlation)
    * left-tailed test (null hypothesis - the correlation  coefficient  is
      greater than or equal to 0)
    * right-tailed test (null hypothesis - the correlation coefficient  is
      less than or equal to 0).

Requirements:
    * the number of elements in each sample is not less than 5
    * normality of distributions of X and Y.

Input parameters:
    R   -   Pearson's correlation coefficient for X and Y
    N   -   number of elements in samples, N&gt;=5.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pearsoncorrelationsignificance(
    <b>double</b> r,
    ae_int_t n,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name='sub_spearmanrankcorrelationsignificance'></a><h3 class=pageheader><code>spearmanrankcorrelationsignificance</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Spearman's rank correlation coefficient significance test

This test checks hypotheses about whether X  and  Y  are  samples  of  two
continuous  distributions  having  zero  correlation  or   whether   their
correlation is non-zero.

The following tests are performed:
    * two-tailed test (null hypothesis - X and Y have zero correlation)
    * left-tailed test (null hypothesis - the correlation  coefficient  is
      greater than or equal to 0)
    * right-tailed test (null hypothesis - the correlation coefficient  is
      less than or equal to 0).

Requirements:
    * the number of elements in each sample is not less than 5.

The test is non-parametric and doesn't require distributions X and Y to be
normal.

Input parameters:
    R   -   Spearman's rank correlation coefficient for X and Y
    N   -   number of elements in samples, N&gt;=5.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spearmanrankcorrelationsignificance(
    <b>double</b> r,
    ae_int_t n,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name=unit_datacomp></a><h2 class=pageheader><code>datacomp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_kmeansgenerate' class=toc>kmeansgenerate</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_kmeansgenerate'></a><h3 class=pageheader><code>kmeansgenerate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
k-means++ clusterization.
Backward compatibility function, we recommend to use CLUSTERING subpackage
as better replacement.

  -- ALGLIB --
     Copyright 21.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kmeansgenerate(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t k,
    ae_int_t restarts,
    ae_int_t&amp; info,
    real_2d_array&amp; c,
    integer_1d_array&amp; xyc);

</div></pre>
<a name=unit_dawson></a><h2 class=pageheader><code>dawson</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dawsonintegral' class=toc>dawsonintegral</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_dawsonintegral'></a><h3 class=pageheader><code>dawsonintegral</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dawson's Integral

Approximates the integral

                            x
                            -
                     2     | |        2
 dawsn(x)  =  exp( -x  )   |    exp( t  ) dt
                         | |
                          -
                          0

Three different rational approximations are employed, for
the intervals 0 to 3.25; 3.25 to 6.25; and 6.25 up.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,10        10000       6.9e-16     1.0e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dawsonintegral(<b>double</b> x);

</div></pre>
<a name=unit_densesolver></a><h2 class=pageheader><code>densesolver</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_densesolverlsreport' class=toc>densesolverlsreport</a><br>
<a href='#struct_densesolverreport' class=toc>densesolverreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlusolve' class=toc>cmatrixlusolve</a><br>
<a href='#sub_cmatrixlusolvem' class=toc>cmatrixlusolvem</a><br>
<a href='#sub_cmatrixmixedsolve' class=toc>cmatrixmixedsolve</a><br>
<a href='#sub_cmatrixmixedsolvem' class=toc>cmatrixmixedsolvem</a><br>
<a href='#sub_cmatrixsolve' class=toc>cmatrixsolve</a><br>
<a href='#sub_cmatrixsolvem' class=toc>cmatrixsolvem</a><br>
<a href='#sub_hpdmatrixcholeskysolve' class=toc>hpdmatrixcholeskysolve</a><br>
<a href='#sub_hpdmatrixcholeskysolvem' class=toc>hpdmatrixcholeskysolvem</a><br>
<a href='#sub_hpdmatrixsolve' class=toc>hpdmatrixsolve</a><br>
<a href='#sub_hpdmatrixsolvem' class=toc>hpdmatrixsolvem</a><br>
<a href='#sub_rmatrixlusolve' class=toc>rmatrixlusolve</a><br>
<a href='#sub_rmatrixlusolvem' class=toc>rmatrixlusolvem</a><br>
<a href='#sub_rmatrixmixedsolve' class=toc>rmatrixmixedsolve</a><br>
<a href='#sub_rmatrixmixedsolvem' class=toc>rmatrixmixedsolvem</a><br>
<a href='#sub_rmatrixsolve' class=toc>rmatrixsolve</a><br>
<a href='#sub_rmatrixsolvels' class=toc>rmatrixsolvels</a><br>
<a href='#sub_rmatrixsolvem' class=toc>rmatrixsolvem</a><br>
<a href='#sub_spdmatrixcholeskysolve' class=toc>spdmatrixcholeskysolve</a><br>
<a href='#sub_spdmatrixcholeskysolvem' class=toc>spdmatrixcholeskysolvem</a><br>
<a href='#sub_spdmatrixsolve' class=toc>spdmatrixsolve</a><br>
<a href='#sub_spdmatrixsolvem' class=toc>spdmatrixsolvem</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_densesolverlsreport'></a><h3 class=pageheader><code>densesolverlsreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> densesolverlsreport
{
    <b>double</b>               r2;
    real_2d_array        cx;
    ae_int_t             n;
    ae_int_t             k;
};

</div></pre>
<a name='struct_densesolverreport'></a><h3 class=pageheader><code>densesolverreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> densesolverreport
{
    <b>double</b>               r1;
    <b>double</b>               rinf;
};

</div></pre>
<a name='sub_cmatrixlusolve'></a><h3 class=pageheader><code>cmatrixlusolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolve(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* O(N^2) complexity
* condition number estimation

No iterative refinement is provided because exact form of original matrix
is not known to subroutine. Use CMatrixSolve or CMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
    P       -   array[0..N-1], pivots array, CMatrixLU result
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlusolve(
    complex_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    complex_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_1d_array&amp; x);

</div></pre>
<a name='sub_cmatrixlusolvem'></a><h3 class=pageheader><code>cmatrixlusolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolveM(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* O(M*N^2) complexity
* condition number estimation

No iterative refinement  is provided because exact form of original matrix
is not known to subroutine. Use CMatrixSolve or CMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
    P       -   array[0..N-1], pivots array, RMatrixLU result
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlusolvem(
    complex_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    complex_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_2d_array&amp; x);

</div></pre>
<a name='sub_cmatrixmixedsolve'></a><h3 class=pageheader><code>cmatrixmixedsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixMixedSolve(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
    P       -   array[0..N-1], pivots array, CMatrixLU result
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolveM
    Rep     -   same as in RMatrixSolveM
    X       -   same as in RMatrixSolveM

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixmixedsolve(
    complex_2d_array a,
    complex_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    complex_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_1d_array&amp; x);

</div></pre>
<a name='sub_cmatrixmixedsolvem'></a><h3 class=pageheader><code>cmatrixmixedsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixMixedSolveM(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(M*N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    LUA     -   array[0..N-1,0..N-1], LU decomposition, CMatrixLU result
    P       -   array[0..N-1], pivots array, CMatrixLU result
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolveM
    Rep     -   same as in RMatrixSolveM
    X       -   same as in RMatrixSolveM

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixmixedsolvem(
    complex_2d_array a,
    complex_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    complex_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_2d_array&amp; x);

</div></pre>
<a name='sub_cmatrixsolve'></a><h3 class=pageheader><code>cmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolve(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(N^3) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixsolve(
    complex_2d_array a,
    ae_int_t n,
    complex_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_1d_array&amp; x);

</div></pre>
<a name='sub_cmatrixsolvem'></a><h3 class=pageheader><code>cmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolveM(), but for complex matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(N^3+M*N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size
    RFS     -   iterative refinement switch:
                * True - refinement is used.
                  Less performance, more precision.
                * False - refinement is not used.
                  More performance, less precision.

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixsolvem(
    complex_2d_array a,
    ae_int_t n,
    complex_2d_array b,
    ae_int_t m,
    <b>bool</b> rfs,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_2d_array&amp; x);

</div></pre>
<a name='sub_hpdmatrixcholeskysolve'></a><h3 class=pageheader><code>hpdmatrixcholeskysolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolve(), but for  HPD matrices  represented
by their Cholesky decomposition.

Algorithm features:
* automatic detection of degenerate cases
* O(N^2) complexity
* condition number estimation
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
                SPDMatrixCholesky result
    N       -   size of A
    IsUpper -   what half of CHA is provided
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixcholeskysolve(
    complex_2d_array cha,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_1d_array&amp; x);

</div></pre>
<a name='sub_hpdmatrixcholeskysolvem'></a><h3 class=pageheader><code>hpdmatrixcholeskysolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolveM(), but for HPD matrices  represented
by their Cholesky decomposition.

Algorithm features:
* automatic detection of degenerate cases
* O(M*N^2) complexity
* condition number estimation
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
                HPDMatrixCholesky result
    N       -   size of CHA
    IsUpper -   what half of CHA is provided
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixcholeskysolvem(
    complex_2d_array cha,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_2d_array&amp; x);

</div></pre>
<a name='sub_hpdmatrixsolve'></a><h3 class=pageheader><code>hpdmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolve(),  but for Hermitian positive definite
matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* O(N^3) complexity
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    IsUpper -   what half of A is provided
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
                Returns -3 for non-HPD matrices.
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixsolve(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_1d_array&amp; x);

</div></pre>
<a name='sub_hpdmatrixsolvem'></a><h3 class=pageheader><code>hpdmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolveM(), but for Hermitian positive definite
matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* O(N^3+M*N^2) complexity
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    IsUpper -   what half of A is provided
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve.
                Returns -3 for non-HPD matrices.
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixsolvem(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    complex_2d_array&amp; x);

</div></pre>
<a name='sub_rmatrixlusolve'></a><h3 class=pageheader><code>rmatrixlusolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

This  subroutine  solves  a  system  A*X=B,  where A is NxN non-denegerate
real matrix given by its LU decomposition, X and B are NxM real matrices.

Algorithm features:
* automatic detection of degenerate cases
* O(N^2) complexity
* condition number estimation

No iterative refinement  is provided because exact form of original matrix
is not known to subroutine. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
    P       -   array[0..N-1], pivots array, RMatrixLU result
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlusolve(
    real_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    real_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_rmatrixlusolvem'></a><h3 class=pageheader><code>rmatrixlusolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

Similar to RMatrixLUSolve() but solves task with multiple right parts
(where b and x are NxM matrices).

Algorithm features:
* automatic detection of degenerate cases
* O(M*N^2) complexity
* condition number estimation

No iterative refinement  is provided because exact form of original matrix
is not known to subroutine. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
    P       -   array[0..N-1], pivots array, RMatrixLU result
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlusolvem(
    real_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    real_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_2d_array&amp; x);

</div></pre>
<a name='sub_rmatrixmixedsolve'></a><h3 class=pageheader><code>rmatrixmixedsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

This  subroutine  solves  a  system  A*x=b,  where BOTH ORIGINAL A AND ITS
LU DECOMPOSITION ARE KNOWN. You can use it if for some  reasons  you  have
both A and its LU decomposition.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
    P       -   array[0..N-1], pivots array, RMatrixLU result
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolveM
    Rep     -   same as in RMatrixSolveM
    X       -   same as in RMatrixSolveM

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixmixedsolve(
    real_2d_array a,
    real_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    real_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_rmatrixmixedsolvem'></a><h3 class=pageheader><code>rmatrixmixedsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

Similar to RMatrixMixedSolve() but  solves task with multiple right  parts
(where b and x are NxM matrices).

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(M*N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    LUA     -   array[0..N-1,0..N-1], LU decomposition, RMatrixLU result
    P       -   array[0..N-1], pivots array, RMatrixLU result
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolveM
    Rep     -   same as in RMatrixSolveM
    X       -   same as in RMatrixSolveM

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixmixedsolvem(
    real_2d_array a,
    real_2d_array lua,
    integer_1d_array p,
    ae_int_t n,
    real_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_2d_array&amp; x);

</div></pre>
<a name='sub_rmatrixsolve'></a><h3 class=pageheader><code>rmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

This  subroutine  solves  a  system  A*x=b,  where A is NxN non-denegerate
real matrix, x and b are vectors.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* iterative refinement
* O(N^3) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   return code:
                * -3    A is singular, or VERY close to singular.
                        X is filled by zeros in such cases.
                * -1    N&lt;=0 was passed
                *  1    task is solved (but matrix A may be ill-conditioned,
                        check R1/RInf parameters for condition numbers).
    Rep     -   solver report, see below for more info
    X       -   array[0..N-1], it contains:
                * solution of A*x=b if A is non-singular (well-conditioned
                  or ill-conditioned, but not very close to singular)
                * zeros,  if  A  is  singular  or  VERY  close to singular
                  (in this case Info=-3).

SOLVER REPORT

Subroutine sets following fields of the Rep structure:
* R1        reciprocal of condition number: 1/cond(A), 1-norm.
* RInf      reciprocal of condition number: 1/cond(A), inf-norm.

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixsolve(
    real_2d_array a,
    ae_int_t n,
    real_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_rmatrixsolvels'></a><h3 class=pageheader><code>rmatrixsolvels</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

This subroutine finds solution of the linear system A*X=B with non-square,
possibly degenerate A.  System  is  solved in the least squares sense, and
general least squares solution  X = X0 + CX*y  which  minimizes |A*X-B| is
returned. If A is non-degenerate, solution in the usual sense is returned.

Algorithm features:
* automatic detection (and correct handling!) of degenerate cases
* iterative refinement
* O(N^3) complexity

INPUT PARAMETERS
    A       -   array[0..NRows-1,0..NCols-1], system matrix
    NRows   -   vertical size of A
    NCols   -   horizontal size of A
    B       -   array[0..NCols-1], right part
    Threshold-  a number in [0,1]. Singular values  beyond  Threshold  are
                considered  zero.  Set  it to 0.0, if you don't understand
                what it means, so the solver will choose good value on its
                own.

OUTPUT PARAMETERS
    Info    -   return code:
                * -4    SVD subroutine failed
                * -1    if NRows&lt;=0 or NCols&lt;=0 or Threshold&lt;0 was passed
                *  1    if task is solved
    Rep     -   solver report, see below for more info
    X       -   array[0..N-1,0..M-1], it contains:
                * solution of A*X=B (even for singular A)
                * zeros, if SVD subroutine failed

SOLVER REPORT

Subroutine sets following fields of the Rep structure:
* R2        reciprocal of condition number: 1/cond(A), 2-norm.
* N         = NCols
* K         dim(Null(A))
* CX        array[0..N-1,0..K-1], kernel of A.
            Columns of CX store such vectors that A*CX[i]=0.

  -- ALGLIB --
     Copyright 24.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixsolvels(
    real_2d_array a,
    ae_int_t nrows,
    ae_int_t ncols,
    real_1d_array b,
    <b>double</b> threshold,
    ae_int_t&amp; info,
    densesolverlsreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_rmatrixsolvem'></a><h3 class=pageheader><code>rmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver.

Similar to RMatrixSolve() but solves task with multiple right parts (where
b and x are NxM matrices).

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* optional iterative refinement
* O(N^3+M*N^2) complexity

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size
    RFS     -   iterative refinement switch:
                * True - refinement is used.
                  Less performance, more precision.
                * False - refinement is not used.
                  More performance, less precision.

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixsolvem(
    real_2d_array a,
    ae_int_t n,
    real_2d_array b,
    ae_int_t m,
    <b>bool</b> rfs,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_2d_array&amp; x);

</div></pre>
<a name='sub_spdmatrixcholeskysolve'></a><h3 class=pageheader><code>spdmatrixcholeskysolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolve(), but for  SPD matrices  represented
by their Cholesky decomposition.

Algorithm features:
* automatic detection of degenerate cases
* O(N^2) complexity
* condition number estimation
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
                SPDMatrixCholesky result
    N       -   size of A
    IsUpper -   what half of CHA is provided
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixcholeskysolve(
    real_2d_array cha,
    ae_int_t n,
    <b>bool</b> isupper,
    real_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_spdmatrixcholeskysolvem'></a><h3 class=pageheader><code>spdmatrixcholeskysolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixLUSolveM(), but for SPD matrices  represented
by their Cholesky decomposition.

Algorithm features:
* automatic detection of degenerate cases
* O(M*N^2) complexity
* condition number estimation
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    CHA     -   array[0..N-1,0..N-1], Cholesky decomposition,
                SPDMatrixCholesky result
    N       -   size of CHA
    IsUpper -   what half of CHA is provided
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixcholeskysolvem(
    real_2d_array cha,
    ae_int_t n,
    <b>bool</b> isupper,
    real_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_2d_array&amp; x);

</div></pre>
<a name='sub_spdmatrixsolve'></a><h3 class=pageheader><code>spdmatrixsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolve(), but for SPD matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* O(N^3) complexity
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    IsUpper -   what half of A is provided
    B       -   array[0..N-1], right part

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve
                Returns -3 for non-SPD matrices.
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixsolve(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    real_1d_array b,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_1d_array&amp; x);

</div></pre>
<a name='sub_spdmatrixsolvem'></a><h3 class=pageheader><code>spdmatrixsolvem</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Dense solver. Same as RMatrixSolveM(), but for symmetric positive definite
matrices.

Algorithm features:
* automatic detection of degenerate cases
* condition number estimation
* O(N^3+M*N^2) complexity
* matrix is represented by its upper or lower triangle

No iterative refinement is provided because such partial representation of
matrix does not allow efficient calculation of extra-precise  matrix-vector
products for large matrices. Use RMatrixSolve or RMatrixMixedSolve  if  you
need iterative refinement.

INPUT PARAMETERS
    A       -   array[0..N-1,0..N-1], system matrix
    N       -   size of A
    IsUpper -   what half of A is provided
    B       -   array[0..N-1,0..M-1], right part
    M       -   right part size

OUTPUT PARAMETERS
    Info    -   same as in RMatrixSolve.
                Returns -3 for non-SPD matrices.
    Rep     -   same as in RMatrixSolve
    X       -   same as in RMatrixSolve

  -- ALGLIB --
     Copyright 27.01.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixsolvem(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    real_2d_array b,
    ae_int_t m,
    ae_int_t&amp; info,
    densesolverreport&amp; rep,
    real_2d_array&amp; x);

</div></pre>
<a name=unit_dforest></a><h2 class=pageheader><code>dforest</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_decisionforest' class=toc>decisionforest</a><br>
<a href='#struct_dfreport' class=toc>dfreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_dfavgce' class=toc>dfavgce</a><br>
<a href='#sub_dfavgerror' class=toc>dfavgerror</a><br>
<a href='#sub_dfavgrelerror' class=toc>dfavgrelerror</a><br>
<a href='#sub_dfbuildrandomdecisionforest' class=toc>dfbuildrandomdecisionforest</a><br>
<a href='#sub_dfbuildrandomdecisionforestx1' class=toc>dfbuildrandomdecisionforestx1</a><br>
<a href='#sub_dfprocess' class=toc>dfprocess</a><br>
<a href='#sub_dfprocessi' class=toc>dfprocessi</a><br>
<a href='#sub_dfrelclserror' class=toc>dfrelclserror</a><br>
<a href='#sub_dfrmserror' class=toc>dfrmserror</a><br>
<a href='#sub_dfserialize' class=toc>dfserialize</a><br>
<a href='#sub_dfunserialize' class=toc>dfunserialize</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_decisionforest'></a><h3 class=pageheader><code>decisionforest</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> decisionforest
{
};

</div></pre>
<a name='struct_dfreport'></a><h3 class=pageheader><code>dfreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> dfreport
{
    <b>double</b>               relclserror;
    <b>double</b>               avgce;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               oobrelclserror;
    <b>double</b>               oobavgce;
    <b>double</b>               oobrmserror;
    <b>double</b>               oobavgerror;
    <b>double</b>               oobavgrelerror;
};

</div></pre>
<a name='sub_dfavgce'></a><h3 class=pageheader><code>dfavgce</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average cross-entropy (in bits per element) on the test set

INPUT PARAMETERS:
    DF      -   decision forest model
    XY      -   test set
    NPoints -   test set size

RESULT:
    CrossEntropy/(NPoints*LN(2)).
    Zero if model solves regression task.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dfavgce(
    decisionforest df,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_dfavgerror'></a><h3 class=pageheader><code>dfavgerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average error on the test set

INPUT PARAMETERS:
    DF      -   decision forest model
    XY      -   test set
    NPoints -   test set size

RESULT:
    Its meaning for regression task is obvious. As for
    classification task, it means average error when estimating posterior
    probabilities.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dfavgerror(
    decisionforest df,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_dfavgrelerror'></a><h3 class=pageheader><code>dfavgrelerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average relative error on the test set

INPUT PARAMETERS:
    DF      -   decision forest model
    XY      -   test set
    NPoints -   test set size

RESULT:
    Its meaning for regression task is obvious. As for
    classification task, it means average relative error when estimating
    posterior probability of belonging to the correct class.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dfavgrelerror(
    decisionforest df,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_dfbuildrandomdecisionforest'></a><h3 class=pageheader><code>dfbuildrandomdecisionforest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds random decision forest.

INPUT PARAMETERS:
    XY          -   training set
    NPoints     -   training set size, NPoints&gt;=1
    NVars       -   number of independent variables, NVars&gt;=1
    NClasses    -   task type:
                    * NClasses=1 - regression task with one
                                   dependent variable
                    * NClasses&gt;1 - classification task with
                                   NClasses classes.
    NTrees      -   number of trees in a forest, NTrees&gt;=1.
                    recommended values: 50-100.
    R           -   percent of a training set used to build
                    individual trees. 0&lt;R&lt;=1.
                    recommended values: 0.1 &lt;= R &lt;= 0.66.

OUTPUT PARAMETERS:
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;1, NVars&lt;1, NClasses&lt;1, NTrees&lt;1, R&lt;=0
                          or R&gt;1).
                    *  1, if task has been solved
    DF          -   model built
    Rep         -   training report, contains error on a training set
                    and out-of-bag estimates of generalization error.

  -- ALGLIB --
     Copyright 19.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dfbuildrandomdecisionforest(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t nclasses,
    ae_int_t ntrees,
    <b>double</b> r,
    ae_int_t&amp; info,
    decisionforest&amp; df,
    dfreport&amp; rep);

</div></pre>
<a name='sub_dfbuildrandomdecisionforestx1'></a><h3 class=pageheader><code>dfbuildrandomdecisionforestx1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds random decision forest.
This function gives ability to tune number of variables used when choosing
best split.

INPUT PARAMETERS:
    XY          -   training set
    NPoints     -   training set size, NPoints&gt;=1
    NVars       -   number of independent variables, NVars&gt;=1
    NClasses    -   task type:
                    * NClasses=1 - regression task with one
                                   dependent variable
                    * NClasses&gt;1 - classification task with
                                   NClasses classes.
    NTrees      -   number of trees in a forest, NTrees&gt;=1.
                    recommended values: 50-100.
    NRndVars    -   number of variables used when choosing best split
    R           -   percent of a training set used to build
                    individual trees. 0&lt;R&lt;=1.
                    recommended values: 0.1 &lt;= R &lt;= 0.66.

OUTPUT PARAMETERS:
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;1, NVars&lt;1, NClasses&lt;1, NTrees&lt;1, R&lt;=0
                          or R&gt;1).
                    *  1, if task has been solved
    DF          -   model built
    Rep         -   training report, contains error on a training set
                    and out-of-bag estimates of generalization error.

  -- ALGLIB --
     Copyright 19.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dfbuildrandomdecisionforestx1(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t nclasses,
    ae_int_t ntrees,
    ae_int_t nrndvars,
    <b>double</b> r,
    ae_int_t&amp; info,
    decisionforest&amp; df,
    dfreport&amp; rep);

</div></pre>
<a name='sub_dfprocess'></a><h3 class=pageheader><code>dfprocess</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procesing

INPUT PARAMETERS:
    DF      -   decision forest model
    X       -   input vector,  array[0..NVars-1].

OUTPUT PARAMETERS:
    Y       -   result. Regression estimate when solving regression  task,
                vector of posterior probabilities for classification task.

See also DFProcessI.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dfprocess(
    decisionforest df,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_dfprocessi'></a><h3 class=pageheader><code>dfprocessi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
'interactive' variant of DFProcess for languages like Python which support
constructs like &quot;Y = DFProcessI(DF,X)&quot; and interactive mode of interpreter

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::dfprocessi(
    decisionforest df,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_dfrelclserror'></a><h3 class=pageheader><code>dfrelclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Relative classification error on the test set

INPUT PARAMETERS:
    DF      -   decision forest model
    XY      -   test set
    NPoints -   test set size

RESULT:
    percent of incorrectly classified cases.
    Zero if model solves regression task.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dfrelclserror(
    decisionforest df,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_dfrmserror'></a><h3 class=pageheader><code>dfrmserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set

INPUT PARAMETERS:
    DF      -   decision forest model
    XY      -   test set
    NPoints -   test set size

RESULT:
    root mean square error.
    Its meaning for regression task is obvious. As for
    classification task, RMS error means error when estimating posterior
    probabilities.

  -- ALGLIB --
     Copyright 16.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::dfrmserror(
    decisionforest df,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_dfserialize'></a><h3 class=pageheader><code>dfserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function serializes data structure to string.

Important properties of s_out:
* it contains alphanumeric characters, dots, underscores, minus signs
* these symbols are grouped into words, which are separated by spaces
  and Windows-style (CR+LF) newlines
* although  serializer  uses  spaces and CR+LF as separators, you can 
  replace any separator character by arbitrary combination of spaces,
  tabs, Windows or Unix newlines. It allows flexible reformatting  of
  the  string  in  case you want to include it into text or XML file. 
  But you should not insert separators into the middle of the &quot;words&quot;
  nor you should change case of letters.
* s_out can be freely moved between 32-bit and 64-bit systems, little
  and big endian machines, and so on. You can serialize structure  on
  32-bit machine and unserialize it on 64-bit one (or vice versa), or
  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also 
  serialize  it  in  C++ version of ALGLIB and unserialize in C# one, 
  and vice versa.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> dfserialize(decisionforest &amp;obj, std::string &amp;s_out);
</div></pre>
<a name='sub_dfunserialize'></a><h3 class=pageheader><code>dfunserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function unserializes data structure from string.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> dfunserialize(std::string &amp;s_in, decisionforest &amp;obj);
</div></pre>
<a name=unit_elliptic></a><h2 class=pageheader><code>elliptic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_ellipticintegrale' class=toc>ellipticintegrale</a><br>
<a href='#sub_ellipticintegralk' class=toc>ellipticintegralk</a><br>
<a href='#sub_ellipticintegralkhighprecision' class=toc>ellipticintegralkhighprecision</a><br>
<a href='#sub_incompleteellipticintegrale' class=toc>incompleteellipticintegrale</a><br>
<a href='#sub_incompleteellipticintegralk' class=toc>incompleteellipticintegralk</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_ellipticintegrale'></a><h3 class=pageheader><code>ellipticintegrale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complete elliptic integral of the second kind

Approximates the integral


           pi/2
            -
           | |                 2
E(m)  =    |    sqrt( 1 - m sin t ) dt
         | |
          -
           0

using the approximation

     P(x)  -  x log x Q(x).

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE       0, 1       10000       2.1e-16     7.3e-17

Cephes Math Library, Release 2.8: June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::ellipticintegrale(<b>double</b> m);

</div></pre>
<a name='sub_ellipticintegralk'></a><h3 class=pageheader><code>ellipticintegralk</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complete elliptic integral of the first kind

Approximates the integral



           pi/2
            -
           | |
           |           dt
K(m)  =    |    ------------------
           |                   2
         | |    sqrt( 1 - m sin t )
          -
           0

using the approximation

    P(x)  -  log x Q(x).

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE       0,1        30000       2.5e-16     6.8e-17

Cephes Math Library, Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::ellipticintegralk(<b>double</b> m);

</div></pre>
<a name='sub_ellipticintegralkhighprecision'></a><h3 class=pageheader><code>ellipticintegralkhighprecision</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complete elliptic integral of the first kind

Approximates the integral



           pi/2
            -
           | |
           |           dt
K(m)  =    |    ------------------
           |                   2
         | |    sqrt( 1 - m sin t )
          -
           0

where m = 1 - m1, using the approximation

    P(x)  -  log x Q(x).

The argument m1 is used rather than m so that the logarithmic
singularity at m = 1 will be shifted to the origin; this
preserves maximum accuracy.

K(0) = pi/2.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE       0,1        30000       2.5e-16     6.8e-17

    Cephes
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::ellipticintegralkhighprecision(<b>double</b> m1);

</div></pre>
<a name='sub_incompleteellipticintegrale'></a><h3 class=pageheader><code>incompleteellipticintegrale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Incomplete elliptic integral of the second kind

Approximates the integral


               phi
                -
               | |
               |                   2
E(phi_\m)  =    |    sqrt( 1 - m sin t ) dt
               |
             | |
              -
               0

of amplitude phi and modulus m, using the arithmetic -
geometric mean algorithm.

ACCURACY:

Tested at random arguments with phi in [-10, 10] and m in
[0, 1].
                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE     -10,10      150000       3.3e-15     1.4e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1993, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::incompleteellipticintegrale(<b>double</b> phi, <b>double</b> m);

</div></pre>
<a name='sub_incompleteellipticintegralk'></a><h3 class=pageheader><code>incompleteellipticintegralk</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Incomplete elliptic integral of the first kind F(phi|m)

Approximates the integral



               phi
                -
               | |
               |           dt
F(phi_\m)  =    |    ------------------
               |                   2
             | |    sqrt( 1 - m sin t )
              -
               0

of amplitude phi and modulus m, using the arithmetic -
geometric mean algorithm.




ACCURACY:

Tested at random points with m in [0, 1] and phi as indicated.

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE     -10,10       200000      7.4e-16     1.0e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::incompleteellipticintegralk(<b>double</b> phi, <b>double</b> m);

</div></pre>
<a name=unit_evd></a><h2 class=pageheader><code>evd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hmatrixevd' class=toc>hmatrixevd</a><br>
<a href='#sub_hmatrixevdi' class=toc>hmatrixevdi</a><br>
<a href='#sub_hmatrixevdr' class=toc>hmatrixevdr</a><br>
<a href='#sub_rmatrixevd' class=toc>rmatrixevd</a><br>
<a href='#sub_smatrixevd' class=toc>smatrixevd</a><br>
<a href='#sub_smatrixevdi' class=toc>smatrixevdi</a><br>
<a href='#sub_smatrixevdr' class=toc>smatrixevdr</a><br>
<a href='#sub_smatrixtdevd' class=toc>smatrixtdevd</a><br>
<a href='#sub_smatrixtdevdi' class=toc>smatrixtdevdi</a><br>
<a href='#sub_smatrixtdevdr' class=toc>smatrixtdevdr</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hmatrixevd'></a><h3 class=pageheader><code>hmatrixevd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Finding the eigenvalues and eigenvectors of a Hermitian matrix

The algorithm finds eigen pairs of a Hermitian matrix by  reducing  it  to
real tridiagonal form and using the QL/QR algorithm.

Input parameters:
    A       -   Hermitian matrix which is given  by  its  upper  or  lower
                triangular part.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   storage format.
    ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
                not. If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.

Output parameters:
    D       -   eigenvalues in ascending order.
                Array whose index ranges within [0..N-1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains the eigenvectors.
                Array whose indexes range within [0..N-1, 0..N-1].
                The eigenvectors are stored in the matrix columns.

Result:
    True, if the algorithm has converged.
    False, if the algorithm hasn't converged (rare case).

Note:
    eigenvectors of Hermitian matrix are defined up to  multiplication  by
    a complex number L, such that |L|=1.

  -- ALGLIB --
     Copyright 2005, 23 March 2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::hmatrixevd(
    complex_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    real_1d_array&amp; d,
    complex_2d_array&amp; z);

</div></pre>
<a name='sub_hmatrixevdi'></a><h3 class=pageheader><code>hmatrixevdi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding the eigenvalues and  eigenvectors  of  a  Hermitian
matrix with given indexes by using bisection and inverse iteration methods

Input parameters:
    A       -   Hermitian matrix which is given  by  its  upper  or  lower
                triangular part.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
                not. If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.
    IsUpperA -  storage format of matrix A.
    I1, I2 -    index interval for searching (from I1 to I2).
                0 &lt;= I1 &lt;= I2 &lt;= N-1.

Output parameters:
    W       -   array of the eigenvalues found.
                Array whose index ranges within [0..I2-I1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains eigenvectors.
                Array whose indexes range within [0..N-1, 0..I2-I1].
                In  that  case,  the eigenvectors are stored in the matrix
                columns.

Result:
    True, if successful. W contains the eigenvalues, Z contains the
    eigenvectors (if needed).

    False, if the bisection method subroutine  wasn't  able  to  find  the
    eigenvalues  in  the  given  interval  or  if  the  inverse  iteration
    subroutine wasn't able to find  all  the  corresponding  eigenvectors.
    In that case, the eigenvalues and eigenvectors are not returned.

Note:
    eigen vectors of Hermitian matrix are defined up to multiplication  by
    a complex number L, such as |L|=1.

  -- ALGLIB --
     Copyright 07.01.2006, 24.03.2007 by Bochkanov Sergey.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::hmatrixevdi(
    complex_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    ae_int_t i1,
    ae_int_t i2,
    real_1d_array&amp; w,
    complex_2d_array&amp; z);

</div></pre>
<a name='sub_hmatrixevdr'></a><h3 class=pageheader><code>hmatrixevdr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding the eigenvalues (and eigenvectors) of  a  Hermitian
matrix  in  a  given half-interval (A, B] by using a bisection and inverse
iteration

Input parameters:
    A       -   Hermitian matrix which is given  by  its  upper  or  lower
                triangular  part.  Array  whose   indexes   range   within
                [0..N-1, 0..N-1].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors  are  needed  or
                not. If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.
    IsUpperA -  storage format of matrix A.
    B1, B2 -    half-interval (B1, B2] to search eigenvalues in.

Output parameters:
    M       -   number of eigenvalues found in a given half-interval, M&gt;=0
    W       -   array of the eigenvalues found.
                Array whose index ranges within [0..M-1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains eigenvectors.
                Array whose indexes range within [0..N-1, 0..M-1].
                The eigenvectors are stored in the matrix columns.

Result:
    True, if successful. M contains the number of eigenvalues in the given
    half-interval (could be equal to 0), W contains the eigenvalues,
    Z contains the eigenvectors (if needed).

    False, if the bisection method subroutine  wasn't  able  to  find  the
    eigenvalues  in  the  given  interval  or  if  the  inverse  iteration
    subroutine  wasn't  able  to  find all the corresponding eigenvectors.
    In that case, the eigenvalues and eigenvectors are not returned, M  is
    equal to 0.

Note:
    eigen vectors of Hermitian matrix are defined up to multiplication  by
    a complex number L, such as |L|=1.

  -- ALGLIB --
     Copyright 07.01.2006, 24.03.2007 by Bochkanov Sergey.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::hmatrixevdr(
    complex_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    <b>double</b> b1,
    <b>double</b> b2,
    ae_int_t&amp; m,
    real_1d_array&amp; w,
    complex_2d_array&amp; z);

</div></pre>
<a name='sub_rmatrixevd'></a><h3 class=pageheader><code>rmatrixevd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Finding eigenvalues and eigenvectors of a general matrix

The algorithm finds eigenvalues and eigenvectors of a general matrix by
using the QR algorithm with multiple shifts. The algorithm can find
eigenvalues and both left and right eigenvectors.

The right eigenvector is a vector x such that A*x = w*x, and the left
eigenvector is a vector y such that y'*A = w*y' (here y' implies a complex
conjugate transposition of vector y).

Input parameters:
    A       -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    VNeeded -   flag controlling whether eigenvectors are needed or not.
                If VNeeded is equal to:
                 * 0, eigenvectors are not returned;
                 * 1, right eigenvectors are returned;
                 * 2, left eigenvectors are returned;
                 * 3, both left and right eigenvectors are returned.

Output parameters:
    WR      -   real parts of eigenvalues.
                Array whose index ranges within [0..N-1].
    WR      -   imaginary parts of eigenvalues.
                Array whose index ranges within [0..N-1].
    VL, VR  -   arrays of left and right eigenvectors (if they are needed).
                If WI[i]=0, the respective eigenvalue is a real number,
                and it corresponds to the column number I of matrices VL/VR.
                If WI[i]&gt;0, we have a pair of complex conjugate numbers with
                positive and negative imaginary parts:
                    the first eigenvalue WR[i] + sqrt(-1)*WI[i];
                    the second eigenvalue WR[i+1] + sqrt(-1)*WI[i+1];
                    WI[i]&gt;0
                    WI[i+1] = -WI[i] &lt; 0
                In that case, the eigenvector  corresponding to the first
                eigenvalue is located in i and i+1 columns of matrices
                VL/VR (the column number i contains the real part, and the
                column number i+1 contains the imaginary part), and the vector
                corresponding to the second eigenvalue is a complex conjugate to
                the first vector.
                Arrays whose indexes range within [0..N-1, 0..N-1].

Result:
    True, if the algorithm has converged.
    False, if the algorithm has not converged.

Note 1:
    Some users may ask the following question: what if WI[N-1]&gt;0?
    WI[N] must contain an eigenvalue which is complex conjugate to the
    N-th eigenvalue, but the array has only size N?
    The answer is as follows: such a situation cannot occur because the
    algorithm finds a pairs of eigenvalues, therefore, if WI[i]&gt;0, I is
    strictly less than N-1.

Note 2:
    The algorithm performance depends on the value of the internal parameter
    NS of the InternalSchurDecomposition subroutine which defines the number
    of shifts in the QR algorithm (similarly to the block width in block-matrix
    algorithms of linear algebra). If you require maximum performance
    on your machine, it is recommended to adjust this parameter manually.


See also the InternalTREVC subroutine.

The algorithm is based on the LAPACK 3.0 library.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::rmatrixevd(
    real_2d_array a,
    ae_int_t n,
    ae_int_t vneeded,
    real_1d_array&amp; wr,
    real_1d_array&amp; wi,
    real_2d_array&amp; vl,
    real_2d_array&amp; vr);

</div></pre>
<a name='sub_smatrixevd'></a><h3 class=pageheader><code>smatrixevd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Finding the eigenvalues and eigenvectors of a symmetric matrix

The algorithm finds eigen pairs of a symmetric matrix by reducing it to
tridiagonal form and using the QL/QR algorithm.

Input parameters:
    A       -   symmetric matrix which is given by its upper or lower
                triangular part.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.
    IsUpper -   storage format.

Output parameters:
    D       -   eigenvalues in ascending order.
                Array whose index ranges within [0..N-1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains the eigenvectors.
                Array whose indexes range within [0..N-1, 0..N-1].
                The eigenvectors are stored in the matrix columns.

Result:
    True, if the algorithm has converged.
    False, if the algorithm hasn't converged (rare case).

  -- ALGLIB --
     Copyright 2005-2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixevd(
    real_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    real_1d_array&amp; d,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixevdi'></a><h3 class=pageheader><code>smatrixevdi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding the eigenvalues and  eigenvectors  of  a  symmetric
matrix with given indexes by using bisection and inverse iteration methods.

Input parameters:
    A       -   symmetric matrix which is given by its upper or lower
                triangular part. Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.
    IsUpperA -  storage format of matrix A.
    I1, I2 -    index interval for searching (from I1 to I2).
                0 &lt;= I1 &lt;= I2 &lt;= N-1.

Output parameters:
    W       -   array of the eigenvalues found.
                Array whose index ranges within [0..I2-I1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains eigenvectors.
                Array whose indexes range within [0..N-1, 0..I2-I1].
                In that case, the eigenvectors are stored in the matrix columns.

Result:
    True, if successful. W contains the eigenvalues, Z contains the
    eigenvectors (if needed).

    False, if the bisection method subroutine wasn't able to find the
    eigenvalues in the given interval or if the inverse iteration subroutine
    wasn't able to find all the corresponding eigenvectors.
    In that case, the eigenvalues and eigenvectors are not returned.

  -- ALGLIB --
     Copyright 07.01.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixevdi(
    real_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    ae_int_t i1,
    ae_int_t i2,
    real_1d_array&amp; w,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixevdr'></a><h3 class=pageheader><code>smatrixevdr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding the eigenvalues (and eigenvectors) of  a  symmetric
matrix  in  a  given half open interval (A, B] by using  a  bisection  and
inverse iteration

Input parameters:
    A       -   symmetric matrix which is given by its upper or lower
                triangular part. Array [0..N-1, 0..N-1].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not returned;
                 * 1, the eigenvectors are returned.
    IsUpperA -  storage format of matrix A.
    B1, B2 -    half open interval (B1, B2] to search eigenvalues in.

Output parameters:
    M       -   number of eigenvalues found in a given half-interval (M&gt;=0).
    W       -   array of the eigenvalues found.
                Array whose index ranges within [0..M-1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains eigenvectors.
                Array whose indexes range within [0..N-1, 0..M-1].
                The eigenvectors are stored in the matrix columns.

Result:
    True, if successful. M contains the number of eigenvalues in the given
    half-interval (could be equal to 0), W contains the eigenvalues,
    Z contains the eigenvectors (if needed).

    False, if the bisection method subroutine wasn't able to find the
    eigenvalues in the given interval or if the inverse iteration subroutine
    wasn't able to find all the corresponding eigenvectors.
    In that case, the eigenvalues and eigenvectors are not returned,
    M is equal to 0.

  -- ALGLIB --
     Copyright 07.01.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixevdr(
    real_2d_array a,
    ae_int_t n,
    ae_int_t zneeded,
    <b>bool</b> isupper,
    <b>double</b> b1,
    <b>double</b> b2,
    ae_int_t&amp; m,
    real_1d_array&amp; w,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixtdevd'></a><h3 class=pageheader><code>smatrixtdevd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Finding the eigenvalues and eigenvectors of a tridiagonal symmetric matrix

The algorithm finds the eigen pairs of a tridiagonal symmetric matrix by
using an QL/QR algorithm with implicit shifts.

Input parameters:
    D       -   the main diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-1].
    E       -   the secondary diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-2].
    N       -   size of matrix A.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not needed;
                 * 1, the eigenvectors of a tridiagonal matrix
                   are multiplied by the square matrix Z. It is used if the
                   tridiagonal matrix is obtained by the similarity
                   transformation of a symmetric matrix;
                 * 2, the eigenvectors of a tridiagonal matrix replace the
                   square matrix Z;
                 * 3, matrix Z contains the first row of the eigenvectors
                   matrix.
    Z       -   if ZNeeded=1, Z contains the square matrix by which the
                eigenvectors are multiplied.
                Array whose indexes range within [0..N-1, 0..N-1].

Output parameters:
    D       -   eigenvalues in ascending order.
                Array whose index ranges within [0..N-1].
    Z       -   if ZNeeded is equal to:
                 * 0, Z hasnt changed;
                 * 1, Z contains the product of a given matrix (from the left)
                   and the eigenvectors matrix (from the right);
                 * 2, Z contains the eigenvectors.
                 * 3, Z contains the first row of the eigenvectors matrix.
                If ZNeeded&lt;3, Z is the array whose indexes range within [0..N-1, 0..N-1].
                In that case, the eigenvectors are stored in the matrix columns.
                If ZNeeded=3, Z is the array whose indexes range within [0..0, 0..N-1].

Result:
    True, if the algorithm has converged.
    False, if the algorithm hasn't converged.

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     September 30, 1994
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixtdevd(
    real_1d_array&amp; d,
    real_1d_array e,
    ae_int_t n,
    ae_int_t zneeded,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixtdevdi'></a><h3 class=pageheader><code>smatrixtdevdi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding tridiagonal matrix eigenvalues/vectors with given
indexes (in ascending order) by using the bisection and inverse iteraion.

Input parameters:
    D       -   the main diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-1].
    E       -   the secondary diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-2].
    N       -   size of matrix. N&gt;=0.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not needed;
                 * 1, the eigenvectors of a tridiagonal matrix are multiplied
                   by the square matrix Z. It is used if the
                   tridiagonal matrix is obtained by the similarity transformation
                   of a symmetric matrix.
                 * 2, the eigenvectors of a tridiagonal matrix replace
                   matrix Z.
    I1, I2  -   index interval for searching (from I1 to I2).
                0 &lt;= I1 &lt;= I2 &lt;= N-1.
    Z       -   if ZNeeded is equal to:
                 * 0, Z isn't used and remains unchanged;
                 * 1, Z contains the square matrix (array whose indexes range within [0..N-1, 0..N-1])
                   which reduces the given symmetric matrix to  tridiagonal form;
                 * 2, Z isn't used (but changed on the exit).

Output parameters:
    D       -   array of the eigenvalues found.
                Array whose index ranges within [0..I2-I1].
    Z       -   if ZNeeded is equal to:
                 * 0, doesn't contain any information;
                 * 1, contains the product of a given NxN matrix Z (from the left) and
                   Nx(I2-I1) matrix of the eigenvectors found (from the right).
                   Array whose indexes range within [0..N-1, 0..I2-I1].
                 * 2, contains the matrix of the eigenvalues found.
                   Array whose indexes range within [0..N-1, 0..I2-I1].


Result:

    True, if successful. In that case, D contains the eigenvalues,
    Z contains the eigenvectors (if needed).
    It should be noted that the subroutine changes the size of arrays D and Z.

    False, if the bisection method subroutine wasn't able to find the eigenvalues
    in the given interval or if the inverse iteration subroutine wasn't able
    to find all the corresponding eigenvectors. In that case, the eigenvalues
    and eigenvectors are not returned.

  -- ALGLIB --
     Copyright 25.12.2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixtdevdi(
    real_1d_array&amp; d,
    real_1d_array e,
    ae_int_t n,
    ae_int_t zneeded,
    ae_int_t i1,
    ae_int_t i2,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixtdevdr'></a><h3 class=pageheader><code>smatrixtdevdr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine for finding the tridiagonal matrix eigenvalues/vectors in a
given half-interval (A, B] by using bisection and inverse iteration.

Input parameters:
    D       -   the main diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-1].
    E       -   the secondary diagonal of a tridiagonal matrix.
                Array whose index ranges within [0..N-2].
    N       -   size of matrix, N&gt;=0.
    ZNeeded -   flag controlling whether the eigenvectors are needed or not.
                If ZNeeded is equal to:
                 * 0, the eigenvectors are not needed;
                 * 1, the eigenvectors of a tridiagonal matrix are multiplied
                   by the square matrix Z. It is used if the tridiagonal
                   matrix is obtained by the similarity transformation
                   of a symmetric matrix.
                 * 2, the eigenvectors of a tridiagonal matrix replace matrix Z.
    A, B    -   half-interval (A, B] to search eigenvalues in.
    Z       -   if ZNeeded is equal to:
                 * 0, Z isn't used and remains unchanged;
                 * 1, Z contains the square matrix (array whose indexes range
                   within [0..N-1, 0..N-1]) which reduces the given symmetric
                   matrix to tridiagonal form;
                 * 2, Z isn't used (but changed on the exit).

Output parameters:
    D       -   array of the eigenvalues found.
                Array whose index ranges within [0..M-1].
    M       -   number of eigenvalues found in the given half-interval (M&gt;=0).
    Z       -   if ZNeeded is equal to:
                 * 0, doesn't contain any information;
                 * 1, contains the product of a given NxN matrix Z (from the
                   left) and NxM matrix of the eigenvectors found (from the
                   right). Array whose indexes range within [0..N-1, 0..M-1].
                 * 2, contains the matrix of the eigenvectors found.
                   Array whose indexes range within [0..N-1, 0..M-1].

Result:

    True, if successful. In that case, M contains the number of eigenvalues
    in the given half-interval (could be equal to 0), D contains the eigenvalues,
    Z contains the eigenvectors (if needed).
    It should be noted that the subroutine changes the size of arrays D and Z.

    False, if the bisection method subroutine wasn't able to find the
    eigenvalues in the given interval or if the inverse iteration subroutine
    wasn't able to find all the corresponding eigenvectors. In that case,
    the eigenvalues and eigenvectors are not returned, M is equal to 0.

  -- ALGLIB --
     Copyright 31.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixtdevdr(
    real_1d_array&amp; d,
    real_1d_array e,
    ae_int_t n,
    ae_int_t zneeded,
    <b>double</b> a,
    <b>double</b> b,
    ae_int_t&amp; m,
    real_2d_array&amp; z);

</div></pre>
<a name=unit_expintegrals></a><h2 class=pageheader><code>expintegrals</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_exponentialintegralei' class=toc>exponentialintegralei</a><br>
<a href='#sub_exponentialintegralen' class=toc>exponentialintegralen</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_exponentialintegralei'></a><h3 class=pageheader><code>exponentialintegralei</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Exponential integral Ei(x)

              x
               -     t
              | |   e
   Ei(x) =   -|-   ---  dt .
            | |     t
             -
            -inf

Not defined for x &lt;= 0.
See also expn.c.



ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE       0,100       50000      8.6e-16     1.3e-16

Cephes Math Library Release 2.8:  May, 1999
Copyright 1999 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::exponentialintegralei(<b>double</b> x);

</div></pre>
<a name='sub_exponentialintegralen'></a><h3 class=pageheader><code>exponentialintegralen</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Exponential integral En(x)

Evaluates the exponential integral

                inf.
                  -
                 | |   -xt
                 |    e
     E (x)  =    |    ----  dt.
      n          |      n
               | |     t
                -
                 1


Both n and x must be nonnegative.

The routine employs either a power series, a continued
fraction, or an asymptotic formula depending on the
relative values of n and x.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0, 30       10000       1.7e-15     3.6e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1985, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::exponentialintegralen(<b>double</b> x, ae_int_t n);

</div></pre>
<a name=unit_fdistr></a><h2 class=pageheader><code>fdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fcdistribution' class=toc>fcdistribution</a><br>
<a href='#sub_fdistribution' class=toc>fdistribution</a><br>
<a href='#sub_invfdistribution' class=toc>invfdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fcdistribution'></a><h3 class=pageheader><code>fcdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complemented F distribution

Returns the area from x to infinity under the F density
function (also known as Snedcor's density or the
variance ratio density).


                     inf.
                      -
             1       | |  a-1      b-1
1-P(x)  =  ------    |   t    (1-t)    dt
           B(a,b)  | |
                    -
                     x


The incomplete beta integral is used, according to the
formula

P(x) = incbet( df2/2, df1/2, (df2/(df2 + df1*x) ).


ACCURACY:

Tested at random points (a,b,x) in the indicated intervals.
               x     a,b                     Relative error:
arithmetic  domain  domain     # trials      peak         rms
   IEEE      0,1    1,100       100000      3.7e-14     5.9e-16
   IEEE      1,5    1,100       100000      8.0e-15     1.6e-15
   IEEE      0,1    1,10000     100000      1.8e-11     3.5e-13
   IEEE      1,5    1,10000     100000      2.0e-11     3.0e-12

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::fcdistribution(ae_int_t a, ae_int_t b, <b>double</b> x);

</div></pre>
<a name='sub_fdistribution'></a><h3 class=pageheader><code>fdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
F distribution

Returns the area from zero to x under the F density
function (also known as Snedcor's density or the
variance ratio density).  This is the density
of x = (u1/df1)/(u2/df2), where u1 and u2 are random
variables having Chi square distributions with df1
and df2 degrees of freedom, respectively.
The incomplete beta integral is used, according to the
formula

P(x) = incbet( df1/2, df2/2, (df1*x/(df2 + df1*x) ).


The arguments a and b are greater than zero, and x is
nonnegative.

ACCURACY:

Tested at random points (a,b,x).

               x     a,b                     Relative error:
arithmetic  domain  domain     # trials      peak         rms
   IEEE      0,1    0,100       100000      9.8e-15     1.7e-15
   IEEE      1,5    0,100       100000      6.5e-15     3.5e-16
   IEEE      0,1    1,10000     100000      2.2e-11     3.3e-12
   IEEE      1,5    1,10000     100000      1.1e-11     1.7e-13

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::fdistribution(ae_int_t a, ae_int_t b, <b>double</b> x);

</div></pre>
<a name='sub_invfdistribution'></a><h3 class=pageheader><code>invfdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of complemented F distribution

Finds the F density argument x such that the integral
from x to infinity of the F density is equal to the
given probability p.

This is accomplished using the inverse beta integral
function and the relations

     z = incbi( df2/2, df1/2, p )
     x = df2 (1-z) / (df1 z).

Note: the following relations hold for the inverse of
the uncomplemented F distribution:

     z = incbi( df1/2, df2/2, p )
     x = df2 z / (df1 (1-z)).

ACCURACY:

Tested at random points (a,b,p).

             a,b                     Relative error:
arithmetic  domain     # trials      peak         rms
 For p between .001 and 1:
   IEEE     1,100       100000      8.3e-15     4.7e-16
   IEEE     1,10000     100000      2.1e-11     1.4e-13
 For p between 10^-6 and 10^-3:
   IEEE     1,100        50000      1.3e-12     8.4e-15
   IEEE     1,10000      50000      3.0e-12     4.8e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invfdistribution(ae_int_t a, ae_int_t b, <b>double</b> y);

</div></pre>
<a name=unit_fft></a><h2 class=pageheader><code>fft</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fftc1d' class=toc>fftc1d</a><br>
<a href='#sub_fftc1dinv' class=toc>fftc1dinv</a><br>
<a href='#sub_fftr1d' class=toc>fftr1d</a><br>
<a href='#sub_fftr1dinv' class=toc>fftr1dinv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_fft_complex_d1' class=toc>fft_complex_d1</a></td><td width=15>&nbsp;</td><td>Complex FFT: simple example</td></tr>
<tr align=left valign=top><td><a href='#example_fft_complex_d2' class=toc>fft_complex_d2</a></td><td width=15>&nbsp;</td><td>Complex FFT: advanced example</td></tr>
<tr align=left valign=top><td><a href='#example_fft_real_d1' class=toc>fft_real_d1</a></td><td width=15>&nbsp;</td><td>Real FFT: simple example</td></tr>
<tr align=left valign=top><td><a href='#example_fft_real_d2' class=toc>fft_real_d2</a></td><td width=15>&nbsp;</td><td>Real FFT: advanced example</td></tr>
</table></div>
<a name='sub_fftc1d'></a><h3 class=pageheader><code>fftc1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex FFT.

Array size N may be arbitrary number (composite or prime).  Composite  N's
are handled with cache-oblivious variation of  a  Cooley-Tukey  algorithm.
Small prime-factors are transformed using hard coded  codelets (similar to
FFTW codelets, but without low-level  optimization),  large  prime-factors
are handled with Bluestein's algorithm.

Fastests transforms are for smooth N's (prime factors are 2, 3,  5  only),
most fast for powers of 2. When N have prime factors  larger  than  these,
but orders of magnitude smaller than N, computations will be about 4 times
slower than for nearby highly composite N's. When N itself is prime, speed
will be 6 times lower.

Algorithm has O(N*logN) complexity for any N (composite or prime).

INPUT PARAMETERS
    A   -   array[0..N-1] - complex function to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    A   -   DFT of a input array, array[0..N-1]
            A_out[j] = SUM(A_in[k]*exp(-2*pi*sqrt(-1)*j*k/N), k = 0..N-1)


  -- ALGLIB --
     Copyright 29.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fftc1d(complex_1d_array&amp; a);
<b>void</b> alglib::fftc1d(complex_1d_array&amp; a, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_fft_complex_d1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_fft_complex_d2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_fftc1dinv'></a><h3 class=pageheader><code>fftc1dinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional complex inverse FFT.

Array size N may be arbitrary number (composite or prime).  Algorithm  has
O(N*logN) complexity for any N (composite or prime).

See FFTC1D() description for more information about algorithm performance.

INPUT PARAMETERS
    A   -   array[0..N-1] - complex array to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    A   -   inverse DFT of a input array, array[0..N-1]
            A_out[j] = SUM(A_in[k]/N*exp(+2*pi*sqrt(-1)*j*k/N), k = 0..N-1)


  -- ALGLIB --
     Copyright 29.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fftc1dinv(complex_1d_array&amp; a);
<b>void</b> alglib::fftc1dinv(complex_1d_array&amp; a, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_fft_complex_d1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_fft_complex_d2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_fftr1d'></a><h3 class=pageheader><code>fftr1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional real FFT.

Algorithm has O(N*logN) complexity for any N (composite or prime).

INPUT PARAMETERS
    A   -   array[0..N-1] - real function to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    F   -   DFT of a input array, array[0..N-1]
            F[j] = SUM(A[k]*exp(-2*pi*sqrt(-1)*j*k/N), k = 0..N-1)

NOTE:
    F[] satisfies symmetry property F[k] = conj(F[N-k]),  so just one half
of  array  is  usually needed. But for convinience subroutine returns full
complex array (with frequencies above N/2), so its result may be  used  by
other FFT-related subroutines.


  -- ALGLIB --
     Copyright 01.06.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fftr1d(real_1d_array a, complex_1d_array&amp; f);
<b>void</b> alglib::fftr1d(real_1d_array a, ae_int_t n, complex_1d_array&amp; f);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_fft_real_d1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_fft_real_d2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_fftr1dinv'></a><h3 class=pageheader><code>fftr1dinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional real inverse FFT.

Algorithm has O(N*logN) complexity for any N (composite or prime).

INPUT PARAMETERS
    F   -   array[0..floor(N/2)] - frequencies from forward real FFT
    N   -   problem size

OUTPUT PARAMETERS
    A   -   inverse DFT of a input array, array[0..N-1]

NOTE:
    F[] should satisfy symmetry property F[k] = conj(F[N-k]), so just  one
half of frequencies array is needed - elements from 0 to floor(N/2).  F[0]
is ALWAYS real. If N is even F[floor(N/2)] is real too. If N is odd,  then
F[floor(N/2)] has no special properties.

Relying on properties noted above, FFTR1DInv subroutine uses only elements
from 0th to floor(N/2)-th. It ignores imaginary part of F[0],  and in case
N is even it ignores imaginary part of F[floor(N/2)] too.

When you call this function using full arguments list - &quot;FFTR1DInv(F,N,A)&quot;
- you can pass either either frequencies array with N elements or  reduced
array with roughly N/2 elements - subroutine will  successfully  transform
both.

If you call this function using reduced arguments list -  &quot;FFTR1DInv(F,A)&quot;
- you must pass FULL array with N elements (although higher  N/2 are still
not used) because array size is used to automatically determine FFT length


  -- ALGLIB --
     Copyright 01.06.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fftr1dinv(complex_1d_array f, real_1d_array&amp; a);
<b>void</b> alglib::fftr1dinv(complex_1d_array f, ae_int_t n, real_1d_array&amp; a);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_fft_real_d1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_fft_real_d2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='example_fft_complex_d1'></a><h3 class=pageheader>fft_complex_d1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;fasttransforms.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// first we demonstrate forward FFT:</font>
    <font color=navy>// [1i,1i,1i,1i] is converted to [4i, 0, 0, 0]</font>
    <font color=navy>//</font>
    complex_1d_array z = <font color=blue><b>&quot;[1i,1i,1i,1i]&quot;</b></font>;
    fftc1d(z);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, z.tostring(3).c_str()); <font color=navy>// EXPECTED: [4i,0,0,0]</font>

    <font color=navy>//</font>
    <font color=navy>// now we convert [4i, 0, 0, 0] back to [1i,1i,1i,1i]</font>
    <font color=navy>// with backward FFT</font>
    <font color=navy>//</font>
    fftc1dinv(z);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, z.tostring(3).c_str()); <font color=navy>// EXPECTED: [1i,1i,1i,1i]</font>
    <b>return</b> 0;
}


</pre><a name='example_fft_complex_d2'></a><h3 class=pageheader>fft_complex_d2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;fasttransforms.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// first we demonstrate forward FFT:</font>
    <font color=navy>// [0,1,0,1i] is converted to [1+1i, -1-1i, -1-1i, 1+1i]</font>
    <font color=navy>//</font>
    complex_1d_array z = <font color=blue><b>&quot;[0,1,0,1i]&quot;</b></font>;
    fftc1d(z);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, z.tostring(3).c_str()); <font color=navy>// EXPECTED: [1+1i, -1-1i, -1-1i, 1+1i]</font>

    <font color=navy>//</font>
    <font color=navy>// now we convert result back with backward FFT</font>
    <font color=navy>//</font>
    fftc1dinv(z);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, z.tostring(3).c_str()); <font color=navy>// EXPECTED: [0,1,0,1i]</font>
    <b>return</b> 0;
}


</pre><a name='example_fft_real_d1'></a><h3 class=pageheader>fft_real_d1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;fasttransforms.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// first we demonstrate forward FFT:</font>
    <font color=navy>// [1,1,1,1] is converted to [4, 0, 0, 0]</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[1,1,1,1]&quot;</b></font>;
    complex_1d_array f;
    real_1d_array x2;
    fftr1d(x, f);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, f.tostring(3).c_str()); <font color=navy>// EXPECTED: [4,0,0,0]</font>

    <font color=navy>//</font>
    <font color=navy>// now we convert [4, 0, 0, 0] back to [1,1,1,1]</font>
    <font color=navy>// with backward FFT</font>
    <font color=navy>//</font>
    fftr1dinv(f, x2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x2.tostring(3).c_str()); <font color=navy>// EXPECTED: [1,1,1,1]</font>
    <b>return</b> 0;
}


</pre><a name='example_fft_real_d2'></a><h3 class=pageheader>fft_real_d2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;fasttransforms.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// first we demonstrate forward FFT:</font>
    <font color=navy>// [1,2,3,4] is converted to [10, -2+2i, -2, -2-2i]</font>
    <font color=navy>//</font>
    <font color=navy>// note that output array is self-adjoint:</font>
    <font color=navy>// * f[0] = conj(f[0])</font>
    <font color=navy>// * f[1] = conj(f[3])</font>
    <font color=navy>// * f[2] = conj(f[2])</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[1,2,3,4]&quot;</b></font>;
    complex_1d_array f;
    real_1d_array x2;
    fftr1d(x, f);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, f.tostring(3).c_str()); <font color=navy>// EXPECTED: [10, -2+2i, -2, -2-2i]</font>

    <font color=navy>//</font>
    <font color=navy>// now we convert [10, -2+2i, -2, -2-2i] back to [1,2,3,4]</font>
    <font color=navy>//</font>
    fftr1dinv(f, x2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x2.tostring(3).c_str()); <font color=navy>// EXPECTED: [1,2,3,4]</font>

    <font color=navy>//</font>
    <font color=navy>// remember that F is self-adjoint? It means that we can pass just half</font>
    <font color=navy>// (slightly larger than half) of F to inverse real FFT and still get our result.</font>
    <font color=navy>//</font>
    <font color=navy>// I.e. instead [10, -2+2i, -2, -2-2i] we pass just [10, -2+2i, -2] and everything works!</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: in this case we should explicitly pass array length (which is 4) to ALGLIB;</font>
    <font color=navy>// <b>if</b> not, it will automatically use array length to determine FFT size and</font>
    <font color=navy>// will erroneously make half-length FFT.</font>
    <font color=navy>//</font>
    f = <font color=blue><b>&quot;[10, -2+2i, -2]&quot;</b></font>;
    fftr1dinv(f, 4, x2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x2.tostring(3).c_str()); <font color=navy>// EXPECTED: [1,2,3,4]</font>
    <b>return</b> 0;
}


</pre><a name=unit_fht></a><h2 class=pageheader><code>fht</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fhtr1d' class=toc>fhtr1d</a><br>
<a href='#sub_fhtr1dinv' class=toc>fhtr1dinv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fhtr1d'></a><h3 class=pageheader><code>fhtr1d</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional Fast Hartley Transform.

Algorithm has O(N*logN) complexity for any N (composite or prime).

INPUT PARAMETERS
    A   -   array[0..N-1] - real function to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    A   -   FHT of a input array, array[0..N-1],
            A_out[k] = sum(A_in[j]*(cos(2*pi*j*k/N)+sin(2*pi*j*k/N)), j=0..N-1)


  -- ALGLIB --
     Copyright 04.06.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fhtr1d(real_1d_array&amp; a, ae_int_t n);

</div></pre>
<a name='sub_fhtr1dinv'></a><h3 class=pageheader><code>fhtr1dinv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional inverse FHT.

Algorithm has O(N*logN) complexity for any N (composite or prime).

INPUT PARAMETERS
    A   -   array[0..N-1] - complex array to be transformed
    N   -   problem size

OUTPUT PARAMETERS
    A   -   inverse FHT of a input array, array[0..N-1]


  -- ALGLIB --
     Copyright 29.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fhtr1dinv(real_1d_array&amp; a, ae_int_t n);

</div></pre>
<a name=unit_filters></a><h2 class=pageheader><code>filters</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_filterema' class=toc>filterema</a><br>
<a href='#sub_filterlrma' class=toc>filterlrma</a><br>
<a href='#sub_filtersma' class=toc>filtersma</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_filters_d_ema' class=toc>filters_d_ema</a></td><td width=15>&nbsp;</td><td>EMA(alpha) filter</td></tr>
<tr align=left valign=top><td><a href='#example_filters_d_lrma' class=toc>filters_d_lrma</a></td><td width=15>&nbsp;</td><td>LRMA(k) filter</td></tr>
<tr align=left valign=top><td><a href='#example_filters_d_sma' class=toc>filters_d_sma</a></td><td width=15>&nbsp;</td><td>SMA(k) filter</td></tr>
</table></div>
<a name='sub_filterema'></a><h3 class=pageheader><code>filterema</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Filters: exponential moving averages.

This filter replaces array by results of EMA(alpha) filter. EMA(alpha) is
defined as filter which replaces X[] by S[]:
    S[0] = X[0]
    S[t] = alpha*X[t] + (1-alpha)*S[t-1]

INPUT PARAMETERS:
    X           -   array[N], array to process. It can be larger than N,
                    in this case only first N points are processed.
    N           -   points count, N&gt;=0
    alpha       -   0&lt;alpha&lt;=1, smoothing parameter.

OUTPUT PARAMETERS:
    X           -   array, whose first N elements were processed
                    with EMA(alpha)

NOTE 1: this function uses efficient in-place  algorithm  which  does not
        allocate temporary arrays.

NOTE 2: this algorithm uses BOTH previous points and  current  one,  i.e.
        new value of X[i] depends on BOTH previous point and X[i] itself.

NOTE 3: technical analytis users quite often work  with  EMA  coefficient
        expressed in DAYS instead of fractions. If you want to  calculate
        EMA(N), where N is a number of days, you can use alpha=2/(N+1).

  -- ALGLIB --
     Copyright 25.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::filterema(real_1d_array&amp; x, <b>double</b> alpha);
<b>void</b> alglib::filterema(real_1d_array&amp; x, ae_int_t n, <b>double</b> alpha);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_filters_d_ema' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_filterlrma'></a><h3 class=pageheader><code>filterlrma</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Filters: linear regression moving averages.

This filter replaces array by results of LRMA(K) filter.

LRMA(K) is defined as filter which, for each data  point,  builds  linear
regression  model  using  K  prevous  points (point itself is included in
these K points) and calculates value of this linear model at the point in
question.

INPUT PARAMETERS:
    X           -   array[N], array to process. It can be larger than N,
                    in this case only first N points are processed.
    N           -   points count, N&gt;=0
    K           -   K&gt;=1 (K can be larger than N ,  such  cases  will  be
                    correctly handled). Window width. K=1 corresponds  to
                    identity transformation (nothing changes).

OUTPUT PARAMETERS:
    X           -   array, whose first N elements were processed with SMA(K)

NOTE 1: this function uses efficient in-place  algorithm  which  does not
        allocate temporary arrays.

NOTE 2: this algorithm makes only one pass through array and uses running
        sum  to speed-up calculation of the averages. Additional measures
        are taken to ensure that running sum on a long sequence  of  zero
        elements will be correctly reset to zero even in the presence  of
        round-off error.

NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT
        averages points after the current one. Only X[i], X[i-1], ... are
        used when calculating new value of X[i]. We should also note that
        this algorithm uses BOTH previous points and  current  one,  i.e.
        new value of X[i] depends on BOTH previous point and X[i] itself.

  -- ALGLIB --
     Copyright 25.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::filterlrma(real_1d_array&amp; x, ae_int_t k);
<b>void</b> alglib::filterlrma(real_1d_array&amp; x, ae_int_t n, ae_int_t k);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_filters_d_lrma' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_filtersma'></a><h3 class=pageheader><code>filtersma</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Filters: simple moving averages (unsymmetric).

This filter replaces array by results of SMA(K) filter. SMA(K) is defined
as filter which averages at most K previous points (previous - not points
AROUND central point) - or less, in case of the first K-1 points.

INPUT PARAMETERS:
    X           -   array[N], array to process. It can be larger than N,
                    in this case only first N points are processed.
    N           -   points count, N&gt;=0
    K           -   K&gt;=1 (K can be larger than N ,  such  cases  will  be
                    correctly handled). Window width. K=1 corresponds  to
                    identity transformation (nothing changes).

OUTPUT PARAMETERS:
    X           -   array, whose first N elements were processed with SMA(K)

NOTE 1: this function uses efficient in-place  algorithm  which  does not
        allocate temporary arrays.

NOTE 2: this algorithm makes only one pass through array and uses running
        sum  to speed-up calculation of the averages. Additional measures
        are taken to ensure that running sum on a long sequence  of  zero
        elements will be correctly reset to zero even in the presence  of
        round-off error.

NOTE 3: this  is  unsymmetric version of the algorithm,  which  does  NOT
        averages points after the current one. Only X[i], X[i-1], ... are
        used when calculating new value of X[i]. We should also note that
        this algorithm uses BOTH previous points and  current  one,  i.e.
        new value of X[i] depends on BOTH previous point and X[i] itself.

  -- ALGLIB --
     Copyright 25.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::filtersma(real_1d_array&amp; x, ae_int_t k);
<b>void</b> alglib::filtersma(real_1d_array&amp; x, ae_int_t n, ae_int_t k);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_filters_d_sma' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_filters_d_ema'></a><h3 class=pageheader>filters_d_ema example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate EMA(0.5) filtering <b>for</b> time series.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[5,6,7,8]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Apply filter.</font>
    <font color=navy>// We should get [5, 5.5, 6.25, 7.125] as result</font>
    <font color=navy>//</font>
    filterema(x, 0.5);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(4).c_str()); <font color=navy>// EXPECTED: [5,5.5,6.25,7.125]</font>
    <b>return</b> 0;
}


</pre><a name='example_filters_d_lrma'></a><h3 class=pageheader>filters_d_lrma example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate LRMA(3) filtering <b>for</b> time series.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[7,8,8,9,12,12]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Apply filter.</font>
    <font color=navy>// We should get [7.0000, 8.0000, 8.1667, 8.8333, 11.6667, 12.5000] as result</font>
    <font color=navy>//    </font>
    filterlrma(x, 3);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(4).c_str()); <font color=navy>// EXPECTED: [7.0000,8.0000,8.1667,8.8333,11.6667,12.5000]</font>
    <b>return</b> 0;
}


</pre><a name='example_filters_d_sma'></a><h3 class=pageheader>filters_d_sma example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate SMA(k) filtering <b>for</b> time series.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[5,6,7,8]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Apply filter.</font>
    <font color=navy>// We should get [5, 5.5, 6.5, 7.5] as result</font>
    <font color=navy>//</font>
    filtersma(x, 2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(4).c_str()); <font color=navy>// EXPECTED: [5,5.5,6.5,7.5]</font>
    <b>return</b> 0;
}


</pre><a name=unit_fresnel></a><h2 class=pageheader><code>fresnel</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fresnelintegral' class=toc>fresnelintegral</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fresnelintegral'></a><h3 class=pageheader><code>fresnelintegral</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Fresnel integral

Evaluates the Fresnel integrals

          x
          -
         | |
C(x) =   |   cos(pi/2 t**2) dt,
       | |
        -
         0

          x
          -
         | |
S(x) =   |   sin(pi/2 t**2) dt.
       | |
        -
         0


The integrals are evaluated by a power series for x &lt; 1.
For x &gt;= 1 auxiliary functions f(x) and g(x) are employed
such that

C(x) = 0.5 + f(x) sin( pi/2 x**2 ) - g(x) cos( pi/2 x**2 )
S(x) = 0.5 - f(x) cos( pi/2 x**2 ) - g(x) sin( pi/2 x**2 )



ACCURACY:

 Relative error.

Arithmetic  function   domain     # trials      peak         rms
  IEEE       S(x)      0, 10       10000       2.0e-15     3.2e-16
  IEEE       C(x)      0, 10       10000       1.8e-15     3.3e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fresnelintegral(<b>double</b> x, <b>double</b>&amp; c, <b>double</b>&amp; s);

</div></pre>
<a name=unit_gammafunc></a><h2 class=pageheader><code>gammafunc</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gammafunction' class=toc>gammafunction</a><br>
<a href='#sub_lngamma' class=toc>lngamma</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gammafunction'></a><h3 class=pageheader><code>gammafunction</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Gamma function

Input parameters:
    X   -   argument

Domain:
    0 &lt; X &lt; 171.6
    -170 &lt; X &lt; 0, X is not an integer.

Relative error:
 arithmetic   domain     # trials      peak         rms
    IEEE    -170,-33      20000       2.3e-15     3.3e-16
    IEEE     -33,  33     20000       9.4e-16     2.2e-16
    IEEE      33, 171.6   20000       2.3e-15     3.2e-16

Cephes Math Library Release 2.8:  June, 2000
Original copyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier
Translated to AlgoPascal by Bochkanov Sergey (2005, 2006, 2007).
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::gammafunction(<b>double</b> x);

</div></pre>
<a name='sub_lngamma'></a><h3 class=pageheader><code>lngamma</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Natural logarithm of gamma function

Input parameters:
    X       -   argument

Result:
    logarithm of the absolute value of the Gamma(X).

Output parameters:
    SgnGam  -   sign(Gamma(X))

Domain:
    0 &lt; X &lt; 2.55e305
    -2.55e305 &lt; X &lt; 0, X is not an integer.

ACCURACY:
arithmetic      domain        # trials     peak         rms
   IEEE    0, 3                 28000     5.4e-16     1.1e-16
   IEEE    2.718, 2.556e305     40000     3.5e-16     8.3e-17
The error criterion was relative when the function magnitude
was greater than one but absolute when it was less than one.

The following test used the relative error criterion, though
at certain points the relative error could be much higher than
indicated.
   IEEE    -200, -4             10000     4.8e-16     1.3e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier
Translated to AlgoPascal by Bochkanov Sergey (2005, 2006, 2007).
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::lngamma(<b>double</b> x, <b>double</b>&amp; sgngam);

</div></pre>
<a name=unit_gkq></a><h2 class=pageheader><code>gkq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gkqgenerategaussjacobi' class=toc>gkqgenerategaussjacobi</a><br>
<a href='#sub_gkqgenerategausslegendre' class=toc>gkqgenerategausslegendre</a><br>
<a href='#sub_gkqgeneraterec' class=toc>gkqgeneraterec</a><br>
<a href='#sub_gkqlegendrecalc' class=toc>gkqlegendrecalc</a><br>
<a href='#sub_gkqlegendretbl' class=toc>gkqlegendretbl</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gkqgenerategaussjacobi'></a><h3 class=pageheader><code>gkqgenerategaussjacobi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns   Gauss   and   Gauss-Kronrod   nodes/weights   for   Gauss-Jacobi
quadrature on [-1,1] with weight function

    W(x)=Power(1-x,Alpha)*Power(1+x,Beta).

INPUT PARAMETERS:
    N           -   number of Kronrod nodes, must be odd number, &gt;=3.
    Alpha       -   power-law coefficient, Alpha&gt;-1
    Beta        -   power-law coefficient, Beta&gt;-1

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -5    no real and positive Gauss-Kronrod formula can
                            be created for such a weight function  with  a
                            given number of nodes.
                    * -4    an  error  was   detected   when   calculating
                            weights/nodes. Alpha or  Beta  are  too  close
                            to -1 to obtain weights/nodes with high enough
                            accuracy, or, may be, N is too large.  Try  to
                            use multiple precision version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N was passed
                    * +1    OK
                    * +2    OK, but quadrature rule have exterior  nodes,
                            x[0]&lt;-1 or x[n-1]&gt;+1
    X           -   array[0..N-1] - array of quadrature nodes, ordered in
                    ascending order.
    WKronrod    -   array[0..N-1] - Kronrod weights
    WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
                    corresponding to extended Kronrod nodes).


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gkqgenerategaussjacobi(
    ae_int_t n,
    <b>double</b> alpha,
    <b>double</b> beta,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; wkronrod,
    real_1d_array&amp; wgauss);

</div></pre>
<a name='sub_gkqgenerategausslegendre'></a><h3 class=pageheader><code>gkqgenerategausslegendre</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns   Gauss   and   Gauss-Kronrod   nodes/weights  for  Gauss-Legendre
quadrature with N points.

GKQLegendreCalc (calculation) or  GKQLegendreTbl  (precomputed  table)  is
used depending on machine precision and number of nodes.

INPUT PARAMETERS:
    N           -   number of Kronrod nodes, must be odd number, &gt;=3.

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error   was   detected   when  calculating
                            weights/nodes.  N  is  too  large   to  obtain
                            weights/nodes  with  high   enough   accuracy.
                            Try  to   use   multiple   precision  version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes, ordered in
                    ascending order.
    WKronrod    -   array[0..N-1] - Kronrod weights
    WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
                    corresponding to extended Kronrod nodes).


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gkqgenerategausslegendre(
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; wkronrod,
    real_1d_array&amp; wgauss);

</div></pre>
<a name='sub_gkqgeneraterec'></a><h3 class=pageheader><code>gkqgeneraterec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Computation of nodes and weights of a Gauss-Kronrod quadrature formula

The algorithm generates the N-point Gauss-Kronrod quadrature formula  with
weight  function  given  by  coefficients  alpha  and beta of a recurrence
relation which generates a system of orthogonal polynomials:

    P-1(x)   =  0
    P0(x)    =  1
    Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)

and zero moment Mu0

    Mu0 = integral(W(x)dx,a,b)


INPUT PARAMETERS:
    Alpha          alpha coefficients, array[0..floor(3*K/2)].
    Beta           beta coefficients,  array[0..ceil(3*K/2)].
                    Beta[0] is not used and may be arbitrary.
                    Beta[I]&gt;0.
    Mu0            zeroth moment of the weight function.
    N              number of nodes of the Gauss-Kronrod quadrature formula,
                    N &gt;= 3,
                    N =  2*K+1.

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -5    no real and positive Gauss-Kronrod formula can
                            be created for such a weight function  with  a
                            given number of nodes.
                    * -4    N is too large, task may be ill  conditioned -
                            x[i]=x[i+1] found.
                    * -3    internal eigenproblem solver hasn't converged
                    * -2    Beta[i]&lt;=0
                    * -1    incorrect N was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes,
                    in ascending order.
    WKronrod    -   array[0..N-1] - Kronrod weights
    WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
                    corresponding to extended Kronrod nodes).

  -- ALGLIB --
     Copyright 08.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gkqgeneraterec(
    real_1d_array alpha,
    real_1d_array beta,
    <b>double</b> mu0,
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; wkronrod,
    real_1d_array&amp; wgauss);

</div></pre>
<a name='sub_gkqlegendrecalc'></a><h3 class=pageheader><code>gkqlegendrecalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns Gauss and Gauss-Kronrod nodes for quadrature with N points.

Reduction to tridiagonal eigenproblem is used.

INPUT PARAMETERS:
    N           -   number of Kronrod nodes, must be odd number, &gt;=3.

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error   was   detected   when  calculating
                            weights/nodes.  N  is  too  large   to  obtain
                            weights/nodes  with  high   enough   accuracy.
                            Try  to   use   multiple   precision  version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes, ordered in
                    ascending order.
    WKronrod    -   array[0..N-1] - Kronrod weights
    WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
                    corresponding to extended Kronrod nodes).

  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gkqlegendrecalc(
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; wkronrod,
    real_1d_array&amp; wgauss);

</div></pre>
<a name='sub_gkqlegendretbl'></a><h3 class=pageheader><code>gkqlegendretbl</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns Gauss and Gauss-Kronrod nodes for quadrature with N  points  using
pre-calculated table. Nodes/weights were  computed  with  accuracy  up  to
1.0E-32 (if MPFR version of ALGLIB is used). In standard double  precision
accuracy reduces to something about 2.0E-16 (depending  on your compiler's
handling of long floating point constants).

INPUT PARAMETERS:
    N           -   number of Kronrod nodes.
                    N can be 15, 21, 31, 41, 51, 61.

OUTPUT PARAMETERS:
    X           -   array[0..N-1] - array of quadrature nodes, ordered in
                    ascending order.
    WKronrod    -   array[0..N-1] - Kronrod weights
    WGauss      -   array[0..N-1] - Gauss weights (interleaved with zeros
                    corresponding to extended Kronrod nodes).


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gkqlegendretbl(
    ae_int_t n,
    real_1d_array&amp; x,
    real_1d_array&amp; wkronrod,
    real_1d_array&amp; wgauss,
    <b>double</b>&amp; eps);

</div></pre>
<a name=unit_gq></a><h2 class=pageheader><code>gq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_gqgenerategausshermite' class=toc>gqgenerategausshermite</a><br>
<a href='#sub_gqgenerategaussjacobi' class=toc>gqgenerategaussjacobi</a><br>
<a href='#sub_gqgenerategausslaguerre' class=toc>gqgenerategausslaguerre</a><br>
<a href='#sub_gqgenerategausslegendre' class=toc>gqgenerategausslegendre</a><br>
<a href='#sub_gqgenerategausslobattorec' class=toc>gqgenerategausslobattorec</a><br>
<a href='#sub_gqgenerategaussradaurec' class=toc>gqgenerategaussradaurec</a><br>
<a href='#sub_gqgeneraterec' class=toc>gqgeneraterec</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_gqgenerategausshermite'></a><h3 class=pageheader><code>gqgenerategausshermite</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns  nodes/weights  for  Gauss-Hermite  quadrature on (-inf,+inf) with
weight function W(x)=Exp(-x*x)

INPUT PARAMETERS:
    N           -   number of nodes, &gt;=1

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error  was   detected   when   calculating
                            weights/nodes.  May be, N is too large. Try to
                            use multiple precision version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N/Alpha was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes,
                    in ascending order.
    W           -   array[0..N-1] - array of quadrature weights.


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategausshermite(
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgenerategaussjacobi'></a><h3 class=pageheader><code>gqgenerategaussjacobi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns  nodes/weights  for  Gauss-Jacobi quadrature on [-1,1] with weight
function W(x)=Power(1-x,Alpha)*Power(1+x,Beta).

INPUT PARAMETERS:
    N           -   number of nodes, &gt;=1
    Alpha       -   power-law coefficient, Alpha&gt;-1
    Beta        -   power-law coefficient, Beta&gt;-1

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error  was   detected   when   calculating
                            weights/nodes. Alpha or  Beta  are  too  close
                            to -1 to obtain weights/nodes with high enough
                            accuracy, or, may be, N is too large.  Try  to
                            use multiple precision version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N/Alpha/Beta was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes,
                    in ascending order.
    W           -   array[0..N-1] - array of quadrature weights.


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategaussjacobi(
    ae_int_t n,
    <b>double</b> alpha,
    <b>double</b> beta,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgenerategausslaguerre'></a><h3 class=pageheader><code>gqgenerategausslaguerre</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns  nodes/weights  for  Gauss-Laguerre  quadrature  on  [0,+inf) with
weight function W(x)=Power(x,Alpha)*Exp(-x)

INPUT PARAMETERS:
    N           -   number of nodes, &gt;=1
    Alpha       -   power-law coefficient, Alpha&gt;-1

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error  was   detected   when   calculating
                            weights/nodes. Alpha is too  close  to  -1  to
                            obtain weights/nodes with high enough accuracy
                            or, may  be,  N  is  too  large.  Try  to  use
                            multiple precision version.
                    * -3    internal eigenproblem solver hasn't converged
                    * -1    incorrect N/Alpha was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes,
                    in ascending order.
    W           -   array[0..N-1] - array of quadrature weights.


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategausslaguerre(
    ae_int_t n,
    <b>double</b> alpha,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgenerategausslegendre'></a><h3 class=pageheader><code>gqgenerategausslegendre</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns nodes/weights for Gauss-Legendre quadrature on [-1,1] with N
nodes.

INPUT PARAMETERS:
    N           -   number of nodes, &gt;=1

OUTPUT PARAMETERS:
    Info        -   error code:
                    * -4    an  error   was   detected   when  calculating
                            weights/nodes.  N  is  too  large   to  obtain
                            weights/nodes  with  high   enough   accuracy.
                            Try  to   use   multiple   precision  version.
                    * -3    internal eigenproblem solver hasn't  converged
                    * -1    incorrect N was passed
                    * +1    OK
    X           -   array[0..N-1] - array of quadrature nodes,
                    in ascending order.
    W           -   array[0..N-1] - array of quadrature weights.


  -- ALGLIB --
     Copyright 12.05.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategausslegendre(
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgenerategausslobattorec'></a><h3 class=pageheader><code>gqgenerategausslobattorec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Computation of nodes and weights for a Gauss-Lobatto quadrature formula

The algorithm generates the N-point Gauss-Lobatto quadrature formula  with
weight function given by coefficients alpha and beta of a recurrence which
generates a system of orthogonal polynomials.

P-1(x)   =  0
P0(x)    =  1
Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)

and zeroth moment Mu0

Mu0 = integral(W(x)dx,a,b)

INPUT PARAMETERS:
    Alpha      array[0..N-2], alpha coefficients
    Beta       array[0..N-2], beta coefficients.
                Zero-indexed element is not used, may be arbitrary.
                Beta[I]&gt;0
    Mu0        zeroth moment of the weighting function.
    A          left boundary of the integration interval.
    B          right boundary of the integration interval.
    N          number of nodes of the quadrature formula, N&gt;=3
                (including the left and right boundary nodes).

OUTPUT PARAMETERS:
    Info    -   error code:
                * -3    internal eigenproblem solver hasn't converged
                * -2    Beta[i]&lt;=0
                * -1    incorrect N was passed
                *  1    OK
    X       -   array[0..N-1] - array of quadrature nodes,
                in ascending order.
    W       -   array[0..N-1] - array of quadrature weights.

  -- ALGLIB --
     Copyright 2005-2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategausslobattorec(
    real_1d_array alpha,
    real_1d_array beta,
    <b>double</b> mu0,
    <b>double</b> a,
    <b>double</b> b,
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgenerategaussradaurec'></a><h3 class=pageheader><code>gqgenerategaussradaurec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Computation of nodes and weights for a Gauss-Radau quadrature formula

The algorithm generates the N-point Gauss-Radau  quadrature  formula  with
weight function given by the coefficients alpha and  beta  of a recurrence
which generates a system of orthogonal polynomials.

P-1(x)   =  0
P0(x)    =  1
Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)

and zeroth moment Mu0

Mu0 = integral(W(x)dx,a,b)

INPUT PARAMETERS:
    Alpha      array[0..N-2], alpha coefficients.
    Beta       array[0..N-1], beta coefficients
                Zero-indexed element is not used.
                Beta[I]&gt;0
    Mu0        zeroth moment of the weighting function.
    A          left boundary of the integration interval.
    N          number of nodes of the quadrature formula, N&gt;=2
                (including the left boundary node).

OUTPUT PARAMETERS:
    Info    -   error code:
                * -3    internal eigenproblem solver hasn't converged
                * -2    Beta[i]&lt;=0
                * -1    incorrect N was passed
                *  1    OK
    X       -   array[0..N-1] - array of quadrature nodes,
                in ascending order.
    W       -   array[0..N-1] - array of quadrature weights.


  -- ALGLIB --
     Copyright 2005-2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgenerategaussradaurec(
    real_1d_array alpha,
    real_1d_array beta,
    <b>double</b> mu0,
    <b>double</b> a,
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_gqgeneraterec'></a><h3 class=pageheader><code>gqgeneraterec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Computation of nodes and weights for a Gauss quadrature formula

The algorithm generates the N-point Gauss quadrature formula  with  weight
function given by coefficients alpha and beta  of  a  recurrence  relation
which generates a system of orthogonal polynomials:

P-1(x)   =  0
P0(x)    =  1
Pn+1(x)  =  (x-alpha(n))*Pn(x)  -  beta(n)*Pn-1(x)

and zeroth moment Mu0

Mu0 = integral(W(x)dx,a,b)

INPUT PARAMETERS:
    Alpha      array[0..N-1], alpha coefficients
    Beta       array[0..N-1], beta coefficients
                Zero-indexed element is not used and may be arbitrary.
                Beta[I]&gt;0.
    Mu0        zeroth moment of the weight function.
    N          number of nodes of the quadrature formula, N&gt;=1

OUTPUT PARAMETERS:
    Info    -   error code:
                * -3    internal eigenproblem solver hasn't converged
                * -2    Beta[i]&lt;=0
                * -1    incorrect N was passed
                *  1    OK
    X       -   array[0..N-1] - array of quadrature nodes,
                in ascending order.
    W       -   array[0..N-1] - array of quadrature weights.

  -- ALGLIB --
     Copyright 2005-2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::gqgeneraterec(
    real_1d_array alpha,
    real_1d_array beta,
    <b>double</b> mu0,
    ae_int_t n,
    ae_int_t&amp; info,
    real_1d_array&amp; x,
    real_1d_array&amp; w);

</div></pre>
<a name=unit_hermite></a><h2 class=pageheader><code>hermite</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hermitecalculate' class=toc>hermitecalculate</a><br>
<a href='#sub_hermitecoefficients' class=toc>hermitecoefficients</a><br>
<a href='#sub_hermitesum' class=toc>hermitesum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hermitecalculate'></a><h3 class=pageheader><code>hermitecalculate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the value of the Hermite polynomial.

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Hermite polynomial Hn at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hermitecalculate(ae_int_t n, <b>double</b> x);

</div></pre>
<a name='sub_hermitecoefficients'></a><h3 class=pageheader><code>hermitecoefficients</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Representation of Hn as C[0] + C[1]*X + ... + C[N]*X^N

Input parameters:
    N   -   polynomial degree, n&gt;=0

Output parameters:
    C   -   coefficients
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hermitecoefficients(ae_int_t n, real_1d_array&amp; c);

</div></pre>
<a name='sub_hermitesum'></a><h3 class=pageheader><code>hermitesum</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Summation of Hermite polynomials using Clenshaws recurrence formula.

This routine calculates
    c[0]*H0(x) + c[1]*H1(x) + ... + c[N]*HN(x)

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Hermite polynomial at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hermitesum(real_1d_array c, ae_int_t n, <b>double</b> x);

</div></pre>
<a name=unit_hqrnd></a><h2 class=pageheader><code>hqrnd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_hqrndstate' class=toc>hqrndstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hqrndcontinuous' class=toc>hqrndcontinuous</a><br>
<a href='#sub_hqrnddiscrete' class=toc>hqrnddiscrete</a><br>
<a href='#sub_hqrndexponential' class=toc>hqrndexponential</a><br>
<a href='#sub_hqrndnormal' class=toc>hqrndnormal</a><br>
<a href='#sub_hqrndnormal2' class=toc>hqrndnormal2</a><br>
<a href='#sub_hqrndrandomize' class=toc>hqrndrandomize</a><br>
<a href='#sub_hqrndseed' class=toc>hqrndseed</a><br>
<a href='#sub_hqrnduniformi' class=toc>hqrnduniformi</a><br>
<a href='#sub_hqrnduniformr' class=toc>hqrnduniformr</a><br>
<a href='#sub_hqrndunit2' class=toc>hqrndunit2</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_hqrndstate'></a><h3 class=pageheader><code>hqrndstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Portable high quality random number generator state.
Initialized with HQRNDRandomize() or HQRNDSeed().

Fields:
    S1, S2      -   seed values
    V           -   precomputed value
    MagicV      -   'magic' value used to determine whether State structure
                    was correctly initialized.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> hqrndstate
{
};

</div></pre>
<a name='sub_hqrndcontinuous'></a><h3 class=pageheader><code>hqrndcontinuous</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function generates random number from continuous  distribution  given
by finite sample X.

INPUT PARAMETERS
    State   -   high quality random number generator, must be
                initialized with HQRNDRandomize() or HQRNDSeed().
        X   -   finite sample, array[N] (can be larger, in this  case only
                leading N elements are used). THIS ARRAY MUST BE SORTED BY
                ASCENDING.
        N   -   number of elements to use, N&gt;=1

RESULT
    this function returns random number from continuous distribution which
    tries to approximate X as mush as possible. min(X)&lt;=Result&lt;=max(X).

  -- ALGLIB --
     Copyright 08.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hqrndcontinuous(
    hqrndstate state,
    real_1d_array x,
    ae_int_t n);

</div></pre>
<a name='sub_hqrnddiscrete'></a><h3 class=pageheader><code>hqrnddiscrete</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function generates  random number from discrete distribution given by
finite sample X.

INPUT PARAMETERS
    State   -   high quality random number generator, must be
                initialized with HQRNDRandomize() or HQRNDSeed().
        X   -   finite sample
        N   -   number of elements to use, N&gt;=1

RESULT
    this function returns one of the X[i] for random i=0..N-1

  -- ALGLIB --
     Copyright 08.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hqrnddiscrete(
    hqrndstate state,
    real_1d_array x,
    ae_int_t n);

</div></pre>
<a name='sub_hqrndexponential'></a><h3 class=pageheader><code>hqrndexponential</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Random number generator: exponential distribution

State structure must be initialized with HQRNDRandomize() or HQRNDSeed().

  -- ALGLIB --
     Copyright 11.08.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hqrndexponential(hqrndstate state, <b>double</b> lambdav);

</div></pre>
<a name='sub_hqrndnormal'></a><h3 class=pageheader><code>hqrndnormal</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Random number generator: normal numbers

This function generates one random number from normal distribution.
Its performance is equal to that of HQRNDNormal2()

State structure must be initialized with HQRNDRandomize() or HQRNDSeed().

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hqrndnormal(hqrndstate state);

</div></pre>
<a name='sub_hqrndnormal2'></a><h3 class=pageheader><code>hqrndnormal2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Random number generator: normal numbers

This function generates two independent random numbers from normal
distribution. Its performance is equal to that of HQRNDNormal()

State structure must be initialized with HQRNDRandomize() or HQRNDSeed().

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hqrndnormal2(hqrndstate state, <b>double</b>&amp; x1, <b>double</b>&amp; x2);

</div></pre>
<a name='sub_hqrndrandomize'></a><h3 class=pageheader><code>hqrndrandomize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
HQRNDState  initialization  with  random  values  which come from standard
RNG.

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hqrndrandomize(hqrndstate&amp; state);

</div></pre>
<a name='sub_hqrndseed'></a><h3 class=pageheader><code>hqrndseed</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
HQRNDState initialization with seed values

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hqrndseed(ae_int_t s1, ae_int_t s2, hqrndstate&amp; state);

</div></pre>
<a name='sub_hqrnduniformi'></a><h3 class=pageheader><code>hqrnduniformi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function generates random integer number in [0, N)

1. State structure must be initialized with HQRNDRandomize() or HQRNDSeed()
2. N can be any positive number except for very large numbers:
   * close to 2^31 on 32-bit systems
   * close to 2^62 on 64-bit systems
   An exception will be generated if N is too large.

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::hqrnduniformi(hqrndstate state, ae_int_t n);

</div></pre>
<a name='sub_hqrnduniformr'></a><h3 class=pageheader><code>hqrnduniformr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function generates random real number in (0,1),
not including interval boundaries

State structure must be initialized with HQRNDRandomize() or HQRNDSeed().

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hqrnduniformr(hqrndstate state);

</div></pre>
<a name='sub_hqrndunit2'></a><h3 class=pageheader><code>hqrndunit2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Random number generator: random X and Y such that X^2+Y^2=1

State structure must be initialized with HQRNDRandomize() or HQRNDSeed().

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hqrndunit2(hqrndstate state, <b>double</b>&amp; x, <b>double</b>&amp; y);

</div></pre>
<a name=unit_ibetaf></a><h2 class=pageheader><code>ibetaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_incompletebeta' class=toc>incompletebeta</a><br>
<a href='#sub_invincompletebeta' class=toc>invincompletebeta</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_incompletebeta'></a><h3 class=pageheader><code>incompletebeta</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Incomplete beta integral

Returns incomplete beta integral of the arguments, evaluated
from zero to x.  The function is defined as

                 x
    -            -
   | (a+b)      | |  a-1     b-1
 -----------    |   t   (1-t)   dt.
  -     -     | |
 | (a) | (b)   -
                0

The domain of definition is 0 &lt;= x &lt;= 1.  In this
implementation a and b are restricted to positive values.
The integral from x to 1 may be obtained by the symmetry
relation

   1 - incbet( a, b, x )  =  incbet( b, a, 1-x ).

The integral is evaluated by a continued fraction expansion
or, when b*x is small, by a power series.

ACCURACY:

Tested at uniformly distributed random points (a,b,x) with a and b
in &quot;domain&quot; and x between 0 and 1.
                                       Relative error
arithmetic   domain     # trials      peak         rms
   IEEE      0,5         10000       6.9e-15     4.5e-16
   IEEE      0,85       250000       2.2e-13     1.7e-14
   IEEE      0,1000      30000       5.3e-12     6.3e-13
   IEEE      0,10000    250000       9.3e-11     7.1e-12
   IEEE      0,100000    10000       8.7e-10     4.8e-11
Outputs smaller than the IEEE gradual underflow threshold
were excluded from these statistics.

Cephes Math Library, Release 2.8:  June, 2000
Copyright 1984, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::incompletebeta(<b>double</b> a, <b>double</b> b, <b>double</b> x);

</div></pre>
<a name='sub_invincompletebeta'></a><h3 class=pageheader><code>invincompletebeta</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of imcomplete beta integral

Given y, the function finds x such that

 incbet( a, b, x ) = y .

The routine performs interval halving or Newton iterations to find the
root of incbet(a,b,x) - y = 0.


ACCURACY:

                     Relative error:
               x     a,b
arithmetic   domain  domain  # trials    peak       rms
   IEEE      0,1    .5,10000   50000    5.8e-12   1.3e-13
   IEEE      0,1   .25,100    100000    1.8e-13   3.9e-15
   IEEE      0,1     0,5       50000    1.1e-12   5.5e-15
With a and b constrained to half-integer or integer values:
   IEEE      0,1    .5,10000   50000    5.8e-12   1.1e-13
   IEEE      0,1    .5,100    100000    1.7e-14   7.9e-16
With a = .5, b constrained to half-integer or integer values:
   IEEE      0,1    .5,10000   10000    8.3e-11   1.0e-11

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1996, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invincompletebeta(<b>double</b> a, <b>double</b> b, <b>double</b> y);

</div></pre>
<a name=unit_idwint></a><h2 class=pageheader><code>idwint</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_idwinterpolant' class=toc>idwinterpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_idwbuildmodifiedshepard' class=toc>idwbuildmodifiedshepard</a><br>
<a href='#sub_idwbuildmodifiedshepardr' class=toc>idwbuildmodifiedshepardr</a><br>
<a href='#sub_idwbuildnoisy' class=toc>idwbuildnoisy</a><br>
<a href='#sub_idwcalc' class=toc>idwcalc</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_idwinterpolant'></a><h3 class=pageheader><code>idwinterpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IDW interpolant.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> idwinterpolant
{
};

</div></pre>
<a name='sub_idwbuildmodifiedshepard'></a><h3 class=pageheader><code>idwbuildmodifiedshepard</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IDW interpolant using modified Shepard method for uniform point
distributions.

INPUT PARAMETERS:
    XY  -   X and Y values, array[0..N-1,0..NX].
            First NX columns contain X-values, last column contain
            Y-values.
    N   -   number of nodes, N&gt;0.
    NX  -   space dimension, NX&gt;=1.
    D   -   nodal function type, either:
            * 0     constant  model.  Just  for  demonstration only, worst
                    model ever.
            * 1     linear model, least squares fitting. Simpe  model  for
                    datasets too small for quadratic models
            * 2     quadratic  model,  least  squares  fitting. Best model
                    available (if your dataset is large enough).
            * -1    &quot;fast&quot;  linear  model,  use  with  caution!!!   It  is
                    significantly  faster than linear/quadratic and better
                    than constant model. But it is less robust (especially
                    in the presence of noise).
    NQ  -   number of points used to calculate  nodal  functions  (ignored
            for constant models). NQ should be LARGER than:
            * max(1.5*(1+NX),2^NX+1) for linear model,
            * max(3/4*(NX+2)*(NX+1),2^NX+1) for quadratic model.
            Values less than this threshold will be silently increased.
    NW  -   number of points used to calculate weights and to interpolate.
            Required: &gt;=2^NX+1, values less than this  threshold  will  be
            silently increased.
            Recommended value: about 2*NQ

OUTPUT PARAMETERS:
    Z   -   IDW interpolant.

NOTES:
  * best results are obtained with quadratic models, worst - with constant
    models
  * when N is large, NQ and NW must be significantly smaller than  N  both
    to obtain optimal performance and to obtain optimal accuracy. In 2  or
    3-dimensional tasks NQ=15 and NW=25 are good values to start with.
  * NQ  and  NW  may  be  greater  than  N.  In  such  cases  they will be
    automatically decreased.
  * this subroutine is always succeeds (as long as correct parameters  are
    passed).
  * see  'Multivariate  Interpolation  of Large Sets of Scattered Data' by
    Robert J. Renka for more information on this algorithm.
  * this subroutine assumes that point distribution is uniform at the small
    scales.  If  it  isn't  -  for  example,  points are concentrated along
    &quot;lines&quot;, but &quot;lines&quot; distribution is uniform at the larger scale - then
    you should use IDWBuildModifiedShepardR()


  -- ALGLIB PROJECT --
     Copyright 02.03.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::idwbuildmodifiedshepard(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t nx,
    ae_int_t d,
    ae_int_t nq,
    ae_int_t nw,
    idwinterpolant&amp; z);

</div></pre>
<a name='sub_idwbuildmodifiedshepardr'></a><h3 class=pageheader><code>idwbuildmodifiedshepardr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IDW interpolant using modified Shepard method for non-uniform datasets.

This type of model uses  constant  nodal  functions and interpolates using
all nodes which are closer than user-specified radius R. It  may  be  used
when points distribution is non-uniform at the small scale, but it  is  at
the distances as large as R.

INPUT PARAMETERS:
    XY  -   X and Y values, array[0..N-1,0..NX].
            First NX columns contain X-values, last column contain
            Y-values.
    N   -   number of nodes, N&gt;0.
    NX  -   space dimension, NX&gt;=1.
    R   -   radius, R&gt;0

OUTPUT PARAMETERS:
    Z   -   IDW interpolant.

NOTES:
* if there is less than IDWKMin points within  R-ball,  algorithm  selects
  IDWKMin closest ones, so that continuity properties of  interpolant  are
  preserved even far from points.

  -- ALGLIB PROJECT --
     Copyright 11.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::idwbuildmodifiedshepardr(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t nx,
    <b>double</b> r,
    idwinterpolant&amp; z);

</div></pre>
<a name='sub_idwbuildnoisy'></a><h3 class=pageheader><code>idwbuildnoisy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IDW model for noisy data.

This subroutine may be used to handle noisy data, i.e. data with noise  in
OUTPUT values.  It differs from IDWBuildModifiedShepard() in the following
aspects:
* nodal functions are not constrained to pass through  nodes:  Qi(xi)&lt;&gt;yi,
  i.e. we have fitting  instead  of  interpolation.
* weights which are used during least  squares fitting stage are all equal
  to 1.0 (independently of distance)
* &quot;fast&quot;-linear or constant nodal functions are not supported (either  not
  robust enough or too rigid)

This problem require far more complex tuning than interpolation  problems.
Below you can find some recommendations regarding this problem:
* focus on tuning NQ; it controls noise reduction. As for NW, you can just
  make it equal to 2*NQ.
* you can use cross-validation to determine optimal NQ.
* optimal NQ is a result of complex tradeoff  between  noise  level  (more
  noise = larger NQ required) and underlying  function  complexity  (given
  fixed N, larger NQ means smoothing of compex features in the data).  For
  example, NQ=N will reduce noise to the minimum level possible,  but  you
  will end up with just constant/linear/quadratic (depending on  D)  least
  squares model for the whole dataset.

INPUT PARAMETERS:
    XY  -   X and Y values, array[0..N-1,0..NX].
            First NX columns contain X-values, last column contain
            Y-values.
    N   -   number of nodes, N&gt;0.
    NX  -   space dimension, NX&gt;=1.
    D   -   nodal function degree, either:
            * 1     linear model, least squares fitting. Simpe  model  for
                    datasets too small for quadratic models (or  for  very
                    noisy problems).
            * 2     quadratic  model,  least  squares  fitting. Best model
                    available (if your dataset is large enough).
    NQ  -   number of points used to calculate nodal functions.  NQ should
            be  significantly   larger   than  1.5  times  the  number  of
            coefficients in a nodal function to overcome effects of noise:
            * larger than 1.5*(1+NX) for linear model,
            * larger than 3/4*(NX+2)*(NX+1) for quadratic model.
            Values less than this threshold will be silently increased.
    NW  -   number of points used to calculate weights and to interpolate.
            Required: &gt;=2^NX+1, values less than this  threshold  will  be
            silently increased.
            Recommended value: about 2*NQ or larger

OUTPUT PARAMETERS:
    Z   -   IDW interpolant.

NOTES:
  * best results are obtained with quadratic models, linear models are not
    recommended to use unless you are pretty sure that it is what you want
  * this subroutine is always succeeds (as long as correct parameters  are
    passed).
  * see  'Multivariate  Interpolation  of Large Sets of Scattered Data' by
    Robert J. Renka for more information on this algorithm.


  -- ALGLIB PROJECT --
     Copyright 02.03.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::idwbuildnoisy(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t nx,
    ae_int_t d,
    ae_int_t nq,
    ae_int_t nw,
    idwinterpolant&amp; z);

</div></pre>
<a name='sub_idwcalc'></a><h3 class=pageheader><code>idwcalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IDW interpolation

INPUT PARAMETERS:
    Z   -   IDW interpolant built with one of model building
            subroutines.
    X   -   array[0..NX-1], interpolation point

Result:
    IDW interpolant Z(X)

  -- ALGLIB --
     Copyright 02.03.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::idwcalc(idwinterpolant z, real_1d_array x);

</div></pre>
<a name=unit_igammaf></a><h2 class=pageheader><code>igammaf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_incompletegamma' class=toc>incompletegamma</a><br>
<a href='#sub_incompletegammac' class=toc>incompletegammac</a><br>
<a href='#sub_invincompletegammac' class=toc>invincompletegammac</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_incompletegamma'></a><h3 class=pageheader><code>incompletegamma</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Incomplete gamma integral

The function is defined by

                          x
                           -
                  1       | |  -t  a-1
 igam(a,x)  =   -----     |   e   t   dt.
                 -      | |
                | (a)    -
                          0


In this implementation both arguments must be positive.
The integral is evaluated by either a power series or
continued fraction expansion, depending on the relative
values of a and x.

ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,30       200000       3.6e-14     2.9e-15
   IEEE      0,100      300000       9.9e-14     1.5e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1985, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::incompletegamma(<b>double</b> a, <b>double</b> x);

</div></pre>
<a name='sub_incompletegammac'></a><h3 class=pageheader><code>incompletegammac</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complemented incomplete gamma integral

The function is defined by


 igamc(a,x)   =   1 - igam(a,x)

                           inf.
                             -
                    1       | |  -t  a-1
              =   -----     |   e   t   dt.
                   -      | |
                  | (a)    -
                            x


In this implementation both arguments must be positive.
The integral is evaluated by either a power series or
continued fraction expansion, depending on the relative
values of a and x.

ACCURACY:

Tested at random a, x.
               a         x                      Relative error:
arithmetic   domain   domain     # trials      peak         rms
   IEEE     0.5,100   0,100      200000       1.9e-14     1.7e-15
   IEEE     0.01,0.5  0,100      200000       1.4e-13     1.6e-15

Cephes Math Library Release 2.8:  June, 2000
Copyright 1985, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::incompletegammac(<b>double</b> a, <b>double</b> x);

</div></pre>
<a name='sub_invincompletegammac'></a><h3 class=pageheader><code>invincompletegammac</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of complemented imcomplete gamma integral

Given p, the function finds x such that

 igamc( a, x ) = p.

Starting with the approximate value

        3
 x = a t

 where

 t = 1 - d - ndtri(p) sqrt(d)

and

 d = 1/9a,

the routine performs up to 10 Newton iterations to find the
root of igamc(a,x) - p = 0.

ACCURACY:

Tested at random a, p in the intervals indicated.

               a        p                      Relative error:
arithmetic   domain   domain     # trials      peak         rms
   IEEE     0.5,100   0,0.5       100000       1.0e-14     1.7e-15
   IEEE     0.01,0.5  0,0.5       100000       9.0e-14     3.4e-15
   IEEE    0.5,10000  0,0.5        20000       2.3e-13     3.8e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invincompletegammac(<b>double</b> a, <b>double</b> y0);

</div></pre>
<a name=unit_inverseupdate></a><h2 class=pageheader><code>inverseupdate</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixinvupdatecolumn' class=toc>rmatrixinvupdatecolumn</a><br>
<a href='#sub_rmatrixinvupdaterow' class=toc>rmatrixinvupdaterow</a><br>
<a href='#sub_rmatrixinvupdatesimple' class=toc>rmatrixinvupdatesimple</a><br>
<a href='#sub_rmatrixinvupdateuv' class=toc>rmatrixinvupdateuv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixinvupdatecolumn'></a><h3 class=pageheader><code>rmatrixinvupdatecolumn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse matrix update by the Sherman-Morrison formula

The algorithm updates matrix A^-1 when adding a vector to a column
of matrix A.

Input parameters:
    InvA        -   inverse of matrix A.
                    Array whose indexes range within [0..N-1, 0..N-1].
    N           -   size of matrix A.
    UpdColumn   -   the column of A whose vector U was added.
                    0 &lt;= UpdColumn &lt;= N-1
    U           -   the vector to be added to a column.
                    Array whose index ranges within [0..N-1].

Output parameters:
    InvA        -   inverse of modified matrix A.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixinvupdatecolumn(
    real_2d_array&amp; inva,
    ae_int_t n,
    ae_int_t updcolumn,
    real_1d_array u);

</div></pre>
<a name='sub_rmatrixinvupdaterow'></a><h3 class=pageheader><code>rmatrixinvupdaterow</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse matrix update by the Sherman-Morrison formula

The algorithm updates matrix A^-1 when adding a vector to a row
of matrix A.

Input parameters:
    InvA    -   inverse of matrix A.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    UpdRow  -   the row of A whose vector V was added.
                0 &lt;= Row &lt;= N-1
    V       -   the vector to be added to a row.
                Array whose index ranges within [0..N-1].

Output parameters:
    InvA    -   inverse of modified matrix A.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixinvupdaterow(
    real_2d_array&amp; inva,
    ae_int_t n,
    ae_int_t updrow,
    real_1d_array v);

</div></pre>
<a name='sub_rmatrixinvupdatesimple'></a><h3 class=pageheader><code>rmatrixinvupdatesimple</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse matrix update by the Sherman-Morrison formula

The algorithm updates matrix A^-1 when adding a number to an element
of matrix A.

Input parameters:
    InvA    -   inverse of matrix A.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    UpdRow  -   row where the element to be updated is stored.
    UpdColumn - column where the element to be updated is stored.
    UpdVal  -   a number to be added to the element.


Output parameters:
    InvA    -   inverse of modified matrix A.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixinvupdatesimple(
    real_2d_array&amp; inva,
    ae_int_t n,
    ae_int_t updrow,
    ae_int_t updcolumn,
    <b>double</b> updval);

</div></pre>
<a name='sub_rmatrixinvupdateuv'></a><h3 class=pageheader><code>rmatrixinvupdateuv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse matrix update by the Sherman-Morrison formula

The algorithm computes the inverse of matrix A+u*v by using the given matrix
A^-1 and the vectors u and v.

Input parameters:
    InvA    -   inverse of matrix A.
                Array whose indexes range within [0..N-1, 0..N-1].
    N       -   size of matrix A.
    U       -   the vector modifying the matrix.
                Array whose index ranges within [0..N-1].
    V       -   the vector modifying the matrix.
                Array whose index ranges within [0..N-1].

Output parameters:
    InvA - inverse of matrix A + u*v'.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixinvupdateuv(
    real_2d_array&amp; inva,
    ae_int_t n,
    real_1d_array u,
    real_1d_array v);

</div></pre>
<a name=unit_jacobianelliptic></a><h2 class=pageheader><code>jacobianelliptic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_jacobianellipticfunctions' class=toc>jacobianellipticfunctions</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_jacobianellipticfunctions'></a><h3 class=pageheader><code>jacobianellipticfunctions</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Jacobian Elliptic Functions

Evaluates the Jacobian elliptic functions sn(u|m), cn(u|m),
and dn(u|m) of parameter m between 0 and 1, and real
argument u.

These functions are periodic, with quarter-period on the
real axis equal to the complete elliptic integral
ellpk(1.0-m).

Relation to incomplete elliptic integral:
If u = ellik(phi,m), then sn(u|m) = sin(phi),
and cn(u|m) = cos(phi).  Phi is called the amplitude of u.

Computation is by means of the arithmetic-geometric mean
algorithm, except when m is within 1e-9 of 0 or 1.  In the
latter case with m close to 1, the approximation applies
only for phi &lt; pi/2.

ACCURACY:

Tested at random points with u between 0 and 10, m between
0 and 1.

           Absolute error (* = relative error):
arithmetic   function   # trials      peak         rms
   IEEE      phi         10000       9.2e-16*    1.4e-16*
   IEEE      sn          50000       4.1e-15     4.6e-16
   IEEE      cn          40000       3.6e-15     4.4e-16
   IEEE      dn          10000       1.3e-12     1.8e-14

 Peak error observed in consistency check using addition
theorem for sn(u+v) was 4e-16 (absolute).  Also tested by
the above relation to the incomplete elliptic integral.
Accuracy deteriorates when u is large.

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::jacobianellipticfunctions(
    <b>double</b> u,
    <b>double</b> m,
    <b>double</b>&amp; sn,
    <b>double</b>&amp; cn,
    <b>double</b>&amp; dn,
    <b>double</b>&amp; ph);

</div></pre>
<a name=unit_jarquebera></a><h2 class=pageheader><code>jarquebera</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_jarqueberatest' class=toc>jarqueberatest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_jarqueberatest'></a><h3 class=pageheader><code>jarqueberatest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Jarque-Bera test

This test checks hypotheses about the fact that a  given  sample  X  is  a
sample of normal random variable.

Requirements:
    * the number of elements in the sample is not less than 5.

Input parameters:
    X   -   sample. Array whose index goes from 0 to N-1.
    N   -   size of the sample. N&gt;=5

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

Accuracy of the approximation used (5&lt;=N&lt;=1951):

p-value  	    relative error (5&lt;=N&lt;=1951)
[1, 0.1]            &lt; 1%
[0.1, 0.01]         &lt; 2%
[0.01, 0.001]       &lt; 6%
[0.001, 0]          wasn't measured

For N&gt;1951 accuracy wasn't measured but it shouldn't be sharply  different
from table values.

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::jarqueberatest(real_1d_array x, ae_int_t n, <b>double</b>&amp; p);

</div></pre>
<a name=unit_laguerre></a><h2 class=pageheader><code>laguerre</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_laguerrecalculate' class=toc>laguerrecalculate</a><br>
<a href='#sub_laguerrecoefficients' class=toc>laguerrecoefficients</a><br>
<a href='#sub_laguerresum' class=toc>laguerresum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_laguerrecalculate'></a><h3 class=pageheader><code>laguerrecalculate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the value of the Laguerre polynomial.

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Laguerre polynomial Ln at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::laguerrecalculate(ae_int_t n, <b>double</b> x);

</div></pre>
<a name='sub_laguerrecoefficients'></a><h3 class=pageheader><code>laguerrecoefficients</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Representation of Ln as C[0] + C[1]*X + ... + C[N]*X^N

Input parameters:
    N   -   polynomial degree, n&gt;=0

Output parameters:
    C   -   coefficients
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::laguerrecoefficients(ae_int_t n, real_1d_array&amp; c);

</div></pre>
<a name='sub_laguerresum'></a><h3 class=pageheader><code>laguerresum</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Summation of Laguerre polynomials using Clenshaws recurrence formula.

This routine calculates c[0]*L0(x) + c[1]*L1(x) + ... + c[N]*LN(x)

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Laguerre polynomial at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::laguerresum(real_1d_array c, ae_int_t n, <b>double</b> x);

</div></pre>
<a name=unit_lda></a><h2 class=pageheader><code>lda</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_fisherlda' class=toc>fisherlda</a><br>
<a href='#sub_fisherldan' class=toc>fisherldan</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_fisherlda'></a><h3 class=pageheader><code>fisherlda</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiclass Fisher LDA

Subroutine finds coefficients of linear combination which optimally separates
training set on classes.

INPUT PARAMETERS:
    XY          -   training set, array[0..NPoints-1,0..NVars].
                    First NVars columns store values of independent
                    variables, next column stores number of class (from 0
                    to NClasses-1) which dataset element belongs to. Fractional
                    values are rounded to nearest integer.
    NPoints     -   training set size, NPoints&gt;=0
    NVars       -   number of independent variables, NVars&gt;=1
    NClasses    -   number of classes, NClasses&gt;=2


OUTPUT PARAMETERS:
    Info        -   return code:
                    * -4, if internal EVD subroutine hasn't converged
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed (NPoints&lt;0,
                          NVars&lt;1, NClasses&lt;2)
                    *  1, if task has been solved
                    *  2, if there was a multicollinearity in training set,
                          but task has been solved.
    W           -   linear combination coefficients, array[0..NVars-1]

  -- ALGLIB --
     Copyright 31.05.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fisherlda(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t nclasses,
    ae_int_t&amp; info,
    real_1d_array&amp; w);

</div></pre>
<a name='sub_fisherldan'></a><h3 class=pageheader><code>fisherldan</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
N-dimensional multiclass Fisher LDA

Subroutine finds coefficients of linear combinations which optimally separates
training set on classes. It returns N-dimensional basis whose vector are sorted
by quality of training set separation (in descending order).

INPUT PARAMETERS:
    XY          -   training set, array[0..NPoints-1,0..NVars].
                    First NVars columns store values of independent
                    variables, next column stores number of class (from 0
                    to NClasses-1) which dataset element belongs to. Fractional
                    values are rounded to nearest integer.
    NPoints     -   training set size, NPoints&gt;=0
    NVars       -   number of independent variables, NVars&gt;=1
    NClasses    -   number of classes, NClasses&gt;=2


OUTPUT PARAMETERS:
    Info        -   return code:
                    * -4, if internal EVD subroutine hasn't converged
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed (NPoints&lt;0,
                          NVars&lt;1, NClasses&lt;2)
                    *  1, if task has been solved
                    *  2, if there was a multicollinearity in training set,
                          but task has been solved.
    W           -   basis, array[0..NVars-1,0..NVars-1]
                    columns of matrix stores basis vectors, sorted by
                    quality of training set separation (in descending order)

  -- ALGLIB --
     Copyright 31.05.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::fisherldan(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t nclasses,
    ae_int_t&amp; info,
    real_2d_array&amp; w);

</div></pre>
<a name=unit_legendre></a><h2 class=pageheader><code>legendre</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_legendrecalculate' class=toc>legendrecalculate</a><br>
<a href='#sub_legendrecoefficients' class=toc>legendrecoefficients</a><br>
<a href='#sub_legendresum' class=toc>legendresum</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_legendrecalculate'></a><h3 class=pageheader><code>legendrecalculate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the value of the Legendre polynomial Pn.

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Legendre polynomial Pn at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::legendrecalculate(ae_int_t n, <b>double</b> x);

</div></pre>
<a name='sub_legendrecoefficients'></a><h3 class=pageheader><code>legendrecoefficients</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Representation of Pn as C[0] + C[1]*X + ... + C[N]*X^N

Input parameters:
    N   -   polynomial degree, n&gt;=0

Output parameters:
    C   -   coefficients
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::legendrecoefficients(ae_int_t n, real_1d_array&amp; c);

</div></pre>
<a name='sub_legendresum'></a><h3 class=pageheader><code>legendresum</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Summation of Legendre polynomials using Clenshaws recurrence formula.

This routine calculates
    c[0]*P0(x) + c[1]*P1(x) + ... + c[N]*PN(x)

Parameters:
    n   -   degree, n&gt;=0
    x   -   argument

Result:
    the value of the Legendre polynomial at x
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::legendresum(real_1d_array c, ae_int_t n, <b>double</b> x);

</div></pre>
<a name=unit_lincg></a><h2 class=pageheader><code>lincg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_lincgreport' class=toc>lincgreport</a><br>
<a href='#struct_lincgstate' class=toc>lincgstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_lincgcreate' class=toc>lincgcreate</a><br>
<a href='#sub_lincgresults' class=toc>lincgresults</a><br>
<a href='#sub_lincgsetcond' class=toc>lincgsetcond</a><br>
<a href='#sub_lincgsetprecdiag' class=toc>lincgsetprecdiag</a><br>
<a href='#sub_lincgsetprecunit' class=toc>lincgsetprecunit</a><br>
<a href='#sub_lincgsetrestartfreq' class=toc>lincgsetrestartfreq</a><br>
<a href='#sub_lincgsetrupdatefreq' class=toc>lincgsetrupdatefreq</a><br>
<a href='#sub_lincgsetstartingpoint' class=toc>lincgsetstartingpoint</a><br>
<a href='#sub_lincgsetxrep' class=toc>lincgsetxrep</a><br>
<a href='#sub_lincgsolvesparse' class=toc>lincgsolvesparse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_lincg_d_1' class=toc>lincg_d_1</a></td><td width=15>&nbsp;</td><td>Solution of sparse linear systems with CG</td></tr>
</table></div>
<a name='struct_lincgreport'></a><h3 class=pageheader><code>lincgreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> lincgreport
{
    ae_int_t             iterationscount;
    ae_int_t             nmv;
    ae_int_t             terminationtype;
    <b>double</b>               r2;
};

</div></pre>
<a name='struct_lincgstate'></a><h3 class=pageheader><code>lincgstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores state of the linear CG method.

You should use ALGLIB functions to work with this object.
Never try to access its fields directly!
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> lincgstate
{
};

</div></pre>
<a name='sub_lincgcreate'></a><h3 class=pageheader><code>lincgcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function initializes linear CG Solver. This solver is used  to  solve
symmetric positive definite problems. If you want  to  solve  nonsymmetric
(or non-positive definite) problem you may use LinLSQR solver provided  by
ALGLIB.

USAGE:
1. User initializes algorithm state with LinCGCreate() call
2. User tunes solver parameters with  LinCGSetCond() and other functions
3. Optionally, user sets starting point with LinCGSetStartingPoint()
4. User  calls LinCGSolveSparse() function which takes algorithm state and
   SparseMatrix object.
5. User calls LinCGResults() to get solution
6. Optionally, user may call LinCGSolveSparse()  again  to  solve  another
   problem  with different matrix and/or right part without reinitializing
   LinCGState structure.

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgcreate(ae_int_t n, lincgstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lincgresults'></a><h3 class=pageheader><code>lincgresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
CG-solver: results.

This function must be called after LinCGSolve

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[N], solution
    Rep     -   optimization report:
                * Rep.TerminationType completetion code:
                    * -5    input matrix is either not positive definite,
                            too large or too small
                    * -4    overflow/underflow during solution
                            (ill conditioned problem)
                    *  1    ||residual||&lt;=EpsF*||b||
                    *  5    MaxIts steps was taken
                    *  7    rounding errors prevent further progress,
                            best point found is returned
                * Rep.IterationsCount contains iterations count
                * NMV countains number of matrix-vector calculations

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgresults(
    lincgstate state,
    real_1d_array&amp; x,
    lincgreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lincgsetcond'></a><h3 class=pageheader><code>lincgsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping criteria.

INPUT PARAMETERS:
    EpsF    -   algorithm will be stopped if norm of residual is less than
                EpsF*||b||.
    MaxIts  -   algorithm will be stopped if number of iterations is  more
                than MaxIts.

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
If  both  EpsF  and  MaxIts  are  zero then small EpsF will be set to small
value.

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetcond(lincgstate state, <b>double</b> epsf, ae_int_t maxits);

</div></pre>
<a name='sub_lincgsetprecdiag'></a><h3 class=pageheader><code>lincgsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
function.  LinCGSolveSparse() will use diagonal of the  system  matrix  as
preconditioner. This preconditioning mode is active by default.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 19.11.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetprecdiag(lincgstate state);

</div></pre>
<a name='sub_lincgsetprecunit'></a><h3 class=pageheader><code>lincgsetprecunit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
function. By default, SolveSparse() uses diagonal preconditioner,  but  if
you want to use solver without preconditioning, you can call this function
which forces solver to use unit matrix for preconditioning.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 19.11.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetprecunit(lincgstate state);

</div></pre>
<a name='sub_lincgsetrestartfreq'></a><h3 class=pageheader><code>lincgsetrestartfreq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets restart frequency. By default, algorithm  is  restarted
after N subsequent iterations.

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetrestartfreq(lincgstate state, ae_int_t srf);

</div></pre>
<a name='sub_lincgsetrupdatefreq'></a><h3 class=pageheader><code>lincgsetrupdatefreq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets frequency of residual recalculations.

Algorithm updates residual r_k using iterative formula,  but  recalculates
it from scratch after each 10 iterations. It is done to avoid accumulation
of numerical errors and to stop algorithm when r_k starts to grow.

Such low update frequence (1/10) gives very  little  overhead,  but  makes
algorithm a bit more robust against numerical errors. However, you may
change it

INPUT PARAMETERS:
    Freq    -   desired update frequency, Freq&gt;=0.
                Zero value means that no updates will be done.

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetrupdatefreq(lincgstate state, ae_int_t freq);

</div></pre>
<a name='sub_lincgsetstartingpoint'></a><h3 class=pageheader><code>lincgsetstartingpoint</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets starting point.
By default, zero starting point is used.

INPUT PARAMETERS:
    X       -   starting point, array[N]

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetstartingpoint(lincgstate state, real_1d_array x);

</div></pre>
<a name='sub_lincgsetxrep'></a><h3 class=pageheader><code>lincgsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinCGOptimize().

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsetxrep(lincgstate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_lincgsolvesparse'></a><h3 class=pageheader><code>lincgsolvesparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procedure for solution of A*x=b with sparse A.

INPUT PARAMETERS:
    State   -   algorithm state
    A       -   sparse matrix in the CRS format (you MUST contvert  it  to
                CRS format by calling SparseConvertToCRS() function).
    IsUpper -   whether upper or lower triangle of A is used:
                * IsUpper=True  =&gt; only upper triangle is used and lower
                                   triangle is not referenced at all
                * IsUpper=False =&gt; only lower triangle is used and upper
                                   triangle is not referenced at all
    B       -   right part, array[N]

RESULT:
    This function returns no result.
    You can get solution by calling LinCGResults()

NOTE: this function uses lightweight preconditioning -  multiplication  by
      inverse of diag(A). If you want, you can turn preconditioning off by
      calling LinCGSetPrecUnit(). However, preconditioning cost is low and
      preconditioner  is  very  important  for  solution  of  badly scaled
      problems.

  -- ALGLIB --
     Copyright 14.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lincgsolvesparse(
    lincgstate state,
    sparsematrix a,
    <b>bool</b> isupper,
    real_1d_array b);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_lincg_d_1'></a><h3 class=pageheader>lincg_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;solvers.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example illustrates solution of sparse linear systems with</font>
    <font color=navy>// conjugate gradient method.</font>
    <font color=navy>// </font>
    <font color=navy>// Suppose that we have linear system A*x=b with sparse symmetric</font>
    <font color=navy>// positive definite A (represented by sparsematrix object)</font>
    <font color=navy>//         [ 5 1       ]</font>
    <font color=navy>//         [ 1 7 2     ]</font>
    <font color=navy>//     A = [   2 8 1   ]</font>
    <font color=navy>//         [     1 4 1 ]</font>
    <font color=navy>//         [       1 4 ]</font>
    <font color=navy>// and right part b</font>
    <font color=navy>//     [  7 ]</font>
    <font color=navy>//     [ 17 ]</font>
    <font color=navy>// b = [ 14 ]</font>
    <font color=navy>//     [ 10 ]</font>
    <font color=navy>//     [  6 ]</font>
    <font color=navy>// and we want to solve this system using sparse linear CG. In order</font>
    <font color=navy>// to <b>do</b> so, we have to create left part (sparsematrix object) and</font>
    <font color=navy>// right part (dense array).</font>
    <font color=navy>//</font>
    <font color=navy>// Initially, sparse matrix is created in the Hash-Table format,</font>
    <font color=navy>// which allows easy initialization, but <b>do</b> not allow matrix to be</font>
    <font color=navy>// used in the linear solvers. So after construction you should convert</font>
    <font color=navy>// sparse matrix to CRS format (one suited <b>for</b> linear operations).</font>
    <font color=navy>//</font>
    <font color=navy>// It is important to note that in our example we initialize full</font>
    <font color=navy>// matrix A, both lower and upper triangles. However, it is symmetric</font>
    <font color=navy>// and sparse solver needs just one half of the matrix. So you may</font>
    <font color=navy>// save about half of the space by filling only one of the triangles.</font>
    <font color=navy>//</font>
    sparsematrix a;
    sparsecreate(5, 5, a);
    sparseset(a, 0, 0, 5.0);
    sparseset(a, 0, 1, 1.0);
    sparseset(a, 1, 0, 1.0);
    sparseset(a, 1, 1, 7.0);
    sparseset(a, 1, 2, 2.0);
    sparseset(a, 2, 1, 2.0);
    sparseset(a, 2, 2, 8.0);
    sparseset(a, 2, 3, 1.0);
    sparseset(a, 3, 2, 1.0);
    sparseset(a, 3, 3, 4.0);
    sparseset(a, 3, 4, 1.0);
    sparseset(a, 4, 3, 1.0);
    sparseset(a, 4, 4, 4.0);

    <font color=navy>//</font>
    <font color=navy>// Now our matrix is fully initialized, but we have to <b>do</b> one more</font>
    <font color=navy>// step - convert it from Hash-Table format to CRS format (see</font>
    <font color=navy>// documentation on sparse matrices <b>for</b> more information about these</font>
    <font color=navy>// formats).</font>
    <font color=navy>//</font>
    <font color=navy>// If you omit this call, ALGLIB will generate exception on the first</font>
    <font color=navy>// attempt to use A in linear operations. </font>
    <font color=navy>//</font>
    sparseconverttocrs(a);

    <font color=navy>//</font>
    <font color=navy>// Initialization of the right part</font>
    <font color=navy>//</font>
    real_1d_array b = <font color=blue><b>&quot;[7,17,14,10,6]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Now we have to create linear solver object and to use it <b>for</b> the</font>
    <font color=navy>// solution of the linear system.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: lincgsolvesparse() accepts additional parameter which tells</font>
    <font color=navy>//       what triangle of the symmetric matrix should be used - upper</font>
    <font color=navy>//       or lower. Because we've filled both parts of the matrix, we</font>
    <font color=navy>//       can use any part - upper or lower.</font>
    <font color=navy>//</font>
    lincgstate s;
    lincgreport rep;
    real_1d_array x;
    lincgcreate(5, s);
    lincgsolvesparse(s, a, true, b);
    lincgresults(s, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [1.000,2.000,1.000,2.000,1.000]</font>
    <b>return</b> 0;
}


</pre><a name=unit_linlsqr></a><h2 class=pageheader><code>linlsqr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_linlsqrreport' class=toc>linlsqrreport</a><br>
<a href='#struct_linlsqrstate' class=toc>linlsqrstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_linlsqrcreate' class=toc>linlsqrcreate</a><br>
<a href='#sub_linlsqrresults' class=toc>linlsqrresults</a><br>
<a href='#sub_linlsqrsetcond' class=toc>linlsqrsetcond</a><br>
<a href='#sub_linlsqrsetlambdai' class=toc>linlsqrsetlambdai</a><br>
<a href='#sub_linlsqrsetprecdiag' class=toc>linlsqrsetprecdiag</a><br>
<a href='#sub_linlsqrsetprecunit' class=toc>linlsqrsetprecunit</a><br>
<a href='#sub_linlsqrsetxrep' class=toc>linlsqrsetxrep</a><br>
<a href='#sub_linlsqrsolvesparse' class=toc>linlsqrsolvesparse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_linlsqr_d_1' class=toc>linlsqr_d_1</a></td><td width=15>&nbsp;</td><td>Solution of sparse linear systems with CG</td></tr>
</table></div>
<a name='struct_linlsqrreport'></a><h3 class=pageheader><code>linlsqrreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> linlsqrreport
{
    ae_int_t             iterationscount;
    ae_int_t             nmv;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_linlsqrstate'></a><h3 class=pageheader><code>linlsqrstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores state of the LinLSQR method.

You should use ALGLIB functions to work with this object.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> linlsqrstate
{
};

</div></pre>
<a name='sub_linlsqrcreate'></a><h3 class=pageheader><code>linlsqrcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function initializes linear LSQR Solver. This solver is used to solve
non-symmetric (and, possibly, non-square) problems. Least squares solution
is returned for non-compatible systems.

USAGE:
1. User initializes algorithm state with LinLSQRCreate() call
2. User tunes solver parameters with  LinLSQRSetCond() and other functions
3. User  calls  LinLSQRSolveSparse()  function which takes algorithm state
   and SparseMatrix object.
4. User calls LinLSQRResults() to get solution
5. Optionally, user may call LinLSQRSolveSparse() again to  solve  another
   problem  with different matrix and/or right part without reinitializing
   LinLSQRState structure.

INPUT PARAMETERS:
    M       -   number of rows in A
    N       -   number of variables, N&gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrcreate(ae_int_t m, ae_int_t n, linlsqrstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_linlsqr_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_linlsqrresults'></a><h3 class=pageheader><code>linlsqrresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LSQR solver: results.

This function must be called after LinLSQRSolve

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[N], solution
    Rep     -   optimization report:
                * Rep.TerminationType completetion code:
                    *  1    ||Rk||&lt;=EpsB*||B||
                    *  4    ||A^T*Rk||/(||A||*||Rk||)&lt;=EpsA
                    *  5    MaxIts steps was taken
                    *  7    rounding errors prevent further progress,
                            X contains best point found so far.
                            (sometimes returned on singular systems)
                * Rep.IterationsCount contains iterations count
                * NMV countains number of matrix-vector calculations

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrresults(
    linlsqrstate state,
    real_1d_array&amp; x,
    linlsqrreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_linlsqr_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_linlsqrsetcond'></a><h3 class=pageheader><code>linlsqrsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping criteria.

INPUT PARAMETERS:
    EpsA    -   algorithm will be stopped if ||A^T*Rk||/(||A||*||Rk||)&lt;=EpsA.
    EpsB    -   algorithm will be stopped if ||Rk||&lt;=EpsB*||B||
    MaxIts  -   algorithm will be stopped if number of iterations
                more than MaxIts.

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTE: if EpsA,EpsB,EpsC and MaxIts are zero then these variables will
be setted as default values.

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsetcond(
    linlsqrstate state,
    <b>double</b> epsa,
    <b>double</b> epsb,
    ae_int_t maxits);

</div></pre>
<a name='sub_linlsqrsetlambdai'></a><h3 class=pageheader><code>linlsqrsetlambdai</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets optional Tikhonov regularization coefficient.
It is zero by default.

INPUT PARAMETERS:
    LambdaI -   regularization factor, LambdaI&gt;=0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsetlambdai(linlsqrstate state, <b>double</b> lambdai);

</div></pre>
<a name='sub_linlsqrsetprecdiag'></a><h3 class=pageheader><code>linlsqrsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  changes  preconditioning  settings  of  LinCGSolveSparse()
function.  LinCGSolveSparse() will use diagonal of the  system  matrix  as
preconditioner. This preconditioning mode is active by default.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 19.11.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsetprecdiag(linlsqrstate state);

</div></pre>
<a name='sub_linlsqrsetprecunit'></a><h3 class=pageheader><code>linlsqrsetprecunit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  changes  preconditioning  settings of LinLSQQSolveSparse()
function. By default, SolveSparse() uses diagonal preconditioner,  but  if
you want to use solver without preconditioning, you can call this function
which forces solver to use unit matrix for preconditioning.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 19.11.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsetprecunit(linlsqrstate state);

</div></pre>
<a name='sub_linlsqrsetxrep'></a><h3 class=pageheader><code>linlsqrsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinCGOptimize().

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsetxrep(linlsqrstate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_linlsqrsolvesparse'></a><h3 class=pageheader><code>linlsqrsolvesparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procedure for solution of A*x=b with sparse A.

INPUT PARAMETERS:
    State   -   algorithm state
    A       -   sparse M*N matrix in the CRS format (you MUST contvert  it
                to CRS format  by  calling  SparseConvertToCRS()  function
                BEFORE you pass it to this function).
    B       -   right part, array[M]

RESULT:
    This function returns no result.
    You can get solution by calling LinCGResults()

NOTE: this function uses lightweight preconditioning -  multiplication  by
      inverse of diag(A). If you want, you can turn preconditioning off by
      calling LinLSQRSetPrecUnit(). However, preconditioning cost is   low
      and preconditioner is very important for solution  of  badly  scaled
      problems.

  -- ALGLIB --
     Copyright 30.11.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::linlsqrsolvesparse(
    linlsqrstate state,
    sparsematrix a,
    real_1d_array b);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_linlsqr_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_linlsqr_d_1'></a><h3 class=pageheader>linlsqr_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;solvers.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example illustrates solution of sparse linear least squares problem</font>
    <font color=navy>// with LSQR algorithm.</font>
    <font color=navy>// </font>
    <font color=navy>// Suppose that we have least squares problem min|A*x-b| with sparse A</font>
    <font color=navy>// represented by sparsematrix object</font>
    <font color=navy>//         [ 1 1 ]</font>
    <font color=navy>//         [ 1 1 ]</font>
    <font color=navy>//     A = [ 2 1 ]</font>
    <font color=navy>//         [ 1   ]</font>
    <font color=navy>//         [   1 ]</font>
    <font color=navy>// and right part b</font>
    <font color=navy>//     [ 4 ]</font>
    <font color=navy>//     [ 2 ]</font>
    <font color=navy>// b = [ 4 ]</font>
    <font color=navy>//     [ 1 ]</font>
    <font color=navy>//     [ 2 ]</font>
    <font color=navy>// and we want to solve this system in the least squares sense using</font>
    <font color=navy>// LSQR algorithm. In order to <b>do</b> so, we have to create left part</font>
    <font color=navy>// (sparsematrix object) and right part (dense array).</font>
    <font color=navy>//</font>
    <font color=navy>// Initially, sparse matrix is created in the Hash-Table format,</font>
    <font color=navy>// which allows easy initialization, but <b>do</b> not allow matrix to be</font>
    <font color=navy>// used in the linear solvers. So after construction you should convert</font>
    <font color=navy>// sparse matrix to CRS format (one suited <b>for</b> linear operations).</font>
    <font color=navy>//</font>
    sparsematrix a;
    sparsecreate(5, 2, a);
    sparseset(a, 0, 0, 1.0);
    sparseset(a, 0, 1, 1.0);
    sparseset(a, 1, 0, 1.0);
    sparseset(a, 1, 1, 1.0);
    sparseset(a, 2, 0, 2.0);
    sparseset(a, 2, 1, 1.0);
    sparseset(a, 3, 0, 1.0);
    sparseset(a, 4, 1, 1.0);

    <font color=navy>//</font>
    <font color=navy>// Now our matrix is fully initialized, but we have to <b>do</b> one more</font>
    <font color=navy>// step - convert it from Hash-Table format to CRS format (see</font>
    <font color=navy>// documentation on sparse matrices <b>for</b> more information about these</font>
    <font color=navy>// formats).</font>
    <font color=navy>//</font>
    <font color=navy>// If you omit this call, ALGLIB will generate exception on the first</font>
    <font color=navy>// attempt to use A in linear operations. </font>
    <font color=navy>//</font>
    sparseconverttocrs(a);

    <font color=navy>//</font>
    <font color=navy>// Initialization of the right part</font>
    <font color=navy>//</font>
    real_1d_array b = <font color=blue><b>&quot;[4,2,4,1,2]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Now we have to create linear solver object and to use it <b>for</b> the</font>
    <font color=navy>// solution of the linear system.</font>
    <font color=navy>//</font>
    linlsqrstate s;
    linlsqrreport rep;
    real_1d_array x;
    linlsqrcreate(5, 2, s);
    linlsqrsolvesparse(s, a, b);
    linlsqrresults(s, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [1.000,2.000]</font>
    <b>return</b> 0;
}


</pre><a name=unit_linreg></a><h2 class=pageheader><code>linreg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_linearmodel' class=toc>linearmodel</a><br>
<a href='#struct_lrreport' class=toc>lrreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_lravgerror' class=toc>lravgerror</a><br>
<a href='#sub_lravgrelerror' class=toc>lravgrelerror</a><br>
<a href='#sub_lrbuild' class=toc>lrbuild</a><br>
<a href='#sub_lrbuilds' class=toc>lrbuilds</a><br>
<a href='#sub_lrbuildz' class=toc>lrbuildz</a><br>
<a href='#sub_lrbuildzs' class=toc>lrbuildzs</a><br>
<a href='#sub_lrpack' class=toc>lrpack</a><br>
<a href='#sub_lrprocess' class=toc>lrprocess</a><br>
<a href='#sub_lrrmserror' class=toc>lrrmserror</a><br>
<a href='#sub_lrunpack' class=toc>lrunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_linearmodel'></a><h3 class=pageheader><code>linearmodel</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> linearmodel
{
};

</div></pre>
<a name='struct_lrreport'></a><h3 class=pageheader><code>lrreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LRReport structure contains additional information about linear model:
* C             -   covariation matrix,  array[0..NVars,0..NVars].
                    C[i,j] = Cov(A[i],A[j])
* RMSError      -   root mean square error on a training set
* AvgError      -   average error on a training set
* AvgRelError   -   average relative error on a training set (excluding
                    observations with zero function value).
* CVRMSError    -   leave-one-out cross-validation estimate of
                    generalization error. Calculated using fast algorithm
                    with O(NVars*NPoints) complexity.
* CVAvgError    -   cross-validation estimate of average error
* CVAvgRelError -   cross-validation estimate of average relative error

All other fields of the structure are intended for internal use and should
not be used outside ALGLIB.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> lrreport
{
    real_2d_array        c;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               cvrmserror;
    <b>double</b>               cvavgerror;
    <b>double</b>               cvavgrelerror;
    ae_int_t             ncvdefects;
    integer_1d_array     cvdefects;
};

</div></pre>
<a name='sub_lravgerror'></a><h3 class=pageheader><code>lravgerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average error on the test set

INPUT PARAMETERS:
    LM      -   linear model
    XY      -   test set
    NPoints -   test set size

RESULT:
    average error.

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::lravgerror(
    linearmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_lravgrelerror'></a><h3 class=pageheader><code>lravgrelerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set

INPUT PARAMETERS:
    LM      -   linear model
    XY      -   test set
    NPoints -   test set size

RESULT:
    average relative error.

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::lravgrelerror(
    linearmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_lrbuild'></a><h3 class=pageheader><code>lrbuild</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Linear regression

Subroutine builds model:

    Y = A(0)*X[0] + ... + A(N-1)*X[N-1] + A(N)

and model found in ALGLIB format, covariation matrix, training set  errors
(rms,  average,  average  relative)   and  leave-one-out  cross-validation
estimate of the generalization error. CV  estimate calculated  using  fast
algorithm with O(NPoints*NVars) complexity.

When  covariation  matrix  is  calculated  standard deviations of function
values are assumed to be equal to RMS error on the training set.

INPUT PARAMETERS:
    XY          -   training set, array [0..NPoints-1,0..NVars]:
                    * NVars columns - independent variables
                    * last column - dependent variable
    NPoints     -   training set size, NPoints&gt;NVars+1
    NVars       -   number of independent variables

OUTPUT PARAMETERS:
    Info        -   return code:
                    * -255, in case of unknown internal error
                    * -4, if internal SVD subroutine haven't converged
                    * -1, if incorrect parameters was passed (NPoints&lt;NVars+2, NVars&lt;1).
                    *  1, if subroutine successfully finished
    LM          -   linear model in the ALGLIB format. Use subroutines of
                    this unit to work with the model.
    AR          -   additional results


  -- ALGLIB --
     Copyright 02.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrbuild(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t&amp; info,
    linearmodel&amp; lm,
    lrreport&amp; ar);

</div></pre>
<a name='sub_lrbuilds'></a><h3 class=pageheader><code>lrbuilds</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Linear regression

Variant of LRBuild which uses vector of standatd deviations (errors in
function values).

INPUT PARAMETERS:
    XY          -   training set, array [0..NPoints-1,0..NVars]:
                    * NVars columns - independent variables
                    * last column - dependent variable
    S           -   standard deviations (errors in function values)
                    array[0..NPoints-1], S[i]&gt;0.
    NPoints     -   training set size, NPoints&gt;NVars+1
    NVars       -   number of independent variables

OUTPUT PARAMETERS:
    Info        -   return code:
                    * -255, in case of unknown internal error
                    * -4, if internal SVD subroutine haven't converged
                    * -1, if incorrect parameters was passed (NPoints&lt;NVars+2, NVars&lt;1).
                    * -2, if S[I]&lt;=0
                    *  1, if subroutine successfully finished
    LM          -   linear model in the ALGLIB format. Use subroutines of
                    this unit to work with the model.
    AR          -   additional results


  -- ALGLIB --
     Copyright 02.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrbuilds(
    real_2d_array xy,
    real_1d_array s,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t&amp; info,
    linearmodel&amp; lm,
    lrreport&amp; ar);

</div></pre>
<a name='sub_lrbuildz'></a><h3 class=pageheader><code>lrbuildz</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like LRBuild but builds model

    Y = A(0)*X[0] + ... + A(N-1)*X[N-1]

i.e. with zero constant term.

  -- ALGLIB --
     Copyright 30.10.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrbuildz(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t&amp; info,
    linearmodel&amp; lm,
    lrreport&amp; ar);

</div></pre>
<a name='sub_lrbuildzs'></a><h3 class=pageheader><code>lrbuildzs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like LRBuildS, but builds model

    Y = A(0)*X[0] + ... + A(N-1)*X[N-1]

i.e. with zero constant term.

  -- ALGLIB --
     Copyright 30.10.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrbuildzs(
    real_2d_array xy,
    real_1d_array s,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t&amp; info,
    linearmodel&amp; lm,
    lrreport&amp; ar);

</div></pre>
<a name='sub_lrpack'></a><h3 class=pageheader><code>lrpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
&quot;Packs&quot; coefficients and creates linear model in ALGLIB format (LRUnpack
reversed).

INPUT PARAMETERS:
    V           -   coefficients, array[0..NVars]
    NVars       -   number of independent variables

OUTPUT PAREMETERS:
    LM          -   linear model.

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrpack(real_1d_array v, ae_int_t nvars, linearmodel&amp; lm);

</div></pre>
<a name='sub_lrprocess'></a><h3 class=pageheader><code>lrprocess</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procesing

INPUT PARAMETERS:
    LM      -   linear model
    X       -   input vector,  array[0..NVars-1].

Result:
    value of linear model regression estimate

  -- ALGLIB --
     Copyright 03.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::lrprocess(linearmodel lm, real_1d_array x);

</div></pre>
<a name='sub_lrrmserror'></a><h3 class=pageheader><code>lrrmserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set

INPUT PARAMETERS:
    LM      -   linear model
    XY      -   test set
    NPoints -   test set size

RESULT:
    root mean square error.

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::lrrmserror(
    linearmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_lrunpack'></a><h3 class=pageheader><code>lrunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacks coefficients of linear model.

INPUT PARAMETERS:
    LM          -   linear model in ALGLIB format

OUTPUT PARAMETERS:
    V           -   coefficients, array[0..NVars]
                    constant term (intercept) is stored in the V[NVars].
    NVars       -   number of independent variables (one less than number
                    of coefficients)

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lrunpack(linearmodel lm, real_1d_array&amp; v, ae_int_t&amp; nvars);

</div></pre>
<a name=unit_logit></a><h2 class=pageheader><code>logit</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_logitmodel' class=toc>logitmodel</a><br>
<a href='#struct_mnlreport' class=toc>mnlreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mnlavgce' class=toc>mnlavgce</a><br>
<a href='#sub_mnlavgerror' class=toc>mnlavgerror</a><br>
<a href='#sub_mnlavgrelerror' class=toc>mnlavgrelerror</a><br>
<a href='#sub_mnlclserror' class=toc>mnlclserror</a><br>
<a href='#sub_mnlpack' class=toc>mnlpack</a><br>
<a href='#sub_mnlprocess' class=toc>mnlprocess</a><br>
<a href='#sub_mnlprocessi' class=toc>mnlprocessi</a><br>
<a href='#sub_mnlrelclserror' class=toc>mnlrelclserror</a><br>
<a href='#sub_mnlrmserror' class=toc>mnlrmserror</a><br>
<a href='#sub_mnltrainh' class=toc>mnltrainh</a><br>
<a href='#sub_mnlunpack' class=toc>mnlunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_logitmodel'></a><h3 class=pageheader><code>logitmodel</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> logitmodel
{
};

</div></pre>
<a name='struct_mnlreport'></a><h3 class=pageheader><code>mnlreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
MNLReport structure contains information about training process:
* NGrad     -   number of gradient calculations
* NHess     -   number of Hessian calculations
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mnlreport
{
    ae_int_t             ngrad;
    ae_int_t             nhess;
};

</div></pre>
<a name='sub_mnlavgce'></a><h3 class=pageheader><code>mnlavgce</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average cross-entropy (in bits per element) on the test set

INPUT PARAMETERS:
    LM      -   logit model
    XY      -   test set
    NPoints -   test set size

RESULT:
    CrossEntropy/(NPoints*ln(2)).

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mnlavgce(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mnlavgerror'></a><h3 class=pageheader><code>mnlavgerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average error on the test set

INPUT PARAMETERS:
    LM      -   logit model
    XY      -   test set
    NPoints -   test set size

RESULT:
    average error (error when estimating posterior probabilities).

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mnlavgerror(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mnlavgrelerror'></a><h3 class=pageheader><code>mnlavgrelerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average relative error on the test set

INPUT PARAMETERS:
    LM      -   logit model
    XY      -   test set
    NPoints -   test set size

RESULT:
    average relative error (error when estimating posterior probabilities).

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mnlavgrelerror(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t ssize);

</div></pre>
<a name='sub_mnlclserror'></a><h3 class=pageheader><code>mnlclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Classification error on test set = MNLRelClsError*NPoints

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mnlclserror(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mnlpack'></a><h3 class=pageheader><code>mnlpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
&quot;Packs&quot; coefficients and creates logit model in ALGLIB format (MNLUnpack
reversed).

INPUT PARAMETERS:
    A           -   model (see MNLUnpack)
    NVars       -   number of independent variables
    NClasses    -   number of classes

OUTPUT PARAMETERS:
    LM          -   logit model.

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mnlpack(
    real_2d_array a,
    ae_int_t nvars,
    ae_int_t nclasses,
    logitmodel&amp; lm);

</div></pre>
<a name='sub_mnlprocess'></a><h3 class=pageheader><code>mnlprocess</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procesing

INPUT PARAMETERS:
    LM      -   logit model, passed by non-constant reference
                (some fields of structure are used as temporaries
                when calculating model output).
    X       -   input vector,  array[0..NVars-1].
    Y       -   (possibly) preallocated buffer; if size of Y is less than
                NClasses, it will be reallocated.If it is large enough, it
                is NOT reallocated, so we can save some time on reallocation.

OUTPUT PARAMETERS:
    Y       -   result, array[0..NClasses-1]
                Vector of posterior probabilities for classification task.

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mnlprocess(logitmodel lm, real_1d_array x, real_1d_array&amp; y);

</div></pre>
<a name='sub_mnlprocessi'></a><h3 class=pageheader><code>mnlprocessi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
'interactive'  variant  of  MNLProcess  for  languages  like  Python which
support constructs like &quot;Y = MNLProcess(LM,X)&quot; and interactive mode of the
interpreter

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mnlprocessi(
    logitmodel lm,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_mnlrelclserror'></a><h3 class=pageheader><code>mnlrelclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Relative classification error on the test set

INPUT PARAMETERS:
    LM      -   logit model
    XY      -   test set
    NPoints -   test set size

RESULT:
    percent of incorrectly classified cases.

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mnlrelclserror(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mnlrmserror'></a><h3 class=pageheader><code>mnlrmserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set

INPUT PARAMETERS:
    LM      -   logit model
    XY      -   test set
    NPoints -   test set size

RESULT:
    root mean square error (error when estimating posterior probabilities).

  -- ALGLIB --
     Copyright 30.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mnlrmserror(
    logitmodel lm,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mnltrainh'></a><h3 class=pageheader><code>mnltrainh</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine trains logit model.

INPUT PARAMETERS:
    XY          -   training set, array[0..NPoints-1,0..NVars]
                    First NVars columns store values of independent
                    variables, next column stores number of class (from 0
                    to NClasses-1) which dataset element belongs to. Fractional
                    values are rounded to nearest integer.
    NPoints     -   training set size, NPoints&gt;=1
    NVars       -   number of independent variables, NVars&gt;=1
    NClasses    -   number of classes, NClasses&gt;=2

OUTPUT PARAMETERS:
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;NVars+2, NVars&lt;1, NClasses&lt;2).
                    *  1, if task has been solved
    LM          -   model built
    Rep         -   training report

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mnltrainh(
    real_2d_array xy,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t nclasses,
    ae_int_t&amp; info,
    logitmodel&amp; lm,
    mnlreport&amp; rep);

</div></pre>
<a name='sub_mnlunpack'></a><h3 class=pageheader><code>mnlunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacks coefficients of logit model. Logit model have form:

    P(class=i) = S(i) / (S(0) + S(1) + ... +S(M-1))
          S(i) = Exp(A[i,0]*X[0] + ... + A[i,N-1]*X[N-1] + A[i,N]), when i&lt;M-1
        S(M-1) = 1

INPUT PARAMETERS:
    LM          -   logit model in ALGLIB format

OUTPUT PARAMETERS:
    V           -   coefficients, array[0..NClasses-2,0..NVars]
    NVars       -   number of independent variables
    NClasses    -   number of classes

  -- ALGLIB --
     Copyright 10.09.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mnlunpack(
    logitmodel lm,
    real_2d_array&amp; a,
    ae_int_t&amp; nvars,
    ae_int_t&amp; nclasses);

</div></pre>
<a name=unit_lsfit></a><h2 class=pageheader><code>lsfit</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_barycentricfitreport' class=toc>barycentricfitreport</a><br>
<a href='#struct_lsfitreport' class=toc>lsfitreport</a><br>
<a href='#struct_lsfitstate' class=toc>lsfitstate</a><br>
<a href='#struct_polynomialfitreport' class=toc>polynomialfitreport</a><br>
<a href='#struct_spline1dfitreport' class=toc>spline1dfitreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_barycentricfitfloaterhormann' class=toc>barycentricfitfloaterhormann</a><br>
<a href='#sub_barycentricfitfloaterhormannwc' class=toc>barycentricfitfloaterhormannwc</a><br>
<a href='#sub_lsfitcreatef' class=toc>lsfitcreatef</a><br>
<a href='#sub_lsfitcreatefg' class=toc>lsfitcreatefg</a><br>
<a href='#sub_lsfitcreatefgh' class=toc>lsfitcreatefgh</a><br>
<a href='#sub_lsfitcreatewf' class=toc>lsfitcreatewf</a><br>
<a href='#sub_lsfitcreatewfg' class=toc>lsfitcreatewfg</a><br>
<a href='#sub_lsfitcreatewfgh' class=toc>lsfitcreatewfgh</a><br>
<a href='#sub_lsfitfit' class=toc>lsfitfit</a><br>
<a href='#sub_lsfitlinear' class=toc>lsfitlinear</a><br>
<a href='#sub_lsfitlinearc' class=toc>lsfitlinearc</a><br>
<a href='#sub_lsfitlinearw' class=toc>lsfitlinearw</a><br>
<a href='#sub_lsfitlinearwc' class=toc>lsfitlinearwc</a><br>
<a href='#sub_lsfitresults' class=toc>lsfitresults</a><br>
<a href='#sub_lsfitsetbc' class=toc>lsfitsetbc</a><br>
<a href='#sub_lsfitsetcond' class=toc>lsfitsetcond</a><br>
<a href='#sub_lsfitsetgradientcheck' class=toc>lsfitsetgradientcheck</a><br>
<a href='#sub_lsfitsetscale' class=toc>lsfitsetscale</a><br>
<a href='#sub_lsfitsetstpmax' class=toc>lsfitsetstpmax</a><br>
<a href='#sub_lsfitsetxrep' class=toc>lsfitsetxrep</a><br>
<a href='#sub_polynomialfit' class=toc>polynomialfit</a><br>
<a href='#sub_polynomialfitwc' class=toc>polynomialfitwc</a><br>
<a href='#sub_spline1dfitcubic' class=toc>spline1dfitcubic</a><br>
<a href='#sub_spline1dfitcubicwc' class=toc>spline1dfitcubicwc</a><br>
<a href='#sub_spline1dfithermite' class=toc>spline1dfithermite</a><br>
<a href='#sub_spline1dfithermitewc' class=toc>spline1dfithermitewc</a><br>
<a href='#sub_spline1dfitpenalized' class=toc>spline1dfitpenalized</a><br>
<a href='#sub_spline1dfitpenalizedw' class=toc>spline1dfitpenalizedw</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_lsfit_d_lin' class=toc>lsfit_d_lin</a></td><td width=15>&nbsp;</td><td>Unconstrained (general) linear least squares fitting with and without weights</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_linc' class=toc>lsfit_d_linc</a></td><td width=15>&nbsp;</td><td>Constrained (general) linear least squares fitting with and without weights</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_nlf' class=toc>lsfit_d_nlf</a></td><td width=15>&nbsp;</td><td>Nonlinear fitting using function value only</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_nlfb' class=toc>lsfit_d_nlfb</a></td><td width=15>&nbsp;</td><td>Bound contstrained nonlinear fitting using function value only</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_nlfg' class=toc>lsfit_d_nlfg</a></td><td width=15>&nbsp;</td><td>Nonlinear fitting using gradient</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_nlfgh' class=toc>lsfit_d_nlfgh</a></td><td width=15>&nbsp;</td><td>Nonlinear fitting using gradient and Hessian</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_nlscale' class=toc>lsfit_d_nlscale</a></td><td width=15>&nbsp;</td><td>Nonlinear fitting with custom scaling and bound constraints</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_pol' class=toc>lsfit_d_pol</a></td><td width=15>&nbsp;</td><td>Unconstrained polynomial fitting</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_polc' class=toc>lsfit_d_polc</a></td><td width=15>&nbsp;</td><td>Constrained polynomial fitting</td></tr>
<tr align=left valign=top><td><a href='#example_lsfit_d_spline' class=toc>lsfit_d_spline</a></td><td width=15>&nbsp;</td><td>Unconstrained fitting by penalized regression spline</td></tr>
</table></div>
<a name='struct_barycentricfitreport'></a><h3 class=pageheader><code>barycentricfitreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Barycentric fitting report:
    RMSError        RMS error
    AvgError        average error
    AvgRelError     average relative error (for non-zero Y[I])
    MaxError        maximum error
    TaskRCond       reciprocal of task's condition number
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> barycentricfitreport
{
    <b>double</b>               taskrcond;
    ae_int_t             dbest;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               maxerror;
};

</div></pre>
<a name='struct_lsfitreport'></a><h3 class=pageheader><code>lsfitreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Least squares fitting report. This structure contains informational fields
which are set by fitting functions provided by this unit.

Different functions initialize different sets of  fields,  so  you  should
read documentation on specific function you used in order  to  know  which
fields are initialized.

    TaskRCond       reciprocal of task's condition number
    IterationsCount number of internal iterations

    VarIdx          if user-supplied gradient contains errors  which  were
                    detected by nonlinear fitter, this  field  is  set  to
                    index  of  the  first  component  of gradient which is
                    suspected to be spoiled by bugs.

    RMSError        RMS error
    AvgError        average error
    AvgRelError     average relative error (for non-zero Y[I])
    MaxError        maximum error

    WRMSError       weighted RMS error

    CovPar          covariance matrix for parameters, filled by some solvers
    ErrPar          vector of errors in parameters, filled by some solvers
    ErrCurve        vector of fit errors -  variability  of  the  best-fit
                    curve, filled by some solvers.
    Noise           vector of per-point noise estimates, filled by
                    some solvers.
    R2              coefficient of determination (non-weighted, non-adjusted),
                    filled by some solvers.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> lsfitreport
{
    <b>double</b>               taskrcond;
    ae_int_t             iterationscount;
    ae_int_t             varidx;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               maxerror;
    <b>double</b>               wrmserror;
    real_2d_array        covpar;
    real_1d_array        errpar;
    real_1d_array        errcurve;
    real_1d_array        noise;
    <b>double</b>               r2;
};

</div></pre>
<a name='struct_lsfitstate'></a><h3 class=pageheader><code>lsfitstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Nonlinear fitter.

You should use ALGLIB functions to work with fitter.
Never try to access its fields directly!
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> lsfitstate
{
};

</div></pre>
<a name='struct_polynomialfitreport'></a><h3 class=pageheader><code>polynomialfitreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Polynomial fitting report:
    TaskRCond       reciprocal of task's condition number
    RMSError        RMS error
    AvgError        average error
    AvgRelError     average relative error (for non-zero Y[I])
    MaxError        maximum error
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> polynomialfitreport
{
    <b>double</b>               taskrcond;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               maxerror;
};

</div></pre>
<a name='struct_spline1dfitreport'></a><h3 class=pageheader><code>spline1dfitreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Spline fitting report:
    RMSError        RMS error
    AvgError        average error
    AvgRelError     average relative error (for non-zero Y[I])
    MaxError        maximum error

Fields  below are  filled  by   obsolete    functions   (Spline1DFitCubic,
Spline1DFitHermite). Modern fitting functions do NOT fill these fields:
    TaskRCond       reciprocal of task's condition number
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> spline1dfitreport
{
    <b>double</b>               taskrcond;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    <b>double</b>               maxerror;
};

</div></pre>
<a name='sub_barycentricfitfloaterhormann'></a><h3 class=pageheader><code>barycentricfitfloaterhormann</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rational least squares fitting using  Floater-Hormann  rational  functions
with optimal D chosen from [0,9].

Equidistant  grid  with M node on [min(x),max(x)]  is  used to build basis
functions. Different values of D are tried, optimal  D  (least  root  mean
square error) is chosen.  Task  is  linear, so linear least squares solver
is used. Complexity  of  this  computational  scheme is  O(N*M^2)  (mostly
dominated by the least squares solver).

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    N   -   number of points, N&gt;0.
    M   -   number of basis functions ( = number_of_nodes), M&gt;=2.

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearWC() subroutine.
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
    B   -   barycentric interpolant.
    Rep -   report, same format as in LSFitLinearWC() subroutine.
            Following fields are set:
            * DBest         best value of the D parameter
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricfitfloaterhormann(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; b,
    barycentricfitreport&amp; rep);

</div></pre>
<a name='sub_barycentricfitfloaterhormannwc'></a><h3 class=pageheader><code>barycentricfitfloaterhormannwc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weghted rational least  squares  fitting  using  Floater-Hormann  rational
functions  with  optimal  D  chosen  from  [0,9],  with  constraints   and
individual weights.

Equidistant  grid  with M node on [min(x),max(x)]  is  used to build basis
functions. Different values of D are tried, optimal D (least WEIGHTED root
mean square error) is chosen.  Task  is  linear,  so  linear least squares
solver  is  used.  Complexity  of  this  computational  scheme is O(N*M^2)
(mostly dominated by the least squares solver).

SEE ALSO
* BarycentricFitFloaterHormann(), &quot;lightweight&quot; fitting without invididual
  weights and constraints.

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    W   -   weights, array[0..N-1]
            Each summand in square  sum  of  approximation deviations from
            given  values  is  multiplied  by  the square of corresponding
            weight. Fill it by 1's if you don't  want  to  solve  weighted
            task.
    N   -   number of points, N&gt;0.
    XC  -   points where function values/derivatives are constrained,
            array[0..K-1].
    YC  -   values of constraints, array[0..K-1]
    DC  -   array[0..K-1], types of constraints:
            * DC[i]=0   means that S(XC[i])=YC[i]
            * DC[i]=1   means that S'(XC[i])=YC[i]
            SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
    K   -   number of constraints, 0&lt;=K&lt;M.
            K=0 means no constraints (XC/YC/DC are not used in such cases)
    M   -   number of basis functions ( = number_of_nodes), M&gt;=2.

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearWC() subroutine.
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
                        -1 means another errors in parameters passed
                           (N&lt;=0, for example)
    B   -   barycentric interpolant.
    Rep -   report, same format as in LSFitLinearWC() subroutine.
            Following fields are set:
            * DBest         best value of the D parameter
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroutine doesn't calculate task's condition number for K&lt;&gt;0.

SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:

Setting constraints can lead  to undesired  results,  like ill-conditioned
behavior, or inconsistency being detected. From the other side,  it allows
us to improve quality of the fit. Here we summarize  our  experience  with
constrained barycentric interpolants:
* excessive  constraints  can  be  inconsistent.   Floater-Hormann   basis
  functions aren't as flexible as splines (although they are very smooth).
* the more evenly constraints are spread across [min(x),max(x)],  the more
  chances that they will be consistent
* the  greater  is  M (given  fixed  constraints),  the  more chances that
  constraints will be consistent
* in the general case, consistency of constraints IS NOT GUARANTEED.
* in the several special cases, however, we CAN guarantee consistency.
* one of this cases is constraints on the function  VALUES at the interval
  boundaries. Note that consustency of the  constraints  on  the  function
  DERIVATIVES is NOT guaranteed (you can use in such cases  cubic  splines
  which are more flexible).
* another  special  case  is ONE constraint on the function value (OR, but
  not AND, derivative) anywhere in the interval

Our final recommendation is to use constraints  WHEN  AND  ONLY  WHEN  you
can't solve your task without them. Anything beyond  special  cases  given
above is not guaranteed and may result in inconsistency.

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricfitfloaterhormannwc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t k,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; b,
    barycentricfitreport&amp; rep);

</div></pre>
<a name='sub_lsfitcreatef'></a><h3 class=pageheader><code>lsfitcreatef</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Nonlinear least squares fitting using function values only.

Combination of numerical differentiation and secant updates is used to
obtain function Jacobian.

Nonlinear task min(F(c)) is solved, where

    F(c) = (f(c,x[0])-y[0])^2 + ... + (f(c,x[n-1])-y[n-1])^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * w is an N-dimensional vector of weight coefficients,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses only f(c,x[i]).

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted
    DiffStep-   numerical differentiation step;
                should not be very small or large;
                large = loss of accuracy
                small = growth of round-off errors

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 18.10.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatef(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    <b>double</b> diffstep,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatef(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    <b>double</b> diffstep,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlf' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfb' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlscale' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitcreatefg'></a><h3 class=pageheader><code>lsfitcreatefg</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Nonlinear least squares fitting using gradient only, without individual
weights.

Nonlinear task min(F(c)) is solved, where

    F(c) = ((f(c,x[0])-y[0]))^2 + ... + ((f(c,x[n-1])-y[n-1]))^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses only f(c,x[i]) and its gradient.

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted
    CheapFG -   boolean flag, which is:
                * True  if both function and gradient calculation complexity
                        are less than O(M^2).  An improved  algorithm  can
                        be  used  which corresponds  to  FGJ  scheme  from
                        MINLM unit.
                * False otherwise.
                        Standard Jacibian-bases  Levenberg-Marquardt  algo
                        will be used (FJ scheme).

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatefg(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    <b>bool</b> cheapfg,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatefg(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    <b>bool</b> cheapfg,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlfg' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitcreatefgh'></a><h3 class=pageheader><code>lsfitcreatefgh</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Nonlinear least squares fitting using gradient/Hessian, without individial
weights.

Nonlinear task min(F(c)) is solved, where

    F(c) = ((f(c,x[0])-y[0]))^2 + ... + ((f(c,x[n-1])-y[n-1]))^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses f(c,x[i]), its gradient and its Hessian.

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state


  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatefgh(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatefgh(
    real_2d_array x,
    real_1d_array y,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlfgh' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitcreatewf'></a><h3 class=pageheader><code>lsfitcreatewf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted nonlinear least squares fitting using function values only.

Combination of numerical differentiation and secant updates is used to
obtain function Jacobian.

Nonlinear task min(F(c)) is solved, where

    F(c) = (w[0]*(f(c,x[0])-y[0]))^2 + ... + (w[n-1]*(f(c,x[n-1])-y[n-1]))^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * w is an N-dimensional vector of weight coefficients,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses only f(c,x[i]).

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    W       -   weights, array[0..N-1]
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted
    DiffStep-   numerical differentiation step;
                should not be very small or large;
                large = loss of accuracy
                small = growth of round-off errors

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 18.10.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatewf(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    <b>double</b> diffstep,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatewf(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    <b>double</b> diffstep,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlf' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfb' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitcreatewfg'></a><h3 class=pageheader><code>lsfitcreatewfg</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted nonlinear least squares fitting using gradient only.

Nonlinear task min(F(c)) is solved, where

    F(c) = (w[0]*(f(c,x[0])-y[0]))^2 + ... + (w[n-1]*(f(c,x[n-1])-y[n-1]))^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * w is an N-dimensional vector of weight coefficients,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses only f(c,x[i]) and its gradient.

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    W       -   weights, array[0..N-1]
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted
    CheapFG -   boolean flag, which is:
                * True  if both function and gradient calculation complexity
                        are less than O(M^2).  An improved  algorithm  can
                        be  used  which corresponds  to  FGJ  scheme  from
                        MINLM unit.
                * False otherwise.
                        Standard Jacibian-bases  Levenberg-Marquardt  algo
                        will be used (FJ scheme).

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

See also:
    LSFitResults
    LSFitCreateFG (fitting without weights)
    LSFitCreateWFGH (fitting using Hessian)
    LSFitCreateFGH (fitting using Hessian, without weights)

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatewfg(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    <b>bool</b> cheapfg,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatewfg(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    <b>bool</b> cheapfg,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlfg' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitcreatewfgh'></a><h3 class=pageheader><code>lsfitcreatewfgh</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted nonlinear least squares fitting using gradient/Hessian.

Nonlinear task min(F(c)) is solved, where

    F(c) = (w[0]*(f(c,x[0])-y[0]))^2 + ... + (w[n-1]*(f(c,x[n-1])-y[n-1]))^2,

    * N is a number of points,
    * M is a dimension of a space points belong to,
    * K is a dimension of a space of parameters being fitted,
    * w is an N-dimensional vector of weight coefficients,
    * x is a set of N points, each of them is an M-dimensional vector,
    * c is a K-dimensional vector of parameters being fitted

This subroutine uses f(c,x[i]), its gradient and its Hessian.

INPUT PARAMETERS:
    X       -   array[0..N-1,0..M-1], points (one row = one point)
    Y       -   array[0..N-1], function values.
    W       -   weights, array[0..N-1]
    C       -   array[0..K-1], initial approximation to the solution,
    N       -   number of points, N&gt;1
    M       -   dimension of space
    K       -   number of parameters being fitted

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitcreatewfgh(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    lsfitstate&amp; state);
<b>void</b> alglib::lsfitcreatewfgh(
    real_2d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array c,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    lsfitstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlfgh' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitfit'></a><h3 class=pageheader><code>lsfitfit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear fitter

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    hess    -   callback which calculates function (or merit function)
                value func, gradient grad and Hessian hess at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL

NOTES:

1. this algorithm is somewhat unusual because it works with  parameterized
   function f(C,X), where X is a function argument (we  have  many  points
   which are characterized by different  argument  values),  and  C  is  a
   parameter to fit.

   For example, if we want to do linear fit by f(c0,c1,x) = c0*x+c1,  then
   x will be argument, and {c0,c1} will be parameters.

   It is important to understand that this algorithm finds minimum in  the
   space of function PARAMETERS (not arguments), so it  needs  derivatives
   of f() with respect to C, not X.

   In the example above it will need f=c0*x+c1 and {df/dc0,df/dc1} = {x,1}
   instead of {df/dx} = {c0}.

2. Callback functions accept C as the first parameter, and X as the second

3. If  state  was  created  with  LSFitCreateFG(),  algorithm  needs  just
   function   and   its   gradient,   but   if   state   was  created with
   LSFitCreateFGH(), algorithm will need function, gradient and Hessian.

   According  to  the  said  above,  there  ase  several  versions of this
   function, which accept different sets of callbacks.

   This flexibility opens way to subtle errors - you may create state with
   LSFitCreateFGH() (optimization using Hessian), but call function  which
   does not accept Hessian. So when algorithm will request Hessian,  there
   will be no callback to call. In this case exception will be thrown.

   Be careful to avoid such errors because there is no way to find them at
   compile time - you can see them at runtime only.

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> lsfitfit(lsfitstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;c, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> lsfitfit(lsfitstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;c, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> lsfitfit(lsfitstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b> (*hess)(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, real_2d_array &amp;hess, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;c, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlf' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfg' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlscale' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitlinear'></a><h3 class=pageheader><code>lsfitlinear</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Linear least squares fitting.

QR decomposition is used to reduce task to MxM, then triangular solver  or
SVD-based solver is used depending on condition number of the  system.  It
allows to maximize speed and retain decent accuracy.

IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
           convenient to use PolynomialFit() function. This function gives
           best  results  on  polynomial  problems  and  solves  numerical
           stability  issues  which  arise  when   you   fit   high-degree
           polynomials to your data.

INPUT PARAMETERS:
    Y       -   array[0..N-1] Function values in  N  points.
    FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
                FMatrix[I, J] - value of J-th basis function in I-th point.
    N       -   number of points used. N&gt;=1.
    M       -   number of basis functions, M&gt;=1.

OUTPUT PARAMETERS:
    Info    -   error code:
                * -4    internal SVD decomposition subroutine failed (very
                        rare and for degenerate systems only)
                *  1    task is solved
    C       -   decomposition coefficients, array[0..M-1]
    Rep     -   fitting report. Following fields are set:
                * Rep.TaskRCond     reciprocal of condition number
                * R2                non-adjusted coefficient of determination
                                    (non-weighted)
                * RMSError          rms error on the (X,Y).
                * AvgError          average error on the (X,Y).
                * AvgRelError       average relative error on the non-zero Y
                * MaxError          maximum error
                                    NON-WEIGHTED ERRORS ARE CALCULATED

ERRORS IN PARAMETERS

This  solver  also  calculates different kinds of errors in parameters and
fills corresponding fields of report:
* Rep.CovPar        covariance matrix for parameters, array[K,K].
* Rep.ErrPar        errors in parameters, array[K],
                    errpar = sqrt(diag(CovPar))
* Rep.ErrCurve      vector of fit errors - standard deviations of empirical
                    best-fit curve from &quot;ideal&quot; best-fit curve built  with
                    infinite number of samples, array[N].
                    errcurve = sqrt(diag(F*CovPar*F')),
                    where F is functions matrix.
* Rep.Noise         vector of per-point estimates of noise, array[N]

NOTE:       noise in the data is estimated as follows:
            * for fitting without user-supplied  weights  all  points  are
              assumed to have same level of noise, which is estimated from
              the data
            * for fitting with user-supplied weights we assume that  noise
              level in I-th point is inversely proportional to Ith weight.
              Coefficient of proportionality is estimated from the data.

NOTE:       we apply small amount of regularization when we invert squared
            Jacobian and calculate covariance matrix. It  guarantees  that
            algorithm won't divide by zero  during  inversion,  but  skews
            error estimates a bit (fractional error is about 10^-9).

            However, we believe that this difference is insignificant  for
            all practical purposes except for the situation when you  want
            to compare ALGLIB results with &quot;reference&quot;  implementation  up
            to the last significant digit.

NOTE:       covariance matrix is estimated using  correction  for  degrees
            of freedom (covariances are divided by N-M instead of dividing
            by N).

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitlinear(
    real_1d_array y,
    real_2d_array fmatrix,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);
<b>void</b> alglib::lsfitlinear(
    real_1d_array y,
    real_2d_array fmatrix,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_lin' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitlinearc'></a><h3 class=pageheader><code>lsfitlinearc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Constained linear least squares fitting.

This  is  variation  of LSFitLinear(),  which searchs for min|A*x=b| given
that  K  additional  constaints  C*x=bc are satisfied. It reduces original
task to modified one: min|B*y-d| WITHOUT constraints,  then  LSFitLinear()
is called.

IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
           convenient to use PolynomialFit() function. This function gives
           best  results  on  polynomial  problems  and  solves  numerical
           stability  issues  which  arise  when   you   fit   high-degree
           polynomials to your data.

INPUT PARAMETERS:
    Y       -   array[0..N-1] Function values in  N  points.
    FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
                FMatrix[I,J] - value of J-th basis function in I-th point.
    CMatrix -   a table of constaints, array[0..K-1,0..M].
                I-th row of CMatrix corresponds to I-th linear constraint:
                CMatrix[I,0]*C[0] + ... + CMatrix[I,M-1]*C[M-1] = CMatrix[I,M]
    N       -   number of points used. N&gt;=1.
    M       -   number of basis functions, M&gt;=1.
    K       -   number of constraints, 0 &lt;= K &lt; M
                K=0 corresponds to absence of constraints.

OUTPUT PARAMETERS:
    Info    -   error code:
                * -4    internal SVD decomposition subroutine failed (very
                        rare and for degenerate systems only)
                * -3    either   too   many  constraints  (M   or   more),
                        degenerate  constraints   (some   constraints  are
                        repetead twice) or inconsistent  constraints  were
                        specified.
                *  1    task is solved
    C       -   decomposition coefficients, array[0..M-1]
    Rep     -   fitting report. Following fields are set:
                * R2                non-adjusted coefficient of determination
                                    (non-weighted)
                * RMSError          rms error on the (X,Y).
                * AvgError          average error on the (X,Y).
                * AvgRelError       average relative error on the non-zero Y
                * MaxError          maximum error
                                    NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.

ERRORS IN PARAMETERS

This  solver  also  calculates different kinds of errors in parameters and
fills corresponding fields of report:
* Rep.CovPar        covariance matrix for parameters, array[K,K].
* Rep.ErrPar        errors in parameters, array[K],
                    errpar = sqrt(diag(CovPar))
* Rep.ErrCurve      vector of fit errors - standard deviations of empirical
                    best-fit curve from &quot;ideal&quot; best-fit curve built  with
                    infinite number of samples, array[N].
                    errcurve = sqrt(diag(F*CovPar*F')),
                    where F is functions matrix.
* Rep.Noise         vector of per-point estimates of noise, array[N]

IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
            account boundary/linear constraints! Presence  of  constraints
            changes distribution of errors, but there is no  easy  way  to
            account for constraints when you calculate covariance matrix.

NOTE:       noise in the data is estimated as follows:
            * for fitting without user-supplied  weights  all  points  are
              assumed to have same level of noise, which is estimated from
              the data
            * for fitting with user-supplied weights we assume that  noise
              level in I-th point is inversely proportional to Ith weight.
              Coefficient of proportionality is estimated from the data.

NOTE:       we apply small amount of regularization when we invert squared
            Jacobian and calculate covariance matrix. It  guarantees  that
            algorithm won't divide by zero  during  inversion,  but  skews
            error estimates a bit (fractional error is about 10^-9).

            However, we believe that this difference is insignificant  for
            all practical purposes except for the situation when you  want
            to compare ALGLIB results with &quot;reference&quot;  implementation  up
            to the last significant digit.

NOTE:       covariance matrix is estimated using  correction  for  degrees
            of freedom (covariances are divided by N-M instead of dividing
            by N).

  -- ALGLIB --
     Copyright 07.09.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitlinearc(
    real_1d_array y,
    real_2d_array fmatrix,
    real_2d_array cmatrix,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);
<b>void</b> alglib::lsfitlinearc(
    real_1d_array y,
    real_2d_array fmatrix,
    real_2d_array cmatrix,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_linc' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitlinearw'></a><h3 class=pageheader><code>lsfitlinearw</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted linear least squares fitting.

QR decomposition is used to reduce task to MxM, then triangular solver  or
SVD-based solver is used depending on condition number of the  system.  It
allows to maximize speed and retain decent accuracy.

IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
           convenient to use PolynomialFit() function. This function gives
           best  results  on  polynomial  problems  and  solves  numerical
           stability  issues  which  arise  when   you   fit   high-degree
           polynomials to your data.

INPUT PARAMETERS:
    Y       -   array[0..N-1] Function values in  N  points.
    W       -   array[0..N-1]  Weights  corresponding to function  values.
                Each summand in square  sum  of  approximation  deviations
                from  given  values  is  multiplied  by  the   square   of
                corresponding weight.
    FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
                FMatrix[I, J] - value of J-th basis function in I-th point.
    N       -   number of points used. N&gt;=1.
    M       -   number of basis functions, M&gt;=1.

OUTPUT PARAMETERS:
    Info    -   error code:
                * -4    internal SVD decomposition subroutine failed (very
                        rare and for degenerate systems only)
                * -1    incorrect N/M were specified
                *  1    task is solved
    C       -   decomposition coefficients, array[0..M-1]
    Rep     -   fitting report. Following fields are set:
                * Rep.TaskRCond     reciprocal of condition number
                * R2                non-adjusted coefficient of determination
                                    (non-weighted)
                * RMSError          rms error on the (X,Y).
                * AvgError          average error on the (X,Y).
                * AvgRelError       average relative error on the non-zero Y
                * MaxError          maximum error
                                    NON-WEIGHTED ERRORS ARE CALCULATED

ERRORS IN PARAMETERS

This  solver  also  calculates different kinds of errors in parameters and
fills corresponding fields of report:
* Rep.CovPar        covariance matrix for parameters, array[K,K].
* Rep.ErrPar        errors in parameters, array[K],
                    errpar = sqrt(diag(CovPar))
* Rep.ErrCurve      vector of fit errors - standard deviations of empirical
                    best-fit curve from &quot;ideal&quot; best-fit curve built  with
                    infinite number of samples, array[N].
                    errcurve = sqrt(diag(F*CovPar*F')),
                    where F is functions matrix.
* Rep.Noise         vector of per-point estimates of noise, array[N]

NOTE:       noise in the data is estimated as follows:
            * for fitting without user-supplied  weights  all  points  are
              assumed to have same level of noise, which is estimated from
              the data
            * for fitting with user-supplied weights we assume that  noise
              level in I-th point is inversely proportional to Ith weight.
              Coefficient of proportionality is estimated from the data.

NOTE:       we apply small amount of regularization when we invert squared
            Jacobian and calculate covariance matrix. It  guarantees  that
            algorithm won't divide by zero  during  inversion,  but  skews
            error estimates a bit (fractional error is about 10^-9).

            However, we believe that this difference is insignificant  for
            all practical purposes except for the situation when you  want
            to compare ALGLIB results with &quot;reference&quot;  implementation  up
            to the last significant digit.

NOTE:       covariance matrix is estimated using  correction  for  degrees
            of freedom (covariances are divided by N-M instead of dividing
            by N).

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitlinearw(
    real_1d_array y,
    real_1d_array w,
    real_2d_array fmatrix,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);
<b>void</b> alglib::lsfitlinearw(
    real_1d_array y,
    real_1d_array w,
    real_2d_array fmatrix,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_lin' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitlinearwc'></a><h3 class=pageheader><code>lsfitlinearwc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted constained linear least squares fitting.

This  is  variation  of LSFitLinearW(), which searchs for min|A*x=b| given
that  K  additional  constaints  C*x=bc are satisfied. It reduces original
task to modified one: min|B*y-d| WITHOUT constraints,  then LSFitLinearW()
is called.

IMPORTANT: if you want to perform  polynomial  fitting,  it  may  be  more
           convenient to use PolynomialFit() function. This function gives
           best  results  on  polynomial  problems  and  solves  numerical
           stability  issues  which  arise  when   you   fit   high-degree
           polynomials to your data.

INPUT PARAMETERS:
    Y       -   array[0..N-1] Function values in  N  points.
    W       -   array[0..N-1]  Weights  corresponding to function  values.
                Each summand in square  sum  of  approximation  deviations
                from  given  values  is  multiplied  by  the   square   of
                corresponding weight.
    FMatrix -   a table of basis functions values, array[0..N-1, 0..M-1].
                FMatrix[I,J] - value of J-th basis function in I-th point.
    CMatrix -   a table of constaints, array[0..K-1,0..M].
                I-th row of CMatrix corresponds to I-th linear constraint:
                CMatrix[I,0]*C[0] + ... + CMatrix[I,M-1]*C[M-1] = CMatrix[I,M]
    N       -   number of points used. N&gt;=1.
    M       -   number of basis functions, M&gt;=1.
    K       -   number of constraints, 0 &lt;= K &lt; M
                K=0 corresponds to absence of constraints.

OUTPUT PARAMETERS:
    Info    -   error code:
                * -4    internal SVD decomposition subroutine failed (very
                        rare and for degenerate systems only)
                * -3    either   too   many  constraints  (M   or   more),
                        degenerate  constraints   (some   constraints  are
                        repetead twice) or inconsistent  constraints  were
                        specified.
                *  1    task is solved
    C       -   decomposition coefficients, array[0..M-1]
    Rep     -   fitting report. Following fields are set:
                * R2                non-adjusted coefficient of determination
                                    (non-weighted)
                * RMSError          rms error on the (X,Y).
                * AvgError          average error on the (X,Y).
                * AvgRelError       average relative error on the non-zero Y
                * MaxError          maximum error
                                    NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.

ERRORS IN PARAMETERS

This  solver  also  calculates different kinds of errors in parameters and
fills corresponding fields of report:
* Rep.CovPar        covariance matrix for parameters, array[K,K].
* Rep.ErrPar        errors in parameters, array[K],
                    errpar = sqrt(diag(CovPar))
* Rep.ErrCurve      vector of fit errors - standard deviations of empirical
                    best-fit curve from &quot;ideal&quot; best-fit curve built  with
                    infinite number of samples, array[N].
                    errcurve = sqrt(diag(F*CovPar*F')),
                    where F is functions matrix.
* Rep.Noise         vector of per-point estimates of noise, array[N]

IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
            account boundary/linear constraints! Presence  of  constraints
            changes distribution of errors, but there is no  easy  way  to
            account for constraints when you calculate covariance matrix.

NOTE:       noise in the data is estimated as follows:
            * for fitting without user-supplied  weights  all  points  are
              assumed to have same level of noise, which is estimated from
              the data
            * for fitting with user-supplied weights we assume that  noise
              level in I-th point is inversely proportional to Ith weight.
              Coefficient of proportionality is estimated from the data.

NOTE:       we apply small amount of regularization when we invert squared
            Jacobian and calculate covariance matrix. It  guarantees  that
            algorithm won't divide by zero  during  inversion,  but  skews
            error estimates a bit (fractional error is about 10^-9).

            However, we believe that this difference is insignificant  for
            all practical purposes except for the situation when you  want
            to compare ALGLIB results with &quot;reference&quot;  implementation  up
            to the last significant digit.

NOTE:       covariance matrix is estimated using  correction  for  degrees
            of freedom (covariances are divided by N-M instead of dividing
            by N).

  -- ALGLIB --
     Copyright 07.09.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitlinearwc(
    real_1d_array y,
    real_1d_array w,
    real_2d_array fmatrix,
    real_2d_array cmatrix,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);
<b>void</b> alglib::lsfitlinearwc(
    real_1d_array y,
    real_1d_array w,
    real_2d_array fmatrix,
    real_2d_array cmatrix,
    ae_int_t n,
    ae_int_t m,
    ae_int_t k,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_linc' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitresults'></a><h3 class=pageheader><code>lsfitresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Nonlinear least squares fitting results.

Called after return from LSFitFit().

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    Info    -   completion code:
                    * -7    gradient verification failed.
                            See LSFitSetGradientCheck() for more information.
                    *  1    relative function improvement is no more than
                            EpsF.
                    *  2    relative step is no more than EpsX.
                    *  4    gradient norm is no more than EpsG
                    *  5    MaxIts steps was taken
                    *  7    stopping conditions are too stringent,
                            further improvement is impossible
    C       -   array[0..K-1], solution
    Rep     -   optimization report. On success following fields are set:
                * R2                non-adjusted coefficient of determination
                                    (non-weighted)
                * RMSError          rms error on the (X,Y).
                * AvgError          average error on the (X,Y).
                * AvgRelError       average relative error on the non-zero Y
                * MaxError          maximum error
                                    NON-WEIGHTED ERRORS ARE CALCULATED
                * WRMSError         weighted rms error on the (X,Y).

ERRORS IN PARAMETERS

This  solver  also  calculates different kinds of errors in parameters and
fills corresponding fields of report:
* Rep.CovPar        covariance matrix for parameters, array[K,K].
* Rep.ErrPar        errors in parameters, array[K],
                    errpar = sqrt(diag(CovPar))
* Rep.ErrCurve      vector of fit errors - standard deviations of empirical
                    best-fit curve from &quot;ideal&quot; best-fit curve built  with
                    infinite number of samples, array[N].
                    errcurve = sqrt(diag(J*CovPar*J')),
                    where J is Jacobian matrix.
* Rep.Noise         vector of per-point estimates of noise, array[N]

IMPORTANT:  errors  in  parameters  are  calculated  without  taking  into
            account boundary/linear constraints! Presence  of  constraints
            changes distribution of errors, but there is no  easy  way  to
            account for constraints when you calculate covariance matrix.

NOTE:       noise in the data is estimated as follows:
            * for fitting without user-supplied  weights  all  points  are
              assumed to have same level of noise, which is estimated from
              the data
            * for fitting with user-supplied weights we assume that  noise
              level in I-th point is inversely proportional to Ith weight.
              Coefficient of proportionality is estimated from the data.

NOTE:       we apply small amount of regularization when we invert squared
            Jacobian and calculate covariance matrix. It  guarantees  that
            algorithm won't divide by zero  during  inversion,  but  skews
            error estimates a bit (fractional error is about 10^-9).

            However, we believe that this difference is insignificant  for
            all practical purposes except for the situation when you  want
            to compare ALGLIB results with &quot;reference&quot;  implementation  up
            to the last significant digit.

NOTE:       covariance matrix is estimated using  correction  for  degrees
            of freedom (covariances are divided by N-M instead of dividing
            by N).

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitresults(
    lsfitstate state,
    ae_int_t&amp; info,
    real_1d_array&amp; c,
    lsfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlf' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfg' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlscale' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitsetbc'></a><h3 class=pageheader><code>lsfitsetbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets boundary constraints for underlying optimizer

Boundary constraints are inactive by default (after initial creation).
They are preserved until explicitly turned off with another SetBC() call.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    BndL    -   lower bounds, array[K].
                If some (all) variables are unbounded, you may specify
                very small number or -INF (latter is recommended because
                it will allow solver to use better algorithm).
    BndU    -   upper bounds, array[K].
                If some (all) variables are unbounded, you may specify
                very large number or +INF (latter is recommended because
                it will allow solver to use better algorithm).

NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].

NOTE 2: unlike other constrained optimization algorithms, this solver  has
following useful properties:
* bound constraints are always satisfied exactly
* function is evaluated only INSIDE area specified by bound constraints

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetbc(
    lsfitstate state,
    real_1d_array bndl,
    real_1d_array bndu);

</div></pre>
<a name='sub_lsfitsetcond'></a><h3 class=pageheader><code>lsfitsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Stopping conditions for nonlinear least squares fitting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsF    -   stopping criterion. Algorithm stops if
                |F(k+1)-F(k)| &lt;= EpsF*max{|F(k)|, |F(k+1)|, 1}
    EpsX    -   &gt;=0
                The subroutine finishes its work if  on  k+1-th  iteration
                the condition |v|&lt;=EpsX is fulfilled, where:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - ste pvector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by LSFitSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations   is    unlimited.   Only   Levenberg-Marquardt
                iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
                counted because their cost is very low compared to that of
                LM).

NOTE

Passing EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to automatic
stopping criterion selection (according to the scheme used by MINLM unit).


  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetcond(
    lsfitstate state,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlf' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfg' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlfb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_lsfit_d_nlscale' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitsetgradientcheck'></a><h3 class=pageheader><code>lsfitsetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  turns  on  verification  of  the  user-supplied analytic
gradient:
* user calls this subroutine before fitting begins
* LSFitFit() is called
* prior to actual fitting, for  each  point  in  data  set  X_i  and  each
  component  of  parameters  being  fited C_j algorithm performs following
  steps:
  * two trial steps are made to C_j-TestStep*S[j] and C_j+TestStep*S[j],
    where C_j is j-th parameter and S[j] is a scale of j-th parameter
  * if needed, steps are bounded with respect to constraints on C[]
  * F(X_i|C) is evaluated at these trial points
  * we perform one more evaluation in the middle point of the interval
  * we  build  cubic  model using function values and derivatives at trial
    points and we compare its prediction with actual value in  the  middle
    point
  * in case difference between prediction and actual value is higher  than
    some predetermined threshold, algorithm stops with completion code -7;
    Rep.VarIdx is set to index of the parameter with incorrect derivative.
* after verification is over, algorithm proceeds to the actual optimization.

NOTE 1: verification needs N*K (points count * parameters count)  gradient
        evaluations. It is very costly and you should use it only for  low
        dimensional  problems,  when  you  want  to  be  sure  that you've
        correctly calculated analytic derivatives. You should not  use  it
        in the production code  (unless  you  want  to  check  derivatives
        provided by some third party).

NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
        (so large that function behaviour is significantly non-cubic) will
        lead to false alarms. You may use  different  step  for  different
        parameters by means of setting scale with LSFitSetScale().

NOTE 3: this function may lead to false positives. In case it reports that
        I-th  derivative was calculated incorrectly, you may decrease test
        step  and  try  one  more  time  - maybe your function changes too
        sharply  and  your  step  is  too  large for such rapidly chanding
        function.

NOTE 4: this function works only for optimizers created with LSFitCreateWFG()
        or LSFitCreateFG() constructors.

INPUT PARAMETERS:
    State       -   structure used to store algorithm state
    TestStep    -   verification step:
                    * TestStep=0 turns verification off
                    * TestStep&gt;0 activates verification

  -- ALGLIB --
     Copyright 15.06.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetgradientcheck(lsfitstate state, <b>double</b> teststep);

</div></pre>
<a name='sub_lsfitsetscale'></a><h3 class=pageheader><code>lsfitsetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients for underlying optimizer.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

Generally, scale is NOT considered to be a form of preconditioner.  But LM
optimizer is unique in that it uses scaling matrix both  in  the  stopping
condition tests and as Marquardt damping factor.

Proper scaling is very important for the algorithm performance. It is less
important for the quality of results, but still has some influence (it  is
easier  to  converge  when  variables  are  properly  scaled, so premature
stopping is possible when very badly scalled variables are  combined  with
relaxed stopping conditions).

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetscale(lsfitstate state, real_1d_array s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_nlscale' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_lsfitsetstpmax'></a><h3 class=pageheader><code>lsfitsetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
                want to limit step length.

Use this subroutine when you optimize target function which contains exp()
or  other  fast  growing  functions,  and optimization algorithm makes too
large  steps  which  leads  to overflow. This function allows us to reject
steps  that  are  too  large  (and  therefore  expose  us  to the possible
overflow) without actually calculating function value at the x+stp*d.

NOTE: non-zero StpMax leads to moderate  performance  degradation  because
intermediate  step  of  preconditioned L-BFGS optimization is incompatible
with limits on step size.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetstpmax(lsfitstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_lsfitsetxrep'></a><h3 class=pageheader><code>lsfitsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

When reports are needed, State.C (current parameters) and State.F (current
value of fitting function) are reported.


  -- ALGLIB --
     Copyright 15.08.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::lsfitsetxrep(lsfitstate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_polynomialfit'></a><h3 class=pageheader><code>polynomialfit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Fitting by polynomials in barycentric form. This function provides  simple
unterface for unconstrained unweighted fitting. See  PolynomialFitWC()  if
you need constrained fitting.

Task is linear, so linear least squares solver is used. Complexity of this
computational scheme is O(N*M^2), mostly dominated by least squares solver

SEE ALSO:
    PolynomialFitWC()

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    N   -   number of points, N&gt;0
            * if given, only leading N elements of X/Y are used
            * if not given, automatically determined from sizes of X/Y
    M   -   number of basis functions (= polynomial_degree + 1), M&gt;=1

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearW() subroutine:
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
    P   -   interpolant in barycentric form.
    Rep -   report, same format as in LSFitLinearW() subroutine.
            Following fields are set:
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

NOTES:
    you can convert P from barycentric form  to  the  power  or  Chebyshev
    basis with PolynomialBar2Pow() or PolynomialBar2Cheb() functions  from
    POLINT subpackage.

  -- ALGLIB PROJECT --
     Copyright 10.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialfit(
    real_1d_array x,
    real_1d_array y,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; p,
    polynomialfitreport&amp; rep);
<b>void</b> alglib::polynomialfit(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; p,
    polynomialfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_pol' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialfitwc'></a><h3 class=pageheader><code>polynomialfitwc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted  fitting by polynomials in barycentric form, with constraints  on
function values or first derivatives.

Small regularizing term is used when solving constrained tasks (to improve
stability).

Task is linear, so linear least squares solver is used. Complexity of this
computational scheme is O(N*M^2), mostly dominated by least squares solver

SEE ALSO:
    PolynomialFit()

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    W   -   weights, array[0..N-1]
            Each summand in square  sum  of  approximation deviations from
            given  values  is  multiplied  by  the square of corresponding
            weight. Fill it by 1's if you don't  want  to  solve  weighted
            task.
    N   -   number of points, N&gt;0.
            * if given, only leading N elements of X/Y/W are used
            * if not given, automatically determined from sizes of X/Y/W
    XC  -   points where polynomial values/derivatives are constrained,
            array[0..K-1].
    YC  -   values of constraints, array[0..K-1]
    DC  -   array[0..K-1], types of constraints:
            * DC[i]=0   means that P(XC[i])=YC[i]
            * DC[i]=1   means that P'(XC[i])=YC[i]
            SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
    K   -   number of constraints, 0&lt;=K&lt;M.
            K=0 means no constraints (XC/YC/DC are not used in such cases)
    M   -   number of basis functions (= polynomial_degree + 1), M&gt;=1

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearW() subroutine:
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
    P   -   interpolant in barycentric form.
    Rep -   report, same format as in LSFitLinearW() subroutine.
            Following fields are set:
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.

NOTES:
    you can convert P from barycentric form  to  the  power  or  Chebyshev
    basis with PolynomialBar2Pow() or PolynomialBar2Cheb() functions  from
    POLINT subpackage.

SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:

Setting constraints can lead  to undesired  results,  like ill-conditioned
behavior, or inconsistency being detected. From the other side,  it allows
us to improve quality of the fit. Here we summarize  our  experience  with
constrained regression splines:
* even simple constraints can be inconsistent, see  Wikipedia  article  on
  this subject: http://en.wikipedia.org/wiki/Birkhoff_interpolation
* the  greater  is  M (given  fixed  constraints),  the  more chances that
  constraints will be consistent
* in the general case, consistency of constraints is NOT GUARANTEED.
* in the one special cases, however, we can  guarantee  consistency.  This
  case  is:  M&gt;1  and constraints on the function values (NOT DERIVATIVES)

Our final recommendation is to use constraints  WHEN  AND  ONLY  when  you
can't solve your task without them. Anything beyond  special  cases  given
above is not guaranteed and may result in inconsistency.

  -- ALGLIB PROJECT --
     Copyright 10.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialfitwc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; p,
    polynomialfitreport&amp; rep);
<b>void</b> alglib::polynomialfitwc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t k,
    ae_int_t m,
    ae_int_t&amp; info,
    barycentricinterpolant&amp; p,
    polynomialfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_polc' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dfitcubic'></a><h3 class=pageheader><code>spline1dfitcubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Least squares fitting by cubic spline.

This subroutine is &quot;lightweight&quot; alternative for more complex and feature-
rich Spline1DFitCubicWC().  See  Spline1DFitCubicWC() for more information
about subroutine parameters (we don't duplicate it here because of length)

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfitcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfitcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<a name='sub_spline1dfitcubicwc'></a><h3 class=pageheader><code>spline1dfitcubicwc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted fitting by cubic  spline,  with constraints on function values or
derivatives.

Equidistant grid with M-2 nodes on [min(x,xc),max(x,xc)] is  used to build
basis functions. Basis functions are cubic splines with continuous  second
derivatives  and  non-fixed first  derivatives  at  interval  ends.  Small
regularizing term is used  when  solving  constrained  tasks  (to  improve
stability).

Task is linear, so linear least squares solver is used. Complexity of this
computational scheme is O(N*M^2), mostly dominated by least squares solver

SEE ALSO
    Spline1DFitHermiteWC()  -   fitting by Hermite splines (more flexible,
                                less smooth)
    Spline1DFitCubic()      -   &quot;lightweight&quot; fitting  by  cubic  splines,
                                without invididual weights and constraints

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    W   -   weights, array[0..N-1]
            Each summand in square  sum  of  approximation deviations from
            given  values  is  multiplied  by  the square of corresponding
            weight. Fill it by 1's if you don't  want  to  solve  weighted
            task.
    N   -   number of points (optional):
            * N&gt;0
            * if given, only first N elements of X/Y/W are processed
            * if not given, automatically determined from X/Y/W sizes
    XC  -   points where spline values/derivatives are constrained,
            array[0..K-1].
    YC  -   values of constraints, array[0..K-1]
    DC  -   array[0..K-1], types of constraints:
            * DC[i]=0   means that S(XC[i])=YC[i]
            * DC[i]=1   means that S'(XC[i])=YC[i]
            SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
    K   -   number of constraints (optional):
            * 0&lt;=K&lt;M.
            * K=0 means no constraints (XC/YC/DC are not used)
            * if given, only first K elements of XC/YC/DC are used
            * if not given, automatically determined from XC/YC/DC
    M   -   number of basis functions ( = number_of_nodes+2), M&gt;=4.

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearWC() subroutine.
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
    S   -   spline interpolant.
    Rep -   report, same format as in LSFitLinearWC() subroutine.
            Following fields are set:
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:

Setting constraints can lead  to undesired  results,  like ill-conditioned
behavior, or inconsistency being detected. From the other side,  it allows
us to improve quality of the fit. Here we summarize  our  experience  with
constrained regression splines:
* excessive constraints can be inconsistent. Splines are  piecewise  cubic
  functions, and it is easy to create an example, where  large  number  of
  constraints  concentrated  in  small  area will result in inconsistency.
  Just because spline is not flexible enough to satisfy all of  them.  And
  same constraints spread across the  [min(x),max(x)]  will  be  perfectly
  consistent.
* the more evenly constraints are spread across [min(x),max(x)],  the more
  chances that they will be consistent
* the  greater  is  M (given  fixed  constraints),  the  more chances that
  constraints will be consistent
* in the general case, consistency of constraints IS NOT GUARANTEED.
* in the several special cases, however, we CAN guarantee consistency.
* one of this cases is constraints  on  the  function  values  AND/OR  its
  derivatives at the interval boundaries.
* another  special  case  is ONE constraint on the function value (OR, but
  not AND, derivative) anywhere in the interval

Our final recommendation is to use constraints  WHEN  AND  ONLY  WHEN  you
can't solve your task without them. Anything beyond  special  cases  given
above is not guaranteed and may result in inconsistency.


  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfitcubicwc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfitcubicwc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t k,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<a name='sub_spline1dfithermite'></a><h3 class=pageheader><code>spline1dfithermite</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Least squares fitting by Hermite spline.

This subroutine is &quot;lightweight&quot; alternative for more complex and feature-
rich Spline1DFitHermiteWC().  See Spline1DFitHermiteWC()  description  for
more information about subroutine parameters (we don't duplicate  it  here
because of length).

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfithermite(
    real_1d_array x,
    real_1d_array y,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfithermite(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<a name='sub_spline1dfithermitewc'></a><h3 class=pageheader><code>spline1dfithermitewc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted  fitting  by Hermite spline,  with constraints on function values
or first derivatives.

Equidistant grid with M nodes on [min(x,xc),max(x,xc)] is  used  to  build
basis functions. Basis functions are Hermite splines.  Small  regularizing
term is used when solving constrained tasks (to improve stability).

Task is linear, so linear least squares solver is used. Complexity of this
computational scheme is O(N*M^2), mostly dominated by least squares solver

SEE ALSO
    Spline1DFitCubicWC()    -   fitting by Cubic splines (less flexible,
                                more smooth)
    Spline1DFitHermite()    -   &quot;lightweight&quot; Hermite fitting, without
                                invididual weights and constraints

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    W   -   weights, array[0..N-1]
            Each summand in square  sum  of  approximation deviations from
            given  values  is  multiplied  by  the square of corresponding
            weight. Fill it by 1's if you don't  want  to  solve  weighted
            task.
    N   -   number of points (optional):
            * N&gt;0
            * if given, only first N elements of X/Y/W are processed
            * if not given, automatically determined from X/Y/W sizes
    XC  -   points where spline values/derivatives are constrained,
            array[0..K-1].
    YC  -   values of constraints, array[0..K-1]
    DC  -   array[0..K-1], types of constraints:
            * DC[i]=0   means that S(XC[i])=YC[i]
            * DC[i]=1   means that S'(XC[i])=YC[i]
            SEE BELOW FOR IMPORTANT INFORMATION ON CONSTRAINTS
    K   -   number of constraints (optional):
            * 0&lt;=K&lt;M.
            * K=0 means no constraints (XC/YC/DC are not used)
            * if given, only first K elements of XC/YC/DC are used
            * if not given, automatically determined from XC/YC/DC
    M   -   number of basis functions (= 2 * number of nodes),
            M&gt;=4,
            M IS EVEN!

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearW() subroutine:
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
                        -2 means odd M was passed (which is not supported)
                        -1 means another errors in parameters passed
                           (N&lt;=0, for example)
    S   -   spline interpolant.
    Rep -   report, same format as in LSFitLinearW() subroutine.
            Following fields are set:
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.

IMPORTANT:
    this subroitine supports only even M's


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

SETTING CONSTRAINTS - DANGERS AND OPPORTUNITIES:

Setting constraints can lead  to undesired  results,  like ill-conditioned
behavior, or inconsistency being detected. From the other side,  it allows
us to improve quality of the fit. Here we summarize  our  experience  with
constrained regression splines:
* excessive constraints can be inconsistent. Splines are  piecewise  cubic
  functions, and it is easy to create an example, where  large  number  of
  constraints  concentrated  in  small  area will result in inconsistency.
  Just because spline is not flexible enough to satisfy all of  them.  And
  same constraints spread across the  [min(x),max(x)]  will  be  perfectly
  consistent.
* the more evenly constraints are spread across [min(x),max(x)],  the more
  chances that they will be consistent
* the  greater  is  M (given  fixed  constraints),  the  more chances that
  constraints will be consistent
* in the general case, consistency of constraints is NOT GUARANTEED.
* in the several special cases, however, we can guarantee consistency.
* one of this cases is  M&gt;=4  and   constraints  on   the  function  value
  (AND/OR its derivative) at the interval boundaries.
* another special case is M&gt;=4  and  ONE  constraint on the function value
  (OR, BUT NOT AND, derivative) anywhere in [min(x),max(x)]

Our final recommendation is to use constraints  WHEN  AND  ONLY  when  you
can't solve your task without them. Anything beyond  special  cases  given
above is not guaranteed and may result in inconsistency.

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfithermitewc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfithermitewc(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    real_1d_array xc,
    real_1d_array yc,
    integer_1d_array dc,
    ae_int_t k,
    ae_int_t m,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<a name='sub_spline1dfitpenalized'></a><h3 class=pageheader><code>spline1dfitpenalized</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rational least squares fitting using  Floater-Hormann  rational  functions
with optimal D chosen from [0,9].

Equidistant  grid  with M node on [min(x),max(x)]  is  used to build basis
functions. Different values of D are tried, optimal  D  (least  root  mean
square error) is chosen.  Task  is  linear, so linear least squares solver
is used. Complexity  of  this  computational  scheme is  O(N*M^2)  (mostly
dominated by the least squares solver).

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    N   -   number of points, N&gt;0.
    M   -   number of basis functions ( = number_of_nodes), M&gt;=2.

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearWC() subroutine.
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD
                        -3 means inconsistent constraints
    B   -   barycentric interpolant.
    Rep -   report, same format as in LSFitLinearWC() subroutine.
            Following fields are set:
            * DBest         best value of the D parameter
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

  -- ALGLIB PROJECT --
     Copyright 18.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfitpenalized(
    real_1d_array x,
    real_1d_array y,
    ae_int_t m,
    <b>double</b> rho,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfitpenalized(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t m,
    <b>double</b> rho,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_spline' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dfitpenalizedw'></a><h3 class=pageheader><code>spline1dfitpenalizedw</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Weighted fitting by penalized cubic spline.

Equidistant grid with M nodes on [min(x,xc),max(x,xc)] is  used  to  build
basis functions. Basis functions are cubic splines with  natural  boundary
conditions. Problem is regularized by  adding non-linearity penalty to the
usual least squares penalty function:

    S(x) = arg min { LS + P }, where
    LS   = SUM { w[i]^2*(y[i] - S(x[i]))^2 } - least squares penalty
    P    = C*10^rho*integral{ S''(x)^2*dx } - non-linearity penalty
    rho  - tunable constant given by user
    C    - automatically determined scale parameter,
           makes penalty invariant with respect to scaling of X, Y, W.

INPUT PARAMETERS:
    X   -   points, array[0..N-1].
    Y   -   function values, array[0..N-1].
    W   -   weights, array[0..N-1]
            Each summand in square  sum  of  approximation deviations from
            given  values  is  multiplied  by  the square of corresponding
            weight. Fill it by 1's if you don't  want  to  solve  weighted
            problem.
    N   -   number of points (optional):
            * N&gt;0
            * if given, only first N elements of X/Y/W are processed
            * if not given, automatically determined from X/Y/W sizes
    M   -   number of basis functions ( = number_of_nodes), M&gt;=4.
    Rho -   regularization  constant  passed   by   user.   It   penalizes
            nonlinearity in the regression spline. It  is  logarithmically
            scaled,  i.e.  actual  value  of  regularization  constant  is
            calculated as 10^Rho. It is automatically scaled so that:
            * Rho=2.0 corresponds to moderate amount of nonlinearity
            * generally, it should be somewhere in the [-8.0,+8.0]
            If you do not want to penalize nonlineary,
            pass small Rho. Values as low as -15 should work.

OUTPUT PARAMETERS:
    Info-   same format as in LSFitLinearWC() subroutine.
            * Info&gt;0    task is solved
            * Info&lt;=0   an error occured:
                        -4 means inconvergence of internal SVD or
                           Cholesky decomposition; problem may be
                           too ill-conditioned (very rare)
    S   -   spline interpolant.
    Rep -   Following fields are set:
            * RMSError      rms error on the (X,Y).
            * AvgError      average error on the (X,Y).
            * AvgRelError   average relative error on the non-zero Y
            * MaxError      maximum error
                            NON-WEIGHTED ERRORS ARE CALCULATED

IMPORTANT:
    this subroitine doesn't calculate task's condition number for K&lt;&gt;0.

NOTE 1: additional nodes are added to the spline outside  of  the  fitting
interval to force linearity when x&lt;min(x,xc) or x&gt;max(x,xc).  It  is  done
for consistency - we penalize non-linearity  at [min(x,xc),max(x,xc)],  so
it is natural to force linearity outside of this interval.

NOTE 2: function automatically sorts points,  so  caller may pass unsorted
array.

  -- ALGLIB PROJECT --
     Copyright 19.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dfitpenalizedw(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t m,
    <b>double</b> rho,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);
<b>void</b> alglib::spline1dfitpenalizedw(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    ae_int_t m,
    <b>double</b> rho,
    ae_int_t&amp; info,
    spline1dinterpolant&amp; s,
    spline1dfitreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_lsfit_d_spline' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_lsfit_d_lin'></a><h3 class=pageheader>lsfit_d_lin example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate linear fitting by f(x|a) = a*exp(0.5*x).</font>
    <font color=navy>//</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * y - vector of experimental data</font>
    <font color=navy>// * fmatrix -  matrix of basis functions calculated at sample points</font>
    <font color=navy>//              Actually, we have only one basis function F0 = exp(0.5*x).</font>
    <font color=navy>//</font>
    real_2d_array fmatrix = <font color=blue><b>&quot;[[0.606531],[0.670320],[0.740818],[0.818731],[0.904837],[1.000000],[1.105171],[1.221403],[1.349859],[1.491825],[1.648721]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[1.133719, 1.306522, 1.504604, 1.554663, 1.884638, 2.072436, 2.257285, 2.534068, 2.622017, 2.897713, 3.219371]&quot;</b></font>;
    ae_int_t info;
    real_1d_array c;
    lsfitreport rep;

    <font color=navy>//</font>
    <font color=navy>// Linear fitting without weights</font>
    <font color=navy>//</font>
    lsfitlinear(y, fmatrix, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(4).c_str()); <font color=navy>// EXPECTED: [1.98650]</font>

    <font color=navy>//</font>
    <font color=navy>// Linear fitting with individual weights.</font>
    <font color=navy>// Slightly different result is returned.</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1.414213, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]&quot;</b></font>;
    lsfitlinearw(y, w, fmatrix, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(4).c_str()); <font color=navy>// EXPECTED: [1.983354]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_linc'></a><h3 class=pageheader>lsfit_d_linc example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate linear fitting by f(x|a,b) = a*x+b</font>
    <font color=navy>// with simple constraint f(0)=0.</font>
    <font color=navy>//</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * y - vector of experimental data</font>
    <font color=navy>// * fmatrix -  matrix of basis functions sampled at [0,1] with step 0.2:</font>
    <font color=navy>//                  [ 1.0   0.0 ]</font>
    <font color=navy>//                  [ 1.0   0.2 ]</font>
    <font color=navy>//                  [ 1.0   0.4 ]</font>
    <font color=navy>//                  [ 1.0   0.6 ]</font>
    <font color=navy>//                  [ 1.0   0.8 ]</font>
    <font color=navy>//                  [ 1.0   1.0 ]</font>
    <font color=navy>//              first column contains value of first basis function (constant term)</font>
    <font color=navy>//              second column contains second basis function (linear term)</font>
    <font color=navy>// * cmatrix -  matrix of linear constraints:</font>
    <font color=navy>//                  [ 1.0  0.0  0.0 ]</font>
    <font color=navy>//              first two columns contain coefficients before basis functions,</font>
    <font color=navy>//              last column contains desired value of their sum.</font>
    <font color=navy>//              So [1,0,0] means <font color=blue><b>&quot;1*constant_term + 0*linear_term = 0&quot;</b></font> </font>
    <font color=navy>//</font>
    real_1d_array y = <font color=blue><b>&quot;[0.072436,0.246944,0.491263,0.522300,0.714064,0.921929]&quot;</b></font>;
    real_2d_array fmatrix = <font color=blue><b>&quot;[[1,0.0],[1,0.2],[1,0.4],[1,0.6],[1,0.8],[1,1.0]]&quot;</b></font>;
    real_2d_array cmatrix = <font color=blue><b>&quot;[[1,0,0]]&quot;</b></font>;
    ae_int_t info;
    real_1d_array c;
    lsfitreport rep;

    <font color=navy>//</font>
    <font color=navy>// Constrained fitting without weights</font>
    <font color=navy>//</font>
    lsfitlinearc(y, fmatrix, cmatrix, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [0,0.932933]</font>

    <font color=navy>//</font>
    <font color=navy>// Constrained fitting with individual weights</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1, 1.414213, 1, 1, 1, 1]&quot;</b></font>;
    lsfitlinearwc(y, w, fmatrix, cmatrix, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(3).c_str()); <font color=navy>// EXPECTED: [0,0.938322]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_nlf'></a><h3 class=pageheader>lsfit_d_nlf example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;
<b>void</b> function_cx_1_func(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0))</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter</font>
    func = exp(-c[0]*pow(x[0],2));
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate exponential fitting</font>
    <font color=navy>// by f(x) = exp(-c*x^2)</font>
    <font color=navy>// using function value only.</font>
    <font color=navy>//</font>
    <font color=navy>// Gradient is estimated using combination of numerical differences</font>
    <font color=navy>// and secant updates. diffstep variable stores differentiation step </font>
    <font color=navy>// (we have to tell algorithm what step to use).</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[-1],[-0.8],[-0.6],[-0.4],[-0.2],[0],[0.2],[0.4],[0.6],[0.8],[1.0]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.223130, 0.382893, 0.582748, 0.786628, 0.941765, 1.000000, 0.941765, 0.786628, 0.582748, 0.382893, 0.223130]&quot;</b></font>;
    real_1d_array c = <font color=blue><b>&quot;[0.3]&quot;</b></font>;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0.000001;
    ae_int_t maxits = 0;
    ae_int_t info;
    lsfitstate state;
    lsfitreport rep;
    <b>double</b> diffstep = 0.0001;

    <font color=navy>//</font>
    <font color=navy>// Fitting without weights</font>
    <font color=navy>//</font>
    lsfitcreatef(x, y, c, diffstep, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>

    <font color=navy>//</font>
    <font color=navy>// Fitting with weights</font>
    <font color=navy>// (you can change weights and see how it changes result)</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1,1,1,1,1,1,1,1,1,1,1]&quot;</b></font>;
    lsfitcreatewf(x, y, w, c, diffstep, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_nlfb'></a><h3 class=pageheader>lsfit_d_nlfb example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;
<b>void</b> function_cx_1_func(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0))</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter</font>
    func = exp(-c[0]*pow(x[0],2));
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate exponential fitting by</font>
    <font color=navy>//     f(x) = exp(-c*x^2)</font>
    <font color=navy>// subject to bound constraints</font>
    <font color=navy>//     0.0 &lt;= c &lt;= 1.0</font>
    <font color=navy>// using function value only.</font>
    <font color=navy>//</font>
    <font color=navy>// Gradient is estimated using combination of numerical differences</font>
    <font color=navy>// and secant updates. diffstep variable stores differentiation step </font>
    <font color=navy>// (we have to tell algorithm what step to use).</font>
    <font color=navy>//</font>
    <font color=navy>// Unconstrained solution is c=1.5, but because of constraints we should</font>
    <font color=navy>// get c=1.0 (at the boundary).</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[-1],[-0.8],[-0.6],[-0.4],[-0.2],[0],[0.2],[0.4],[0.6],[0.8],[1.0]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.223130, 0.382893, 0.582748, 0.786628, 0.941765, 1.000000, 0.941765, 0.786628, 0.582748, 0.382893, 0.223130]&quot;</b></font>;
    real_1d_array c = <font color=blue><b>&quot;[0.3]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[0.0]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[1.0]&quot;</b></font>;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0.000001;
    ae_int_t maxits = 0;
    ae_int_t info;
    lsfitstate state;
    lsfitreport rep;
    <b>double</b> diffstep = 0.0001;

    lsfitcreatef(x, y, c, diffstep, state);
    lsfitsetbc(state, bndl, bndu);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.0]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_nlfg'></a><h3 class=pageheader>lsfit_d_nlfg example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;
<b>void</b> function_cx_1_func(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0))</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter</font>
    func = exp(-c[0]*pow(x[0],2));
}
<b>void</b> function_cx_1_grad(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0)) and gradient G={df/dc[i]}</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter.</font>
    <font color=navy>// IMPORTANT: gradient is calculated with respect to C, not to X</font>
    func = exp(-c[0]*pow(x[0],2));
    grad[0] = -pow(x[0],2)*func;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate exponential fitting</font>
    <font color=navy>// by f(x) = exp(-c*x^2)</font>
    <font color=navy>// using function value and gradient (with respect to c).</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[-1],[-0.8],[-0.6],[-0.4],[-0.2],[0],[0.2],[0.4],[0.6],[0.8],[1.0]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.223130, 0.382893, 0.582748, 0.786628, 0.941765, 1.000000, 0.941765, 0.786628, 0.582748, 0.382893, 0.223130]&quot;</b></font>;
    real_1d_array c = <font color=blue><b>&quot;[0.3]&quot;</b></font>;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0.000001;
    ae_int_t maxits = 0;
    ae_int_t info;
    lsfitstate state;
    lsfitreport rep;

    <font color=navy>//</font>
    <font color=navy>// Fitting without weights</font>
    <font color=navy>//</font>
    lsfitcreatefg(x, y, c, true, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func, function_cx_1_grad);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>

    <font color=navy>//</font>
    <font color=navy>// Fitting with weights</font>
    <font color=navy>// (you can change weights and see how it changes result)</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1,1,1,1,1,1,1,1,1,1,1]&quot;</b></font>;
    lsfitcreatewfg(x, y, w, c, true, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func, function_cx_1_grad);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_nlfgh'></a><h3 class=pageheader>lsfit_d_nlfgh example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;
<b>void</b> function_cx_1_func(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0))</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter</font>
    func = exp(-c[0]*pow(x[0],2));
}
<b>void</b> function_cx_1_grad(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0)) and gradient G={df/dc[i]}</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter.</font>
    <font color=navy>// IMPORTANT: gradient is calculated with respect to C, not to X</font>
    func = exp(-c[0]*pow(x[0],2));
    grad[0] = -pow(x[0],2)*func;
}
<b>void</b> function_cx_1_hess(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, real_2d_array &amp;hess, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(c,x)=exp(-c0*sqr(x0)), gradient G={df/dc[i]} and Hessian H={d2f/(dc[i]*dc[j])}</font>
    <font color=navy>// where x is a position on X-axis and c is adjustable parameter.</font>
    <font color=navy>// IMPORTANT: gradient/Hessian are calculated with respect to C, not to X</font>
    func = exp(-c[0]*pow(x[0],2));
    grad[0] = -pow(x[0],2)*func;
    hess[0][0] = pow(x[0],4)*func;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate exponential fitting</font>
    <font color=navy>// by f(x) = exp(-c*x^2)</font>
    <font color=navy>// using function value, gradient and Hessian (with respect to c)</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[-1],[-0.8],[-0.6],[-0.4],[-0.2],[0],[0.2],[0.4],[0.6],[0.8],[1.0]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.223130, 0.382893, 0.582748, 0.786628, 0.941765, 1.000000, 0.941765, 0.786628, 0.582748, 0.382893, 0.223130]&quot;</b></font>;
    real_1d_array c = <font color=blue><b>&quot;[0.3]&quot;</b></font>;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0.000001;
    ae_int_t maxits = 0;
    ae_int_t info;
    lsfitstate state;
    lsfitreport rep;

    <font color=navy>//</font>
    <font color=navy>// Fitting without weights</font>
    <font color=navy>//</font>
    lsfitcreatefgh(x, y, c, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func, function_cx_1_grad, function_cx_1_hess);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>

    <font color=navy>//</font>
    <font color=navy>// Fitting with weights</font>
    <font color=navy>// (you can change weights and see how it changes result)</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1,1,1,1,1,1,1,1,1,1,1]&quot;</b></font>;
    lsfitcreatewfgh(x, y, w, c, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    alglib::lsfitfit(state, function_cx_1_func, function_cx_1_grad, function_cx_1_hess);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.5]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_nlscale'></a><h3 class=pageheader>lsfit_d_nlscale example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;
<b>void</b> function_debt_func(<b>const</b> real_1d_array &amp;c, <b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(c,x)=c[0]*(1+c[1]*(pow(x[0]-1999,c[2])-1))</font>
    <font color=navy>//</font>
    func = c[0]*(1+c[1]*(pow(x[0]-1999,c[2])-1));
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate fitting by</font>
    <font color=navy>//     f(x) = c[0]*(1+c[1]*((x-1999)^c[2]-1))</font>
    <font color=navy>// subject to bound constraints</font>
    <font color=navy>//     -INF  &lt; c[0] &lt; +INF</font>
    <font color=navy>//      -10 &lt;= c[1] &lt;= +10</font>
    <font color=navy>//      0.1 &lt;= c[2] &lt;= 2.0</font>
    <font color=navy>// Data we want to fit are time series of Japan national debt</font>
    <font color=navy>// collected from 2000 to 2008 measured in USD (dollars, not</font>
    <font color=navy>// millions of dollars).</font>
    <font color=navy>//</font>
    <font color=navy>// Our variables are:</font>
    <font color=navy>//     c[0] - debt value at initial moment (2000),</font>
    <font color=navy>//     c[1] - direction coefficient (growth or decrease),</font>
    <font color=navy>//     c[2] - curvature coefficient.</font>
    <font color=navy>// You may see that our variables are badly scaled - first one </font>
    <font color=navy>// is order of 10^12, and next two are somewhere about 1 in </font>
    <font color=navy>// magnitude. Such problem is difficult to solve without some</font>
    <font color=navy>// kind of scaling.</font>
    <font color=navy>// That is exactly where lsfitsetscale() function can be used.</font>
    <font color=navy>// We set scale of our variables to [1.0E12, 1, 1], which allows</font>
    <font color=navy>// us to easily solve this problem.</font>
    <font color=navy>//</font>
    <font color=navy>// You can try commenting out lsfitsetscale() call - and you will </font>
    <font color=navy>// see that algorithm will fail to converge.</font>
    <font color=navy>//</font>
    real_2d_array x = <font color=blue><b>&quot;[[2000],[2001],[2002],[2003],[2004],[2005],[2006],[2007],[2008]]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[4323239600000.0, 4560913100000.0, 5564091500000.0, 6743189300000.0, 7284064600000.0, 7050129600000.0, 7092221500000.0, 8483907600000.0, 8625804400000.0]&quot;</b></font>;
    real_1d_array c = <font color=blue><b>&quot;[1.0e+13, 1, 1]&quot;</b></font>;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 1.0e-5;
    real_1d_array bndl = <font color=blue><b>&quot;[-inf, -10, 0.1]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[+inf, +10, 2.0]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1.0e+12, 1, 1]&quot;</b></font>;
    ae_int_t maxits = 0;
    ae_int_t info;
    lsfitstate state;
    lsfitreport rep;
    <b>double</b> diffstep = 1.0e-5;

    lsfitcreatef(x, y, c, diffstep, state);
    lsfitsetcond(state, epsf, epsx, maxits);
    lsfitsetbc(state, bndl, bndu);
    lsfitsetscale(state, s);
    alglib::lsfitfit(state, function_debt_func);
    lsfitresults(state, info, c, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 2</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(-2).c_str()); <font color=navy>// EXPECTED: [4.142560E+12, 0.434240, 0.565376]</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_pol'></a><h3 class=pageheader>lsfit_d_pol example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates polynomial fitting.</font>
    <font color=navy>//</font>
    <font color=navy>// Fitting is done by two (M=2) functions from polynomial basis:</font>
    <font color=navy>//     f0 = 1</font>
    <font color=navy>//     f1 = x</font>
    <font color=navy>// Basically, it just a linear fit; more complex polynomials may be used</font>
    <font color=navy>// (e.g. parabolas with M=3, cubic with M=4), but even such simple fit allows</font>
    <font color=navy>// us to demonstrate polynomialfit() function in action.</font>
    <font color=navy>//</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * x      set of abscissas</font>
    <font color=navy>// * y      experimental data</font>
    <font color=navy>//</font>
    <font color=navy>// Additionally we demonstrate weighted fitting, where second point has</font>
    <font color=navy>// more weight than other ones.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.00,0.05,0.26,0.32,0.33,0.43,0.60,0.60,0.77,0.98,1.02]&quot;</b></font>;
    ae_int_t m = 2;
    <b>double</b> t = 2;
    ae_int_t info;
    barycentricinterpolant p;
    polynomialfitreport rep;
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// Fitting without individual weights</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: result is returned as barycentricinterpolant structure.</font>
    <font color=navy>//       <b>if</b> you want to get representation in the power basis,</font>
    <font color=navy>//       you can use barycentricbar2pow() function to convert</font>
    <font color=navy>//       from barycentric to power representation (see docs <b>for</b> </font>
    <font color=navy>//       POLINT subpackage <b>for</b> more info).</font>
    <font color=navy>//</font>
    polynomialfit(x, y, m, info, p, rep);
    v = barycentriccalc(p, t);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.011</font>

    <font color=navy>//</font>
    <font color=navy>// Fitting with individual weights</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: slightly different result is returned</font>
    <font color=navy>//</font>
    real_1d_array w = <font color=blue><b>&quot;[1,1.414213562,1,1,1,1,1,1,1,1,1]&quot;</b></font>;
    real_1d_array xc = <font color=blue><b>&quot;[]&quot;</b></font>;
    real_1d_array yc = <font color=blue><b>&quot;[]&quot;</b></font>;
    integer_1d_array dc = <font color=blue><b>&quot;[]&quot;</b></font>;
    polynomialfitwc(x, y, w, xc, yc, dc, m, info, p, rep);
    v = barycentriccalc(p, t);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.023</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_polc'></a><h3 class=pageheader>lsfit_d_polc example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates polynomial fitting.</font>
    <font color=navy>//</font>
    <font color=navy>// Fitting is done by two (M=2) functions from polynomial basis:</font>
    <font color=navy>//     f0 = 1</font>
    <font color=navy>//     f1 = x</font>
    <font color=navy>// with simple constraint on function value</font>
    <font color=navy>//     f(0) = 0</font>
    <font color=navy>// Basically, it just a linear fit; more complex polynomials may be used</font>
    <font color=navy>// (e.g. parabolas with M=3, cubic with M=4), but even such simple fit allows</font>
    <font color=navy>// us to demonstrate polynomialfit() function in action.</font>
    <font color=navy>//</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * x      set of abscissas</font>
    <font color=navy>// * y      experimental data</font>
    <font color=navy>// * xc     points where constraints are placed</font>
    <font color=navy>// * yc     constraints on derivatives</font>
    <font color=navy>// * dc     derivative indices</font>
    <font color=navy>//          (0 means function itself, 1 means first derivative)</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[1.0,1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.9,1.1]&quot;</b></font>;
    real_1d_array w = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array xc = <font color=blue><b>&quot;[0]&quot;</b></font>;
    real_1d_array yc = <font color=blue><b>&quot;[0]&quot;</b></font>;
    integer_1d_array dc = <font color=blue><b>&quot;[0]&quot;</b></font>;
    <b>double</b> t = 2;
    ae_int_t m = 2;
    ae_int_t info;
    barycentricinterpolant p;
    polynomialfitreport rep;
    <b>double</b> v;

    polynomialfitwc(x, y, w, xc, yc, dc, m, info, p, rep);
    v = barycentriccalc(p, t);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.000</font>
    <b>return</b> 0;
}


</pre><a name='example_lsfit_d_spline'></a><h3 class=pageheader>lsfit_d_spline example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// In this example we demonstrate penalized spline fitting of noisy data</font>
    <font color=navy>//</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * x - abscissas</font>
    <font color=navy>// * y - vector of experimental data, straight line with small noise</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.00,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.10,0.00,0.30,0.40,0.30,0.40,0.62,0.68,0.75,0.95]&quot;</b></font>;
    ae_int_t info;
    <b>double</b> v;
    spline1dinterpolant s;
    spline1dfitreport rep;
    <b>double</b> rho;

    <font color=navy>//</font>
    <font color=navy>// Fit with VERY small amount of smoothing (rho = -5.0)</font>
    <font color=navy>// and large number of basis functions (M=50).</font>
    <font color=navy>//</font>
    <font color=navy>// With such small regularization penalized spline almost fully reproduces function values</font>
    <font color=navy>//</font>
    rho = -5.0;
    spline1dfitpenalized(x, y, 50, rho, info, s, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    v = spline1dcalc(s, 0.0);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.10</font>

    <font color=navy>//</font>
    <font color=navy>// Fit with VERY large amount of smoothing (rho = 10.0)</font>
    <font color=navy>// and large number of basis functions (M=50).</font>
    <font color=navy>//</font>
    <font color=navy>// With such regularization our spline should become close to the straight line fit.</font>
    <font color=navy>// We will compare its value in x=1.0 with results obtained from such fit.</font>
    <font color=navy>//</font>
    rho = +10.0;
    spline1dfitpenalized(x, y, 50, rho, info, s, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    v = spline1dcalc(s, 1.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.969</font>

    <font color=navy>//</font>
    <font color=navy>// In real life applications you may need some moderate degree of fitting,</font>
    <font color=navy>// so we try to fit once more with rho=3.0.</font>
    <font color=navy>//</font>
    rho = +3.0;
    spline1dfitpenalized(x, y, 50, rho, info, s, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    <b>return</b> 0;
}


</pre><a name=unit_mannwhitneyu></a><h2 class=pageheader><code>mannwhitneyu</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mannwhitneyutest' class=toc>mannwhitneyutest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_mannwhitneyutest'></a><h3 class=pageheader><code>mannwhitneyutest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Mann-Whitney U-test

This test checks hypotheses about whether X  and  Y  are  samples  of  two
continuous distributions of the same shape  and  same  median  or  whether
their medians are different.

The following tests are performed:
    * two-tailed test (null hypothesis - the medians are equal)
    * left-tailed test (null hypothesis - the median of the  first  sample
      is greater than or equal to the median of the second sample)
    * right-tailed test (null hypothesis - the median of the first  sample
      is less than or equal to the median of the second sample).

Requirements:
    * the samples are independent
    * X and Y are continuous distributions (or discrete distributions well-
      approximating continuous distributions)
    * distributions of X and Y have the  same  shape.  The  only  possible
      difference is their position (i.e. the value of the median)
    * the number of elements in each sample is not less than 5
    * the scale of measurement should be ordinal, interval or ratio  (i.e.
      the test could not be applied to nominal variables).

The test is non-parametric and doesn't require distributions to be normal.

Input parameters:
    X   -   sample 1. Array whose index goes from 0 to N-1.
    N   -   size of the sample. N&gt;=5
    Y   -   sample 2. Array whose index goes from 0 to M-1.
    M   -   size of the sample. M&gt;=5

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

To calculate p-values, special approximation is used. This method lets  us
calculate p-values with satisfactory  accuracy  in  interval  [0.0001, 1].
There is no approximation outside the [0.0001, 1] interval. Therefore,  if
the significance level outlies this interval, the test returns 0.0001.

Relative precision of approximation of p-value:

N          M          Max.err.   Rms.err.
5..10      N..10      1.4e-02    6.0e-04
5..10      N..100     2.2e-02    5.3e-06
10..15     N..15      1.0e-02    3.2e-04
10..15     N..100     1.0e-02    2.2e-05
15..100    N..100     6.1e-03    2.7e-06

For N,M&gt;100 accuracy checks weren't put into  practice,  but  taking  into
account characteristics of asymptotic approximation used, precision should
not be sharply different from the values for interval [5, 100].

  -- ALGLIB --
     Copyright 09.04.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mannwhitneyutest(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name=unit_matdet></a><h2 class=pageheader><code>matdet</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixdet' class=toc>cmatrixdet</a><br>
<a href='#sub_cmatrixludet' class=toc>cmatrixludet</a><br>
<a href='#sub_rmatrixdet' class=toc>rmatrixdet</a><br>
<a href='#sub_rmatrixludet' class=toc>rmatrixludet</a><br>
<a href='#sub_spdmatrixcholeskydet' class=toc>spdmatrixcholeskydet</a><br>
<a href='#sub_spdmatrixdet' class=toc>spdmatrixdet</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_matdet_d_1' class=toc>matdet_d_1</a></td><td width=15>&nbsp;</td><td>Determinant calculation, real matrix, short form</td></tr>
<tr align=left valign=top><td><a href='#example_matdet_d_2' class=toc>matdet_d_2</a></td><td width=15>&nbsp;</td><td>Determinant calculation, real matrix, full form</td></tr>
<tr align=left valign=top><td><a href='#example_matdet_d_3' class=toc>matdet_d_3</a></td><td width=15>&nbsp;</td><td>Determinant calculation, complex matrix, short form</td></tr>
<tr align=left valign=top><td><a href='#example_matdet_d_4' class=toc>matdet_d_4</a></td><td width=15>&nbsp;</td><td>Determinant calculation, complex matrix, full form</td></tr>
<tr align=left valign=top><td><a href='#example_matdet_d_5' class=toc>matdet_d_5</a></td><td width=15>&nbsp;</td><td>Determinant calculation, complex matrix with zero imaginary part, short form</td></tr>
</table></div>
<a name='sub_cmatrixdet'></a><h3 class=pageheader><code>cmatrixdet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the determinant of a general matrix

Input parameters:
    A       -   matrix, array[0..N-1, 0..N-1]
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)

Result: determinant of matrix A.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>alglib::complex alglib::cmatrixdet(complex_2d_array a);
alglib::complex alglib::cmatrixdet(complex_2d_array a, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matdet_d_3' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_matdet_d_4' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_matdet_d_5' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_cmatrixludet'></a><h3 class=pageheader><code>cmatrixludet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Determinant calculation of the matrix given by its LU decomposition.

Input parameters:
    A       -   LU decomposition of the matrix (output of
                RMatrixLU subroutine).
    Pivots  -   table of permutations which were made during
                the LU decomposition.
                Output of RMatrixLU subroutine.
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)

Result: matrix determinant.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>alglib::complex alglib::cmatrixludet(
    complex_2d_array a,
    integer_1d_array pivots);
alglib::complex alglib::cmatrixludet(
    complex_2d_array a,
    integer_1d_array pivots,
    ae_int_t n);

</div></pre>
<a name='sub_rmatrixdet'></a><h3 class=pageheader><code>rmatrixdet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of the determinant of a general matrix

Input parameters:
    A       -   matrix, array[0..N-1, 0..N-1]
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)

Result: determinant of matrix A.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixdet(real_2d_array a);
<b>double</b> alglib::rmatrixdet(real_2d_array a, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matdet_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_matdet_d_2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_rmatrixludet'></a><h3 class=pageheader><code>rmatrixludet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Determinant calculation of the matrix given by its LU decomposition.

Input parameters:
    A       -   LU decomposition of the matrix (output of
                RMatrixLU subroutine).
    Pivots  -   table of permutations which were made during
                the LU decomposition.
                Output of RMatrixLU subroutine.
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)

Result: matrix determinant.

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixludet(real_2d_array a, integer_1d_array pivots);
<b>double</b> alglib::rmatrixludet(
    real_2d_array a,
    integer_1d_array pivots,
    ae_int_t n);

</div></pre>
<a name='sub_spdmatrixcholeskydet'></a><h3 class=pageheader><code>spdmatrixcholeskydet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Determinant calculation of the matrix given by the Cholesky decomposition.

Input parameters:
    A       -   Cholesky decomposition,
                output of SMatrixCholesky subroutine.
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)

As the determinant is equal to the product of squares of diagonal elements,
its not necessary to specify which triangle - lower or upper - the matrix
is stored in.

Result:
    matrix determinant.

  -- ALGLIB --
     Copyright 2005-2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spdmatrixcholeskydet(real_2d_array a);
<b>double</b> alglib::spdmatrixcholeskydet(real_2d_array a, ae_int_t n);

</div></pre>
<a name='sub_spdmatrixdet'></a><h3 class=pageheader><code>spdmatrixdet</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Determinant calculation of the symmetric positive definite matrix.

Input parameters:
    A       -   matrix. Array with elements [0..N-1, 0..N-1].
    N       -   (optional) size of matrix A:
                * if given, only principal NxN submatrix is processed and
                  overwritten. other elements are unchanged.
                * if not given, automatically determined from matrix size
                  (A must be square matrix)
    IsUpper -   (optional) storage type:
                * if True, symmetric matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt used/changed  by
                  function
                * if False, symmetric matrix  A  is  given  by  its lower
                  triangle, and the upper triangle isnt used/changed  by
                  function
                * if not given, both lower and upper  triangles  must  be
                  filled.

Result:
    determinant of matrix A.
    If matrix A is not positive definite, exception is thrown.

  -- ALGLIB --
     Copyright 2005-2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spdmatrixdet(real_2d_array a);
<b>double</b> alglib::spdmatrixdet(real_2d_array a, ae_int_t n, <b>bool</b> isupper);

</div></pre>
<a name='example_matdet_d_1'></a><h3 class=pageheader>matdet_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array b = <font color=blue><b>&quot;[[1,2],[2,1]]&quot;</b></font>;
    <b>double</b> a;
    a = rmatrixdet(b);
    printf(<font color=blue><b>&quot;%.3f\n&quot;</b></font>, <b>double</b>(a)); <font color=navy>// EXPECTED: -3</font>
    <b>return</b> 0;
}


</pre><a name='example_matdet_d_2'></a><h3 class=pageheader>matdet_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array b = <font color=blue><b>&quot;[[5,4],[4,5]]&quot;</b></font>;
    <b>double</b> a;
    a = rmatrixdet(b, 2);
    printf(<font color=blue><b>&quot;%.3f\n&quot;</b></font>, <b>double</b>(a)); <font color=navy>// EXPECTED: 9</font>
    <b>return</b> 0;
}


</pre><a name='example_matdet_d_3'></a><h3 class=pageheader>matdet_d_3 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    complex_2d_array b = <font color=blue><b>&quot;[[1+1i,2],[2,1-1i]]&quot;</b></font>;
    alglib::complex a;
    a = cmatrixdet(b);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(3).c_str()); <font color=navy>// EXPECTED: -2</font>
    <b>return</b> 0;
}


</pre><a name='example_matdet_d_4'></a><h3 class=pageheader>matdet_d_4 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    alglib::complex a;
    complex_2d_array b = <font color=blue><b>&quot;[[5i,4],[4i,5]]&quot;</b></font>;
    a = cmatrixdet(b, 2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(3).c_str()); <font color=navy>// EXPECTED: 9i</font>
    <b>return</b> 0;
}


</pre><a name='example_matdet_d_5'></a><h3 class=pageheader>matdet_d_5 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    alglib::complex a;
    complex_2d_array b = <font color=blue><b>&quot;[[9,1],[2,1]]&quot;</b></font>;
    a = cmatrixdet(b);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(3).c_str()); <font color=navy>// EXPECTED: 7</font>
    <b>return</b> 0;
}


</pre><a name=unit_matgen></a><h2 class=pageheader><code>matgen</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixrndcond' class=toc>cmatrixrndcond</a><br>
<a href='#sub_cmatrixrndorthogonal' class=toc>cmatrixrndorthogonal</a><br>
<a href='#sub_cmatrixrndorthogonalfromtheleft' class=toc>cmatrixrndorthogonalfromtheleft</a><br>
<a href='#sub_cmatrixrndorthogonalfromtheright' class=toc>cmatrixrndorthogonalfromtheright</a><br>
<a href='#sub_hmatrixrndcond' class=toc>hmatrixrndcond</a><br>
<a href='#sub_hmatrixrndmultiply' class=toc>hmatrixrndmultiply</a><br>
<a href='#sub_hpdmatrixrndcond' class=toc>hpdmatrixrndcond</a><br>
<a href='#sub_rmatrixrndcond' class=toc>rmatrixrndcond</a><br>
<a href='#sub_rmatrixrndorthogonal' class=toc>rmatrixrndorthogonal</a><br>
<a href='#sub_rmatrixrndorthogonalfromtheleft' class=toc>rmatrixrndorthogonalfromtheleft</a><br>
<a href='#sub_rmatrixrndorthogonalfromtheright' class=toc>rmatrixrndorthogonalfromtheright</a><br>
<a href='#sub_smatrixrndcond' class=toc>smatrixrndcond</a><br>
<a href='#sub_smatrixrndmultiply' class=toc>smatrixrndmultiply</a><br>
<a href='#sub_spdmatrixrndcond' class=toc>spdmatrixrndcond</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixrndcond'></a><h3 class=pageheader><code>cmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN complex matrix with given condition number C and
norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrndcond(ae_int_t n, <b>double</b> c, complex_2d_array&amp; a);

</div></pre>
<a name='sub_cmatrixrndorthogonal'></a><h3 class=pageheader><code>cmatrixrndorthogonal</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of a random Haar distributed orthogonal complex matrix

INPUT PARAMETERS:
    N   -   matrix size, N&gt;=1

OUTPUT PARAMETERS:
    A   -   orthogonal NxN matrix, array[0..N-1,0..N-1]

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrndorthogonal(ae_int_t n, complex_2d_array&amp; a);

</div></pre>
<a name='sub_cmatrixrndorthogonalfromtheleft'></a><h3 class=pageheader><code>cmatrixrndorthogonalfromtheleft</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication of MxN complex matrix by MxM random Haar distributed
complex orthogonal matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..M-1, 0..N-1]
    M, N-   matrix size

OUTPUT PARAMETERS:
    A   -   Q*A, where Q is random MxM orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrndorthogonalfromtheleft(
    complex_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n);

</div></pre>
<a name='sub_cmatrixrndorthogonalfromtheright'></a><h3 class=pageheader><code>cmatrixrndorthogonalfromtheright</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication of MxN complex matrix by NxN random Haar distributed
complex orthogonal matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..M-1, 0..N-1]
    M, N-   matrix size

OUTPUT PARAMETERS:
    A   -   A*Q, where Q is random NxN orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixrndorthogonalfromtheright(
    complex_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n);

</div></pre>
<a name='sub_hmatrixrndcond'></a><h3 class=pageheader><code>hmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN Hermitian matrix with given condition number  and
norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hmatrixrndcond(ae_int_t n, <b>double</b> c, complex_2d_array&amp; a);

</div></pre>
<a name='sub_hmatrixrndmultiply'></a><h3 class=pageheader><code>hmatrixrndmultiply</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Hermitian multiplication of NxN matrix by random Haar distributed
complex orthogonal matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..N-1, 0..N-1]
    N   -   matrix size

OUTPUT PARAMETERS:
    A   -   Q^H*A*Q, where Q is random NxN orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hmatrixrndmultiply(complex_2d_array&amp; a, ae_int_t n);

</div></pre>
<a name='sub_hpdmatrixrndcond'></a><h3 class=pageheader><code>hpdmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN Hermitian positive definite matrix with given
condition number and norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random HPD matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixrndcond(ae_int_t n, <b>double</b> c, complex_2d_array&amp; a);

</div></pre>
<a name='sub_rmatrixrndcond'></a><h3 class=pageheader><code>rmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN matrix with given condition number and norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrndcond(ae_int_t n, <b>double</b> c, real_2d_array&amp; a);

</div></pre>
<a name='sub_rmatrixrndorthogonal'></a><h3 class=pageheader><code>rmatrixrndorthogonal</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of a random uniformly distributed (Haar) orthogonal matrix

INPUT PARAMETERS:
    N   -   matrix size, N&gt;=1

OUTPUT PARAMETERS:
    A   -   orthogonal NxN matrix, array[0..N-1,0..N-1]

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrndorthogonal(ae_int_t n, real_2d_array&amp; a);

</div></pre>
<a name='sub_rmatrixrndorthogonalfromtheleft'></a><h3 class=pageheader><code>rmatrixrndorthogonalfromtheleft</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication of MxN matrix by MxM random Haar distributed orthogonal matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..M-1, 0..N-1]
    M, N-   matrix size

OUTPUT PARAMETERS:
    A   -   Q*A, where Q is random MxM orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrndorthogonalfromtheleft(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n);

</div></pre>
<a name='sub_rmatrixrndorthogonalfromtheright'></a><h3 class=pageheader><code>rmatrixrndorthogonalfromtheright</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication of MxN matrix by NxN random Haar distributed orthogonal matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..M-1, 0..N-1]
    M, N-   matrix size

OUTPUT PARAMETERS:
    A   -   A*Q, where Q is random NxN orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixrndorthogonalfromtheright(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n);

</div></pre>
<a name='sub_smatrixrndcond'></a><h3 class=pageheader><code>smatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN symmetric matrix with given condition number  and
norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::smatrixrndcond(ae_int_t n, <b>double</b> c, real_2d_array&amp; a);

</div></pre>
<a name='sub_smatrixrndmultiply'></a><h3 class=pageheader><code>smatrixrndmultiply</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Symmetric multiplication of NxN matrix by random Haar distributed
orthogonal  matrix

INPUT PARAMETERS:
    A   -   matrix, array[0..N-1, 0..N-1]
    N   -   matrix size

OUTPUT PARAMETERS:
    A   -   Q'*A*Q, where Q is random NxN orthogonal matrix

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::smatrixrndmultiply(real_2d_array&amp; a, ae_int_t n);

</div></pre>
<a name='sub_spdmatrixrndcond'></a><h3 class=pageheader><code>spdmatrixrndcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Generation of random NxN symmetric positive definite matrix with given
condition number and norm2(A)=1

INPUT PARAMETERS:
    N   -   matrix size
    C   -   condition number (in 2-norm)

OUTPUT PARAMETERS:
    A   -   random SPD matrix with norm2(A)=1 and cond(A)=C

  -- ALGLIB routine --
     04.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixrndcond(ae_int_t n, <b>double</b> c, real_2d_array&amp; a);

</div></pre>
<a name=unit_matinv></a><h2 class=pageheader><code>matinv</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_matinvreport' class=toc>matinvreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixinverse' class=toc>cmatrixinverse</a><br>
<a href='#sub_cmatrixluinverse' class=toc>cmatrixluinverse</a><br>
<a href='#sub_cmatrixtrinverse' class=toc>cmatrixtrinverse</a><br>
<a href='#sub_hpdmatrixcholeskyinverse' class=toc>hpdmatrixcholeskyinverse</a><br>
<a href='#sub_hpdmatrixinverse' class=toc>hpdmatrixinverse</a><br>
<a href='#sub_rmatrixinverse' class=toc>rmatrixinverse</a><br>
<a href='#sub_rmatrixluinverse' class=toc>rmatrixluinverse</a><br>
<a href='#sub_rmatrixtrinverse' class=toc>rmatrixtrinverse</a><br>
<a href='#sub_spdmatrixcholeskyinverse' class=toc>spdmatrixcholeskyinverse</a><br>
<a href='#sub_spdmatrixinverse' class=toc>spdmatrixinverse</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_matinv_d_c1' class=toc>matinv_d_c1</a></td><td width=15>&nbsp;</td><td>Complex matrix inverse</td></tr>
<tr align=left valign=top><td><a href='#example_matinv_d_hpd1' class=toc>matinv_d_hpd1</a></td><td width=15>&nbsp;</td><td>HPD matrix inverse</td></tr>
<tr align=left valign=top><td><a href='#example_matinv_d_r1' class=toc>matinv_d_r1</a></td><td width=15>&nbsp;</td><td>Real matrix inverse</td></tr>
<tr align=left valign=top><td><a href='#example_matinv_d_spd1' class=toc>matinv_d_spd1</a></td><td width=15>&nbsp;</td><td>SPD matrix inverse</td></tr>
</table></div>
<a name='struct_matinvreport'></a><h3 class=pageheader><code>matinvreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Matrix inverse report:
* R1    reciprocal of condition number in 1-norm
* RInf  reciprocal of condition number in inf-norm
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> matinvreport
{
    <b>double</b>               r1;
    <b>double</b>               rinf;
};

</div></pre>
<a name='sub_cmatrixinverse'></a><h3 class=pageheader><code>cmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a general matrix.

Input parameters:
    A       -   matrix
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixinverse(
    complex_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::cmatrixinverse(
    complex_2d_array&amp; a,
    ae_int_t n,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matinv_d_c1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_cmatrixluinverse'></a><h3 class=pageheader><code>cmatrixluinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a matrix given by its LU decomposition.

INPUT PARAMETERS:
    A       -   LU decomposition of the matrix
                (output of CMatrixLU subroutine).
    Pivots  -   table of permutations
                (the output of CMatrixLU subroutine).
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)

OUTPUT PARAMETERS:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB routine --
     05.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixluinverse(
    complex_2d_array&amp; a,
    integer_1d_array pivots,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::cmatrixluinverse(
    complex_2d_array&amp; a,
    integer_1d_array pivots,
    ae_int_t n,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_cmatrixtrinverse'></a><h3 class=pageheader><code>cmatrixtrinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix inverse (complex)

The subroutine inverts the following types of matrices:
    * upper triangular
    * upper triangular with unit diagonal
    * lower triangular
    * lower triangular with unit diagonal

In case of an upper (lower) triangular matrix,  the  inverse  matrix  will
also be upper (lower) triangular, and after the end of the algorithm,  the
inverse matrix replaces the source matrix. The elements  below (above) the
main diagonal are not changed by the algorithm.

If  the matrix  has a unit diagonal, the inverse matrix also  has  a  unit
diagonal, and the diagonal elements are not passed to the algorithm.

Input parameters:
    A       -   matrix, array[0..N-1, 0..N-1].
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   diagonal type (optional):
                * if True, matrix has unit diagonal (a[i,i] are NOT used)
                * if False, matrix diagonal is arbitrary
                * if not given, False is assumed

Output parameters:
    Info    -   same as for RMatrixLUInverse
    Rep     -   same as for RMatrixLUInverse
    A       -   same as for RMatrixLUInverse.

  -- ALGLIB --
     Copyright 05.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixtrinverse(
    complex_2d_array&amp; a,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::cmatrixtrinverse(
    complex_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_hpdmatrixcholeskyinverse'></a><h3 class=pageheader><code>hpdmatrixcholeskyinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a Hermitian positive definite matrix which is given
by Cholesky decomposition.

Input parameters:
    A       -   Cholesky decomposition of the matrix to be inverted:
                A=U*U or A = L*L'.
                Output of  HPDMatrixCholesky subroutine.
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   storage type (optional):
                * if True, symmetric  matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt  used/changed  by
                  function
                * if False,  symmetric matrix  A  is  given  by  its lower
                  triangle, and the  upper triangle isnt used/changed  by
                  function
                * if not given, lower half is used.

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB routine --
     10.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixcholeskyinverse(
    complex_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::hpdmatrixcholeskyinverse(
    complex_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_hpdmatrixinverse'></a><h3 class=pageheader><code>hpdmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a Hermitian positive definite matrix.

Given an upper or lower triangle of a Hermitian positive definite matrix,
the algorithm generates matrix A^-1 and saves the upper or lower triangle
depending on the input.

Input parameters:
    A       -   matrix to be inverted (upper or lower triangle).
                Array with elements [0..N-1,0..N-1].
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   storage type (optional):
                * if True, symmetric  matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt  used/changed  by
                  function
                * if False,  symmetric matrix  A  is  given  by  its lower
                  triangle, and the  upper triangle isnt used/changed  by
                  function
                * if not given,  both lower and upper  triangles  must  be
                  filled.

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB routine --
     10.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hpdmatrixinverse(
    complex_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::hpdmatrixinverse(
    complex_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matinv_d_hpd1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rmatrixinverse'></a><h3 class=pageheader><code>rmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a general matrix.

Input parameters:
    A       -   matrix.
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

Result:
    True, if the matrix is not singular.
    False, if the matrix is singular.

  -- ALGLIB --
     Copyright 2005-2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixinverse(
    real_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::rmatrixinverse(
    real_2d_array&amp; a,
    ae_int_t n,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matinv_d_r1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rmatrixluinverse'></a><h3 class=pageheader><code>rmatrixluinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a matrix given by its LU decomposition.

INPUT PARAMETERS:
    A       -   LU decomposition of the matrix
                (output of RMatrixLU subroutine).
    Pivots  -   table of permutations
                (the output of RMatrixLU subroutine).
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)

OUTPUT PARAMETERS:
    Info    -   return code:
                * -3    A is singular, or VERY close to singular.
                        it is filled by zeros in such cases.
                *  1    task is solved (but matrix A may be ill-conditioned,
                        check R1/RInf parameters for condition numbers).
    Rep     -   solver report, see below for more info
    A       -   inverse of matrix A.
                Array whose indexes range within [0..N-1, 0..N-1].

SOLVER REPORT

Subroutine sets following fields of the Rep structure:
* R1        reciprocal of condition number: 1/cond(A), 1-norm.
* RInf      reciprocal of condition number: 1/cond(A), inf-norm.

  -- ALGLIB routine --
     05.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixluinverse(
    real_2d_array&amp; a,
    integer_1d_array pivots,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::rmatrixluinverse(
    real_2d_array&amp; a,
    integer_1d_array pivots,
    ae_int_t n,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_rmatrixtrinverse'></a><h3 class=pageheader><code>rmatrixtrinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix inverse (real)

The subroutine inverts the following types of matrices:
    * upper triangular
    * upper triangular with unit diagonal
    * lower triangular
    * lower triangular with unit diagonal

In case of an upper (lower) triangular matrix,  the  inverse  matrix  will
also be upper (lower) triangular, and after the end of the algorithm,  the
inverse matrix replaces the source matrix. The elements  below (above) the
main diagonal are not changed by the algorithm.

If  the matrix  has a unit diagonal, the inverse matrix also  has  a  unit
diagonal, and the diagonal elements are not passed to the algorithm.

Input parameters:
    A       -   matrix, array[0..N-1, 0..N-1].
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   diagonal type (optional):
                * if True, matrix has unit diagonal (a[i,i] are NOT used)
                * if False, matrix diagonal is arbitrary
                * if not given, False is assumed

Output parameters:
    Info    -   same as for RMatrixLUInverse
    Rep     -   same as for RMatrixLUInverse
    A       -   same as for RMatrixLUInverse.

  -- ALGLIB --
     Copyright 05.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixtrinverse(
    real_2d_array&amp; a,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::rmatrixtrinverse(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_spdmatrixcholeskyinverse'></a><h3 class=pageheader><code>spdmatrixcholeskyinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a symmetric positive definite matrix which is given
by Cholesky decomposition.

Input parameters:
    A       -   Cholesky decomposition of the matrix to be inverted:
                A=U*U or A = L*L'.
                Output of  SPDMatrixCholesky subroutine.
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   storage type (optional):
                * if True, symmetric  matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt  used/changed  by
                  function
                * if False,  symmetric matrix  A  is  given  by  its lower
                  triangle, and the  upper triangle isnt used/changed  by
                  function
                * if not given, lower half is used.

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB routine --
     10.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixcholeskyinverse(
    real_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::spdmatrixcholeskyinverse(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<a name='sub_spdmatrixinverse'></a><h3 class=pageheader><code>spdmatrixinverse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inversion of a symmetric positive definite matrix.

Given an upper or lower triangle of a symmetric positive definite matrix,
the algorithm generates matrix A^-1 and saves the upper or lower triangle
depending on the input.

Input parameters:
    A       -   matrix to be inverted (upper or lower triangle).
                Array with elements [0..N-1,0..N-1].
    N       -   size of matrix A (optional) :
                * if given, only principal NxN submatrix is processed  and
                  overwritten. other elements are unchanged.
                * if not given,  size  is  automatically  determined  from
                  matrix size (A must be square matrix)
    IsUpper -   storage type (optional):
                * if True, symmetric  matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt  used/changed  by
                  function
                * if False,  symmetric matrix  A  is  given  by  its lower
                  triangle, and the  upper triangle isnt used/changed  by
                  function
                * if not given,  both lower and upper  triangles  must  be
                  filled.

Output parameters:
    Info    -   return code, same as in RMatrixLUInverse
    Rep     -   solver report, same as in RMatrixLUInverse
    A       -   inverse of matrix A, same as in RMatrixLUInverse

  -- ALGLIB routine --
     10.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spdmatrixinverse(
    real_2d_array&amp; a,
    ae_int_t&amp; info,
    matinvreport&amp; rep);
<b>void</b> alglib::spdmatrixinverse(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    ae_int_t&amp; info,
    matinvreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_matinv_d_spd1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_matinv_d_c1'></a><h3 class=pageheader>matinv_d_c1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    complex_2d_array a = <font color=blue><b>&quot;[[1i,-1],[1i,1]]&quot;</b></font>;
    ae_int_t info;
    matinvreport rep;
    cmatrixinverse(a, info, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(4).c_str()); <font color=navy>// EXPECTED: [[-0.5i,-0.5i],[-0.5,0.5]]</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(rep.r1)); <font color=navy>// EXPECTED: 0.5</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(rep.rinf)); <font color=navy>// EXPECTED: 0.5</font>
    <b>return</b> 0;
}


</pre><a name='example_matinv_d_hpd1'></a><h3 class=pageheader>matinv_d_hpd1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    complex_2d_array a = <font color=blue><b>&quot;[[2,1],[1,2]]&quot;</b></font>;
    ae_int_t info;
    matinvreport rep;
    hpdmatrixinverse(a, info, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(4).c_str()); <font color=navy>// EXPECTED: [[0.666666,-0.333333],[-0.333333,0.666666]]</font>
    <b>return</b> 0;
}


</pre><a name='example_matinv_d_r1'></a><h3 class=pageheader>matinv_d_r1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array a = <font color=blue><b>&quot;[[1,-1],[1,1]]&quot;</b></font>;
    ae_int_t info;
    matinvreport rep;
    rmatrixinverse(a, info, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(4).c_str()); <font color=navy>// EXPECTED: [[0.5,0.5],[-0.5,0.5]]</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(rep.r1)); <font color=navy>// EXPECTED: 0.5</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(rep.rinf)); <font color=navy>// EXPECTED: 0.5</font>
    <b>return</b> 0;
}


</pre><a name='example_matinv_d_spd1'></a><h3 class=pageheader>matinv_d_spd1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array a = <font color=blue><b>&quot;[[2,1],[1,2]]&quot;</b></font>;
    ae_int_t info;
    matinvreport rep;
    spdmatrixinverse(a, info, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(info)); <font color=navy>// EXPECTED: 1</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a.tostring(4).c_str()); <font color=navy>// EXPECTED: [[0.666666,-0.333333],[-0.333333,0.666666]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_mcpd></a><h2 class=pageheader><code>mcpd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_mcpdreport' class=toc>mcpdreport</a><br>
<a href='#struct_mcpdstate' class=toc>mcpdstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mcpdaddbc' class=toc>mcpdaddbc</a><br>
<a href='#sub_mcpdaddec' class=toc>mcpdaddec</a><br>
<a href='#sub_mcpdaddtrack' class=toc>mcpdaddtrack</a><br>
<a href='#sub_mcpdcreate' class=toc>mcpdcreate</a><br>
<a href='#sub_mcpdcreateentry' class=toc>mcpdcreateentry</a><br>
<a href='#sub_mcpdcreateentryexit' class=toc>mcpdcreateentryexit</a><br>
<a href='#sub_mcpdcreateexit' class=toc>mcpdcreateexit</a><br>
<a href='#sub_mcpdresults' class=toc>mcpdresults</a><br>
<a href='#sub_mcpdsetbc' class=toc>mcpdsetbc</a><br>
<a href='#sub_mcpdsetec' class=toc>mcpdsetec</a><br>
<a href='#sub_mcpdsetlc' class=toc>mcpdsetlc</a><br>
<a href='#sub_mcpdsetpredictionweights' class=toc>mcpdsetpredictionweights</a><br>
<a href='#sub_mcpdsetprior' class=toc>mcpdsetprior</a><br>
<a href='#sub_mcpdsettikhonovregularizer' class=toc>mcpdsettikhonovregularizer</a><br>
<a href='#sub_mcpdsolve' class=toc>mcpdsolve</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_mcpd_simple1' class=toc>mcpd_simple1</a></td><td width=15>&nbsp;</td><td>Simple unconstrained MCPD model (no entry/exit states)</td></tr>
<tr align=left valign=top><td><a href='#example_mcpd_simple2' class=toc>mcpd_simple2</a></td><td width=15>&nbsp;</td><td>Simple MCPD model (no entry/exit states) with equality constraints</td></tr>
</table></div>
<a name='struct_mcpdreport'></a><h3 class=pageheader><code>mcpdreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure is a MCPD training report:
    InnerIterationsCount    -   number of inner iterations of the
                                underlying optimization algorithm
    OuterIterationsCount    -   number of outer iterations of the
                                underlying optimization algorithm
    NFEV                    -   number of merit function evaluations
    TerminationType         -   termination type
                                (same as for MinBLEIC optimizer, positive
                                values denote success, negative ones -
                                failure)

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mcpdreport
{
    ae_int_t             inneriterationscount;
    ae_int_t             outeriterationscount;
    ae_int_t             nfev;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_mcpdstate'></a><h3 class=pageheader><code>mcpdstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure is a MCPD (Markov Chains for Population Data) solver.

You should use ALGLIB functions in order to work with this object.

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mcpdstate
{
};

</div></pre>
<a name='sub_mcpdaddbc'></a><h3 class=pageheader><code>mcpdaddbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to add bound constraints  on  the  elements  of  the
transition matrix P.

MCPD solver has four types of constraints which can be placed on P:
* user-specified equality constraints (optional)
* user-specified bound constraints (optional)
* user-specified general linear constraints (optional)
* basic constraints (always present):
  * non-negativity: P[i,j]&gt;=0
  * consistency: every column of P sums to 1.0

Final  constraints  which  are  passed  to  the  underlying  optimizer are
calculated  as  intersection  of all present constraints. For example, you
may specify boundary constraint on P[0,0] and equality one:
    0.1&lt;=P[0,0]&lt;=0.9
    P[0,0]=0.5
Such  combination  of  constraints  will  be  silently  reduced  to  their
intersection, which is P[0,0]=0.5.

This  function  can  be  used to ADD bound constraint for one element of P
without changing constraints for other elements.

You  can  also  use  MCPDSetBC()  function  which  allows to  place  bound
constraints  on arbitrary subset of elements of P.   Set of constraints is
specified  by  BndL/BndU matrices, which may contain arbitrary combination
of finite numbers or infinities (like -INF&lt;x&lt;=0.5 or 0.1&lt;=x&lt;+INF).

These functions (MCPDSetBC and MCPDAddBC) interact as follows:
* there is internal matrix of bound constraints which is stored in the
  MCPD solver
* MCPDSetBC() replaces this matrix by another one (SET)
* MCPDAddBC() modifies one element of this matrix and  leaves  other  ones
  unchanged (ADD)
* thus  MCPDAddBC()  call  preserves  all  modifications  done by previous
  calls,  while  MCPDSetBC()  completely discards all changes  done to the
  equality constraints.

INPUT PARAMETERS:
    S       -   solver
    I       -   row index of element being constrained
    J       -   column index of element being constrained
    BndL    -   lower bound
    BndU    -   upper bound

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdaddbc(
    mcpdstate s,
    ae_int_t i,
    ae_int_t j,
    <b>double</b> bndl,
    <b>double</b> bndu);

</div></pre>
<a name='sub_mcpdaddec'></a><h3 class=pageheader><code>mcpdaddec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to add equality constraints on the elements  of  the
transition matrix P.

MCPD solver has four types of constraints which can be placed on P:
* user-specified equality constraints (optional)
* user-specified bound constraints (optional)
* user-specified general linear constraints (optional)
* basic constraints (always present):
  * non-negativity: P[i,j]&gt;=0
  * consistency: every column of P sums to 1.0

Final  constraints  which  are  passed  to  the  underlying  optimizer are
calculated  as  intersection  of all present constraints. For example, you
may specify boundary constraint on P[0,0] and equality one:
    0.1&lt;=P[0,0]&lt;=0.9
    P[0,0]=0.5
Such  combination  of  constraints  will  be  silently  reduced  to  their
intersection, which is P[0,0]=0.5.

This function can be used to ADD equality constraint for one element of  P
without changing constraints for other elements.

You  can  also  use  MCPDSetEC()  function  which  allows  you  to specify
arbitrary set of equality constraints in one call.

These functions (MCPDSetEC and MCPDAddEC) interact as follows:
* there is internal matrix of equality constraints which is stored in the
  MCPD solver
* MCPDSetEC() replaces this matrix by another one (SET)
* MCPDAddEC() modifies one element of this matrix and leaves  other  ones
  unchanged (ADD)
* thus  MCPDAddEC()  call  preserves  all  modifications done by previous
  calls,  while  MCPDSetEC()  completely discards all changes done to the
  equality constraints.

INPUT PARAMETERS:
    S       -   solver
    I       -   row index of element being constrained
    J       -   column index of element being constrained
    C       -   value (constraint for P[I,J]).  Can  be  either  NAN  (no
                constraint) or finite value from [0,1].

NOTES:

1. infinite values of C  will lead to exception being thrown. Values  less
than 0.0 or greater than 1.0 will lead to error code being returned  after
call to MCPDSolve().

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdaddec(mcpdstate s, ae_int_t i, ae_int_t j, <b>double</b> c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mcpd_simple2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_mcpdaddtrack'></a><h3 class=pageheader><code>mcpdaddtrack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  is  used to add a track - sequence of system states at the
different moments of its evolution.

You  may  add  one  or several tracks to the MCPD solver. In case you have
several tracks, they won't overwrite each other. For example,  if you pass
two tracks, A1-A2-A3 (system at t=A+1, t=A+2 and t=A+3) and B1-B2-B3, then
solver will try to model transitions from t=A+1 to t=A+2, t=A+2 to  t=A+3,
t=B+1 to t=B+2, t=B+2 to t=B+3. But it WONT mix these two tracks - i.e. it
wont try to model transition from t=A+3 to t=B+1.

INPUT PARAMETERS:
    S       -   solver
    XY      -   track, array[K,N]:
                * I-th row is a state at t=I
                * elements of XY must be non-negative (exception will be
                  thrown on negative elements)
    K       -   number of points in a track
                * if given, only leading K rows of XY are used
                * if not given, automatically determined from size of XY

NOTES:

1. Track may contain either proportional or population data:
   * with proportional data all rows of XY must sum to 1.0, i.e. we have
     proportions instead of absolute population values
   * with population data rows of XY contain population counts and generally
     do not sum to 1.0 (although they still must be non-negative)

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdaddtrack(mcpdstate s, real_2d_array xy);
<b>void</b> alglib::mcpdaddtrack(mcpdstate s, real_2d_array xy, ae_int_t k);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mcpd_simple1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mcpd_simple2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mcpdcreate'></a><h3 class=pageheader><code>mcpdcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
DESCRIPTION:

This function creates MCPD (Markov Chains for Population Data) solver.

This  solver  can  be  used  to find transition matrix P for N-dimensional
prediction  problem  where transition from X[i] to X[i+1] is  modelled  as
    X[i+1] = P*X[i]
where X[i] and X[i+1] are N-dimensional population vectors (components  of
each X are non-negative), and P is a N*N transition matrix (elements of  P
are non-negative, each column sums to 1.0).

Such models arise when when:
* there is some population of individuals
* individuals can have different states
* individuals can transit from one state to another
* population size is constant, i.e. there is no new individuals and no one
  leaves population
* you want to model transitions of individuals from one state into another

USAGE:

Here we give very brief outline of the MCPD. We strongly recommend you  to
read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
on data analysis which is available at http://www.alglib.net/dataanalysis/

1. User initializes algorithm state with MCPDCreate() call

2. User  adds  one  or  more  tracks -  sequences of states which describe
   evolution of a system being modelled from different starting conditions

3. User may add optional boundary, equality  and/or  linear constraints on
   the coefficients of P by calling one of the following functions:
   * MCPDSetEC() to set equality constraints
   * MCPDSetBC() to set bound constraints
   * MCPDSetLC() to set linear constraints

4. Optionally,  user  may  set  custom  weights  for prediction errors (by
   default, algorithm assigns non-equal, automatically chosen weights  for
   errors in the prediction of different components of X). It can be  done
   with a call of MCPDSetPredictionWeights() function.

5. User calls MCPDSolve() function which takes algorithm  state and
   pointer (delegate, etc.) to callback function which calculates F/G.

6. User calls MCPDResults() to get solution

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;=1

OUTPUT PARAMETERS:
    State   -   structure stores algorithm state

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdcreate(ae_int_t n, mcpdstate&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mcpd_simple1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mcpd_simple2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mcpdcreateentry'></a><h3 class=pageheader><code>mcpdcreateentry</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
DESCRIPTION:

This function is a specialized version of MCPDCreate()  function,  and  we
recommend  you  to read comments for this function for general information
about MCPD solver.

This  function  creates  MCPD (Markov Chains for Population  Data)  solver
for &quot;Entry-state&quot; model,  i.e. model  where transition from X[i] to X[i+1]
is modelled as
    X[i+1] = P*X[i]
where
    X[i] and X[i+1] are N-dimensional state vectors
    P is a N*N transition matrix
and  one  selected component of X[] is called &quot;entry&quot; state and is treated
in a special way:
    system state always transits from &quot;entry&quot; state to some another state
    system state can not transit from any state into &quot;entry&quot; state
Such conditions basically mean that row of P which corresponds to  &quot;entry&quot;
state is zero.

Such models arise when:
* there is some population of individuals
* individuals can have different states
* individuals can transit from one state to another
* population size is NOT constant -  at every moment of time there is some
  (unpredictable) amount of &quot;new&quot; individuals, which can transit into  one
  of the states at the next turn, but still no one leaves population
* you want to model transitions of individuals from one state into another
* but you do NOT want to predict amount of &quot;new&quot;  individuals  because  it
  does not depends on individuals already present (hence  system  can  not
  transit INTO entry state - it can only transit FROM it).

This model is discussed  in  more  details  in  the ALGLIB User Guide (see
http://www.alglib.net/dataanalysis/ for more data).

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;=2
    EntryState- index of entry state, in 0..N-1

OUTPUT PARAMETERS:
    State   -   structure stores algorithm state

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdcreateentry(
    ae_int_t n,
    ae_int_t entrystate,
    mcpdstate&amp; s);

</div></pre>
<a name='sub_mcpdcreateentryexit'></a><h3 class=pageheader><code>mcpdcreateentryexit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
DESCRIPTION:

This function is a specialized version of MCPDCreate()  function,  and  we
recommend  you  to read comments for this function for general information
about MCPD solver.

This  function  creates  MCPD (Markov Chains for Population  Data)  solver
for &quot;Entry-Exit-states&quot; model, i.e. model where  transition  from  X[i] to
X[i+1] is modelled as
    X[i+1] = P*X[i]
where
    X[i] and X[i+1] are N-dimensional state vectors
    P is a N*N transition matrix
one selected component of X[] is called &quot;entry&quot; state and is treated in  a
special way:
    system state always transits from &quot;entry&quot; state to some another state
    system state can not transit from any state into &quot;entry&quot; state
and another one component of X[] is called &quot;exit&quot; state and is treated  in
a special way too:
    system state can transit from any state into &quot;exit&quot; state
    system state can not transit from &quot;exit&quot; state into any other state
    transition operator discards &quot;exit&quot; state (makes it zero at each turn)
Such conditions basically mean that:
    row of P which corresponds to &quot;entry&quot; state is zero
    column of P which corresponds to &quot;exit&quot; state is zero
Multiplication by such P may decrease sum of vector components.

Such models arise when:
* there is some population of individuals
* individuals can have different states
* individuals can transit from one state to another
* population size is NOT constant
* at every moment of time there is some (unpredictable)  amount  of  &quot;new&quot;
  individuals, which can transit into one of the states at the next turn
* some  individuals  can  move  (predictably)  into &quot;exit&quot; state and leave
  population at the next turn
* you want to model transitions of individuals from one state into another,
  including transitions from the &quot;entry&quot; state and into the &quot;exit&quot; state.
* but you do NOT want to predict amount of &quot;new&quot;  individuals  because  it
  does not depends on individuals already present (hence  system  can  not
  transit INTO entry state - it can only transit FROM it).

This model is discussed  in  more  details  in  the ALGLIB User Guide (see
http://www.alglib.net/dataanalysis/ for more data).

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;=2
    EntryState- index of entry state, in 0..N-1
    ExitState-  index of exit state, in 0..N-1

OUTPUT PARAMETERS:
    State   -   structure stores algorithm state

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdcreateentryexit(
    ae_int_t n,
    ae_int_t entrystate,
    ae_int_t exitstate,
    mcpdstate&amp; s);

</div></pre>
<a name='sub_mcpdcreateexit'></a><h3 class=pageheader><code>mcpdcreateexit</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
DESCRIPTION:

This function is a specialized version of MCPDCreate()  function,  and  we
recommend  you  to read comments for this function for general information
about MCPD solver.

This  function  creates  MCPD (Markov Chains for Population  Data)  solver
for &quot;Exit-state&quot; model,  i.e. model  where  transition from X[i] to X[i+1]
is modelled as
    X[i+1] = P*X[i]
where
    X[i] and X[i+1] are N-dimensional state vectors
    P is a N*N transition matrix
and  one  selected component of X[] is called &quot;exit&quot;  state and is treated
in a special way:
    system state can transit from any state into &quot;exit&quot; state
    system state can not transit from &quot;exit&quot; state into any other state
    transition operator discards &quot;exit&quot; state (makes it zero at each turn)
Such  conditions  basically  mean  that  column  of P which corresponds to
&quot;exit&quot; state is zero. Multiplication by such P may decrease sum of  vector
components.

Such models arise when:
* there is some population of individuals
* individuals can have different states
* individuals can transit from one state to another
* population size is NOT constant - individuals can move into &quot;exit&quot; state
  and leave population at the next turn, but there are no new individuals
* amount of individuals which leave population can be predicted
* you want to model transitions of individuals from one state into another
  (including transitions into the &quot;exit&quot; state)

This model is discussed  in  more  details  in  the ALGLIB User Guide (see
http://www.alglib.net/dataanalysis/ for more data).

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;=2
    ExitState-  index of exit state, in 0..N-1

OUTPUT PARAMETERS:
    State   -   structure stores algorithm state

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdcreateexit(ae_int_t n, ae_int_t exitstate, mcpdstate&amp; s);

</div></pre>
<a name='sub_mcpdresults'></a><h3 class=pageheader><code>mcpdresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
MCPD results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    P       -   array[N,N], transition matrix
    Rep     -   optimization report. You should check Rep.TerminationType
                in  order  to  distinguish  successful  termination  from
                unsuccessful one. Speaking short, positive values  denote
                success, negative ones are failures.
                More information about fields of this  structure  can  be
                found in the comments on MCPDReport datatype.


  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdresults(mcpdstate s, real_2d_array&amp; p, mcpdreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mcpd_simple1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mcpd_simple2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mcpdsetbc'></a><h3 class=pageheader><code>mcpdsetbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to add bound constraints  on  the  elements  of  the
transition matrix P.

MCPD solver has four types of constraints which can be placed on P:
* user-specified equality constraints (optional)
* user-specified bound constraints (optional)
* user-specified general linear constraints (optional)
* basic constraints (always present):
  * non-negativity: P[i,j]&gt;=0
  * consistency: every column of P sums to 1.0

Final  constraints  which  are  passed  to  the  underlying  optimizer are
calculated  as  intersection  of all present constraints. For example, you
may specify boundary constraint on P[0,0] and equality one:
    0.1&lt;=P[0,0]&lt;=0.9
    P[0,0]=0.5
Such  combination  of  constraints  will  be  silently  reduced  to  their
intersection, which is P[0,0]=0.5.

This  function  can  be  used  to  place bound   constraints  on arbitrary
subset  of  elements  of  P.  Set of constraints is specified by BndL/BndU
matrices, which may contain arbitrary combination  of  finite  numbers  or
infinities (like -INF&lt;x&lt;=0.5 or 0.1&lt;=x&lt;+INF).

You can also use MCPDAddBC() function which allows to ADD bound constraint
for one element of P without changing constraints for other elements.

These functions (MCPDSetBC and MCPDAddBC) interact as follows:
* there is internal matrix of bound constraints which is stored in the
  MCPD solver
* MCPDSetBC() replaces this matrix by another one (SET)
* MCPDAddBC() modifies one element of this matrix and  leaves  other  ones
  unchanged (ADD)
* thus  MCPDAddBC()  call  preserves  all  modifications  done by previous
  calls,  while  MCPDSetBC()  completely discards all changes  done to the
  equality constraints.

INPUT PARAMETERS:
    S       -   solver
    BndL    -   lower bounds constraints, array[N,N]. Elements of BndL can
                be finite numbers or -INF.
    BndU    -   upper bounds constraints, array[N,N]. Elements of BndU can
                be finite numbers or +INF.

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsetbc(
    mcpdstate s,
    real_2d_array bndl,
    real_2d_array bndu);

</div></pre>
<a name='sub_mcpdsetec'></a><h3 class=pageheader><code>mcpdsetec</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to add equality constraints on the elements  of  the
transition matrix P.

MCPD solver has four types of constraints which can be placed on P:
* user-specified equality constraints (optional)
* user-specified bound constraints (optional)
* user-specified general linear constraints (optional)
* basic constraints (always present):
  * non-negativity: P[i,j]&gt;=0
  * consistency: every column of P sums to 1.0

Final  constraints  which  are  passed  to  the  underlying  optimizer are
calculated  as  intersection  of all present constraints. For example, you
may specify boundary constraint on P[0,0] and equality one:
    0.1&lt;=P[0,0]&lt;=0.9
    P[0,0]=0.5
Such  combination  of  constraints  will  be  silently  reduced  to  their
intersection, which is P[0,0]=0.5.

This  function  can  be  used  to  place equality constraints on arbitrary
subset of elements of P. Set of constraints is specified by EC, which  may
contain either NAN's or finite numbers from [0,1]. NAN denotes absence  of
constraint, finite number denotes equality constraint on specific  element
of P.

You can also  use  MCPDAddEC()  function  which  allows  to  ADD  equality
constraint  for  one  element  of P without changing constraints for other
elements.

These functions (MCPDSetEC and MCPDAddEC) interact as follows:
* there is internal matrix of equality constraints which is stored in  the
  MCPD solver
* MCPDSetEC() replaces this matrix by another one (SET)
* MCPDAddEC() modifies one element of this matrix and  leaves  other  ones
  unchanged (ADD)
* thus  MCPDAddEC()  call  preserves  all  modifications  done by previous
  calls,  while  MCPDSetEC()  completely discards all changes  done to the
  equality constraints.

INPUT PARAMETERS:
    S       -   solver
    EC      -   equality constraints, array[N,N]. Elements of  EC  can  be
                either NAN's or finite  numbers from  [0,1].  NAN  denotes
                absence  of  constraints,  while  finite  value    denotes
                equality constraint on the corresponding element of P.

NOTES:

1. infinite values of EC will lead to exception being thrown. Values  less
than 0.0 or greater than 1.0 will lead to error code being returned  after
call to MCPDSolve().

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsetec(mcpdstate s, real_2d_array ec);

</div></pre>
<a name='sub_mcpdsetlc'></a><h3 class=pageheader><code>mcpdsetlc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to set linear equality/inequality constraints on the
elements of the transition matrix P.

This function can be used to set one or several general linear constraints
on the elements of P. Two types of constraints are supported:
* equality constraints
* inequality constraints (both less-or-equal and greater-or-equal)

Coefficients  of  constraints  are  specified  by  matrix  C (one  of  the
parameters).  One  row  of  C  corresponds  to  one  constraint.   Because
transition  matrix P has N*N elements,  we  need  N*N columns to store all
coefficients  (they  are  stored row by row), and one more column to store
right part - hence C has N*N+1 columns.  Constraint  kind is stored in the
CT array.

Thus, I-th linear constraint is
    P[0,0]*C[I,0] + P[0,1]*C[I,1] + .. + P[0,N-1]*C[I,N-1] +
        + P[1,0]*C[I,N] + P[1,1]*C[I,N+1] + ... +
        + P[N-1,N-1]*C[I,N*N-1]  ?=?  C[I,N*N]
where ?=? can be either &quot;=&quot; (CT[i]=0), &quot;&lt;=&quot; (CT[i]&lt;0) or &quot;&gt;=&quot; (CT[i]&gt;0).

Your constraint may involve only some subset of P (less than N*N elements).
For example it can be something like
    P[0,0] + P[0,1] = 0.5
In this case you still should pass matrix  with N*N+1 columns, but all its
elements (except for C[0,0], C[0,1] and C[0,N*N-1]) will be zero.

INPUT PARAMETERS:
    S       -   solver
    C       -   array[K,N*N+1] - coefficients of constraints
                (see above for complete description)
    CT      -   array[K] - constraint types
                (see above for complete description)
    K       -   number of equality/inequality constraints, K&gt;=0:
                * if given, only leading K elements of C/CT are used
                * if not given, automatically determined from sizes of C/CT

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsetlc(mcpdstate s, real_2d_array c, integer_1d_array ct);
<b>void</b> alglib::mcpdsetlc(
    mcpdstate s,
    real_2d_array c,
    integer_1d_array ct,
    ae_int_t k);

</div></pre>
<a name='sub_mcpdsetpredictionweights'></a><h3 class=pageheader><code>mcpdsetpredictionweights</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to change prediction weights

MCPD solver scales prediction errors as follows
    Error(P) = ||W*(y-P*x)||^2
where
    x is a system state at time t
    y is a system state at time t+1
    P is a transition matrix
    W is a diagonal scaling matrix

By default, weights are chosen in order  to  minimize  relative prediction
error instead of absolute one. For example, if one component of  state  is
about 0.5 in magnitude and another one is about 0.05, then algorithm  will
make corresponding weights equal to 2.0 and 20.0.

INPUT PARAMETERS:
    S       -   solver
    PW      -   array[N], weights:
                * must be non-negative values (exception will be thrown otherwise)
                * zero values will be replaced by automatically chosen values

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsetpredictionweights(mcpdstate s, real_1d_array pw);

</div></pre>
<a name='sub_mcpdsetprior'></a><h3 class=pageheader><code>mcpdsetprior</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  allows to set prior values used for regularization of your
problem.

By default, regularizing term is equal to r*||P-prior_P||^2, where r is  a
small non-zero value,  P is transition matrix, prior_P is identity matrix,
||X||^2 is a sum of squared elements of X.

This  function  allows  you to change prior values prior_P. You  can  also
change r with MCPDSetTikhonovRegularizer() function.

INPUT PARAMETERS:
    S       -   solver
    PP      -   array[N,N], matrix of prior values:
                1. elements must be real numbers from [0,1]
                2. columns must sum to 1.0.
                First property is checked (exception is thrown otherwise),
                while second one is not checked/enforced.

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsetprior(mcpdstate s, real_2d_array pp);

</div></pre>
<a name='sub_mcpdsettikhonovregularizer'></a><h3 class=pageheader><code>mcpdsettikhonovregularizer</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function allows to  tune  amount  of  Tikhonov  regularization  being
applied to your problem.

By default, regularizing term is equal to r*||P-prior_P||^2, where r is  a
small non-zero value,  P is transition matrix, prior_P is identity matrix,
||X||^2 is a sum of squared elements of X.

This  function  allows  you to change coefficient r. You can  also  change
prior values with MCPDSetPrior() function.

INPUT PARAMETERS:
    S       -   solver
    V       -   regularization  coefficient, finite non-negative value. It
                is  not  recommended  to specify zero value unless you are
                pretty sure that you want it.

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsettikhonovregularizer(mcpdstate s, <b>double</b> v);

</div></pre>
<a name='sub_mcpdsolve'></a><h3 class=pageheader><code>mcpdsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to start solution of the MCPD problem.

After return from this function, you can use MCPDResults() to get solution
and completion code.

  -- ALGLIB --
     Copyright 23.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mcpdsolve(mcpdstate s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mcpd_simple1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mcpd_simple2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='example_mcpd_simple1'></a><h3 class=pageheader>mcpd_simple1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// The very simple MCPD example</font>
    <font color=navy>//</font>
    <font color=navy>// We have a loan portfolio. Our loans can be in one of two states:</font>
    <font color=navy>// * normal loans (<font color=blue><b>&quot;good&quot;</b></font> ones)</font>
    <font color=navy>// * past due loans (<font color=blue><b>&quot;bad&quot;</b></font> ones)</font>
    <font color=navy>//</font>
    <font color=navy>// We assume that:</font>
    <font color=navy>// * loans can transition from any state to any other state. In </font>
    <font color=navy>//   particular, past due loan can become <font color=blue><b>&quot;good&quot;</b></font> one at any moment </font>
    <font color=navy>//   with same (fixed) probability. Not realistic, but it is toy example :)</font>
    <font color=navy>// * portfolio size does not change over time</font>
    <font color=navy>//</font>
    <font color=navy>// Thus, we have following model</font>
    <font color=navy>//     state_new = P*state_old</font>
    <font color=navy>// where</font>
    <font color=navy>//         ( p00  p01 )</font>
    <font color=navy>//     P = (          )</font>
    <font color=navy>//         ( p10  p11 )</font>
    <font color=navy>//</font>
    <font color=navy>// We want to model transitions between these two states using MCPD</font>
    <font color=navy>// approach (Markov Chains <b>for</b> Proportional/Population Data), i.e.</font>
    <font color=navy>// to restore hidden transition matrix P using actual portfolio data.</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * poportional data, i.e. proportion of loans in the normal and past </font>
    <font color=navy>//   due states (not portfolio size measured in some currency, although </font>
    <font color=navy>//   it is possible to work with population data too)</font>
    <font color=navy>// * two tracks, i.e. two sequences which describe portfolio</font>
    <font color=navy>//   evolution from two different starting states: [1,0] (all loans </font>
    <font color=navy>//   are <font color=blue><b>&quot;good&quot;</b></font>) and [0.8,0.2] (only 80% of portfolio is in the <font color=blue><b>&quot;good&quot;</b></font></font>
    <font color=navy>//   state)</font>
    <font color=navy>//</font>
    mcpdstate s;
    mcpdreport rep;
    real_2d_array p;
    real_2d_array track0 = <font color=blue><b>&quot;[[1.00000,0.00000],[0.95000,0.05000],[0.92750,0.07250],[0.91738,0.08263],[0.91282,0.08718]]&quot;</b></font>;
    real_2d_array track1 = <font color=blue><b>&quot;[[0.80000,0.20000],[0.86000,0.14000],[0.88700,0.11300],[0.89915,0.10085]]&quot;</b></font>;

    mcpdcreate(2, s);
    mcpdaddtrack(s, track0);
    mcpdaddtrack(s, track1);
    mcpdsolve(s);
    mcpdresults(s, p, rep);

    <font color=navy>//</font>
    <font color=navy>// Hidden matrix P is equal to</font>
    <font color=navy>//         ( 0.95  0.50 )</font>
    <font color=navy>//         (            )</font>
    <font color=navy>//         ( 0.05  0.50 )</font>
    <font color=navy>// which means that <font color=blue><b>&quot;good&quot;</b></font> loans can become <font color=blue><b>&quot;bad&quot;</b></font> with 5% probability, </font>
    <font color=navy>// <b>while</b> <font color=blue><b>&quot;bad&quot;</b></font> loans will <b>return</b> to good state with 50% probability.</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, p.tostring(2).c_str()); <font color=navy>// EXPECTED: [[0.95,0.50],[0.05,0.50]]</font>
    <b>return</b> 0;
}


</pre><a name='example_mcpd_simple2'></a><h3 class=pageheader>mcpd_simple2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Simple MCPD example</font>
    <font color=navy>//</font>
    <font color=navy>// We have a loan portfolio. Our loans can be in one of three states:</font>
    <font color=navy>// * normal loans</font>
    <font color=navy>// * past due loans</font>
    <font color=navy>// * charged off loans</font>
    <font color=navy>//</font>
    <font color=navy>// We assume that:</font>
    <font color=navy>// * normal loan can stay normal or become past due (but not charged off)</font>
    <font color=navy>// * past due loan can stay past due, become normal or charged off</font>
    <font color=navy>// * charged off loan will stay charged off <b>for</b> the rest of eternity</font>
    <font color=navy>// * portfolio size does not change over time</font>
    <font color=navy>// Not realistic, but it is toy example :)</font>
    <font color=navy>//</font>
    <font color=navy>// Thus, we have following model</font>
    <font color=navy>//     state_new = P*state_old</font>
    <font color=navy>// where</font>
    <font color=navy>//         ( p00  p01    )</font>
    <font color=navy>//     P = ( p10  p11    )</font>
    <font color=navy>//         (      p21  1 )</font>
    <font color=navy>// i.e. four elements of P are known a priori.</font>
    <font color=navy>//</font>
    <font color=navy>// Although it is possible (given enough data) to In order to enforce </font>
    <font color=navy>// this property we set equality constraints on these elements.</font>
    <font color=navy>//</font>
    <font color=navy>// We want to model transitions between these two states using MCPD</font>
    <font color=navy>// approach (Markov Chains <b>for</b> Proportional/Population Data), i.e.</font>
    <font color=navy>// to restore hidden transition matrix P using actual portfolio data.</font>
    <font color=navy>// We have:</font>
    <font color=navy>// * poportional data, i.e. proportion of loans in the current and past </font>
    <font color=navy>//   due states (not portfolio size measured in some currency, although </font>
    <font color=navy>//   it is possible to work with population data too)</font>
    <font color=navy>// * two tracks, i.e. two sequences which describe portfolio</font>
    <font color=navy>//   evolution from two different starting states: [1,0,0] (all loans </font>
    <font color=navy>//   are <font color=blue><b>&quot;good&quot;</b></font>) and [0.8,0.2,0.0] (only 80% of portfolio is in the <font color=blue><b>&quot;good&quot;</b></font></font>
    <font color=navy>//   state)</font>
    <font color=navy>//</font>
    mcpdstate s;
    mcpdreport rep;
    real_2d_array p;
    real_2d_array track0 = <font color=blue><b>&quot;[[1.000000,0.000000,0.000000],[0.950000,0.050000,0.000000],[0.927500,0.060000,0.012500],[0.911125,0.061375,0.027500],[0.896256,0.060900,0.042844]]&quot;</b></font>;
    real_2d_array track1 = <font color=blue><b>&quot;[[0.800000,0.200000,0.000000],[0.860000,0.090000,0.050000],[0.862000,0.065500,0.072500],[0.851650,0.059475,0.088875],[0.838805,0.057451,0.103744]]&quot;</b></font>;

    mcpdcreate(3, s);
    mcpdaddtrack(s, track0);
    mcpdaddtrack(s, track1);
    mcpdaddec(s, 0, 2, 0.0);
    mcpdaddec(s, 1, 2, 0.0);
    mcpdaddec(s, 2, 2, 1.0);
    mcpdaddec(s, 2, 0, 0.0);
    mcpdsolve(s);
    mcpdresults(s, p, rep);

    <font color=navy>//</font>
    <font color=navy>// Hidden matrix P is equal to</font>
    <font color=navy>//         ( 0.95 0.50      )</font>
    <font color=navy>//         ( 0.05 0.25      )</font>
    <font color=navy>//         (      0.25 1.00 ) </font>
    <font color=navy>// which means that <font color=blue><b>&quot;good&quot;</b></font> loans can become past due with 5% probability, </font>
    <font color=navy>// <b>while</b> past due loans will become charged off with 25% probability or</font>
    <font color=navy>// <b>return</b> back to normal state with 50% probability.</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, p.tostring(2).c_str()); <font color=navy>// EXPECTED: [[0.95,0.50,0.00],[0.05,0.25,0.00],[0.00,0.25,1.00]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_minbleic></a><h2 class=pageheader><code>minbleic</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_minbleicreport' class=toc>minbleicreport</a><br>
<a href='#struct_minbleicstate' class=toc>minbleicstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minbleiccreate' class=toc>minbleiccreate</a><br>
<a href='#sub_minbleiccreatef' class=toc>minbleiccreatef</a><br>
<a href='#sub_minbleicoptimize' class=toc>minbleicoptimize</a><br>
<a href='#sub_minbleicrestartfrom' class=toc>minbleicrestartfrom</a><br>
<a href='#sub_minbleicresults' class=toc>minbleicresults</a><br>
<a href='#sub_minbleicresultsbuf' class=toc>minbleicresultsbuf</a><br>
<a href='#sub_minbleicsetbc' class=toc>minbleicsetbc</a><br>
<a href='#sub_minbleicsetcond' class=toc>minbleicsetcond</a><br>
<a href='#sub_minbleicsetgradientcheck' class=toc>minbleicsetgradientcheck</a><br>
<a href='#sub_minbleicsetlc' class=toc>minbleicsetlc</a><br>
<a href='#sub_minbleicsetprecdefault' class=toc>minbleicsetprecdefault</a><br>
<a href='#sub_minbleicsetprecdiag' class=toc>minbleicsetprecdiag</a><br>
<a href='#sub_minbleicsetprecscale' class=toc>minbleicsetprecscale</a><br>
<a href='#sub_minbleicsetscale' class=toc>minbleicsetscale</a><br>
<a href='#sub_minbleicsetstpmax' class=toc>minbleicsetstpmax</a><br>
<a href='#sub_minbleicsetxrep' class=toc>minbleicsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_minbleic_d_1' class=toc>minbleic_d_1</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization with bound constraints</td></tr>
<tr align=left valign=top><td><a href='#example_minbleic_d_2' class=toc>minbleic_d_2</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization with linear inequality constraints</td></tr>
<tr align=left valign=top><td><a href='#example_minbleic_ftrim' class=toc>minbleic_ftrim</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by BLEIC, function with singularities</td></tr>
<tr align=left valign=top><td><a href='#example_minbleic_numdiff' class=toc>minbleic_numdiff</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization with bound constraints and numerical differentiation</td></tr>
</table></div>
<a name='struct_minbleicreport'></a><h3 class=pageheader><code>minbleicreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure stores optimization report:
* IterationsCount           number of iterations
* NFEV                      number of gradient evaluations
* TerminationType           termination type (see below)

TERMINATION CODES

TerminationType field contains completion code, which can be:
  -7    gradient verification failed.
        See MinBLEICSetGradientCheck() for more information.
  -3    inconsistent constraints. Feasible point is
        either nonexistent or too hard to find. Try to
        restart optimizer with better initial approximation
   1    relative function improvement is no more than EpsF.
   2    relative step is no more than EpsX.
   4    gradient norm is no more than EpsG
   5    MaxIts steps was taken
   7    stopping conditions are too stringent,
        further improvement is impossible,
        X contains best point found so far.

ADDITIONAL FIELDS

There are additional fields which can be used for debugging:
* DebugEqErr                error in the equality constraints (2-norm)
* DebugFS                   f, calculated at projection of initial point
                            to the feasible set
* DebugFF                   f, calculated at the final point
* DebugDX                   |X_start-X_final|
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minbleicreport
{
    ae_int_t             iterationscount;
    ae_int_t             nfev;
    ae_int_t             varidx;
    ae_int_t             terminationtype;
    <b>double</b>               debugeqerr;
    <b>double</b>               debugfs;
    <b>double</b>               debugff;
    <b>double</b>               debugdx;
    ae_int_t             debugfeasqpits;
    ae_int_t             debugfeasgpaits;
    ae_int_t             inneriterationscount;
    ae_int_t             outeriterationscount;
};

</div></pre>
<a name='struct_minbleicstate'></a><h3 class=pageheader><code>minbleicstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores nonlinear optimizer state.
You should use functions provided by MinBLEIC subpackage to work with this
object
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minbleicstate
{
};

</div></pre>
<a name='sub_minbleiccreate'></a><h3 class=pageheader><code>minbleiccreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
                     BOUND CONSTRAINED OPTIMIZATION
       WITH ADDITIONAL LINEAR EQUALITY AND INEQUALITY CONSTRAINTS

DESCRIPTION:
The  subroutine  minimizes  function   F(x)  of N arguments subject to any
combination of:
* bound constraints
* linear inequality constraints
* linear equality constraints

REQUIREMENTS:
* user must provide function value and gradient
* starting point X0 must be feasible or
  not too far away from the feasible set
* grad(f) must be Lipschitz continuous on a level set:
  L = { x : f(x)&lt;=f(x0) }
* function must be defined everywhere on the feasible set F

USAGE:

Constrained optimization if far more complex than the unconstrained one.
Here we give very brief outline of the BLEIC optimizer. We strongly recommend
you to read examples in the ALGLIB Reference Manual and to read ALGLIB User Guide
on optimization, which is available at http://www.alglib.net/optimization/

1. User initializes algorithm state with MinBLEICCreate() call

2. USer adds boundary and/or linear constraints by calling
   MinBLEICSetBC() and MinBLEICSetLC() functions.

3. User sets stopping conditions with MinBLEICSetCond().

4. User calls MinBLEICOptimize() function which takes algorithm  state and
   pointer (delegate, etc.) to callback function which calculates F/G.

5. User calls MinBLEICResults() to get solution

6. Optionally user may call MinBLEICRestartFrom() to solve another problem
   with same N but another starting point.
   MinBLEICRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0:
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size ofX
    X       -   starting point, array[N]:
                * it is better to set X to a feasible point
                * but X can be infeasible, in which case algorithm will try
                  to find feasible point first, using X as initial
                  approximation.

OUTPUT PARAMETERS:
    State   -   structure stores algorithm state

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleiccreate(real_1d_array x, minbleicstate&amp; state);
<b>void</b> alglib::minbleiccreate(
    ae_int_t n,
    real_1d_array x,
    minbleicstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minbleic_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minbleic_ftrim' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleiccreatef'></a><h3 class=pageheader><code>minbleiccreatef</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The subroutine is finite difference variant of MinBLEICCreate().  It  uses
finite differences in order to differentiate target function.

Description below contains information which is specific to  this function
only. We recommend to read comments on MinBLEICCreate() in  order  to  get
more information about creation of BLEIC optimizer.

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0:
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    X       -   starting point, array[0..N-1].
    DiffStep-   differentiation step, &gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
1. algorithm uses 4-point central formula for differentiation.
2. differentiation step along I-th axis is equal to DiffStep*S[I] where
   S[] is scaling vector which can be set by MinBLEICSetScale() call.
3. we recommend you to use moderate values of  differentiation  step.  Too
   large step will result in too large truncation  errors, while too small
   step will result in too large numerical  errors.  1.0E-6  can  be  good
   value to start with.
4. Numerical  differentiation  is   very   inefficient  -   one   gradient
   calculation needs 4*N function evaluations. This function will work for
   any N - either small (1...10), moderate (10...100) or  large  (100...).
   However, performance penalty will be too severe for any N's except  for
   small ones.
   We should also say that code which relies on numerical  differentiation
   is  less  robust and precise. CG needs exact gradient values. Imprecise
   gradient may slow  down  convergence, especially  on  highly  nonlinear
   problems.
   Thus  we  recommend to use this function for fast prototyping on small-
   dimensional problems only, and to implement analytical gradient as soon
   as possible.

  -- ALGLIB --
     Copyright 16.05.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleiccreatef(
    real_1d_array x,
    <b>double</b> diffstep,
    minbleicstate&amp; state);
<b>void</b> alglib::minbleiccreatef(
    ae_int_t n,
    real_1d_array x,
    <b>double</b> diffstep,
    minbleicstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_numdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicoptimize'></a><h3 class=pageheader><code>minbleicoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear optimizer

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL

NOTES:

1. This function has two different implementations: one which  uses  exact
   (analytical) user-supplied gradient,  and one which uses function value
   only  and  numerically  differentiates  function  in  order  to  obtain
   gradient.

   Depending  on  the  specific  function  used to create optimizer object
   (either  MinBLEICCreate() for analytical gradient or  MinBLEICCreateF()
   for numerical differentiation) you should choose appropriate variant of
   MinBLEICOptimize() - one  which  accepts  function  AND gradient or one
   which accepts function ONLY.

   Be careful to choose variant of MinBLEICOptimize() which corresponds to
   your optimization scheme! Table below lists different  combinations  of
   callback (function/gradient) passed to MinBLEICOptimize()  and specific
   function used to create optimizer.


                     |         USER PASSED TO MinBLEICOptimize()
   CREATED WITH      |  function only   |  function and gradient
   ------------------------------------------------------------
   MinBLEICCreateF() |     work                FAIL
   MinBLEICCreate()  |     FAIL                work

   Here &quot;FAIL&quot; denotes inappropriate combinations  of  optimizer  creation
   function  and  MinBLEICOptimize()  version.   Attemps   to   use   such
   combination (for  example,  to  create optimizer with MinBLEICCreateF()
   and  to  pass  gradient  information  to  MinCGOptimize()) will lead to
   exception being thrown. Either  you  did  not pass gradient when it WAS
   needed or you passed gradient when it was NOT needed.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> minbleicoptimize(minbleicstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minbleicoptimize(minbleicstate &amp;state,
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minbleic_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minbleic_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minbleic_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicrestartfrom'></a><h3 class=pageheader><code>minbleicrestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine restarts algorithm from new point.
All optimization parameters (including constraints) are left unchanged.

This  function  allows  to  solve multiple  optimization  problems  (which
must have  same number of dimensions) without object reallocation penalty.

INPUT PARAMETERS:
    State   -   structure previously allocated with MinBLEICCreate call.
    X       -   new starting point.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicrestartfrom(minbleicstate state, real_1d_array x);

</div></pre>
<a name='sub_minbleicresults'></a><h3 class=pageheader><code>minbleicresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
BLEIC results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution
    Rep     -   optimization report. You should check Rep.TerminationType
                in  order  to  distinguish  successful  termination  from
                unsuccessful one:
                * -7   gradient verification failed.
                       See MinBLEICSetGradientCheck() for more information.
                * -3   inconsistent constraints. Feasible point is
                       either nonexistent or too hard to find. Try to
                       restart optimizer with better initial approximation
                *  1   relative function improvement is no more than EpsF.
                *  2   scaled step is no more than EpsX.
                *  4   scaled gradient norm is no more than EpsG.
                *  5   MaxIts steps was taken
                More information about fields of this  structure  can  be
                found in the comments on MinBLEICReport datatype.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicresults(
    minbleicstate state,
    real_1d_array&amp; x,
    minbleicreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minbleic_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minbleic_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minbleic_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicresultsbuf'></a><h3 class=pageheader><code>minbleicresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
BLEIC results

Buffered implementation of MinBLEICResults() which uses pre-allocated buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicresultsbuf(
    minbleicstate state,
    real_1d_array&amp; x,
    minbleicreport&amp; rep);

</div></pre>
<a name='sub_minbleicsetbc'></a><h3 class=pageheader><code>minbleicsetbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets boundary constraints for BLEIC optimizer.

Boundary constraints are inactive by default (after initial creation).
They are preserved after algorithm restart with MinBLEICRestartFrom().

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    BndL    -   lower bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very small number or -INF.
    BndU    -   upper bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very large number or +INF.

NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].

NOTE 2: this solver has following useful properties:
* bound constraints are always satisfied exactly
* function is evaluated only INSIDE area specified by  bound  constraints,
  even  when  numerical  differentiation is used (algorithm adjusts  nodes
  according to boundary constraints)

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetbc(
    minbleicstate state,
    real_1d_array bndl,
    real_1d_array bndu);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minbleic_numdiff' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicsetcond'></a><h3 class=pageheader><code>minbleicsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping conditions for the optimizer.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsG    -   &gt;=0
                The  subroutine  finishes  its  work   if   the  condition
                |v|&lt;EpsG is satisfied, where:
                * |.| means Euclidian norm
                * v - scaled gradient vector, v[i]=g[i]*s[i]
                * g - gradient
                * s - scaling coefficients set by MinBLEICSetScale()
    EpsF    -   &gt;=0
                The  subroutine  finishes  its work if on k+1-th iteration
                the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
                is satisfied.
    EpsX    -   &gt;=0
                The subroutine finishes its work if  on  k+1-th  iteration
                the condition |v|&lt;=EpsX is fulfilled, where:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - step vector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by MinBLEICSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations is unlimited.

Passing EpsG=0, EpsF=0 and EpsX=0 and MaxIts=0 (simultaneously) will lead
to automatic stopping criterion selection.

NOTE: when SetCond() called with non-zero MaxIts, BLEIC solver may perform
      slightly more than MaxIts iterations. I.e., MaxIts  sets  non-strict
      limit on iterations count.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetcond(
    minbleicstate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minbleic_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minbleic_numdiff' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicsetgradientcheck'></a><h3 class=pageheader><code>minbleicsetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  turns  on  verification  of  the  user-supplied analytic
gradient:
* user calls this subroutine before optimization begins
* MinBLEICOptimize() is called
* prior to  actual  optimization, for each component  of  parameters being
  optimized X[i] algorithm performs following steps:
  * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
    where X[i] is i-th component of the initial point and S[i] is a  scale
    of i-th parameter
  * if needed, steps are bounded with respect to constraints on X[]
  * F(X) is evaluated at these trial points
  * we perform one more evaluation in the middle point of the interval
  * we  build  cubic  model using function values and derivatives at trial
    points and we compare its prediction with actual value in  the  middle
    point
  * in case difference between prediction and actual value is higher  than
    some predetermined threshold, algorithm stops with completion code -7;
    Rep.VarIdx is set to index of the parameter with incorrect derivative.
* after verification is over, algorithm proceeds to the actual optimization.

NOTE 1: verification  needs  N (parameters count) gradient evaluations. It
        is very costly and you should use  it  only  for  low  dimensional
        problems,  when  you  want  to  be  sure  that  you've   correctly
        calculated  analytic  derivatives.  You  should  not use it in the
        production code (unless you want to check derivatives provided  by
        some third party).

NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
        (so large that function behaviour is significantly non-cubic) will
        lead to false alarms. You may use  different  step  for  different
        parameters by means of setting scale with MinBLEICSetScale().

NOTE 3: this function may lead to false positives. In case it reports that
        I-th  derivative was calculated incorrectly, you may decrease test
        step  and  try  one  more  time  - maybe your function changes too
        sharply  and  your  step  is  too  large for such rapidly chanding
        function.

INPUT PARAMETERS:
    State       -   structure used to store algorithm state
    TestStep    -   verification step:
                    * TestStep=0 turns verification off
                    * TestStep&gt;0 activates verification

  -- ALGLIB --
     Copyright 15.06.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetgradientcheck(
    minbleicstate state,
    <b>double</b> teststep);

</div></pre>
<a name='sub_minbleicsetlc'></a><h3 class=pageheader><code>minbleicsetlc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets linear constraints for BLEIC optimizer.

Linear constraints are inactive by default (after initial creation).
They are preserved after algorithm restart with MinBLEICRestartFrom().

INPUT PARAMETERS:
    State   -   structure previously allocated with MinBLEICCreate call.
    C       -   linear constraints, array[K,N+1].
                Each row of C represents one constraint, either equality
                or inequality (see below):
                * first N elements correspond to coefficients,
                * last element corresponds to the right part.
                All elements of C (including right part) must be finite.
    CT      -   type of constraints, array[K]:
                * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
                * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
                * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
    K       -   number of equality/inequality constraints, K&gt;=0:
                * if given, only leading K elements of C/CT are used
                * if not given, automatically determined from sizes of C/CT

NOTE 1: linear (non-bound) constraints are satisfied only approximately:
* there always exists some minor violation (about Epsilon in magnitude)
  due to rounding errors
* numerical differentiation, if used, may  lead  to  function  evaluations
  outside  of the feasible  area,   because   algorithm  does  NOT  change
  numerical differentiation formula according to linear constraints.
If you want constraints to be  satisfied  exactly, try to reformulate your
problem  in  such  manner  that  all constraints will become boundary ones
(this kind of constraints is always satisfied exactly, both in  the  final
solution and in all intermediate points).

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetlc(
    minbleicstate state,
    real_2d_array c,
    integer_1d_array ct);
<b>void</b> alglib::minbleicsetlc(
    minbleicstate state,
    real_2d_array c,
    integer_1d_array ct,
    ae_int_t k);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minbleic_d_2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minbleicsetprecdefault'></a><h3 class=pageheader><code>minbleicsetprecdefault</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: preconditioning is turned off.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetprecdefault(minbleicstate state);

</div></pre>
<a name='sub_minbleicsetprecdiag'></a><h3 class=pageheader><code>minbleicsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification  of  the  preconditioner:  diagonal of approximate Hessian is
used.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    D       -   diagonal of the approximate Hessian, array[0..N-1],
                (if larger, only leading N elements are used).

NOTE 1: D[i] should be positive. Exception will be thrown otherwise.

NOTE 2: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetprecdiag(minbleicstate state, real_1d_array d);

</div></pre>
<a name='sub_minbleicsetprecscale'></a><h3 class=pageheader><code>minbleicsetprecscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: scale-based diagonal preconditioning.

This preconditioning mode can be useful when you  don't  have  approximate
diagonal of Hessian, but you know that your  variables  are  badly  scaled
(for  example,  one  variable is in [1,10], and another in [1000,100000]),
and most part of the ill-conditioning comes from different scales of vars.

In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
can greatly improve convergence.

IMPRTANT: you should set scale of your variables  with  MinBLEICSetScale()
call  (before  or after MinBLEICSetPrecScale() call). Without knowledge of
the scale of your variables scale-based preconditioner will be  just  unit
matrix.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetprecscale(minbleicstate state);

</div></pre>
<a name='sub_minbleicsetscale'></a><h3 class=pageheader><code>minbleicsetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients for BLEIC optimizer.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

Scaling is also used by finite difference variant of the optimizer  - step
along I-th axis is equal to DiffStep*S[I].

In  most  optimizers  (and  in  the  BLEIC  too)  scaling is NOT a form of
preconditioning. It just  affects  stopping  conditions.  You  should  set
preconditioner  by  separate  call  to  one  of  the  MinBLEICSetPrec...()
functions.

There is a special  preconditioning  mode, however,  which  uses   scaling
coefficients to form diagonal preconditioning matrix. You  can  turn  this
mode on, if you want.   But  you should understand that scaling is not the
same thing as preconditioning - these are two different, although  related
forms of tuning solver.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetscale(minbleicstate state, real_1d_array s);

</div></pre>
<a name='sub_minbleicsetstpmax'></a><h3 class=pageheader><code>minbleicsetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

IMPORTANT: this feature is hard to combine with preconditioning. You can't
set upper limit on step length, when you solve optimization  problem  with
linear (non-boundary) constraints AND preconditioner turned on.

When  non-boundary  constraints  are  present,  you  have to either a) use
preconditioner, or b) use upper limit on step length.  YOU CAN'T USE BOTH!
In this case algorithm will terminate with appropriate error code.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
                want to limit step length.

Use this subroutine when you optimize target function which contains exp()
or  other  fast  growing  functions,  and optimization algorithm makes too
large  steps  which  lead   to overflow. This function allows us to reject
steps  that  are  too  large  (and  therefore  expose  us  to the possible
overflow) without actually calculating function value at the x+stp*d.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetstpmax(minbleicstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_minbleicsetxrep'></a><h3 class=pageheader><code>minbleicsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinBLEICOptimize().

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetxrep(minbleicstate state, <b>bool</b> needxrep);

</div></pre>
<a name='example_minbleic_d_1'></a><h3 class=pageheader>minbleic_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// subject to bound constraints -1&lt;=x&lt;=+1, -1&lt;=y&lt;=+1, using BLEIC optimizer.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[-1,-1]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[+1,+1]&quot;</b></font>;
    minbleicstate state;
    minbleicreport rep;

    <font color=navy>//</font>
    <font color=navy>// These variables define stopping conditions <b>for</b> the optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// We use very simple condition - |g|&lt;=epsg</font>
    <font color=navy>//</font>
    <b>double</b> epsg = 0.000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;

    <font color=navy>//</font>
    <font color=navy>// Now we are ready to actually optimize something:</font>
    <font color=navy>// * first we create optimizer</font>
    <font color=navy>// * we add boundary constraints</font>
    <font color=navy>// * we tune stopping conditions</font>
    <font color=navy>// * and, finally, optimize and obtain results...</font>
    <font color=navy>//</font>
    minbleiccreate(x, state);
    minbleicsetbc(state, bndl, bndu);
    minbleicsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minbleicoptimize(state, function1_grad);
    minbleicresults(state, x, rep);

    <font color=navy>//</font>
    <font color=navy>// ...and evaluate these results</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-1,1]</font>
    <b>return</b> 0;
}


</pre><a name='example_minbleic_d_2'></a><h3 class=pageheader>minbleic_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// subject to inequality constraints:</font>
    <font color=navy>// * x&gt;=2 (posed as general linear constraint),</font>
    <font color=navy>// * x+y&gt;=6</font>
    <font color=navy>// using BLEIC optimizer.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[5,5]&quot;</b></font>;
    real_2d_array c = <font color=blue><b>&quot;[[1,0,2],[1,1,6]]&quot;</b></font>;
    integer_1d_array ct = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    minbleicstate state;
    minbleicreport rep;

    <font color=navy>//</font>
    <font color=navy>// These variables define stopping conditions <b>for</b> the optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// We use very simple condition - |g|&lt;=epsg</font>
    <font color=navy>//</font>
    <b>double</b> epsg = 0.000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;

    <font color=navy>//</font>
    <font color=navy>// Now we are ready to actually optimize something:</font>
    <font color=navy>// * first we create optimizer</font>
    <font color=navy>// * we add linear constraints</font>
    <font color=navy>// * we tune stopping conditions</font>
    <font color=navy>// * and, finally, optimize and obtain results...</font>
    <font color=navy>//</font>
    minbleiccreate(x, state);
    minbleicsetlc(state, c, ct);
    minbleicsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minbleicoptimize(state, function1_grad);
    minbleicresults(state, x, rep);

    <font color=navy>//</font>
    <font color=navy>// ...and evaluate these results</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [2,4]</font>
    <b>return</b> 0;
}


</pre><a name='example_minbleic_ftrim'></a><h3 class=pageheader>minbleic_ftrim example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> s1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x and its gradient.</font>
    <font color=navy>//</font>
    <font color=navy>// function is trimmed when we calculate it near the singular points or outside of the [-1,+1].</font>
    <font color=navy>// Note that we <b>do</b> NOT calculate gradient in this case.</font>
    <font color=navy>//</font>
    <b>if</b>( (x[0]&lt;=-0.999999999999) || (x[0]&gt;=+0.999999999999) )
    {
        func = 1.0E+300;
        <b>return</b>;
    }
    func = pow(1+x[0],-0.2) + pow(1-x[0],-0.3) + 1000*x[0];
    grad[0] = -0.2*pow(1+x[0],-1.2) +0.3*pow(1-x[0],-1.3) + 1000;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x.</font>
    <font color=navy>//</font>
    <font color=navy>// This function is undefined outside of (-1,+1) and has singularities at x=-1 and x=+1.</font>
    <font color=navy>// Special technique called <font color=blue><b>&quot;function trimming&quot;</b></font> allows us to solve this optimization problem </font>
    <font color=navy>// - without using boundary constraints!</font>
    <font color=navy>//</font>
    <font color=navy>// See http://www.alglib.net/optimization/tipsandtricks.php#ftrimming <b>for</b> more information</font>
    <font color=navy>// on this subject.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    <b>double</b> epsg = 1.0e-6;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minbleicstate state;
    minbleicreport rep;

    minbleiccreate(x, state);
    minbleicsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minbleicoptimize(state, s1_grad);
    minbleicresults(state, x, rep);

    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(5).c_str()); <font color=navy>// EXPECTED: [-0.99917305]</font>
    <b>return</b> 0;
}


</pre><a name='example_minbleic_numdiff'></a><h3 class=pageheader>minbleic_numdiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_func(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// subject to bound constraints -1&lt;=x&lt;=+1, -1&lt;=y&lt;=+1, using BLEIC optimizer.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[-1,-1]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[+1,+1]&quot;</b></font>;
    minbleicstate state;
    minbleicreport rep;

    <font color=navy>//</font>
    <font color=navy>// These variables define stopping conditions <b>for</b> the optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// We use very simple condition - |g|&lt;=epsg</font>
    <font color=navy>//</font>
    <b>double</b> epsg = 0.000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;

    <font color=navy>//</font>
    <font color=navy>// This variable contains differentiation step</font>
    <font color=navy>//</font>
    <b>double</b> diffstep = 1.0e-6;

    <font color=navy>//</font>
    <font color=navy>// Now we are ready to actually optimize something:</font>
    <font color=navy>// * first we create optimizer</font>
    <font color=navy>// * we add boundary constraints</font>
    <font color=navy>// * we tune stopping conditions</font>
    <font color=navy>// * and, finally, optimize and obtain results...</font>
    <font color=navy>//</font>
    minbleiccreatef(x, diffstep, state);
    minbleicsetbc(state, bndl, bndu);
    minbleicsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minbleicoptimize(state, function1_func);
    minbleicresults(state, x, rep);

    <font color=navy>//</font>
    <font color=navy>// ...and evaluate these results</font>
    <font color=navy>//</font>
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-1,1]</font>
    <b>return</b> 0;
}


</pre><a name=unit_mincg></a><h2 class=pageheader><code>mincg</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_mincgreport' class=toc>mincgreport</a><br>
<a href='#struct_mincgstate' class=toc>mincgstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mincgcreate' class=toc>mincgcreate</a><br>
<a href='#sub_mincgcreatef' class=toc>mincgcreatef</a><br>
<a href='#sub_mincgoptimize' class=toc>mincgoptimize</a><br>
<a href='#sub_mincgrestartfrom' class=toc>mincgrestartfrom</a><br>
<a href='#sub_mincgresults' class=toc>mincgresults</a><br>
<a href='#sub_mincgresultsbuf' class=toc>mincgresultsbuf</a><br>
<a href='#sub_mincgsetcgtype' class=toc>mincgsetcgtype</a><br>
<a href='#sub_mincgsetcond' class=toc>mincgsetcond</a><br>
<a href='#sub_mincgsetgradientcheck' class=toc>mincgsetgradientcheck</a><br>
<a href='#sub_mincgsetprecdefault' class=toc>mincgsetprecdefault</a><br>
<a href='#sub_mincgsetprecdiag' class=toc>mincgsetprecdiag</a><br>
<a href='#sub_mincgsetprecscale' class=toc>mincgsetprecscale</a><br>
<a href='#sub_mincgsetscale' class=toc>mincgsetscale</a><br>
<a href='#sub_mincgsetstpmax' class=toc>mincgsetstpmax</a><br>
<a href='#sub_mincgsetxrep' class=toc>mincgsetxrep</a><br>
<a href='#sub_mincgsuggeststep' class=toc>mincgsuggeststep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_mincg_d_1' class=toc>mincg_d_1</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by CG</td></tr>
<tr align=left valign=top><td><a href='#example_mincg_d_2' class=toc>mincg_d_2</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization with additional settings and restarts</td></tr>
<tr align=left valign=top><td><a href='#example_mincg_ftrim' class=toc>mincg_ftrim</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by CG, function with singularities</td></tr>
<tr align=left valign=top><td><a href='#example_mincg_numdiff' class=toc>mincg_numdiff</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by CG with numerical differentiation</td></tr>
</table></div>
<a name='struct_mincgreport'></a><h3 class=pageheader><code>mincgreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mincgreport
{
    ae_int_t             iterationscount;
    ae_int_t             nfev;
    ae_int_t             varidx;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_mincgstate'></a><h3 class=pageheader><code>mincgstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores state of the nonlinear CG optimizer.

You should use ALGLIB functions to work with this object.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mincgstate
{
};

</div></pre>
<a name='sub_mincgcreate'></a><h3 class=pageheader><code>mincgcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
        NONLINEAR CONJUGATE GRADIENT METHOD

DESCRIPTION:
The subroutine minimizes function F(x) of N arguments by using one of  the
nonlinear conjugate gradient methods.

These CG methods are globally convergent (even on non-convex functions) as
long as grad(f) is Lipschitz continuous in  a  some  neighborhood  of  the
L = { x : f(x)&lt;=f(x0) }.


REQUIREMENTS:
Algorithm will request following information during its operation:
* function value F and its gradient G (simultaneously) at given point X


USAGE:
1. User initializes algorithm state with MinCGCreate() call
2. User tunes solver parameters with MinCGSetCond(), MinCGSetStpMax() and
   other functions
3. User calls MinCGOptimize() function which takes algorithm  state   and
   pointer (delegate, etc.) to callback function which calculates F/G.
4. User calls MinCGResults() to get solution
5. Optionally, user may call MinCGRestartFrom() to solve another  problem
   with same N but another starting point and/or another function.
   MinCGRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0:
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    X       -   starting point, array[0..N-1].

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 25.03.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgcreate(real_1d_array x, mincgstate&amp; state);
<b>void</b> alglib::mincgcreate(ae_int_t n, real_1d_array x, mincgstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mincg_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_mincg_ftrim' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgcreatef'></a><h3 class=pageheader><code>mincgcreatef</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The subroutine is finite difference variant of MinCGCreate(). It uses
finite differences in order to differentiate target function.

Description below contains information which is specific to this function
only. We recommend to read comments on MinCGCreate() in order to get more
information about creation of CG optimizer.

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0:
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    X       -   starting point, array[0..N-1].
    DiffStep-   differentiation step, &gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
1. algorithm uses 4-point central formula for differentiation.
2. differentiation step along I-th axis is equal to DiffStep*S[I] where
   S[] is scaling vector which can be set by MinCGSetScale() call.
3. we recommend you to use moderate values of  differentiation  step.  Too
   large step will result in too large truncation  errors, while too small
   step will result in too large numerical  errors.  1.0E-6  can  be  good
   value to start with.
4. Numerical  differentiation  is   very   inefficient  -   one   gradient
   calculation needs 4*N function evaluations. This function will work for
   any N - either small (1...10), moderate (10...100) or  large  (100...).
   However, performance penalty will be too severe for any N's except  for
   small ones.
   We should also say that code which relies on numerical  differentiation
   is  less  robust  and  precise.  L-BFGS  needs  exact  gradient values.
   Imprecise  gradient may slow down  convergence,  especially  on  highly
   nonlinear problems.
   Thus  we  recommend to use this function for fast prototyping on small-
   dimensional problems only, and to implement analytical gradient as soon
   as possible.

  -- ALGLIB --
     Copyright 16.05.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgcreatef(
    real_1d_array x,
    <b>double</b> diffstep,
    mincgstate&amp; state);
<b>void</b> alglib::mincgcreatef(
    ae_int_t n,
    real_1d_array x,
    <b>double</b> diffstep,
    mincgstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_numdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgoptimize'></a><h3 class=pageheader><code>mincgoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear optimizer

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL

NOTES:

1. This function has two different implementations: one which  uses  exact
   (analytical) user-supplied  gradient, and one which uses function value
   only  and  numerically  differentiates  function  in  order  to  obtain
   gradient.

   Depending  on  the  specific  function  used to create optimizer object
   (either MinCGCreate()  for analytical gradient  or  MinCGCreateF()  for
   numerical differentiation) you should  choose  appropriate  variant  of
   MinCGOptimize() - one which accepts function AND gradient or one  which
   accepts function ONLY.

   Be careful to choose variant of MinCGOptimize()  which  corresponds  to
   your optimization scheme! Table below lists different  combinations  of
   callback (function/gradient) passed  to  MinCGOptimize()  and  specific
   function used to create optimizer.


                  |         USER PASSED TO MinCGOptimize()
   CREATED WITH   |  function only   |  function and gradient
   ------------------------------------------------------------
   MinCGCreateF() |     work                FAIL
   MinCGCreate()  |     FAIL                work

   Here &quot;FAIL&quot; denotes inappropriate combinations  of  optimizer  creation
   function and MinCGOptimize() version. Attemps to use  such  combination
   (for  example,  to create optimizer with  MinCGCreateF()  and  to  pass
   gradient information to MinCGOptimize()) will lead to  exception  being
   thrown. Either  you  did  not  pass  gradient when it WAS needed or you
   passed gradient when it was NOT needed.

  -- ALGLIB --
     Copyright 20.04.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> mincgoptimize(mincgstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> mincgoptimize(mincgstate &amp;state,
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mincg_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_mincg_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_mincg_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgrestartfrom'></a><h3 class=pageheader><code>mincgrestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  restarts  CG  algorithm from new point. All optimization
parameters are left unchanged.

This  function  allows  to  solve multiple  optimization  problems  (which
must have same number of dimensions) without object reallocation penalty.

INPUT PARAMETERS:
    State   -   structure used to store algorithm state.
    X       -   new starting point.

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgrestartfrom(mincgstate state, real_1d_array x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_d_2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgresults'></a><h3 class=pageheader><code>mincgresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conjugate gradient results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution
    Rep     -   optimization report:
                * Rep.TerminationType completetion code:
                    * -7    gradient verification failed.
                            See MinCGSetGradientCheck() for more information.
                    *  1    relative function improvement is no more than
                            EpsF.
                    *  2    relative step is no more than EpsX.
                    *  4    gradient norm is no more than EpsG
                    *  5    MaxIts steps was taken
                    *  7    stopping conditions are too stringent,
                            further improvement is impossible,
                            we return best X found so far
                    *  8    terminated by user
                * Rep.IterationsCount contains iterations count
                * NFEV countains number of function calculations

  -- ALGLIB --
     Copyright 20.04.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgresults(
    mincgstate state,
    real_1d_array&amp; x,
    mincgreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mincg_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_mincg_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_mincg_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgresultsbuf'></a><h3 class=pageheader><code>mincgresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conjugate gradient results

Buffered implementation of MinCGResults(), which uses pre-allocated buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 20.04.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgresultsbuf(
    mincgstate state,
    real_1d_array&amp; x,
    mincgreport&amp; rep);

</div></pre>
<a name='sub_mincgsetcgtype'></a><h3 class=pageheader><code>mincgsetcgtype</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets CG algorithm.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    CGType  -   algorithm type:
                * -1    automatic selection of the best algorithm
                * 0     DY (Dai and Yuan) algorithm
                * 1     Hybrid DY-HS algorithm

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetcgtype(mincgstate state, ae_int_t cgtype);

</div></pre>
<a name='sub_mincgsetcond'></a><h3 class=pageheader><code>mincgsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping conditions for CG optimization algorithm.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsG    -   &gt;=0
                The  subroutine  finishes  its  work   if   the  condition
                |v|&lt;EpsG is satisfied, where:
                * |.| means Euclidian norm
                * v - scaled gradient vector, v[i]=g[i]*s[i]
                * g - gradient
                * s - scaling coefficients set by MinCGSetScale()
    EpsF    -   &gt;=0
                The  subroutine  finishes  its work if on k+1-th iteration
                the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
                is satisfied.
    EpsX    -   &gt;=0
                The subroutine finishes its work if  on  k+1-th  iteration
                the condition |v|&lt;=EpsX is fulfilled, where:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - ste pvector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by MinCGSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations is unlimited.

Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
automatic stopping criterion selection (small EpsX).

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetcond(
    mincgstate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_mincg_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_mincg_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_mincg_numdiff' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_mincgsetgradientcheck'></a><h3 class=pageheader><code>mincgsetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

This  subroutine  turns  on  verification  of  the  user-supplied analytic
gradient:
* user calls this subroutine before optimization begins
* MinCGOptimize() is called
* prior to  actual  optimization, for each component  of  parameters being
  optimized X[i] algorithm performs following steps:
  * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
    where X[i] is i-th component of the initial point and S[i] is a  scale
    of i-th parameter
  * F(X) is evaluated at these trial points
  * we perform one more evaluation in the middle point of the interval
  * we  build  cubic  model using function values and derivatives at trial
    points and we compare its prediction with actual value in  the  middle
    point
  * in case difference between prediction and actual value is higher  than
    some predetermined threshold, algorithm stops with completion code -7;
    Rep.VarIdx is set to index of the parameter with incorrect derivative.
* after verification is over, algorithm proceeds to the actual optimization.

NOTE 1: verification  needs  N (parameters count) gradient evaluations. It
        is very costly and you should use  it  only  for  low  dimensional
        problems,  when  you  want  to  be  sure  that  you've   correctly
        calculated  analytic  derivatives.  You  should  not use it in the
        production code (unless you want to check derivatives provided  by
        some third party).

NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
        (so large that function behaviour is significantly non-cubic) will
        lead to false alarms. You may use  different  step  for  different
        parameters by means of setting scale with MinCGSetScale().

NOTE 3: this function may lead to false positives. In case it reports that
        I-th  derivative was calculated incorrectly, you may decrease test
        step  and  try  one  more  time  - maybe your function changes too
        sharply  and  your  step  is  too  large for such rapidly chanding
        function.

INPUT PARAMETERS:
    State       -   structure used to store algorithm state
    TestStep    -   verification step:
                    * TestStep=0 turns verification off
                    * TestStep&gt;0 activates verification

  -- ALGLIB --
     Copyright 31.05.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetgradientcheck(mincgstate state, <b>double</b> teststep);

</div></pre>
<a name='sub_mincgsetprecdefault'></a><h3 class=pageheader><code>mincgsetprecdefault</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: preconditioning is turned off.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetprecdefault(mincgstate state);

</div></pre>
<a name='sub_mincgsetprecdiag'></a><h3 class=pageheader><code>mincgsetprecdiag</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification  of  the  preconditioner:  diagonal of approximate Hessian is
used.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    D       -   diagonal of the approximate Hessian, array[0..N-1],
                (if larger, only leading N elements are used).

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

NOTE 2: D[i] should be positive. Exception will be thrown otherwise.

NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetprecdiag(mincgstate state, real_1d_array d);

</div></pre>
<a name='sub_mincgsetprecscale'></a><h3 class=pageheader><code>mincgsetprecscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: scale-based diagonal preconditioning.

This preconditioning mode can be useful when you  don't  have  approximate
diagonal of Hessian, but you know that your  variables  are  badly  scaled
(for  example,  one  variable is in [1,10], and another in [1000,100000]),
and most part of the ill-conditioning comes from different scales of vars.

In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
can greatly improve convergence.

IMPRTANT: you should set scale of your variables with MinCGSetScale() call
(before or after MinCGSetPrecScale() call). Without knowledge of the scale
of your variables scale-based preconditioner will be just unit matrix.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetprecscale(mincgstate state);

</div></pre>
<a name='sub_mincgsetscale'></a><h3 class=pageheader><code>mincgsetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients for CG optimizer.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

Scaling is also used by finite difference variant of CG optimizer  -  step
along I-th axis is equal to DiffStep*S[I].

In   most   optimizers  (and  in  the  CG  too)  scaling is NOT a form  of
preconditioning. It just  affects  stopping  conditions.  You  should  set
preconditioner by separate call to one of the MinCGSetPrec...() functions.

There  is  special  preconditioning  mode, however,  which  uses   scaling
coefficients to form diagonal preconditioning matrix. You  can  turn  this
mode on, if you want.   But  you should understand that scaling is not the
same thing as preconditioning - these are two different, although  related
forms of tuning solver.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetscale(mincgstate state, real_1d_array s);

</div></pre>
<a name='sub_mincgsetstpmax'></a><h3 class=pageheader><code>mincgsetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
                want to limit step length.

Use this subroutine when you optimize target function which contains exp()
or  other  fast  growing  functions,  and optimization algorithm makes too
large  steps  which  leads  to overflow. This function allows us to reject
steps  that  are  too  large  (and  therefore  expose  us  to the possible
overflow) without actually calculating function value at the x+stp*d.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetstpmax(mincgstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_mincgsetxrep'></a><h3 class=pageheader><code>mincgsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinCGOptimize().

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsetxrep(mincgstate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_mincgsuggeststep'></a><h3 class=pageheader><code>mincgsuggeststep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function allows to suggest initial step length to the CG algorithm.

Suggested  step  length  is used as starting point for the line search. It
can be useful when you have  badly  scaled  problem,  i.e.  when  ||grad||
(which is used as initial estimate for the first step) is many  orders  of
magnitude different from the desired step.

Line search  may  fail  on  such problems without good estimate of initial
step length. Imagine, for example, problem with ||grad||=10^50 and desired
step equal to 0.1 Line  search function will use 10^50  as  initial  step,
then  it  will  decrease step length by 2 (up to 20 attempts) and will get
10^44, which is still too large.

This function allows us to tell than line search should  be  started  from
some moderate step length, like 1.0, so algorithm will be able  to  detect
desired step length in a several searches.

Default behavior (when no step is suggested) is to use preconditioner,  if
it is available, to generate initial estimate of step length.

This function influences only first iteration of algorithm. It  should  be
called between MinCGCreate/MinCGRestartFrom() call and MinCGOptimize call.
Suggested step is ignored if you have preconditioner.

INPUT PARAMETERS:
    State   -   structure used to store algorithm state.
    Stp     -   initial estimate of the step length.
                Can be zero (no estimate).

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mincgsuggeststep(mincgstate state, <b>double</b> stp);

</div></pre>
<a name='example_mincg_d_1'></a><h3 class=pageheader>mincg_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// with nonlinear conjugate gradient method.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    mincgstate state;
    mincgreport rep;

    mincgcreate(x, state);
    mincgsetcond(state, epsg, epsf, epsx, maxits);
    alglib::mincgoptimize(state, function1_grad);
    mincgresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name='example_mincg_d_2'></a><h3 class=pageheader>mincg_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// with nonlinear conjugate gradient method.</font>
    <font color=navy>//</font>
    <font color=navy>// Several advanced techniques are demonstrated:</font>
    <font color=navy>// * upper limit on step size</font>
    <font color=navy>// * restart from new point</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    <b>double</b> stpmax = 0.1;
    ae_int_t maxits = 0;
    mincgstate state;
    mincgreport rep;

    <font color=navy>// first run</font>
    mincgcreate(x, state);
    mincgsetcond(state, epsg, epsf, epsx, maxits);
    mincgsetstpmax(state, stpmax);
    alglib::mincgoptimize(state, function1_grad);
    mincgresults(state, x, rep);

    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>

    <font color=navy>// second run - algorithm is restarted with mincgrestartfrom()</font>
    x = <font color=blue><b>&quot;[10,10]&quot;</b></font>;
    mincgrestartfrom(state, x);
    alglib::mincgoptimize(state, function1_grad);
    mincgresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name='example_mincg_ftrim'></a><h3 class=pageheader>mincg_ftrim example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> s1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x and its gradient.</font>
    <font color=navy>//</font>
    <font color=navy>// function is trimmed when we calculate it near the singular points or outside of the [-1,+1].</font>
    <font color=navy>// Note that we <b>do</b> NOT calculate gradient in this case.</font>
    <font color=navy>//</font>
    <b>if</b>( (x[0]&lt;=-0.999999999999) || (x[0]&gt;=+0.999999999999) )
    {
        func = 1.0E+300;
        <b>return</b>;
    }
    func = pow(1+x[0],-0.2) + pow(1-x[0],-0.3) + 1000*x[0];
    grad[0] = -0.2*pow(1+x[0],-1.2) +0.3*pow(1-x[0],-1.3) + 1000;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x.</font>
    <font color=navy>// This function has singularities at the boundary of the [-1,+1], but technique called</font>
    <font color=navy>// <font color=blue><b>&quot;function trimming&quot;</b></font> allows us to solve this optimization problem.</font>
    <font color=navy>//</font>
    <font color=navy>// See http://www.alglib.net/optimization/tipsandtricks.php#ftrimming <b>for</b> more information</font>
    <font color=navy>// on this subject.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    <b>double</b> epsg = 1.0e-6;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    mincgstate state;
    mincgreport rep;

    mincgcreate(x, state);
    mincgsetcond(state, epsg, epsf, epsx, maxits);
    alglib::mincgoptimize(state, s1_grad);
    mincgresults(state, x, rep);

    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(5).c_str()); <font color=navy>// EXPECTED: [-0.99917305]</font>
    <b>return</b> 0;
}


</pre><a name='example_mincg_numdiff'></a><h3 class=pageheader>mincg_numdiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_func(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// using numerical differentiation to calculate gradient.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    <b>double</b> diffstep = 1.0e-6;
    ae_int_t maxits = 0;
    mincgstate state;
    mincgreport rep;

    mincgcreatef(x, diffstep, state);
    mincgsetcond(state, epsg, epsf, epsx, maxits);
    alglib::mincgoptimize(state, function1_func);
    mincgresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name=unit_mincomp></a><h2 class=pageheader><code>mincomp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_minasareport' class=toc>minasareport</a><br>
<a href='#struct_minasastate' class=toc>minasastate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minasacreate' class=toc>minasacreate</a><br>
<a href='#sub_minasaoptimize' class=toc>minasaoptimize</a><br>
<a href='#sub_minasarestartfrom' class=toc>minasarestartfrom</a><br>
<a href='#sub_minasaresults' class=toc>minasaresults</a><br>
<a href='#sub_minasaresultsbuf' class=toc>minasaresultsbuf</a><br>
<a href='#sub_minasasetalgorithm' class=toc>minasasetalgorithm</a><br>
<a href='#sub_minasasetcond' class=toc>minasasetcond</a><br>
<a href='#sub_minasasetstpmax' class=toc>minasasetstpmax</a><br>
<a href='#sub_minasasetxrep' class=toc>minasasetxrep</a><br>
<a href='#sub_minbleicsetbarrierdecay' class=toc>minbleicsetbarrierdecay</a><br>
<a href='#sub_minbleicsetbarrierwidth' class=toc>minbleicsetbarrierwidth</a><br>
<a href='#sub_minlbfgssetcholeskypreconditioner' class=toc>minlbfgssetcholeskypreconditioner</a><br>
<a href='#sub_minlbfgssetdefaultpreconditioner' class=toc>minlbfgssetdefaultpreconditioner</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_minasareport'></a><h3 class=pageheader><code>minasareport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minasareport
{
    ae_int_t             iterationscount;
    ae_int_t             nfev;
    ae_int_t             terminationtype;
    ae_int_t             activeconstraints;
};

</div></pre>
<a name='struct_minasastate'></a><h3 class=pageheader><code>minasastate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minasastate
{
};

</div></pre>
<a name='sub_minasacreate'></a><h3 class=pageheader><code>minasacreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 25.03.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasacreate(
    real_1d_array x,
    real_1d_array bndl,
    real_1d_array bndu,
    minasastate&amp; state);
<b>void</b> alglib::minasacreate(
    ae_int_t n,
    real_1d_array x,
    real_1d_array bndl,
    real_1d_array bndu,
    minasastate&amp; state);

</div></pre>
<a name='sub_minasaoptimize'></a><h3 class=pageheader><code>minasaoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear optimizer

These functions accept following parameters:
    state   -   algorithm state
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL


  -- ALGLIB --
     Copyright 20.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> minasaoptimize(minasastate &amp;state,
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<a name='sub_minasarestartfrom'></a><h3 class=pageheader><code>minasarestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasarestartfrom(
    minasastate state,
    real_1d_array x,
    real_1d_array bndl,
    real_1d_array bndu);

</div></pre>
<a name='sub_minasaresults'></a><h3 class=pageheader><code>minasaresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 20.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasaresults(
    minasastate state,
    real_1d_array&amp; x,
    minasareport&amp; rep);

</div></pre>
<a name='sub_minasaresultsbuf'></a><h3 class=pageheader><code>minasaresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 20.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasaresultsbuf(
    minasastate state,
    real_1d_array&amp; x,
    minasareport&amp; rep);

</div></pre>
<a name='sub_minasasetalgorithm'></a><h3 class=pageheader><code>minasasetalgorithm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasasetalgorithm(minasastate state, ae_int_t algotype);

</div></pre>
<a name='sub_minasasetcond'></a><h3 class=pageheader><code>minasasetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasasetcond(
    minasastate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<a name='sub_minasasetstpmax'></a><h3 class=pageheader><code>minasasetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasasetstpmax(minasastate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_minasasetxrep'></a><h3 class=pageheader><code>minasasetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete optimization algorithm.
Was replaced by MinBLEIC subpackage.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minasasetxrep(minasastate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_minbleicsetbarrierdecay'></a><h3 class=pageheader><code>minbleicsetbarrierdecay</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This is obsolete function which was used by previous version of the  BLEIC
optimizer. It does nothing in the current version of BLEIC.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetbarrierdecay(minbleicstate state, <b>double</b> mudecay);

</div></pre>
<a name='sub_minbleicsetbarrierwidth'></a><h3 class=pageheader><code>minbleicsetbarrierwidth</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This is obsolete function which was used by previous version of the  BLEIC
optimizer. It does nothing in the current version of BLEIC.

  -- ALGLIB --
     Copyright 28.11.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minbleicsetbarrierwidth(minbleicstate state, <b>double</b> mu);

</div></pre>
<a name='sub_minlbfgssetcholeskypreconditioner'></a><h3 class=pageheader><code>minlbfgssetcholeskypreconditioner</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete function, use MinLBFGSSetCholeskyPreconditioner() instead.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetcholeskypreconditioner(
    minlbfgsstate state,
    real_2d_array p,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_minlbfgssetdefaultpreconditioner'></a><h3 class=pageheader><code>minlbfgssetdefaultpreconditioner</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Obsolete function, use MinLBFGSSetPrecDefault() instead.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetdefaultpreconditioner(minlbfgsstate state);

</div></pre>
<a name=unit_minlbfgs></a><h2 class=pageheader><code>minlbfgs</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_minlbfgsreport' class=toc>minlbfgsreport</a><br>
<a href='#struct_minlbfgsstate' class=toc>minlbfgsstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minlbfgscreate' class=toc>minlbfgscreate</a><br>
<a href='#sub_minlbfgscreatef' class=toc>minlbfgscreatef</a><br>
<a href='#sub_minlbfgsoptimize' class=toc>minlbfgsoptimize</a><br>
<a href='#sub_minlbfgsrestartfrom' class=toc>minlbfgsrestartfrom</a><br>
<a href='#sub_minlbfgsresults' class=toc>minlbfgsresults</a><br>
<a href='#sub_minlbfgsresultsbuf' class=toc>minlbfgsresultsbuf</a><br>
<a href='#sub_minlbfgssetcond' class=toc>minlbfgssetcond</a><br>
<a href='#sub_minlbfgssetgradientcheck' class=toc>minlbfgssetgradientcheck</a><br>
<a href='#sub_minlbfgssetpreccholesky' class=toc>minlbfgssetpreccholesky</a><br>
<a href='#sub_minlbfgssetprecdefault' class=toc>minlbfgssetprecdefault</a><br>
<a href='#sub_minlbfgssetprecdiag' class=toc>minlbfgssetprecdiag</a><br>
<a href='#sub_minlbfgssetprecscale' class=toc>minlbfgssetprecscale</a><br>
<a href='#sub_minlbfgssetscale' class=toc>minlbfgssetscale</a><br>
<a href='#sub_minlbfgssetstpmax' class=toc>minlbfgssetstpmax</a><br>
<a href='#sub_minlbfgssetxrep' class=toc>minlbfgssetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_minlbfgs_d_1' class=toc>minlbfgs_d_1</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by L-BFGS</td></tr>
<tr align=left valign=top><td><a href='#example_minlbfgs_d_2' class=toc>minlbfgs_d_2</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization with additional settings and restarts</td></tr>
<tr align=left valign=top><td><a href='#example_minlbfgs_ftrim' class=toc>minlbfgs_ftrim</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by LBFGS, function with singularities</td></tr>
<tr align=left valign=top><td><a href='#example_minlbfgs_numdiff' class=toc>minlbfgs_numdiff</a></td><td width=15>&nbsp;</td><td>Nonlinear optimization by L-BFGS with numerical differentiation</td></tr>
</table></div>
<a name='struct_minlbfgsreport'></a><h3 class=pageheader><code>minlbfgsreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minlbfgsreport
{
    ae_int_t             iterationscount;
    ae_int_t             nfev;
    ae_int_t             varidx;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_minlbfgsstate'></a><h3 class=pageheader><code>minlbfgsstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minlbfgsstate
{
};

</div></pre>
<a name='sub_minlbfgscreate'></a><h3 class=pageheader><code>minlbfgscreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
        LIMITED MEMORY BFGS METHOD FOR LARGE SCALE OPTIMIZATION

DESCRIPTION:
The subroutine minimizes function F(x) of N arguments by  using  a  quasi-
Newton method (LBFGS scheme) which is optimized to use  a  minimum  amount
of memory.
The subroutine generates the approximation of an inverse Hessian matrix by
using information about the last M steps of the algorithm  (instead of N).
It lessens a required amount of memory from a value  of  order  N^2  to  a
value of order 2*N*M.


REQUIREMENTS:
Algorithm will request following information during its operation:
* function value F and its gradient G (simultaneously) at given point X


USAGE:
1. User initializes algorithm state with MinLBFGSCreate() call
2. User tunes solver parameters with MinLBFGSSetCond() MinLBFGSSetStpMax()
   and other functions
3. User calls MinLBFGSOptimize() function which takes algorithm  state and
   pointer (delegate, etc.) to callback function which calculates F/G.
4. User calls MinLBFGSResults() to get solution
5. Optionally user may call MinLBFGSRestartFrom() to solve another problem
   with same N/M but another starting point and/or another function.
   MinLBFGSRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   problem dimension. N&gt;0
    M       -   number of corrections in the BFGS scheme of Hessian
                approximation update. Recommended value:  3&lt;=M&lt;=7. The smaller
                value causes worse convergence, the bigger will  not  cause  a
                considerably better convergence, but will cause a fall in  the
                performance. M&lt;=N.
    X       -   initial solution approximation, array[0..N-1].


OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state


NOTES:
1. you may tune stopping conditions with MinLBFGSSetCond() function
2. if target function contains exp() or other fast growing functions,  and
   optimization algorithm makes too large steps which leads  to  overflow,
   use MinLBFGSSetStpMax() function to bound algorithm's  steps.  However,
   L-BFGS rarely needs such a tuning.


  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgscreate(
    ae_int_t m,
    real_1d_array x,
    minlbfgsstate&amp; state);
<b>void</b> alglib::minlbfgscreate(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    minlbfgsstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_ftrim' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgscreatef'></a><h3 class=pageheader><code>minlbfgscreatef</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The subroutine is finite difference variant of MinLBFGSCreate().  It  uses
finite differences in order to differentiate target function.

Description below contains information which is specific to  this function
only. We recommend to read comments on MinLBFGSCreate() in  order  to  get
more information about creation of LBFGS optimizer.

INPUT PARAMETERS:
    N       -   problem dimension, N&gt;0:
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    M       -   number of corrections in the BFGS scheme of Hessian
                approximation update. Recommended value:  3&lt;=M&lt;=7. The smaller
                value causes worse convergence, the bigger will  not  cause  a
                considerably better convergence, but will cause a fall in  the
                performance. M&lt;=N.
    X       -   starting point, array[0..N-1].
    DiffStep-   differentiation step, &gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
1. algorithm uses 4-point central formula for differentiation.
2. differentiation step along I-th axis is equal to DiffStep*S[I] where
   S[] is scaling vector which can be set by MinLBFGSSetScale() call.
3. we recommend you to use moderate values of  differentiation  step.  Too
   large step will result in too large truncation  errors, while too small
   step will result in too large numerical  errors.  1.0E-6  can  be  good
   value to start with.
4. Numerical  differentiation  is   very   inefficient  -   one   gradient
   calculation needs 4*N function evaluations. This function will work for
   any N - either small (1...10), moderate (10...100) or  large  (100...).
   However, performance penalty will be too severe for any N's except  for
   small ones.
   We should also say that code which relies on numerical  differentiation
   is   less  robust  and  precise.  LBFGS  needs  exact  gradient values.
   Imprecise gradient may slow  down  convergence,  especially  on  highly
   nonlinear problems.
   Thus  we  recommend to use this function for fast prototyping on small-
   dimensional problems only, and to implement analytical gradient as soon
   as possible.

  -- ALGLIB --
     Copyright 16.05.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgscreatef(
    ae_int_t m,
    real_1d_array x,
    <b>double</b> diffstep,
    minlbfgsstate&amp; state);
<b>void</b> alglib::minlbfgscreatef(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    <b>double</b> diffstep,
    minlbfgsstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_numdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgsoptimize'></a><h3 class=pageheader><code>minlbfgsoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear optimizer

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL

NOTES:

1. This function has two different implementations: one which  uses  exact
   (analytical) user-supplied gradient,  and one which uses function value
   only  and  numerically  differentiates  function  in  order  to  obtain
   gradient.

   Depending  on  the  specific  function  used to create optimizer object
   (either MinLBFGSCreate() for analytical gradient  or  MinLBFGSCreateF()
   for numerical differentiation) you should choose appropriate variant of
   MinLBFGSOptimize() - one  which  accepts  function  AND gradient or one
   which accepts function ONLY.

   Be careful to choose variant of MinLBFGSOptimize() which corresponds to
   your optimization scheme! Table below lists different  combinations  of
   callback (function/gradient) passed to MinLBFGSOptimize()  and specific
   function used to create optimizer.


                     |         USER PASSED TO MinLBFGSOptimize()
   CREATED WITH      |  function only   |  function and gradient
   ------------------------------------------------------------
   MinLBFGSCreateF() |     work                FAIL
   MinLBFGSCreate()  |     FAIL                work

   Here &quot;FAIL&quot; denotes inappropriate combinations  of  optimizer  creation
   function  and  MinLBFGSOptimize()  version.   Attemps   to   use   such
   combination (for example, to create optimizer with MinLBFGSCreateF() and
   to pass gradient information to MinCGOptimize()) will lead to exception
   being thrown. Either  you  did  not pass gradient when it WAS needed or
   you passed gradient when it was NOT needed.

  -- ALGLIB --
     Copyright 20.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> minlbfgsoptimize(minlbfgsstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minlbfgsoptimize(minlbfgsstate &amp;state,
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgsrestartfrom'></a><h3 class=pageheader><code>minlbfgsrestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine restarts LBFGS algorithm from new point. All optimization
parameters are left unchanged.

This  function  allows  to  solve multiple  optimization  problems  (which
must have same number of dimensions) without object reallocation penalty.

INPUT PARAMETERS:
    State   -   structure used to store algorithm state
    X       -   new starting point.

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgsrestartfrom(minlbfgsstate state, real_1d_array x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_d_2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgsresults'></a><h3 class=pageheader><code>minlbfgsresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
L-BFGS algorithm results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution
    Rep     -   optimization report:
                * Rep.TerminationType completetion code:
                    * -7    gradient verification failed.
                            See MinLBFGSSetGradientCheck() for more information.
                    * -2    rounding errors prevent further improvement.
                            X contains best point found.
                    * -1    incorrect parameters were specified
                    *  1    relative function improvement is no more than
                            EpsF.
                    *  2    relative step is no more than EpsX.
                    *  4    gradient norm is no more than EpsG
                    *  5    MaxIts steps was taken
                    *  7    stopping conditions are too stringent,
                            further improvement is impossible
                * Rep.IterationsCount contains iterations count
                * NFEV countains number of function calculations

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgsresults(
    minlbfgsstate state,
    real_1d_array&amp; x,
    minlbfgsreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_numdiff' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_ftrim' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgsresultsbuf'></a><h3 class=pageheader><code>minlbfgsresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
L-BFGS algorithm results

Buffered implementation of MinLBFGSResults which uses pre-allocated buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 20.08.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgsresultsbuf(
    minlbfgsstate state,
    real_1d_array&amp; x,
    minlbfgsreport&amp; rep);

</div></pre>
<a name='sub_minlbfgssetcond'></a><h3 class=pageheader><code>minlbfgssetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping conditions for L-BFGS optimization algorithm.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsG    -   &gt;=0
                The  subroutine  finishes  its  work   if   the  condition
                |v|&lt;EpsG is satisfied, where:
                * |.| means Euclidian norm
                * v - scaled gradient vector, v[i]=g[i]*s[i]
                * g - gradient
                * s - scaling coefficients set by MinLBFGSSetScale()
    EpsF    -   &gt;=0
                The  subroutine  finishes  its work if on k+1-th iteration
                the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
                is satisfied.
    EpsX    -   &gt;=0
                The subroutine finishes its work if  on  k+1-th  iteration
                the condition |v|&lt;=EpsX is fulfilled, where:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - ste pvector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by MinLBFGSSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations is unlimited.

Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
automatic stopping criterion selection (small EpsX).

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetcond(
    minlbfgsstate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlbfgs_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_d_2' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlbfgs_numdiff' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_minlbfgssetgradientcheck'></a><h3 class=pageheader><code>minlbfgssetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  turns  on  verification  of  the  user-supplied analytic
gradient:
* user calls this subroutine before optimization begins
* MinLBFGSOptimize() is called
* prior to  actual  optimization, for each component  of  parameters being
  optimized X[i] algorithm performs following steps:
  * two trial steps are made to X[i]-TestStep*S[i] and X[i]+TestStep*S[i],
    where X[i] is i-th component of the initial point and S[i] is a  scale
    of i-th parameter
  * if needed, steps are bounded with respect to constraints on X[]
  * F(X) is evaluated at these trial points
  * we perform one more evaluation in the middle point of the interval
  * we  build  cubic  model using function values and derivatives at trial
    points and we compare its prediction with actual value in  the  middle
    point
  * in case difference between prediction and actual value is higher  than
    some predetermined threshold, algorithm stops with completion code -7;
    Rep.VarIdx is set to index of the parameter with incorrect derivative.
* after verification is over, algorithm proceeds to the actual optimization.

NOTE 1: verification  needs  N (parameters count) gradient evaluations. It
        is very costly and you should use  it  only  for  low  dimensional
        problems,  when  you  want  to  be  sure  that  you've   correctly
        calculated  analytic  derivatives.  You  should  not use it in the
        production code (unless you want to check derivatives provided  by
        some third party).

NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
        (so large that function behaviour is significantly non-cubic) will
        lead to false alarms. You may use  different  step  for  different
        parameters by means of setting scale with MinLBFGSSetScale().

NOTE 3: this function may lead to false positives. In case it reports that
        I-th  derivative was calculated incorrectly, you may decrease test
        step  and  try  one  more  time  - maybe your function changes too
        sharply  and  your  step  is  too  large for such rapidly chanding
        function.

INPUT PARAMETERS:
    State       -   structure used to store algorithm state
    TestStep    -   verification step:
                    * TestStep=0 turns verification off
                    * TestStep&gt;0 activates verification

  -- ALGLIB --
     Copyright 24.05.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetgradientcheck(
    minlbfgsstate state,
    <b>double</b> teststep);

</div></pre>
<a name='sub_minlbfgssetpreccholesky'></a><h3 class=pageheader><code>minlbfgssetpreccholesky</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: Cholesky factorization of  approximate
Hessian is used.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    P       -   triangular preconditioner, Cholesky factorization of
                the approximate Hessian. array[0..N-1,0..N-1],
                (if larger, only leading N elements are used).
    IsUpper -   whether upper or lower triangle of P is given
                (other triangle is not referenced)

After call to this function preconditioner is changed to P  (P  is  copied
into the internal buffer).

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

NOTE 2:  P  should  be nonsingular. Exception will be thrown otherwise.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetpreccholesky(
    minlbfgsstate state,
    real_2d_array p,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_minlbfgssetprecdefault'></a><h3 class=pageheader><code>minlbfgssetprecdefault</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification  of  the  preconditioner:  default  preconditioner    (simple
scaling, same for all elements of X) is used.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetprecdefault(minlbfgsstate state);

</div></pre>
<a name='sub_minlbfgssetprecdiag'></a><h3 class=pageheader><code>minlbfgssetprecdiag</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification  of  the  preconditioner:  diagonal of approximate Hessian is
used.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    D       -   diagonal of the approximate Hessian, array[0..N-1],
                (if larger, only leading N elements are used).

NOTE:  you  can  change  preconditioner  &quot;on  the  fly&quot;,  during algorithm
iterations.

NOTE 2: D[i] should be positive. Exception will be thrown otherwise.

NOTE 3: you should pass diagonal of approximate Hessian - NOT ITS INVERSE.

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetprecdiag(minlbfgsstate state, real_1d_array d);

</div></pre>
<a name='sub_minlbfgssetprecscale'></a><h3 class=pageheader><code>minlbfgssetprecscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Modification of the preconditioner: scale-based diagonal preconditioning.

This preconditioning mode can be useful when you  don't  have  approximate
diagonal of Hessian, but you know that your  variables  are  badly  scaled
(for  example,  one  variable is in [1,10], and another in [1000,100000]),
and most part of the ill-conditioning comes from different scales of vars.

In this case simple  scale-based  preconditioner,  with H[i] = 1/(s[i]^2),
can greatly improve convergence.

IMPRTANT: you should set scale of your variables  with  MinLBFGSSetScale()
call  (before  or after MinLBFGSSetPrecScale() call). Without knowledge of
the scale of your variables scale-based preconditioner will be  just  unit
matrix.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 13.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetprecscale(minlbfgsstate state);

</div></pre>
<a name='sub_minlbfgssetscale'></a><h3 class=pageheader><code>minlbfgssetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients for LBFGS optimizer.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

Scaling is also used by finite difference variant of the optimizer  - step
along I-th axis is equal to DiffStep*S[I].

In  most  optimizers  (and  in  the  LBFGS  too)  scaling is NOT a form of
preconditioning. It just  affects  stopping  conditions.  You  should  set
preconditioner  by  separate  call  to  one  of  the  MinLBFGSSetPrec...()
functions.

There  is  special  preconditioning  mode, however,  which  uses   scaling
coefficients to form diagonal preconditioning matrix. You  can  turn  this
mode on, if you want.   But  you should understand that scaling is not the
same thing as preconditioning - these are two different, although  related
forms of tuning solver.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetscale(minlbfgsstate state, real_1d_array s);

</div></pre>
<a name='sub_minlbfgssetstpmax'></a><h3 class=pageheader><code>minlbfgssetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0 (default),  if
                you don't want to limit step length.

Use this subroutine when you optimize target function which contains exp()
or  other  fast  growing  functions,  and optimization algorithm makes too
large  steps  which  leads  to overflow. This function allows us to reject
steps  that  are  too  large  (and  therefore  expose  us  to the possible
overflow) without actually calculating function value at the x+stp*d.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetstpmax(minlbfgsstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_minlbfgssetxrep'></a><h3 class=pageheader><code>minlbfgssetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinLBFGSOptimize().


  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlbfgssetxrep(minlbfgsstate state, <b>bool</b> needxrep);

</div></pre>
<a name='example_minlbfgs_d_1'></a><h3 class=pageheader>minlbfgs_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// using LBFGS method.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlbfgsstate state;
    minlbfgsreport rep;

    minlbfgscreate(1, x, state);
    minlbfgssetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlbfgsoptimize(state, function1_grad);
    minlbfgsresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlbfgs_d_2'></a><h3 class=pageheader>minlbfgs_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// using LBFGS method.</font>
    <font color=navy>//</font>
    <font color=navy>// Several advanced techniques are demonstrated:</font>
    <font color=navy>// * upper limit on step size</font>
    <font color=navy>// * restart from new point</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    <b>double</b> stpmax = 0.1;
    ae_int_t maxits = 0;
    minlbfgsstate state;
    minlbfgsreport rep;

    <font color=navy>// first run</font>
    minlbfgscreate(1, x, state);
    minlbfgssetcond(state, epsg, epsf, epsx, maxits);
    minlbfgssetstpmax(state, stpmax);
    alglib::minlbfgsoptimize(state, function1_grad);
    minlbfgsresults(state, x, rep);

    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>

    <font color=navy>// second run - algorithm is restarted</font>
    x = <font color=blue><b>&quot;[10,10]&quot;</b></font>;
    minlbfgsrestartfrom(state, x);
    alglib::minlbfgsoptimize(state, function1_grad);
    minlbfgsresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlbfgs_ftrim'></a><h3 class=pageheader>minlbfgs_ftrim example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> s1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x and its gradient.</font>
    <font color=navy>//</font>
    <font color=navy>// function is trimmed when we calculate it near the singular points or outside of the [-1,+1].</font>
    <font color=navy>// Note that we <b>do</b> NOT calculate gradient in this case.</font>
    <font color=navy>//</font>
    <b>if</b>( (x[0]&lt;=-0.999999999999) || (x[0]&gt;=+0.999999999999) )
    {
        func = 1.0E+300;
        <b>return</b>;
    }
    func = pow(1+x[0],-0.2) + pow(1-x[0],-0.3) + 1000*x[0];
    grad[0] = -0.2*pow(1+x[0],-1.2) +0.3*pow(1-x[0],-1.3) + 1000;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x) = (1+x)^(-0.2) + (1-x)^(-0.3) + 1000*x.</font>
    <font color=navy>// This function has singularities at the boundary of the [-1,+1], but technique called</font>
    <font color=navy>// <font color=blue><b>&quot;function trimming&quot;</b></font> allows us to solve this optimization problem.</font>
    <font color=navy>//</font>
    <font color=navy>// See http://www.alglib.net/optimization/tipsandtricks.php#ftrimming <b>for</b> more information</font>
    <font color=navy>// on this subject.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    <b>double</b> epsg = 1.0e-6;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlbfgsstate state;
    minlbfgsreport rep;

    minlbfgscreate(1, x, state);
    minlbfgssetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlbfgsoptimize(state, s1_grad);
    minlbfgsresults(state, x, rep);

    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(5).c_str()); <font color=navy>// EXPECTED: [-0.99917305]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlbfgs_numdiff'></a><h3 class=pageheader>minlbfgs_numdiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_func(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of f(x,y) = 100*(x+3)^4+(y-3)^4</font>
    <font color=navy>// using numerical differentiation to calculate gradient.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    <b>double</b> diffstep = 1.0e-6;
    ae_int_t maxits = 0;
    minlbfgsstate state;
    minlbfgsreport rep;

    minlbfgscreatef(1, x, diffstep, state);
    minlbfgssetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlbfgsoptimize(state, function1_func);
    minlbfgsresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,3]</font>
    <b>return</b> 0;
}


</pre><a name=unit_minlm></a><h2 class=pageheader><code>minlm</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_minlmreport' class=toc>minlmreport</a><br>
<a href='#struct_minlmstate' class=toc>minlmstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minlmcreatefgh' class=toc>minlmcreatefgh</a><br>
<a href='#sub_minlmcreatefgj' class=toc>minlmcreatefgj</a><br>
<a href='#sub_minlmcreatefj' class=toc>minlmcreatefj</a><br>
<a href='#sub_minlmcreatev' class=toc>minlmcreatev</a><br>
<a href='#sub_minlmcreatevgj' class=toc>minlmcreatevgj</a><br>
<a href='#sub_minlmcreatevj' class=toc>minlmcreatevj</a><br>
<a href='#sub_minlmoptimize' class=toc>minlmoptimize</a><br>
<a href='#sub_minlmrestartfrom' class=toc>minlmrestartfrom</a><br>
<a href='#sub_minlmresults' class=toc>minlmresults</a><br>
<a href='#sub_minlmresultsbuf' class=toc>minlmresultsbuf</a><br>
<a href='#sub_minlmsetacctype' class=toc>minlmsetacctype</a><br>
<a href='#sub_minlmsetbc' class=toc>minlmsetbc</a><br>
<a href='#sub_minlmsetcond' class=toc>minlmsetcond</a><br>
<a href='#sub_minlmsetgradientcheck' class=toc>minlmsetgradientcheck</a><br>
<a href='#sub_minlmsetscale' class=toc>minlmsetscale</a><br>
<a href='#sub_minlmsetstpmax' class=toc>minlmsetstpmax</a><br>
<a href='#sub_minlmsetxrep' class=toc>minlmsetxrep</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_minlm_d_fgh' class=toc>minlm_d_fgh</a></td><td width=15>&nbsp;</td><td>Nonlinear Hessian-based optimization for general functions</td></tr>
<tr align=left valign=top><td><a href='#example_minlm_d_restarts' class=toc>minlm_d_restarts</a></td><td width=15>&nbsp;</td><td>Efficient restarts of LM optimizer</td></tr>
<tr align=left valign=top><td><a href='#example_minlm_d_v' class=toc>minlm_d_v</a></td><td width=15>&nbsp;</td><td>Nonlinear least squares optimization using function vector only</td></tr>
<tr align=left valign=top><td><a href='#example_minlm_d_vb' class=toc>minlm_d_vb</a></td><td width=15>&nbsp;</td><td>Bound constrained nonlinear least squares optimization</td></tr>
<tr align=left valign=top><td><a href='#example_minlm_d_vj' class=toc>minlm_d_vj</a></td><td width=15>&nbsp;</td><td>Nonlinear least squares optimization using function vector and Jacobian</td></tr>
</table></div>
<a name='struct_minlmreport'></a><h3 class=pageheader><code>minlmreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Optimization report, filled by MinLMResults() function

FIELDS:
* TerminationType, completetion code:
    * -7    derivative correctness check failed;
            see Rep.WrongNum, Rep.WrongI, Rep.WrongJ for
            more information.
    *  1    relative function improvement is no more than
            EpsF.
    *  2    relative step is no more than EpsX.
    *  4    gradient is no more than EpsG.
    *  5    MaxIts steps was taken
    *  7    stopping conditions are too stringent,
            further improvement is impossible
* IterationsCount, contains iterations count
* NFunc, number of function calculations
* NJac, number of Jacobi matrix calculations
* NGrad, number of gradient calculations
* NHess, number of Hessian calculations
* NCholesky, number of Cholesky decomposition calculations
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minlmreport
{
    ae_int_t             iterationscount;
    ae_int_t             terminationtype;
    ae_int_t             funcidx;
    ae_int_t             varidx;
    ae_int_t             nfunc;
    ae_int_t             njac;
    ae_int_t             ngrad;
    ae_int_t             nhess;
    ae_int_t             ncholesky;
};

</div></pre>
<a name='struct_minlmstate'></a><h3 class=pageheader><code>minlmstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Levenberg-Marquardt optimizer.

This structure should be created using one of the MinLMCreate???()
functions. You should not access its fields directly; use ALGLIB functions
to work with it.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minlmstate
{
};

</div></pre>
<a name='sub_minlmcreatefgh'></a><h3 class=pageheader><code>minlmcreatefgh</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
    LEVENBERG-MARQUARDT-LIKE METHOD FOR NON-LINEAR OPTIMIZATION

DESCRIPTION:
This  function  is  used  to  find  minimum  of general form (not &quot;sum-of-
-squares&quot;) function
    F = F(x[0], ..., x[n-1])
using  its  gradient  and  Hessian.  Levenberg-Marquardt modification with
L-BFGS pre-optimization and internal pre-conditioned  L-BFGS  optimization
after each Levenberg-Marquardt step is used.


REQUIREMENTS:
This algorithm will request following information during its operation:

* function value F at given point X
* F and gradient G (simultaneously) at given point X
* F, G and Hessian H (simultaneously) at given point X

There are several overloaded versions of  MinLMOptimize()  function  which
correspond  to  different LM-like optimization algorithms provided by this
unit. You should choose version which accepts func(),  grad()  and  hess()
function pointers. First pointer is used to calculate F  at  given  point,
second  one  calculates  F(x)  and  grad F(x),  third one calculates F(x),
grad F(x), hess F(x).

You can try to initialize MinLMState structure with FGH-function and  then
use incorrect version of MinLMOptimize() (for example, version which  does
not provide Hessian matrix), but it will lead to  exception  being  thrown
after first attempt to calculate Hessian.


USAGE:
1. User initializes algorithm state with MinLMCreateFGH() call
2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
   other functions
3. User calls MinLMOptimize() function which  takes algorithm  state   and
   pointers (delegates, etc.) to callback functions.
4. User calls MinLMResults() to get solution
5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
   with same N but another starting point and/or another function.
   MinLMRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   dimension, N&gt;1
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    X       -   initial solution, array[0..N-1]

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
1. you may tune stopping conditions with MinLMSetCond() function
2. if target function contains exp() or other fast growing functions,  and
   optimization algorithm makes too large steps which leads  to  overflow,
   use MinLMSetStpMax() function to bound algorithm's steps.

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatefgh(real_1d_array x, minlmstate&amp; state);
<b>void</b> alglib::minlmcreatefgh(
    ae_int_t n,
    real_1d_array x,
    minlmstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_fgh' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmcreatefgj'></a><h3 class=pageheader><code>minlmcreatefgj</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This is obsolete function.

Since ALGLIB 3.3 it is equivalent to MinLMCreateFJ().

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatefgj(
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);
<b>void</b> alglib::minlmcreatefgj(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);

</div></pre>
<a name='sub_minlmcreatefj'></a><h3 class=pageheader><code>minlmcreatefj</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is considered obsolete since ALGLIB 3.1.0 and is present for
backward  compatibility  only.  We  recommend  to use MinLMCreateVJ, which
provides similar, but more consistent and feature-rich interface.

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatefj(
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);
<b>void</b> alglib::minlmcreatefj(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);

</div></pre>
<a name='sub_minlmcreatev'></a><h3 class=pageheader><code>minlmcreatev</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
                IMPROVED LEVENBERG-MARQUARDT METHOD FOR
                 NON-LINEAR LEAST SQUARES OPTIMIZATION

DESCRIPTION:
This function is used to find minimum of function which is represented  as
sum of squares:
    F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
using value of function vector f[] only. Finite differences  are  used  to
calculate Jacobian.


REQUIREMENTS:
This algorithm will request following information during its operation:
* function vector f[] at given point X

There are several overloaded versions of  MinLMOptimize()  function  which
correspond  to  different LM-like optimization algorithms provided by this
unit. You should choose version which accepts fvec() callback.

You can try to initialize MinLMState structure with VJ  function and  then
use incorrect version  of  MinLMOptimize()  (for  example,  version  which
works with general form function and does not accept function vector), but
it will  lead  to  exception being thrown after first attempt to calculate
Jacobian.


USAGE:
1. User initializes algorithm state with MinLMCreateV() call
2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
   other functions
3. User calls MinLMOptimize() function which  takes algorithm  state   and
   callback functions.
4. User calls MinLMResults() to get solution
5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
   with same N/M but another starting point and/or another function.
   MinLMRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   dimension, N&gt;1
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    M       -   number of functions f[i]
    X       -   initial solution, array[0..N-1]
    DiffStep-   differentiation step, &gt;0

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

See also MinLMIteration, MinLMResults.

NOTES:
1. you may tune stopping conditions with MinLMSetCond() function
2. if target function contains exp() or other fast growing functions,  and
   optimization algorithm makes too large steps which leads  to  overflow,
   use MinLMSetStpMax() function to bound algorithm's steps.

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatev(
    ae_int_t m,
    real_1d_array x,
    <b>double</b> diffstep,
    minlmstate&amp; state);
<b>void</b> alglib::minlmcreatev(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    <b>double</b> diffstep,
    minlmstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_v' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vb' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlm_d_restarts' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmcreatevgj'></a><h3 class=pageheader><code>minlmcreatevgj</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This is obsolete function.

Since ALGLIB 3.3 it is equivalent to MinLMCreateVJ().

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatevgj(
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);
<b>void</b> alglib::minlmcreatevgj(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);

</div></pre>
<a name='sub_minlmcreatevj'></a><h3 class=pageheader><code>minlmcreatevj</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
                IMPROVED LEVENBERG-MARQUARDT METHOD FOR
                 NON-LINEAR LEAST SQUARES OPTIMIZATION

DESCRIPTION:
This function is used to find minimum of function which is represented  as
sum of squares:
    F(x) = f[0]^2(x[0],...,x[n-1]) + ... + f[m-1]^2(x[0],...,x[n-1])
using value of function vector f[] and Jacobian of f[].


REQUIREMENTS:
This algorithm will request following information during its operation:

* function vector f[] at given point X
* function vector f[] and Jacobian of f[] (simultaneously) at given point

There are several overloaded versions of  MinLMOptimize()  function  which
correspond  to  different LM-like optimization algorithms provided by this
unit. You should choose version which accepts fvec()  and jac() callbacks.
First  one  is used to calculate f[] at given point, second one calculates
f[] and Jacobian df[i]/dx[j].

You can try to initialize MinLMState structure with VJ  function and  then
use incorrect version  of  MinLMOptimize()  (for  example,  version  which
works  with  general  form function and does not provide Jacobian), but it
will  lead  to  exception  being  thrown  after first attempt to calculate
Jacobian.


USAGE:
1. User initializes algorithm state with MinLMCreateVJ() call
2. User tunes solver parameters with MinLMSetCond(),  MinLMSetStpMax() and
   other functions
3. User calls MinLMOptimize() function which  takes algorithm  state   and
   callback functions.
4. User calls MinLMResults() to get solution
5. Optionally, user may call MinLMRestartFrom() to solve  another  problem
   with same N/M but another starting point and/or another function.
   MinLMRestartFrom() allows to reuse already initialized structure.


INPUT PARAMETERS:
    N       -   dimension, N&gt;1
                * if given, only leading N elements of X are used
                * if not given, automatically determined from size of X
    M       -   number of functions f[i]
    X       -   initial solution, array[0..N-1]

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state

NOTES:
1. you may tune stopping conditions with MinLMSetCond() function
2. if target function contains exp() or other fast growing functions,  and
   optimization algorithm makes too large steps which leads  to  overflow,
   use MinLMSetStpMax() function to bound algorithm's steps.

  -- ALGLIB --
     Copyright 30.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmcreatevj(
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);
<b>void</b> alglib::minlmcreatevj(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    minlmstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_vj' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmoptimize'></a><h3 class=pageheader><code>minlmoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear optimizer

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    grad    -   callback which calculates function (or merit function)
                value func and gradient grad at given point x
    hess    -   callback which calculates function (or merit function)
                value func, gradient grad and Hessian hess at given point x
    fvec    -   callback which calculates function vector fi[]
                at given point x
    jac     -   callback which calculates function vector fi[]
                and Jacobian jac at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL

NOTES:

1. Depending on function used to create state  structure,  this  algorithm
   may accept Jacobian and/or Hessian and/or gradient.  According  to  the
   said above, there ase several versions of this function,  which  accept
   different sets of callbacks.

   This flexibility opens way to subtle errors - you may create state with
   MinLMCreateFGH() (optimization using Hessian), but call function  which
   does not accept Hessian. So when algorithm will request Hessian,  there
   will be no callback to call. In this case exception will be thrown.

   Be careful to avoid such errors because there is no way to find them at
   compile time - you can see them at runtime only.

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> minlmoptimize(minlmstate &amp;state,
    <b>void</b> (*fvec)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minlmoptimize(minlmstate &amp;state,
    <b>void</b> (*fvec)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr),
    <b>void</b>  (*jac)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, real_2d_array &amp;jac, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minlmoptimize(minlmstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b> (*hess)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, real_2d_array &amp;hess, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minlmoptimize(minlmstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*jac)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, real_2d_array &amp;jac, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
<b>void</b> minlmoptimize(minlmstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b> (*grad)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr),
    <b>void</b>  (*jac)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, real_2d_array &amp;jac, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_v' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vj' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlm_d_fgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minlm_d_restarts' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmrestartfrom'></a><h3 class=pageheader><code>minlmrestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  restarts  LM  algorithm from new point. All optimization
parameters are left unchanged.

This  function  allows  to  solve multiple  optimization  problems  (which
must have same number of dimensions) without object reallocation penalty.

INPUT PARAMETERS:
    State   -   structure used for reverse communication previously
                allocated with MinLMCreateXXX call.
    X       -   new starting point.

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmrestartfrom(minlmstate state, real_1d_array x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_restarts' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmresults'></a><h3 class=pageheader><code>minlmresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Levenberg-Marquardt algorithm results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution
    Rep     -   optimization report;
                see comments for this structure for more info.

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmresults(
    minlmstate state,
    real_1d_array&amp; x,
    minlmreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_v' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vj' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlm_d_fgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minlm_d_restarts' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmresultsbuf'></a><h3 class=pageheader><code>minlmresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Levenberg-Marquardt algorithm results

Buffered implementation of MinLMResults(), which uses pre-allocated buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmresultsbuf(
    minlmstate state,
    real_1d_array&amp; x,
    minlmreport&amp; rep);

</div></pre>
<a name='sub_minlmsetacctype'></a><h3 class=pageheader><code>minlmsetacctype</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to change acceleration settings

You can choose between three acceleration strategies:
* AccType=0, no acceleration.
* AccType=1, secant updates are used to update quadratic model after  each
  iteration. After fixed number of iterations (or after  model  breakdown)
  we  recalculate  quadratic  model  using  analytic  Jacobian  or  finite
  differences. Number of secant-based iterations depends  on  optimization
  settings: about 3 iterations - when we have analytic Jacobian, up to 2*N
  iterations - when we use finite differences to calculate Jacobian.

AccType=1 is recommended when Jacobian  calculation  cost  is  prohibitive
high (several Mx1 function vector calculations  followed  by  several  NxN
Cholesky factorizations are faster than calculation of one M*N  Jacobian).
It should also be used when we have no Jacobian, because finite difference
approximation takes too much time to compute.

Table below list  optimization  protocols  (XYZ  protocol  corresponds  to
MinLMCreateXYZ) and acceleration types they support (and use by  default).

ACCELERATION TYPES SUPPORTED BY OPTIMIZATION PROTOCOLS:

protocol    0   1   comment
V           +   +
VJ          +   +
FGH         +

DAFAULT VALUES:

protocol    0   1   comment
V               x   without acceleration it is so slooooooooow
VJ          x
FGH         x

NOTE: this  function should be called before optimization. Attempt to call
it during algorithm iterations may result in unexpected behavior.

NOTE: attempt to call this function with unsupported protocol/acceleration
combination will result in exception being thrown.

  -- ALGLIB --
     Copyright 14.10.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetacctype(minlmstate state, ae_int_t acctype);

</div></pre>
<a name='sub_minlmsetbc'></a><h3 class=pageheader><code>minlmsetbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets boundary constraints for LM optimizer

Boundary constraints are inactive by default (after initial creation).
They are preserved until explicitly turned off with another SetBC() call.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    BndL    -   lower bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very small number or -INF (latter is recommended because
                it will allow solver to use better algorithm).
    BndU    -   upper bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very large number or +INF (latter is recommended because
                it will allow solver to use better algorithm).

NOTE 1: it is possible to specify BndL[i]=BndU[i]. In this case I-th
variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].

NOTE 2: this solver has following useful properties:
* bound constraints are always satisfied exactly
* function is evaluated only INSIDE area specified by bound constraints
  or at its boundary

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetbc(
    minlmstate state,
    real_1d_array bndl,
    real_1d_array bndu);

</div></pre>
<a name='sub_minlmsetcond'></a><h3 class=pageheader><code>minlmsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping conditions for Levenberg-Marquardt optimization
algorithm.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsG    -   &gt;=0
                The  subroutine  finishes  its  work   if   the  condition
                |v|&lt;EpsG is satisfied, where:
                * |.| means Euclidian norm
                * v - scaled gradient vector, v[i]=g[i]*s[i]
                * g - gradient
                * s - scaling coefficients set by MinLMSetScale()
    EpsF    -   &gt;=0
                The  subroutine  finishes  its work if on k+1-th iteration
                the  condition  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
                is satisfied.
    EpsX    -   &gt;=0
                The subroutine finishes its work if  on  k+1-th  iteration
                the condition |v|&lt;=EpsX is fulfilled, where:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - ste pvector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by MinLMSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations   is    unlimited.   Only   Levenberg-Marquardt
                iterations  are  counted  (L-BFGS/CG  iterations  are  NOT
                counted because their cost is very low compared to that of
                LM).

Passing EpsG=0, EpsF=0, EpsX=0 and MaxIts=0 (simultaneously) will lead to
automatic stopping criterion selection (small EpsX).

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetcond(
    minlmstate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minlm_d_v' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vj' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minlm_d_fgh' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minlm_d_vb' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minlm_d_restarts' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minlmsetgradientcheck'></a><h3 class=pageheader><code>minlmsetgradientcheck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  turns  on  verification  of  the  user-supplied analytic
gradient:
* user calls this subroutine before optimization begins
* MinLMOptimize() is called
* prior to actual optimization, for  each  function Fi and each  component
  of parameters  being  optimized X[j] algorithm performs following steps:
  * two trial steps are made to X[j]-TestStep*S[j] and X[j]+TestStep*S[j],
    where X[j] is j-th parameter and S[j] is a scale of j-th parameter
  * if needed, steps are bounded with respect to constraints on X[]
  * Fi(X) is evaluated at these trial points
  * we perform one more evaluation in the middle point of the interval
  * we  build  cubic  model using function values and derivatives at trial
    points and we compare its prediction with actual value in  the  middle
    point
  * in case difference between prediction and actual value is higher  than
    some predetermined threshold, algorithm stops with completion code -7;
    Rep.VarIdx is set to index of the parameter with incorrect derivative,
    Rep.FuncIdx is set to index of the function.
* after verification is over, algorithm proceeds to the actual optimization.

NOTE 1: verification  needs  N (parameters count) Jacobian evaluations. It
        is  very  costly  and  you  should use it only for low dimensional
        problems,  when  you  want  to  be  sure  that  you've   correctly
        calculated  analytic  derivatives.  You should not  use  it in the
        production code  (unless  you  want  to check derivatives provided
        by some third party).

NOTE 2: you  should  carefully  choose  TestStep. Value which is too large
        (so large that function behaviour is significantly non-cubic) will
        lead to false alarms. You may use  different  step  for  different
        parameters by means of setting scale with MinLMSetScale().

NOTE 3: this function may lead to false positives. In case it reports that
        I-th  derivative was calculated incorrectly, you may decrease test
        step  and  try  one  more  time  - maybe your function changes too
        sharply  and  your  step  is  too  large for such rapidly chanding
        function.

INPUT PARAMETERS:
    State       -   structure used to store algorithm state
    TestStep    -   verification step:
                    * TestStep=0 turns verification off
                    * TestStep&gt;0 activates verification

  -- ALGLIB --
     Copyright 15.06.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetgradientcheck(minlmstate state, <b>double</b> teststep);

</div></pre>
<a name='sub_minlmsetscale'></a><h3 class=pageheader><code>minlmsetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients for LM optimizer.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

Generally, scale is NOT considered to be a form of preconditioner.  But LM
optimizer is unique in that it uses scaling matrix both  in  the  stopping
condition tests and as Marquardt damping factor.

Proper scaling is very important for the algorithm performance. It is less
important for the quality of results, but still has some influence (it  is
easier  to  converge  when  variables  are  properly  scaled, so premature
stopping is possible when very badly scalled variables are  combined  with
relaxed stopping conditions).

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetscale(minlmstate state, real_1d_array s);

</div></pre>
<a name='sub_minlmsetstpmax'></a><h3 class=pageheader><code>minlmsetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
                want to limit step length.

Use this subroutine when you optimize target function which contains exp()
or  other  fast  growing  functions,  and optimization algorithm makes too
large  steps  which  leads  to overflow. This function allows us to reject
steps  that  are  too  large  (and  therefore  expose  us  to the possible
overflow) without actually calculating function value at the x+stp*d.

NOTE: non-zero StpMax leads to moderate  performance  degradation  because
intermediate  step  of  preconditioned L-BFGS optimization is incompatible
with limits on step size.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetstpmax(minlmstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_minlmsetxrep'></a><h3 class=pageheader><code>minlmsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to MinLMOptimize(). Both Levenberg-Marquardt and internal  L-BFGS
iterations are reported.

  -- ALGLIB --
     Copyright 02.04.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minlmsetxrep(minlmstate state, <b>bool</b> needxrep);

</div></pre>
<a name='example_minlm_d_fgh'></a><h3 class=pageheader>minlm_d_fgh example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b> function1_func(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
}
<b>void</b> function1_grad(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, <b>void</b> *ptr) 
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// and its derivatives df/d0 and df/dx1</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
}
<b>void</b> function1_hess(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, real_1d_array &amp;grad, real_2d_array &amp;hess, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates f(x0,x1) = 100*(x0+3)^4 + (x1-3)^4</font>
    <font color=navy>// its derivatives df/d0 and df/dx1</font>
    <font color=navy>// and its Hessian.</font>
    <font color=navy>//</font>
    func = 100*pow(x[0]+3,4) + pow(x[1]-3,4);
    grad[0] = 400*pow(x[0]+3,3);
    grad[1] = 4*pow(x[1]-3,3);
    hess[0][0] = 1200*pow(x[0]+3,2);
    hess[0][1] = 0;
    hess[1][0] = 0;
    hess[1][1] = 12*pow(x[1]-3,2);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = 100*(x0+3)^4+(x1-3)^4</font>
    <font color=navy>// using <font color=blue><b>&quot;FGH&quot;</b></font> mode of the Levenberg-Marquardt optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// F is treated like a monolitic function without internal structure,</font>
    <font color=navy>// i.e. we <b>do</b> NOT represent it as a sum of squares.</font>
    <font color=navy>//</font>
    <font color=navy>// Optimization algorithm uses:</font>
    <font color=navy>// * function value F(x0,x1)</font>
    <font color=navy>// * gradient G={dF/dxi}</font>
    <font color=navy>// * Hessian H={d2F/(dxi*dxj)}</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlmstate state;
    minlmreport rep;

    minlmcreatefgh(x, state);
    minlmsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlmoptimize(state, function1_func, function1_grad, function1_hess);
    minlmresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,+3]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlm_d_restarts'></a><h3 class=pageheader>minlm_d_restarts example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b>  function1_fvec(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = 100*(x0+3)^4,</font>
    <font color=navy>// f1(x0,x1) = (x1-3)^4</font>
    <font color=navy>//</font>
    fi[0] = 10*pow(x[0]+3,2);
    fi[1] = pow(x[1]-3,2);
}
<b>void</b>  function2_fvec(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = x0^2+1</font>
    <font color=navy>// f1(x0,x1) = x1-1</font>
    <font color=navy>//</font>
    fi[0] = x[0]*x[0]+1;
    fi[1] = x[1]-1;
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = f0^2+f1^2, where </font>
    <font color=navy>//</font>
    <font color=navy>//     f0(x0,x1) = 10*(x0+3)^2</font>
    <font color=navy>//     f1(x0,x1) = (x1-3)^2</font>
    <font color=navy>//</font>
    <font color=navy>// using several starting points and efficient restarts.</font>
    <font color=navy>//</font>
    real_1d_array x;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlmstate state;
    minlmreport rep;

    <font color=navy>//</font>
    <font color=navy>// create optimizer using minlmcreatev()</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[10,10]&quot;</b></font>;
    minlmcreatev(2, x, 0.0001, state);
    minlmsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlmoptimize(state, function1_fvec);
    minlmresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,+3]</font>

    <font color=navy>//</font>
    <font color=navy>// restart optimizer using minlmrestartfrom()</font>
    <font color=navy>//</font>
    <font color=navy>// we can use different starting point, different function,</font>
    <font color=navy>// different stopping conditions, but problem size</font>
    <font color=navy>// must remain unchanged.</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[4,4]&quot;</b></font>;
    minlmrestartfrom(state, x);
    alglib::minlmoptimize(state, function2_fvec);
    minlmresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [0,1]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlm_d_v'></a><h3 class=pageheader>minlm_d_v example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b>  function1_fvec(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = 100*(x0+3)^4,</font>
    <font color=navy>// f1(x0,x1) = (x1-3)^4</font>
    <font color=navy>//</font>
    fi[0] = 10*pow(x[0]+3,2);
    fi[1] = pow(x[1]-3,2);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = f0^2+f1^2, where </font>
    <font color=navy>//</font>
    <font color=navy>//     f0(x0,x1) = 10*(x0+3)^2</font>
    <font color=navy>//     f1(x0,x1) = (x1-3)^2</font>
    <font color=navy>//</font>
    <font color=navy>// using <font color=blue><b>&quot;V&quot;</b></font> mode of the Levenberg-Marquardt optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// Optimization algorithm uses:</font>
    <font color=navy>// * function vector f[] = {f1,f2}</font>
    <font color=navy>//</font>
    <font color=navy>// No other information (Jacobian, gradient, etc.) is needed.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlmstate state;
    minlmreport rep;

    minlmcreatev(2, x, 0.0001, state);
    minlmsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlmoptimize(state, function1_fvec);
    minlmresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,+3]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlm_d_vb'></a><h3 class=pageheader>minlm_d_vb example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b>  function1_fvec(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = 100*(x0+3)^4,</font>
    <font color=navy>// f1(x0,x1) = (x1-3)^4</font>
    <font color=navy>//</font>
    fi[0] = 10*pow(x[0]+3,2);
    fi[1] = pow(x[1]-3,2);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = f0^2+f1^2, where </font>
    <font color=navy>//</font>
    <font color=navy>//     f0(x0,x1) = 10*(x0+3)^2</font>
    <font color=navy>//     f1(x0,x1) = (x1-3)^2</font>
    <font color=navy>//</font>
    <font color=navy>// with boundary constraints</font>
    <font color=navy>//</font>
    <font color=navy>//     -1 &lt;= x0 &lt;= +1</font>
    <font color=navy>//     -1 &lt;= x1 &lt;= +1</font>
    <font color=navy>//</font>
    <font color=navy>// using <font color=blue><b>&quot;V&quot;</b></font> mode of the Levenberg-Marquardt optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// Optimization algorithm uses:</font>
    <font color=navy>// * function vector f[] = {f1,f2}</font>
    <font color=navy>//</font>
    <font color=navy>// No other information (Jacobian, gradient, etc.) is needed.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[-1,-1]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[+1,+1]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlmstate state;
    minlmreport rep;

    minlmcreatev(2, x, 0.0001, state);
    minlmsetbc(state, bndl, bndu);
    minlmsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlmoptimize(state, function1_fvec);
    minlmresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-1,+1]</font>
    <b>return</b> 0;
}


</pre><a name='example_minlm_d_vj'></a><h3 class=pageheader>minlm_d_vj example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;
<b>void</b>  function1_fvec(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = 100*(x0+3)^4,</font>
    <font color=navy>// f1(x0,x1) = (x1-3)^4</font>
    <font color=navy>//</font>
    fi[0] = 10*pow(x[0]+3,2);
    fi[1] = pow(x[1]-3,2);
}
<b>void</b>  function1_jac(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, real_2d_array &amp;jac, <b>void</b> *ptr)
{
    <font color=navy>//</font>
    <font color=navy>// this callback calculates</font>
    <font color=navy>// f0(x0,x1) = 100*(x0+3)^4,</font>
    <font color=navy>// f1(x0,x1) = (x1-3)^4</font>
    <font color=navy>// and Jacobian matrix J = [dfi/dxj]</font>
    <font color=navy>//</font>
    fi[0] = 10*pow(x[0]+3,2);
    fi[1] = pow(x[1]-3,2);
    jac[0][0] = 20*(x[0]+3);
    jac[0][1] = 0;
    jac[1][0] = 0;
    jac[1][1] = 2*(x[1]-3);
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = f0^2+f1^2, where </font>
    <font color=navy>//</font>
    <font color=navy>//     f0(x0,x1) = 10*(x0+3)^2</font>
    <font color=navy>//     f1(x0,x1) = (x1-3)^2</font>
    <font color=navy>//</font>
    <font color=navy>// using <font color=blue><b>&quot;VJ&quot;</b></font> mode of the Levenberg-Marquardt optimizer.</font>
    <font color=navy>//</font>
    <font color=navy>// Optimization algorithm uses:</font>
    <font color=navy>// * function vector f[] = {f1,f2}</font>
    <font color=navy>// * Jacobian matrix J = {dfi/dxj}.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    <b>double</b> epsg = 0.0000000001;
    <b>double</b> epsf = 0;
    <b>double</b> epsx = 0;
    ae_int_t maxits = 0;
    minlmstate state;
    minlmreport rep;

    minlmcreatevj(2, x, state);
    minlmsetcond(state, epsg, epsf, epsx, maxits);
    alglib::minlmoptimize(state, function1_fvec, function1_jac);
    minlmresults(state, x, rep);

    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [-3,+3]</font>
    <b>return</b> 0;
}


</pre><a name=unit_minqp></a><h2 class=pageheader><code>minqp</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_minqpreport' class=toc>minqpreport</a><br>
<a href='#struct_minqpstate' class=toc>minqpstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_minqpcreate' class=toc>minqpcreate</a><br>
<a href='#sub_minqpoptimize' class=toc>minqpoptimize</a><br>
<a href='#sub_minqpresults' class=toc>minqpresults</a><br>
<a href='#sub_minqpresultsbuf' class=toc>minqpresultsbuf</a><br>
<a href='#sub_minqpsetalgobleic' class=toc>minqpsetalgobleic</a><br>
<a href='#sub_minqpsetalgocholesky' class=toc>minqpsetalgocholesky</a><br>
<a href='#sub_minqpsetbc' class=toc>minqpsetbc</a><br>
<a href='#sub_minqpsetlc' class=toc>minqpsetlc</a><br>
<a href='#sub_minqpsetlinearterm' class=toc>minqpsetlinearterm</a><br>
<a href='#sub_minqpsetorigin' class=toc>minqpsetorigin</a><br>
<a href='#sub_minqpsetquadraticterm' class=toc>minqpsetquadraticterm</a><br>
<a href='#sub_minqpsetquadratictermsparse' class=toc>minqpsetquadratictermsparse</a><br>
<a href='#sub_minqpsetscale' class=toc>minqpsetscale</a><br>
<a href='#sub_minqpsetstartingpoint' class=toc>minqpsetstartingpoint</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_minqp_d_bc1' class=toc>minqp_d_bc1</a></td><td width=15>&nbsp;</td><td>Bound constrained dense quadratic programming</td></tr>
<tr align=left valign=top><td><a href='#example_minqp_d_lc1' class=toc>minqp_d_lc1</a></td><td width=15>&nbsp;</td><td>Linearly constrained dense quadratic programming</td></tr>
<tr align=left valign=top><td><a href='#example_minqp_d_nonconvex' class=toc>minqp_d_nonconvex</a></td><td width=15>&nbsp;</td><td>Nonconvex quadratic programming</td></tr>
<tr align=left valign=top><td><a href='#example_minqp_d_u1' class=toc>minqp_d_u1</a></td><td width=15>&nbsp;</td><td>Unconstrained dense quadratic programming</td></tr>
<tr align=left valign=top><td><a href='#example_minqp_d_u2' class=toc>minqp_d_u2</a></td><td width=15>&nbsp;</td><td>Unconstrained sparse quadratic programming</td></tr>
</table></div>
<a name='struct_minqpreport'></a><h3 class=pageheader><code>minqpreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This structure stores optimization report:
* InnerIterationsCount      number of inner iterations
* OuterIterationsCount      number of outer iterations
* NCholesky                 number of Cholesky decomposition
* NMV                       number of matrix-vector products
                            (only products calculated as part of iterative
                            process are counted)
* TerminationType           completion code (see below)

Completion codes:
* -5    inappropriate solver was used:
        * Cholesky solver for semidefinite or indefinite problems
        * Cholesky solver for problems with non-boundary constraints
* -4    BLEIC-QP algorithm found unconstrained direction
        of negative curvature (function is unbounded from
        below  even  under  constraints),  no  meaningful
        minimum can be found.
* -3    inconsistent constraints (or, maybe, feasible point is
        too hard to find). If you are sure that constraints are feasible,
        try to restart optimizer with better initial approximation.
* -1    solver error
*  4    successful completion
*  5    MaxIts steps was taken
*  7    stopping conditions are too stringent,
        further improvement is impossible,
        X contains best point found so far.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minqpreport
{
    ae_int_t             inneriterationscount;
    ae_int_t             outeriterationscount;
    ae_int_t             nmv;
    ae_int_t             ncholesky;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_minqpstate'></a><h3 class=pageheader><code>minqpstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores nonlinear optimizer state.
You should use functions provided by MinQP subpackage to work with this
object
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> minqpstate
{
};

</div></pre>
<a name='sub_minqpcreate'></a><h3 class=pageheader><code>minqpcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
                    CONSTRAINED QUADRATIC PROGRAMMING

The subroutine creates QP optimizer. After initial creation,  it  contains
default optimization problem with zero quadratic and linear terms  and  no
constraints. You should set quadratic/linear terms with calls to functions
provided by MinQP subpackage.

INPUT PARAMETERS:
    N       -   problem size

OUTPUT PARAMETERS:
    State   -   optimizer with zero quadratic/linear terms
                and no constraints

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpcreate(ae_int_t n, minqpstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpoptimize'></a><h3 class=pageheader><code>minqpoptimize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves quadratic programming problem.
You should call it after setting solver options with MinQPSet...() calls.

INPUT PARAMETERS:
    State   -   algorithm state

You should use MinQPResults() function to access results after calls
to this function.

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey.
     Special thanks to Elvira Illarionova  for  important  suggestions  on
     the linearly constrained QP algorithm.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpoptimize(minqpstate state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpresults'></a><h3 class=pageheader><code>minqpresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
QP solver results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution.
                This array is allocated and initialized only when
                Rep.TerminationType parameter is positive (success).
    Rep     -   optimization report. You should check Rep.TerminationType,
                which contains completion code, and you may check  another
                fields which contain another information  about  algorithm
                functioning.

                Failure codes returned by algorithm are:
                * -5    inappropriate solver was used:
                        * Cholesky solver for (semi)indefinite problems
                        * Cholesky solver for problems with sparse matrix
                * -4    BLEIC-QP algorithm found unconstrained direction
                        of negative curvature (function is unbounded from
                        below  even  under  constraints),  no  meaningful
                        minimum can be found.
                * -3    inconsistent constraints (or maybe  feasible point
                        is too  hard  to  find).  If  you  are  sure  that
                        constraints are feasible, try to restart optimizer
                        with better initial approximation.

                Completion codes specific for Cholesky algorithm:
                *  4   successful completion

                Completion codes specific for BLEIC-based algorithm:
                *  1   relative function improvement is no more than EpsF.
                *  2   scaled step is no more than EpsX.
                *  4   scaled gradient norm is no more than EpsG.
                *  5   MaxIts steps was taken

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpresults(
    minqpstate state,
    real_1d_array&amp; x,
    minqpreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpresultsbuf'></a><h3 class=pageheader><code>minqpresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
QP results

Buffered implementation of MinQPResults() which uses pre-allocated  buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpresultsbuf(
    minqpstate state,
    real_1d_array&amp; x,
    minqpreport&amp; rep);

</div></pre>
<a name='sub_minqpsetalgobleic'></a><h3 class=pageheader><code>minqpsetalgobleic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function tells solver to use BLEIC-based algorithm and sets  stopping
criteria for the algorithm.

DESCRIPTION:

BLEIC-based QP algorithm can be used for any kind of QP problems:
* problems with both dense and sparse quadratic terms
* problems with positive definite, semidefinite, indefinite terms

BLEIC-based algorithm can solve even indefinite problems - as long as they
are bounded from below on the feasible set. Of course, global  minimum  is
found only  for  positive  definite  and  semidefinite  problems.  As  for
indefinite ones - only local minimum is found.

BENEFITS AND DRAWBACKS:

This algorithm can be used to solve both convex and indefinite QP problems
and it can utilize sparsity of the quadratic  term  (algorithm  calculates
matrix-vector products, which can be  performed  efficiently  in  case  of
sparse matrix).

Algorithm has iteration cost, which (assuming fixed amount of non-boundary
linear constraints) linearly depends on problem size. Boundary constraints
does not significantly change iteration cost.

Thus, it outperforms Cholesky-based QP algorithm (CQP) on high-dimensional
sparse problems with moderate amount of constraints.


From the other side, unlike CQP solver, this algorithm does NOT  make  use
of Level 3 Dense BLAS. Thus, its performance on dense problems is inferior
to that of CQP solver.

Its precision is also inferior to that of CQP. CQP performs  Newton  steps
which are know to achieve very good  precision. In many cases Newton  step
leads us exactly to the solution. BLEIC-QP performs LBFGS steps, which are
good at detecting neighborhood of the solution, buy need  many  iterations
to find solution with 6 digits of precision.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsG    -   &gt;=0
                The  subroutine  finishes  its  work   if   the  condition
                |v|&lt;EpsG is satisfied, where:
                * |.| means Euclidian norm
                * v - scaled constrained gradient vector, v[i]=g[i]*s[i]
                * g - gradient
                * s - scaling coefficients set by MinQPSetScale()
    EpsF    -   &gt;=0
                The  subroutine  finishes  its work if exploratory steepest
                descent  step  on  k+1-th  iteration  satisfies   following
                condition:  |F(k+1)-F(k)|&lt;=EpsF*max{|F(k)|,|F(k+1)|,1}
    EpsX    -   &gt;=0
                The  subroutine  finishes  its work if exploratory steepest
                descent  step  on  k+1-th  iteration  satisfies   following
                condition:
                * |.| means Euclidian norm
                * v - scaled step vector, v[i]=dx[i]/s[i]
                * dx - step vector, dx=X(k+1)-X(k)
                * s - scaling coefficients set by MinQPSetScale()
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations is unlimited.

Passing EpsG=0, EpsF=0 and EpsX=0 and MaxIts=0 (simultaneously) will lead
to automatic stopping criterion selection (presently it is  small    step
length, but it may change in the future versions of ALGLIB).

IT IS VERY IMPORTANT THAT YOU CALL MinQPSetScale() WHEN YOU USE THIS ALGO!

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetalgobleic(
    minqpstate state,
    <b>double</b> epsg,
    <b>double</b> epsf,
    <b>double</b> epsx,
    ae_int_t maxits);

</div></pre>
<a name='sub_minqpsetalgocholesky'></a><h3 class=pageheader><code>minqpsetalgocholesky</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function tells solver to use Cholesky-based algorithm. This algorithm
is active by default.

DESCRIPTION:

Cholesky-based algorithm can be used only for problems which:
* have dense quadratic term, set  by  MinQPSetQuadraticTerm(),  sparse  or
  structured problems are not supported.
* are strictly convex, i.e. quadratic term is symmetric positive definite,
  indefinite or semidefinite problems are not supported by this algorithm.

If anything of what listed above is violated, you may use  BLEIC-based  QP
algorithm which can be activated by MinQPSetAlgoBLEIC().

BENEFITS AND DRAWBACKS:

This  algorithm  gives  best  precision amongst all QP solvers provided by
ALGLIB (Newton iterations  have  much  higher  precision  than  any  other
optimization algorithm). This solver also gracefully handles problems with
very large amount of constraints.

Performance of the algorithm is good because internally  it  uses  Level 3
Dense BLAS for its performance-critical parts.


From the other side, algorithm has  O(N^3)  complexity  for  unconstrained
problems and up to orders of  magnitude  slower  on  constrained  problems
(these additional iterations are needed to identify  active  constraints).
So, its running time depends on number of constraints active  at solution.

Furthermore, this algorithm can not solve problems with sparse matrices or
problems with semidefinite/indefinite matrices of any kind (dense/sparse).

INPUT PARAMETERS:
    State   -   structure which stores algorithm state

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetalgocholesky(minqpstate state);

</div></pre>
<a name='sub_minqpsetbc'></a><h3 class=pageheader><code>minqpsetbc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets boundary constraints for QP solver

Boundary constraints are inactive by default (after initial creation).
After  being  set,  they  are  preserved  until explicitly turned off with
another SetBC() call.

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    BndL    -   lower bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very small number or -INF (latter is recommended because
                it will allow solver to use better algorithm).
    BndU    -   upper bounds, array[N].
                If some (all) variables are unbounded, you may specify
                very large number or +INF (latter is recommended because
                it will allow solver to use better algorithm).

NOTE: it is possible to specify BndL[i]=BndU[i]. In this case I-th
variable will be &quot;frozen&quot; at X[i]=BndL[i]=BndU[i].

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetbc(
    minqpstate state,
    real_1d_array bndl,
    real_1d_array bndu);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpsetlc'></a><h3 class=pageheader><code>minqpsetlc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets linear constraints for QP optimizer.

Linear constraints are inactive by default (after initial creation).

INPUT PARAMETERS:
    State   -   structure previously allocated with MinQPCreate call.
    C       -   linear constraints, array[K,N+1].
                Each row of C represents one constraint, either equality
                or inequality (see below):
                * first N elements correspond to coefficients,
                * last element corresponds to the right part.
                All elements of C (including right part) must be finite.
    CT      -   type of constraints, array[K]:
                * if CT[i]&gt;0, then I-th constraint is C[i,*]*x &gt;= C[i,n+1]
                * if CT[i]=0, then I-th constraint is C[i,*]*x  = C[i,n+1]
                * if CT[i]&lt;0, then I-th constraint is C[i,*]*x &lt;= C[i,n+1]
    K       -   number of equality/inequality constraints, K&gt;=0:
                * if given, only leading K elements of C/CT are used
                * if not given, automatically determined from sizes of C/CT

NOTE 1: linear (non-bound) constraints are satisfied only approximately  -
        there always exists some minor violation (about 10^-10...10^-13)
        due to numerical errors.

  -- ALGLIB --
     Copyright 19.06.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetlc(
    minqpstate state,
    real_2d_array c,
    integer_1d_array ct);
<b>void</b> alglib::minqpsetlc(
    minqpstate state,
    real_2d_array c,
    integer_1d_array ct,
    ae_int_t k);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpsetlinearterm'></a><h3 class=pageheader><code>minqpsetlinearterm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets linear term for QP solver.

By default, linear term is zero.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    B       -   linear term, array[N].

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetlinearterm(minqpstate state, real_1d_array b);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpsetorigin'></a><h3 class=pageheader><code>minqpsetorigin</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function sets origin for QP solver. By default, following QP program
is solved:

    min(0.5*x'*A*x+b'*x)

This function allows to solve different problem:

    min(0.5*(x-x_origin)'*A*(x-x_origin)+b'*(x-x_origin))

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    XOrigin -   origin, array[N].

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetorigin(minqpstate state, real_1d_array xorigin);

</div></pre>
<a name='sub_minqpsetquadraticterm'></a><h3 class=pageheader><code>minqpsetquadraticterm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets  dense  quadratic  term  for  QP solver. By  default,
quadratic term is zero.

SUPPORT BY ALGLIB QP ALGORITHMS:

Dense quadratic term can be handled by any of the QP algorithms  supported
by ALGLIB QP Solver.

IMPORTANT:

This solver minimizes following  function:
    f(x) = 0.5*x'*A*x + b'*x.
Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
    f(x) = x^2 + x
you should rewrite your problem as follows:
    f(x) = 0.5*(2*x^2) + x
and your matrix A will be equal to [[2.0]], not to [[1.0]]

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    A       -   matrix, array[N,N]
    IsUpper -   (optional) storage type:
                * if True, symmetric matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt used
                * if False, symmetric matrix  A  is  given  by  its lower
                  triangle, and the upper triangle isnt used
                * if not given, both lower and upper  triangles  must  be
                  filled.

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetquadraticterm(minqpstate state, real_2d_array a);
<b>void</b> alglib::minqpsetquadraticterm(
    minqpstate state,
    real_2d_array a,
    <b>bool</b> isupper);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpsetquadratictermsparse'></a><h3 class=pageheader><code>minqpsetquadratictermsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets  sparse  quadratic  term  for  QP solver. By default,
quadratic term is zero.

SUPPORT BY ALGLIB QP ALGORITHMS:

Sparse quadratic term is supported only by BLEIC-based QP  algorithm  (one
which is activated by MinQPSetAlgoBLEIC function). Cholesky-based QP  algo
won't be able to deal  with  sparse  quadratic  term  and  will  terminate
abnormally.

IF YOU CALLED THIS FUNCTION, YOU MUST SWITCH TO BLEIC-BASED  QP  ALGORITHM
BEFORE CALLING MINQPOPTIMIZE() FUNCTION.

IMPORTANT:

This solver minimizes following  function:
    f(x) = 0.5*x'*A*x + b'*x.
Note that quadratic term has 0.5 before it. So if  you  want  to  minimize
    f(x) = x^2 + x
you should rewrite your problem as follows:
    f(x) = 0.5*(2*x^2) + x
and your matrix A will be equal to [[2.0]], not to [[1.0]]

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    A       -   matrix, array[N,N]
    IsUpper -   (optional) storage type:
                * if True, symmetric matrix  A  is  given  by  its  upper
                  triangle, and the lower triangle isnt used
                * if False, symmetric matrix  A  is  given  by  its lower
                  triangle, and the upper triangle isnt used
                * if not given, both lower and upper  triangles  must  be
                  filled.

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetquadratictermsparse(
    minqpstate state,
    sparsematrix a,
    <b>bool</b> isupper);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_minqpsetscale'></a><h3 class=pageheader><code>minqpsetscale</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets scaling coefficients.

ALGLIB optimizers use scaling matrices to test stopping  conditions  (step
size and gradient are scaled before comparison with tolerances).  Scale of
the I-th variable is a translation invariant measure of:
a) &quot;how large&quot; the variable is
b) how large the step should be to make significant changes in the function

BLEIC-based QP solver uses scale for two purposes:
* to evaluate stopping conditions
* for preconditioning of the underlying BLEIC solver

INPUT PARAMETERS:
    State   -   structure stores algorithm state
    S       -   array[N], non-zero scaling coefficients
                S[i] may be negative, sign doesn't matter.

  -- ALGLIB --
     Copyright 14.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetscale(minqpstate state, real_1d_array s);

</div></pre>
<a name='sub_minqpsetstartingpoint'></a><h3 class=pageheader><code>minqpsetstartingpoint</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets starting point for QP solver. It is useful to have
good initial approximation to the solution, because it will increase
speed of convergence and identification of active constraints.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    X       -   starting point, array[N].

  -- ALGLIB --
     Copyright 11.01.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::minqpsetstartingpoint(minqpstate state, real_1d_array x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_minqp_d_u1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_minqp_d_bc1' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_minqp_d_lc1' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_minqp_d_u2' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_minqp_d_nonconvex' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='example_minqp_d_bc1'></a><h3 class=pageheader>minqp_d_bc1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = x0^2 + x1^2 -6*x0 - 4*x1</font>
    <font color=navy>// subject to bound constraints 0&lt;=x0&lt;=2.5, 0&lt;=x1&lt;=2.5</font>
    <font color=navy>//</font>
    <font color=navy>// Exact solution is [x0,x1] = [2.5,2]</font>
    <font color=navy>//</font>
    <font color=navy>// We provide algorithm with starting point. With such small problem good starting</font>
    <font color=navy>// point is not really necessary, but with high-dimensional problem it can save us</font>
    <font color=navy>// a lot of time.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this solver minimizes  following  function:</font>
    <font color=navy>//     f(x) = 0.5*x'*A*x + b'*x.</font>
    <font color=navy>// Note that quadratic term has 0.5 before it. So <b>if</b> you want to minimize</font>
    <font color=navy>// quadratic function, you should rewrite it in such way that quadratic term</font>
    <font color=navy>// is multiplied by 0.5 too.</font>
    <font color=navy>// For example, our function is f(x)=x0^2+x1^2+..., but we rewrite it as </font>
    <font color=navy>//     f(x) = 0.5*(2*x0^2+2*x1^2) + ....</font>
    <font color=navy>// and pass diag(2,2) as quadratic term - NOT diag(1,1)!</font>
    <font color=navy>//</font>
    real_2d_array a = <font color=blue><b>&quot;[[2,0],[0,2]]&quot;</b></font>;
    real_1d_array b = <font color=blue><b>&quot;[-6,-4]&quot;</b></font>;
    real_1d_array x0 = <font color=blue><b>&quot;[0,1]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[0.0,0.0]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[2.5,2.5]&quot;</b></font>;
    real_1d_array x;
    minqpstate state;
    minqpreport rep;

    <font color=navy>// create solver, set quadratic/linear terms</font>
    minqpcreate(2, state);
    minqpsetquadraticterm(state, a);
    minqpsetlinearterm(state, b);
    minqpsetstartingpoint(state, x0);
    minqpsetbc(state, bndl, bndu);

    <font color=navy>// Set scale of the parameters.</font>
    <font color=navy>// It is strongly recommended that you set scale of your variables.</font>
    <font color=navy>// Knowing their scales is essential <b>for</b> evaluation of stopping criteria</font>
    <font color=navy>// and <b>for</b> preconditioning of the algorithm steps.</font>
    <font color=navy>// You can find more information on scaling at http://www.alglib.net/optimization/scaling.php</font>
    minqpsetscale(state, s);

    <font color=navy>// solve problem with Cholesky-based QP solver</font>
    minqpsetalgocholesky(state);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [2.5,2]</font>

    <font color=navy>// solve problem with BLEIC-based QP solver</font>
    <font color=navy>// default stopping criteria are used.</font>
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [2.5,2]</font>
    <b>return</b> 0;
}


</pre><a name='example_minqp_d_lc1'></a><h3 class=pageheader>minqp_d_lc1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = x0^2 + x1^2 -6*x0 - 4*x1</font>
    <font color=navy>// subject to linear constraint x0+x1&lt;=2</font>
    <font color=navy>//</font>
    <font color=navy>// Exact solution is [x0,x1] = [1.5,0.5]</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this solver minimizes  following  function:</font>
    <font color=navy>//     f(x) = 0.5*x'*A*x + b'*x.</font>
    <font color=navy>// Note that quadratic term has 0.5 before it. So <b>if</b> you want to minimize</font>
    <font color=navy>// quadratic function, you should rewrite it in such way that quadratic term</font>
    <font color=navy>// is multiplied by 0.5 too.</font>
    <font color=navy>// For example, our function is f(x)=x0^2+x1^2+..., but we rewrite it as </font>
    <font color=navy>//     f(x) = 0.5*(2*x0^2+2*x1^2) + ....</font>
    <font color=navy>// and pass diag(2,2) as quadratic term - NOT diag(1,1)!</font>
    <font color=navy>//</font>
    real_2d_array a = <font color=blue><b>&quot;[[2,0],[0,2]]&quot;</b></font>;
    real_1d_array b = <font color=blue><b>&quot;[-6,-4]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_2d_array c = <font color=blue><b>&quot;[[1.0,1.0,2.0]]&quot;</b></font>;
    integer_1d_array ct = <font color=blue><b>&quot;[-1]&quot;</b></font>;
    real_1d_array x;
    minqpstate state;
    minqpreport rep;

    <font color=navy>// create solver, set quadratic/linear terms</font>
    minqpcreate(2, state);
    minqpsetquadraticterm(state, a);
    minqpsetlinearterm(state, b);
    minqpsetlc(state, c, ct);

    <font color=navy>// Set scale of the parameters.</font>
    <font color=navy>// It is strongly recommended that you set scale of your variables.</font>
    <font color=navy>// Knowing their scales is essential <b>for</b> evaluation of stopping criteria</font>
    <font color=navy>// and <b>for</b> preconditioning of the algorithm steps.</font>
    <font color=navy>// You can find more information on scaling at http://www.alglib.net/optimization/scaling.php</font>
    minqpsetscale(state, s);

    <font color=navy>// solve problem with Cholesky-based QP solver</font>
    minqpsetalgocholesky(state);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.500,0.500]</font>

    <font color=navy>// solve problem with BLEIC-based QP solver</font>
    <font color=navy>// default stopping criteria are used.</font>
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.500,0.500]</font>
    <b>return</b> 0;
}


</pre><a name='example_minqp_d_nonconvex'></a><h3 class=pageheader>minqp_d_nonconvex example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of nonconvex function</font>
    <font color=navy>//     F(x0,x1) = -(x0^2+x1^2)</font>
    <font color=navy>// subject to constraints x0,x1 in [1.0,2.0]</font>
    <font color=navy>// Exact solution is [x0,x1] = [2,2].</font>
    <font color=navy>//</font>
    <font color=navy>// Such problem (non-convex) can be solved only with BLEIC-QP solver.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this solver minimizes  following  function:</font>
    <font color=navy>//     f(x) = 0.5*x'*A*x + b'*x.</font>
    <font color=navy>// Note that quadratic term has 0.5 before it. So <b>if</b> you want to minimize</font>
    <font color=navy>// quadratic function, you should rewrite it in such way that quadratic term</font>
    <font color=navy>// is multiplied by 0.5 too.</font>
    <font color=navy>//</font>
    <font color=navy>// For example, our function is f(x)=-(x0^2+x1^2), but we rewrite it as </font>
    <font color=navy>//     f(x) = 0.5*(-2*x0^2-2*x1^2)</font>
    <font color=navy>// and pass diag(-2,-2) as quadratic term - NOT diag(-1,-1)!</font>
    <font color=navy>//</font>
    real_2d_array a = <font color=blue><b>&quot;[[-2,0],[0,-2]]&quot;</b></font>;
    real_1d_array x0 = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array bndl = <font color=blue><b>&quot;[1.0,1.0]&quot;</b></font>;
    real_1d_array bndu = <font color=blue><b>&quot;[2.0,2.0]&quot;</b></font>;
    real_1d_array x;
    minqpstate state;
    minqpreport rep;

    <font color=navy>// create solver, set quadratic/linear terms, constraints</font>
    minqpcreate(2, state);
    minqpsetquadraticterm(state, a);
    minqpsetstartingpoint(state, x0);
    minqpsetbc(state, bndl, bndu);

    <font color=navy>// Set scale of the parameters.</font>
    <font color=navy>// It is strongly recommended that you set scale of your variables.</font>
    <font color=navy>// Knowing their scales is essential <b>for</b> evaluation of stopping criteria</font>
    <font color=navy>// and <b>for</b> preconditioning of the algorithm steps.</font>
    <font color=navy>// You can find more information on scaling at http://www.alglib.net/optimization/scaling.php</font>
    minqpsetscale(state, s);

    <font color=navy>// solve problem with BLEIC-QP solver.</font>
    <font color=navy>// default stopping criteria are used.</font>
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [2,2]</font>

    <font color=navy>// Hmm... this problem is bounded from below (has solution) only under constraints.</font>
    <font color=navy>// What it we remove them?</font>
    <font color=navy>//</font>
    <font color=navy>// You may see that algorithm detects unboundedness of the problem, </font>
    <font color=navy>// -4 is returned as completion code.</font>
    real_1d_array nobndl = <font color=blue><b>&quot;[-inf,-inf]&quot;</b></font>;
    real_1d_array nobndu = <font color=blue><b>&quot;[+inf,+inf]&quot;</b></font>;
    minqpsetbc(state, nobndl, nobndu);
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: -4</font>
    <b>return</b> 0;
}


</pre><a name='example_minqp_d_u1'></a><h3 class=pageheader>minqp_d_u1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = x0^2 + x1^2 -6*x0 - 4*x1</font>
    <font color=navy>//</font>
    <font color=navy>// Exact solution is [x0,x1] = [3,2]</font>
    <font color=navy>//</font>
    <font color=navy>// We provide algorithm with starting point, although in this case</font>
    <font color=navy>// (dense matrix, no constraints) it can work without such information.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this solver minimizes  following  function:</font>
    <font color=navy>//     f(x) = 0.5*x'*A*x + b'*x.</font>
    <font color=navy>// Note that quadratic term has 0.5 before it. So <b>if</b> you want to minimize</font>
    <font color=navy>// quadratic function, you should rewrite it in such way that quadratic term</font>
    <font color=navy>// is multiplied by 0.5 too.</font>
    <font color=navy>//</font>
    <font color=navy>// For example, our function is f(x)=x0^2+x1^2+..., but we rewrite it as </font>
    <font color=navy>//     f(x) = 0.5*(2*x0^2+2*x1^2) + ....</font>
    <font color=navy>// and pass diag(2,2) as quadratic term - NOT diag(1,1)!</font>
    <font color=navy>//</font>
    real_2d_array a = <font color=blue><b>&quot;[[2,0],[0,2]]&quot;</b></font>;
    real_1d_array b = <font color=blue><b>&quot;[-6,-4]&quot;</b></font>;
    real_1d_array x0 = <font color=blue><b>&quot;[0,1]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array x;
    minqpstate state;
    minqpreport rep;

    <font color=navy>// create solver, set quadratic/linear terms</font>
    minqpcreate(2, state);
    minqpsetquadraticterm(state, a);
    minqpsetlinearterm(state, b);
    minqpsetstartingpoint(state, x0);

    <font color=navy>// Set scale of the parameters.</font>
    <font color=navy>// It is strongly recommended that you set scale of your variables.</font>
    <font color=navy>// Knowing their scales is essential <b>for</b> evaluation of stopping criteria</font>
    <font color=navy>// and <b>for</b> preconditioning of the algorithm steps.</font>
    <font color=navy>// You can find more information on scaling at http://www.alglib.net/optimization/scaling.php</font>
    minqpsetscale(state, s);

    <font color=navy>// solve problem with Cholesky-based QP solver</font>
    minqpsetalgocholesky(state);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [3,2]</font>

    <font color=navy>// solve problem with BLEIC-based QP solver.</font>
    <font color=navy>// default stopping criteria are used.</font>
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [3,2]</font>
    <b>return</b> 0;
}


</pre><a name='example_minqp_d_u2'></a><h3 class=pageheader>minqp_d_u2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;optimization.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates minimization of F(x0,x1) = x0^2 + x1^2 -6*x0 - 4*x1,</font>
    <font color=navy>// with quadratic term given by sparse matrix structure.</font>
    <font color=navy>//</font>
    <font color=navy>// Exact solution is [x0,x1] = [3,2]</font>
    <font color=navy>//</font>
    <font color=navy>// We provide algorithm with starting point, although in this case</font>
    <font color=navy>// (dense matrix, no constraints) it can work without such information.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT: this solver minimizes  following  function:</font>
    <font color=navy>//     f(x) = 0.5*x'*A*x + b'*x.</font>
    <font color=navy>// Note that quadratic term has 0.5 before it. So <b>if</b> you want to minimize</font>
    <font color=navy>// quadratic function, you should rewrite it in such way that quadratic term</font>
    <font color=navy>// is multiplied by 0.5 too.</font>
    <font color=navy>//</font>
    <font color=navy>// For example, our function is f(x)=x0^2+x1^2+..., but we rewrite it as </font>
    <font color=navy>//     f(x) = 0.5*(2*x0^2+2*x1^2) + ....</font>
    <font color=navy>// and pass diag(2,2) as quadratic term - NOT diag(1,1)!</font>
    <font color=navy>//</font>
    sparsematrix a;
    real_1d_array b = <font color=blue><b>&quot;[-6,-4]&quot;</b></font>;
    real_1d_array x0 = <font color=blue><b>&quot;[0,1]&quot;</b></font>;
    real_1d_array s = <font color=blue><b>&quot;[1,1]&quot;</b></font>;
    real_1d_array x;
    minqpstate state;
    minqpreport rep;

    <font color=navy>// initialize sparsematrix structure</font>
    sparsecreate(2, 2, 0, a);
    sparseset(a, 0, 0, 2.0);
    sparseset(a, 1, 1, 2.0);

    <font color=navy>// create solver, set quadratic/linear terms</font>
    minqpcreate(2, state);
    minqpsetquadratictermsparse(state, a, true);
    minqpsetlinearterm(state, b);
    minqpsetstartingpoint(state, x0);

    <font color=navy>// Set scale of the parameters.</font>
    <font color=navy>// It is strongly recommended that you set scale of your variables.</font>
    <font color=navy>// Knowing their scales is essential <b>for</b> evaluation of stopping criteria</font>
    <font color=navy>// and <b>for</b> preconditioning of the algorithm steps.</font>
    <font color=navy>// You can find more information on scaling at http://www.alglib.net/optimization/scaling.php</font>
    minqpsetscale(state, s);

    <font color=navy>// solve problem with BLEIC-based QP solver.</font>
    <font color=navy>// default stopping criteria are used.</font>
    minqpsetalgobleic(state, 0.0, 0.0, 0.0, 0);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, x.tostring(2).c_str()); <font color=navy>// EXPECTED: [3,2]</font>

    <font color=navy>// try to solve problem with Cholesky-based QP solver...</font>
    <font color=navy>// Oops! It does not support sparse matrices, -5 returned as completion code!</font>
    minqpsetalgocholesky(state);
    minqpoptimize(state);
    minqpresults(state, x, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: -5</font>
    <b>return</b> 0;
}


</pre><a name=unit_mlpbase></a><h2 class=pageheader><code>mlpbase</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_modelerrors' class=toc>modelerrors</a><br>
<a href='#struct_multilayerperceptron' class=toc>multilayerperceptron</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpactivationfunction' class=toc>mlpactivationfunction</a><br>
<a href='#sub_mlpallerrorssparsesubset' class=toc>mlpallerrorssparsesubset</a><br>
<a href='#sub_mlpallerrorssubset' class=toc>mlpallerrorssubset</a><br>
<a href='#sub_mlpavgce' class=toc>mlpavgce</a><br>
<a href='#sub_mlpavgcesparse' class=toc>mlpavgcesparse</a><br>
<a href='#sub_mlpavgerror' class=toc>mlpavgerror</a><br>
<a href='#sub_mlpavgerrorsparse' class=toc>mlpavgerrorsparse</a><br>
<a href='#sub_mlpavgrelerror' class=toc>mlpavgrelerror</a><br>
<a href='#sub_mlpavgrelerrorsparse' class=toc>mlpavgrelerrorsparse</a><br>
<a href='#sub_mlpclserror' class=toc>mlpclserror</a><br>
<a href='#sub_mlpcreate0' class=toc>mlpcreate0</a><br>
<a href='#sub_mlpcreate1' class=toc>mlpcreate1</a><br>
<a href='#sub_mlpcreate2' class=toc>mlpcreate2</a><br>
<a href='#sub_mlpcreateb0' class=toc>mlpcreateb0</a><br>
<a href='#sub_mlpcreateb1' class=toc>mlpcreateb1</a><br>
<a href='#sub_mlpcreateb2' class=toc>mlpcreateb2</a><br>
<a href='#sub_mlpcreatec0' class=toc>mlpcreatec0</a><br>
<a href='#sub_mlpcreatec1' class=toc>mlpcreatec1</a><br>
<a href='#sub_mlpcreatec2' class=toc>mlpcreatec2</a><br>
<a href='#sub_mlpcreater0' class=toc>mlpcreater0</a><br>
<a href='#sub_mlpcreater1' class=toc>mlpcreater1</a><br>
<a href='#sub_mlpcreater2' class=toc>mlpcreater2</a><br>
<a href='#sub_mlperror' class=toc>mlperror</a><br>
<a href='#sub_mlperrorn' class=toc>mlperrorn</a><br>
<a href='#sub_mlperrorsparse' class=toc>mlperrorsparse</a><br>
<a href='#sub_mlperrorsparsesubset' class=toc>mlperrorsparsesubset</a><br>
<a href='#sub_mlperrorsubset' class=toc>mlperrorsubset</a><br>
<a href='#sub_mlpgetinputscaling' class=toc>mlpgetinputscaling</a><br>
<a href='#sub_mlpgetinputscount' class=toc>mlpgetinputscount</a><br>
<a href='#sub_mlpgetlayerscount' class=toc>mlpgetlayerscount</a><br>
<a href='#sub_mlpgetlayersize' class=toc>mlpgetlayersize</a><br>
<a href='#sub_mlpgetneuroninfo' class=toc>mlpgetneuroninfo</a><br>
<a href='#sub_mlpgetoutputscaling' class=toc>mlpgetoutputscaling</a><br>
<a href='#sub_mlpgetoutputscount' class=toc>mlpgetoutputscount</a><br>
<a href='#sub_mlpgetweight' class=toc>mlpgetweight</a><br>
<a href='#sub_mlpgetweightscount' class=toc>mlpgetweightscount</a><br>
<a href='#sub_mlpgrad' class=toc>mlpgrad</a><br>
<a href='#sub_mlpgradbatch' class=toc>mlpgradbatch</a><br>
<a href='#sub_mlpgradbatchsparse' class=toc>mlpgradbatchsparse</a><br>
<a href='#sub_mlpgradbatchsparsesubset' class=toc>mlpgradbatchsparsesubset</a><br>
<a href='#sub_mlpgradbatchsubset' class=toc>mlpgradbatchsubset</a><br>
<a href='#sub_mlpgradn' class=toc>mlpgradn</a><br>
<a href='#sub_mlpgradnbatch' class=toc>mlpgradnbatch</a><br>
<a href='#sub_mlphessianbatch' class=toc>mlphessianbatch</a><br>
<a href='#sub_mlphessiannbatch' class=toc>mlphessiannbatch</a><br>
<a href='#sub_mlpissoftmax' class=toc>mlpissoftmax</a><br>
<a href='#sub_mlpprocess' class=toc>mlpprocess</a><br>
<a href='#sub_mlpprocessi' class=toc>mlpprocessi</a><br>
<a href='#sub_mlpproperties' class=toc>mlpproperties</a><br>
<a href='#sub_mlprandomize' class=toc>mlprandomize</a><br>
<a href='#sub_mlprandomizefull' class=toc>mlprandomizefull</a><br>
<a href='#sub_mlprelclserror' class=toc>mlprelclserror</a><br>
<a href='#sub_mlprelclserrorsparse' class=toc>mlprelclserrorsparse</a><br>
<a href='#sub_mlprmserror' class=toc>mlprmserror</a><br>
<a href='#sub_mlprmserrorsparse' class=toc>mlprmserrorsparse</a><br>
<a href='#sub_mlpserialize' class=toc>mlpserialize</a><br>
<a href='#sub_mlpsetinputscaling' class=toc>mlpsetinputscaling</a><br>
<a href='#sub_mlpsetneuroninfo' class=toc>mlpsetneuroninfo</a><br>
<a href='#sub_mlpsetoutputscaling' class=toc>mlpsetoutputscaling</a><br>
<a href='#sub_mlpsetweight' class=toc>mlpsetweight</a><br>
<a href='#sub_mlpunserialize' class=toc>mlpunserialize</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_modelerrors'></a><h3 class=pageheader><code>modelerrors</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Model's errors:
    * RelCLSError   -   fraction of misclassified cases.
    * AvgCE         -   acerage cross-entropy
    * RMSError      -   root-mean-square error
    * AvgError      -   average error
    * AvgRelError   -   average relative error

NOTE 1: RelCLSError/AvgCE are zero on regression problems.

NOTE 2: on classification problems  RMSError/AvgError/AvgRelError  contain
        errors in prediction of posterior probabilities
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> modelerrors
{
    <b>double</b>               relclserror;
    <b>double</b>               avgce;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
};

</div></pre>
<a name='struct_multilayerperceptron'></a><h3 class=pageheader><code>multilayerperceptron</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> multilayerperceptron
{
};

</div></pre>
<a name='sub_mlpactivationfunction'></a><h3 class=pageheader><code>mlpactivationfunction</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Neural network activation function

INPUT PARAMETERS:
    NET         -   neuron input
    K           -   function index (zero for linear function)

OUTPUT PARAMETERS:
    F           -   function
    DF          -   its derivative
    D2F         -   its second derivative

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpactivationfunction(
    <b>double</b> net,
    ae_int_t k,
    <b>double</b>&amp; f,
    <b>double</b>&amp; df,
    <b>double</b>&amp; d2f);

</div></pre>
<a name='sub_mlpallerrorssparsesubset'></a><h3 class=pageheader><code>mlpallerrorssparsesubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of all types of errors on sparse dataset.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset given by sparse matrix;
                one sample = one row;
                first NIn columns contain inputs,
                next NOut columns - desired outputs.
    SetSize -   real size of XY, SetSize&gt;=0;
    Subset  -   subset of SubsetSize elements, array[SubsetSize];
    SubsetSize- number of elements in Subset[] array.

OUTPUT PARAMETERS:
    Rep     -   it contains all type of errors.

NOTE: when SubsetSize&lt;0 is used full dataset by call MLPGradBatch function.

  -- ALGLIB --
     Copyright 04.09.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpallerrorssparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize,
    modelerrors&amp; rep);
<b>void</b> alglib::smp_mlpallerrorssparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize,
    modelerrors&amp; rep);

</div></pre>
<a name='sub_mlpallerrorssubset'></a><h3 class=pageheader><code>mlpallerrorssubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Calculation of all types of errors.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset; one sample = one row;
                first NIn columns contain inputs,
                next NOut columns - desired outputs.
    SetSize -   real size of XY, SetSize&gt;=0;
    Subset  -   subset of SubsetSize elements, array[SubsetSize];
    SubsetSize- number of elements in Subset[] array.

OUTPUT PARAMETERS:
    Rep     -   it contains all type of errors.

NOTE: when SubsetSize&lt;0 is used full dataset by call MLPGradBatch function.

  -- ALGLIB --
     Copyright 04.09.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpallerrorssubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize,
    modelerrors&amp; rep);
<b>void</b> alglib::smp_mlpallerrorssubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize,
    modelerrors&amp; rep);

</div></pre>
<a name='sub_mlpavgce'></a><h3 class=pageheader><code>mlpavgce</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average cross-entropy  (in bits  per element) on the test set.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
CrossEntropy/(NPoints*LN(2)).
Zero if network solves regression task.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 08.01.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgce(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgce(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpavgcesparse'></a><h3 class=pageheader><code>mlpavgcesparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average  cross-entropy  (in bits  per element)  on the  test set  given by
sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.  Sparse  matrix  must  use  CRS  format for
                    storage.
    NPoints     -   points count, &gt;=0.

RESULT:
CrossEntropy/(NPoints*LN(2)).
Zero if network solves regression task.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 9.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgcesparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgcesparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpavgerror'></a><h3 class=pageheader><code>mlpavgerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average absolute error on the test set.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
Its meaning for regression task is obvious. As for classification task, it
means average error when estimating posterior probabilities.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 11.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgerror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgerror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpavgerrorsparse'></a><h3 class=pageheader><code>mlpavgerrorsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average absolute error on the test set given by sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.  Sparse  matrix  must  use  CRS  format for
                    storage.
    NPoints     -   points count, &gt;=0.

RESULT:
Its meaning for regression task is obvious. As for classification task, it
means average error when estimating posterior probabilities.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 09.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgerrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgerrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpavgrelerror'></a><h3 class=pageheader><code>mlpavgrelerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average relative error on the test set.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
Its meaning for regression task is obvious. As for classification task, it
means  average  relative  error  when  estimating posterior probability of
belonging to the correct class.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 11.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgrelerror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgrelerror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpavgrelerrorsparse'></a><h3 class=pageheader><code>mlpavgrelerrorsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average relative error on the test set given by sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.  Sparse  matrix  must  use  CRS  format for
                    storage.
    NPoints     -   points count, &gt;=0.

RESULT:
Its meaning for regression task is obvious. As for classification task, it
means  average  relative  error  when  estimating posterior probability of
belonging to the correct class.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 09.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpavgrelerrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlpavgrelerrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpclserror'></a><h3 class=pageheader><code>mlpclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Classification error of the neural network on dataset.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
    classification error (number of misclassified cases)

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpclserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
ae_int_t alglib::smp_mlpclserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpcreate0'></a><h3 class=pageheader><code>mlpcreate0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
layers, with linear output layer. Network weights are  filled  with  small
random values.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreate0(
    ae_int_t nin,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreate1'></a><h3 class=pageheader><code>mlpcreate1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same  as  MLPCreate0,  but  with  one  hidden  layer  (NHid  neurons) with
non-linear activation function. Output layer is linear.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreate1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreate2'></a><h3 class=pageheader><code>mlpcreate2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreate0, but with two hidden layers (NHid1 and  NHid2  neurons)
with non-linear activation function. Output layer is linear.
 $ALL

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreate2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreateb0'></a><h3 class=pageheader><code>mlpcreateb0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
layers with non-linear output layer. Network weights are filled with small
random values.

Activation function of the output layer takes values:

    (B, +INF), if D&gt;=0

or

    (-INF, B), if D&lt;0.


  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreateb0(
    ae_int_t nin,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreateb1'></a><h3 class=pageheader><code>mlpcreateb1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateB0 but with non-linear hidden layer.

  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreateb1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreateb2'></a><h3 class=pageheader><code>mlpcreateb2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateB0 but with two non-linear hidden layers.

  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreateb2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreatec0'></a><h3 class=pageheader><code>mlpcreatec0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creates classifier network with NIn  inputs  and  NOut  possible  classes.
Network contains no hidden layers and linear output  layer  with  SOFTMAX-
normalization  (so  outputs  sums  up  to  1.0  and  converge to posterior
probabilities).

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreatec0(
    ae_int_t nin,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreatec1'></a><h3 class=pageheader><code>mlpcreatec1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateC0, but with one non-linear hidden layer.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreatec1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreatec2'></a><h3 class=pageheader><code>mlpcreatec2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateC0, but with two non-linear hidden layers.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreatec2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreater0'></a><h3 class=pageheader><code>mlpcreater0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creates  neural  network  with  NIn  inputs,  NOut outputs, without hidden
layers with non-linear output layer. Network weights are filled with small
random values. Activation function of the output layer takes values [A,B].

  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreater0(
    ae_int_t nin,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreater1'></a><h3 class=pageheader><code>mlpcreater1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateR0, but with non-linear hidden layer.

  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreater1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlpcreater2'></a><h3 class=pageheader><code>mlpcreater2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Same as MLPCreateR0, but with two non-linear hidden layers.

  -- ALGLIB --
     Copyright 30.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreater2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    multilayerperceptron&amp; network);

</div></pre>
<a name='sub_mlperror'></a><h3 class=pageheader><code>mlperror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Error of the neural network on dataset.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore systems.
  ! Second improvement gives constant speedup (2-3x, depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
    sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlperror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlperrorn'></a><h3 class=pageheader><code>mlperrorn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Natural error function for neural network, internal subroutine.

NOTE: this function is single-threaded. Unlike other  error  function,  it
receives no speed-up from being executed in SMP mode.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperrorn(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize);

</div></pre>
<a name='sub_mlperrorsparse'></a><h3 class=pageheader><code>mlperrorsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Error of the neural network on dataset given by sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore systems.
  ! Second improvement gives constant speedup (2-3x, depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.  Sparse  matrix  must  use  CRS  format for
                    storage.
    NPoints     -   points count, &gt;=0

RESULT:
    sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlperrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlperrorsparsesubset'></a><h3 class=pageheader><code>mlperrorsparsesubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Error of the neural network on sparse dataset.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network   -   neural network;
    XY        -   training  set,  see  below  for  information  on   the
                  training set format. This function checks  correctness
                  of  the  dataset  (no  NANs/INFs,  class  numbers  are
                  correct) and throws exception when  incorrect  dataset
                  is passed.  Sparse  matrix  must  use  CRS  format for
                  storage.
    SetSize   -   real size of XY, SetSize&gt;=0;
                  it is used when SubsetSize&lt;0;
    Subset    -   subset of SubsetSize elements, array[SubsetSize];
    SubsetSize-   number of elements in Subset[] array.

RESULT:
    sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 04.09.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperrorsparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize);
<b>double</b> alglib::smp_mlperrorsparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize);

</div></pre>
<a name='sub_mlperrorsubset'></a><h3 class=pageheader><code>mlperrorsubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Error of the neural network on dataset.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network   -   neural network;
    XY        -   training  set,  see  below  for  information  on   the
                  training set format;
    SetSize   -   real size of XY, SetSize&gt;=0;
    Subset    -   subset of SubsetSize elements, array[SubsetSize];
    SubsetSize-   number of elements in Subset[] array.

RESULT:
    sum-of-squares error, SUM(sqr(y[i]-desired_y[i])/2)

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 04.09.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperrorsubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize);
<b>double</b> alglib::smp_mlperrorsubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array subset,
    ae_int_t subsetsize);

</div></pre>
<a name='sub_mlpgetinputscaling'></a><h3 class=pageheader><code>mlpgetinputscaling</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns offset/scaling coefficients for I-th input of the
network.

INPUT PARAMETERS:
    Network     -   network
    I           -   input index

OUTPUT PARAMETERS:
    Mean        -   mean term
    Sigma       -   sigma term, guaranteed to be nonzero.

I-th input is passed through linear transformation
    IN[i] = (IN[i]-Mean)/Sigma
before feeding to the network

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgetinputscaling(
    multilayerperceptron network,
    ae_int_t i,
    <b>double</b>&amp; mean,
    <b>double</b>&amp; sigma);

</div></pre>
<a name='sub_mlpgetinputscount'></a><h3 class=pageheader><code>mlpgetinputscount</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns number of inputs.

  -- ALGLIB --
     Copyright 19.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpgetinputscount(multilayerperceptron network);

</div></pre>
<a name='sub_mlpgetlayerscount'></a><h3 class=pageheader><code>mlpgetlayerscount</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns total number of layers (including input, hidden and
output layers).

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpgetlayerscount(multilayerperceptron network);

</div></pre>
<a name='sub_mlpgetlayersize'></a><h3 class=pageheader><code>mlpgetlayersize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns size of K-th layer.

K=0 corresponds to input layer, K=CNT-1 corresponds to output layer.

Size of the output layer is always equal to the number of outputs, although
when we have softmax-normalized network, last neuron doesn't have any
connections - it is just zero.

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpgetlayersize(
    multilayerperceptron network,
    ae_int_t k);

</div></pre>
<a name='sub_mlpgetneuroninfo'></a><h3 class=pageheader><code>mlpgetneuroninfo</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns information about Ith neuron of Kth layer

INPUT PARAMETERS:
    Network     -   network
    K           -   layer index
    I           -   neuron index (within layer)

OUTPUT PARAMETERS:
    FKind       -   activation function type (used by MLPActivationFunction())
                    this value is zero for input or linear neurons
    Threshold   -   also called offset, bias
                    zero for input neurons

NOTE: this function throws exception if layer or neuron with  given  index
do not exists.

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgetneuroninfo(
    multilayerperceptron network,
    ae_int_t k,
    ae_int_t i,
    ae_int_t&amp; fkind,
    <b>double</b>&amp; threshold);

</div></pre>
<a name='sub_mlpgetoutputscaling'></a><h3 class=pageheader><code>mlpgetoutputscaling</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns offset/scaling coefficients for I-th output of the
network.

INPUT PARAMETERS:
    Network     -   network
    I           -   input index

OUTPUT PARAMETERS:
    Mean        -   mean term
    Sigma       -   sigma term, guaranteed to be nonzero.

I-th output is passed through linear transformation
    OUT[i] = OUT[i]*Sigma+Mean
before returning it to user. In case we have SOFTMAX-normalized network,
we return (Mean,Sigma)=(0.0,1.0).

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgetoutputscaling(
    multilayerperceptron network,
    ae_int_t i,
    <b>double</b>&amp; mean,
    <b>double</b>&amp; sigma);

</div></pre>
<a name='sub_mlpgetoutputscount'></a><h3 class=pageheader><code>mlpgetoutputscount</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns number of outputs.

  -- ALGLIB --
     Copyright 19.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpgetoutputscount(multilayerperceptron network);

</div></pre>
<a name='sub_mlpgetweight'></a><h3 class=pageheader><code>mlpgetweight</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns information about connection from I0-th neuron of
K0-th layer to I1-th neuron of K1-th layer.

INPUT PARAMETERS:
    Network     -   network
    K0          -   layer index
    I0          -   neuron index (within layer)
    K1          -   layer index
    I1          -   neuron index (within layer)

RESULT:
    connection weight (zero for non-existent connections)

This function:
1. throws exception if layer or neuron with given index do not exists.
2. returns zero if neurons exist, but there is no connection between them

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpgetweight(
    multilayerperceptron network,
    ae_int_t k0,
    ae_int_t i0,
    ae_int_t k1,
    ae_int_t i1);

</div></pre>
<a name='sub_mlpgetweightscount'></a><h3 class=pageheader><code>mlpgetweightscount</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns number of weights.

  -- ALGLIB --
     Copyright 19.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::mlpgetweightscount(multilayerperceptron network);

</div></pre>
<a name='sub_mlpgrad'></a><h3 class=pageheader><code>mlpgrad</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Gradient calculation

INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    X       -   input vector, length of array must be at least NIn
    DesiredY-   desired outputs, length of array must be at least NOut
    Grad    -   possibly preallocated array. If size of array is smaller
                than WCount, it will be reallocated. It is recommended to
                reuse previously allocated array to reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
    Grad    -   gradient of E with respect to weights of network, array[WCount]

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgrad(
    multilayerperceptron network,
    real_1d_array x,
    real_1d_array desiredy,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradbatch'></a><h3 class=pageheader><code>mlpgradbatch</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch gradient calculation for a set of inputs/outputs


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset in dense format; one sample = one row:
                * first NIn columns contain inputs,
                * for regression problem, next NOut columns store
                  desired outputs.
                * for classification problem, next column (just one!)
                  stores class number.
    SSize   -   number of elements in XY
    Grad    -   possibly preallocated array. If size of array is smaller
                than WCount, it will be reallocated. It is recommended to
                reuse previously allocated array to reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
    Grad    -   gradient of E with respect to weights of network, array[WCount]

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradbatch(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);
<b>void</b> alglib::smp_mlpgradbatch(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradbatchsparse'></a><h3 class=pageheader><code>mlpgradbatchsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch gradient calculation for a set  of inputs/outputs  given  by  sparse
matrices


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset in sparse format; one sample = one row:
                * MATRIX MUST BE STORED IN CRS FORMAT
                * first NIn columns contain inputs.
                * for regression problem, next NOut columns store
                  desired outputs.
                * for classification problem, next column (just one!)
                  stores class number.
    SSize   -   number of elements in XY
    Grad    -   possibly preallocated array. If size of array is smaller
                than WCount, it will be reallocated. It is recommended to
                reuse previously allocated array to reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
    Grad    -   gradient of E with respect to weights of network, array[WCount]

  -- ALGLIB --
     Copyright 26.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradbatchsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);
<b>void</b> alglib::smp_mlpgradbatchsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradbatchsparsesubset'></a><h3 class=pageheader><code>mlpgradbatchsparsesubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch gradient calculation for a set of inputs/outputs  for  a  subset  of
dataset given by set of indexes.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset in sparse format; one sample = one row:
                * MATRIX MUST BE STORED IN CRS FORMAT
                * first NIn columns contain inputs,
                * for regression problem, next NOut columns store
                  desired outputs.
                * for classification problem, next column (just one!)
                  stores class number.
    SetSize -   real size of XY, SetSize&gt;=0;
    Idx     -   subset of SubsetSize elements, array[SubsetSize]:
                * Idx[I] stores row index in the original dataset which is
                  given by XY. Gradient is calculated with respect to rows
                  whose indexes are stored in Idx[].
                * Idx[]  must store correct indexes; this function  throws
                  an  exception  in  case  incorrect index (less than 0 or
                  larger than rows(XY)) is given
                * Idx[]  may  store  indexes  in  any  order and even with
                  repetitions.
    SubsetSize- number of elements in Idx[] array:
                * positive value means that subset given by Idx[] is processed
                * zero value results in zero gradient
                * negative value means that full dataset is processed
    Grad      - possibly  preallocated array. If size of array is  smaller
                than WCount, it will be reallocated. It is  recommended to
                reuse  previously  allocated  array  to  reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, SUM(sqr(y[i]-desiredy[i])/2,i)
    Grad    -   gradient  of  E  with  respect   to  weights  of  network,
                array[WCount]

NOTE: when  SubsetSize&lt;0 is used full dataset by call MLPGradBatchSparse
      function.

  -- ALGLIB --
     Copyright 26.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradbatchsparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array idx,
    ae_int_t subsetsize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);
<b>void</b> alglib::smp_mlpgradbatchsparsesubset(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t setsize,
    integer_1d_array idx,
    ae_int_t subsetsize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradbatchsubset'></a><h3 class=pageheader><code>mlpgradbatchsubset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch gradient calculation for a subset of dataset


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   original dataset in dense format; one sample = one row:
                * first NIn columns contain inputs,
                * for regression problem, next NOut columns store
                  desired outputs.
                * for classification problem, next column (just one!)
                  stores class number.
    SetSize -   real size of XY, SetSize&gt;=0;
    Idx     -   subset of SubsetSize elements, array[SubsetSize]:
                * Idx[I] stores row index in the original dataset which is
                  given by XY. Gradient is calculated with respect to rows
                  whose indexes are stored in Idx[].
                * Idx[]  must store correct indexes; this function  throws
                  an  exception  in  case  incorrect index (less than 0 or
                  larger than rows(XY)) is given
                * Idx[]  may  store  indexes  in  any  order and even with
                  repetitions.
    SubsetSize- number of elements in Idx[] array:
                * positive value means that subset given by Idx[] is processed
                * zero value results in zero gradient
                * negative value means that full dataset is processed
    Grad      - possibly  preallocated array. If size of array is  smaller
                than WCount, it will be reallocated. It is  recommended to
                reuse  previously  allocated  array  to  reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E         - error function, SUM(sqr(y[i]-desiredy[i])/2,i)
    Grad      - gradient  of  E  with  respect   to  weights  of  network,
                array[WCount]

  -- ALGLIB --
     Copyright 26.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradbatchsubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array idx,
    ae_int_t subsetsize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);
<b>void</b> alglib::smp_mlpgradbatchsubset(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t setsize,
    integer_1d_array idx,
    ae_int_t subsetsize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradn'></a><h3 class=pageheader><code>mlpgradn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Gradient calculation (natural error function is used)

INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    X       -   input vector, length of array must be at least NIn
    DesiredY-   desired outputs, length of array must be at least NOut
    Grad    -   possibly preallocated array. If size of array is smaller
                than WCount, it will be reallocated. It is recommended to
                reuse previously allocated array to reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, sum-of-squares for regression networks,
                cross-entropy for classification networks.
    Grad    -   gradient of E with respect to weights of network, array[WCount]

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradn(
    multilayerperceptron network,
    real_1d_array x,
    real_1d_array desiredy,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlpgradnbatch'></a><h3 class=pageheader><code>mlpgradnbatch</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch gradient calculation for a set of inputs/outputs
(natural error function is used)

INPUT PARAMETERS:
    Network -   network initialized with one of the network creation funcs
    XY      -   set of inputs/outputs; one sample = one row;
                first NIn columns contain inputs,
                next NOut columns - desired outputs.
    SSize   -   number of elements in XY
    Grad    -   possibly preallocated array. If size of array is smaller
                than WCount, it will be reallocated. It is recommended to
                reuse previously allocated array to reduce allocation
                overhead.

OUTPUT PARAMETERS:
    E       -   error function, sum-of-squares for regression networks,
                cross-entropy for classification networks.
    Grad    -   gradient of E with respect to weights of network, array[WCount]

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpgradnbatch(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad);

</div></pre>
<a name='sub_mlphessianbatch'></a><h3 class=pageheader><code>mlphessianbatch</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch Hessian calculation using R-algorithm.
Internal subroutine.

  -- ALGLIB --
     Copyright 26.01.2008 by Bochkanov Sergey.

     Hessian calculation based on R-algorithm described in
     &quot;Fast Exact Multiplication by the Hessian&quot;,
     B. A. Pearlmutter,
     Neural Computation, 1994.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlphessianbatch(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad,
    real_2d_array&amp; h);

</div></pre>
<a name='sub_mlphessiannbatch'></a><h3 class=pageheader><code>mlphessiannbatch</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Batch Hessian calculation (natural error function) using R-algorithm.
Internal subroutine.

  -- ALGLIB --
     Copyright 26.01.2008 by Bochkanov Sergey.

     Hessian calculation based on R-algorithm described in
     &quot;Fast Exact Multiplication by the Hessian&quot;,
     B. A. Pearlmutter,
     Neural Computation, 1994.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlphessiannbatch(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t ssize,
    <b>double</b>&amp; e,
    real_1d_array&amp; grad,
    real_2d_array&amp; h);

</div></pre>
<a name='sub_mlpissoftmax'></a><h3 class=pageheader><code>mlpissoftmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Tells whether network is SOFTMAX-normalized (i.e. classifier) or not.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::mlpissoftmax(multilayerperceptron network);

</div></pre>
<a name='sub_mlpprocess'></a><h3 class=pageheader><code>mlpprocess</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procesing

INPUT PARAMETERS:
    Network -   neural network
    X       -   input vector,  array[0..NIn-1].

OUTPUT PARAMETERS:
    Y       -   result. Regression estimate when solving regression  task,
                vector of posterior probabilities for classification task.

See also MLPProcessI

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpprocess(
    multilayerperceptron network,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_mlpprocessi'></a><h3 class=pageheader><code>mlpprocessi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
'interactive'  variant  of  MLPProcess  for  languages  like  Python which
support constructs like &quot;Y = MLPProcess(NN,X)&quot; and interactive mode of the
interpreter

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 21.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpprocessi(
    multilayerperceptron network,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_mlpproperties'></a><h3 class=pageheader><code>mlpproperties</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Returns information about initialized network: number of inputs, outputs,
weights.

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpproperties(
    multilayerperceptron network,
    ae_int_t&amp; nin,
    ae_int_t&amp; nout,
    ae_int_t&amp; wcount);

</div></pre>
<a name='sub_mlprandomize'></a><h3 class=pageheader><code>mlprandomize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Randomization of neural network weights

  -- ALGLIB --
     Copyright 06.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlprandomize(multilayerperceptron network);

</div></pre>
<a name='sub_mlprandomizefull'></a><h3 class=pageheader><code>mlprandomizefull</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Randomization of neural network weights and standartisator

  -- ALGLIB --
     Copyright 10.03.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlprandomizefull(multilayerperceptron network);

</div></pre>
<a name='sub_mlprelclserror'></a><h3 class=pageheader><code>mlprelclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Relative classification error on the test set.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
Percent   of incorrectly   classified  cases.  Works  both  for classifier
networks and general purpose networks used as classifiers.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 25.12.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlprelclserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlprelclserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlprelclserrorsparse'></a><h3 class=pageheader><code>mlprelclserrorsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Relative classification error on the test set given by sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. Sparse matrix must use CRS format
                    for storage.
    NPoints     -   points count, &gt;=0.

RESULT:
Percent   of incorrectly   classified  cases.  Works  both  for classifier
networks and general purpose networks used as classifiers.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 09.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlprelclserrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlprelclserrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlprmserror'></a><h3 class=pageheader><code>mlprmserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set given.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format;
    NPoints     -   points count.

RESULT:
Root mean  square error. Its meaning for regression task is obvious. As for
classification  task,  RMS  error  means  error  when estimating  posterior
probabilities.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 04.11.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlprmserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlprmserror(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlprmserrorsparse'></a><h3 class=pageheader><code>mlprmserrorsparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set given by sparse matrix.


FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support
  !
  ! First improvement gives close-to-linear speedup on multicore  systems.
  ! Second improvement gives constant speedup (2-3x depending on your CPU)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.


INPUT PARAMETERS:
    Network     -   neural network;
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.  Sparse  matrix  must  use  CRS  format for
                    storage.
    NPoints     -   points count, &gt;=0.

RESULT:
Root mean  square error. Its meaning for regression task is obvious. As for
classification  task,  RMS  error  means  error  when estimating  posterior
probabilities.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
dataset format is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 09.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlprmserrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);
<b>double</b> alglib::smp_mlprmserrorsparse(
    multilayerperceptron network,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpserialize'></a><h3 class=pageheader><code>mlpserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function serializes data structure to string.

Important properties of s_out:
* it contains alphanumeric characters, dots, underscores, minus signs
* these symbols are grouped into words, which are separated by spaces
  and Windows-style (CR+LF) newlines
* although  serializer  uses  spaces and CR+LF as separators, you can 
  replace any separator character by arbitrary combination of spaces,
  tabs, Windows or Unix newlines. It allows flexible reformatting  of
  the  string  in  case you want to include it into text or XML file. 
  But you should not insert separators into the middle of the &quot;words&quot;
  nor you should change case of letters.
* s_out can be freely moved between 32-bit and 64-bit systems, little
  and big endian machines, and so on. You can serialize structure  on
  32-bit machine and unserialize it on 64-bit one (or vice versa), or
  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also 
  serialize  it  in  C++ version of ALGLIB and unserialize in C# one, 
  and vice versa.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> mlpserialize(multilayerperceptron &amp;obj, std::string &amp;s_out);
</div></pre>
<a name='sub_mlpsetinputscaling'></a><h3 class=pageheader><code>mlpsetinputscaling</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets offset/scaling coefficients for I-th input of the
network.

INPUT PARAMETERS:
    Network     -   network
    I           -   input index
    Mean        -   mean term
    Sigma       -   sigma term (if zero, will be replaced by 1.0)

NTE: I-th input is passed through linear transformation
    IN[i] = (IN[i]-Mean)/Sigma
before feeding to the network. This function sets Mean and Sigma.

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetinputscaling(
    multilayerperceptron network,
    ae_int_t i,
    <b>double</b> mean,
    <b>double</b> sigma);

</div></pre>
<a name='sub_mlpsetneuroninfo'></a><h3 class=pageheader><code>mlpsetneuroninfo</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function modifies information about Ith neuron of Kth layer

INPUT PARAMETERS:
    Network     -   network
    K           -   layer index
    I           -   neuron index (within layer)
    FKind       -   activation function type (used by MLPActivationFunction())
                    this value must be zero for input neurons
                    (you can not set activation function for input neurons)
    Threshold   -   also called offset, bias
                    this value must be zero for input neurons
                    (you can not set threshold for input neurons)

NOTES:
1. this function throws exception if layer or neuron with given index do
   not exists.
2. this function also throws exception when you try to set non-linear
   activation function for input neurons (any kind of network) or for output
   neurons of classifier network.
3. this function throws exception when you try to set non-zero threshold for
   input neurons (any kind of network).

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetneuroninfo(
    multilayerperceptron network,
    ae_int_t k,
    ae_int_t i,
    ae_int_t fkind,
    <b>double</b> threshold);

</div></pre>
<a name='sub_mlpsetoutputscaling'></a><h3 class=pageheader><code>mlpsetoutputscaling</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets offset/scaling coefficients for I-th output of the
network.

INPUT PARAMETERS:
    Network     -   network
    I           -   input index
    Mean        -   mean term
    Sigma       -   sigma term (if zero, will be replaced by 1.0)

OUTPUT PARAMETERS:

NOTE: I-th output is passed through linear transformation
    OUT[i] = OUT[i]*Sigma+Mean
before returning it to user. This function sets Sigma/Mean. In case we
have SOFTMAX-normalized network, you can not set (Sigma,Mean) to anything
other than(0.0,1.0) - this function will throw exception.

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetoutputscaling(
    multilayerperceptron network,
    ae_int_t i,
    <b>double</b> mean,
    <b>double</b> sigma);

</div></pre>
<a name='sub_mlpsetweight'></a><h3 class=pageheader><code>mlpsetweight</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function modifies information about connection from I0-th neuron of
K0-th layer to I1-th neuron of K1-th layer.

INPUT PARAMETERS:
    Network     -   network
    K0          -   layer index
    I0          -   neuron index (within layer)
    K1          -   layer index
    I1          -   neuron index (within layer)
    W           -   connection weight (must be zero for non-existent
                    connections)

This function:
1. throws exception if layer or neuron with given index do not exists.
2. throws exception if you try to set non-zero weight for non-existent
   connection

  -- ALGLIB --
     Copyright 25.03.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetweight(
    multilayerperceptron network,
    ae_int_t k0,
    ae_int_t i0,
    ae_int_t k1,
    ae_int_t i1,
    <b>double</b> w);

</div></pre>
<a name='sub_mlpunserialize'></a><h3 class=pageheader><code>mlpunserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function unserializes data structure from string.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> mlpunserialize(std::string &amp;s_in, multilayerperceptron &amp;obj);
</div></pre>
<a name=unit_mlpe></a><h2 class=pageheader><code>mlpe</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_mlpensemble' class=toc>mlpensemble</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpeavgce' class=toc>mlpeavgce</a><br>
<a href='#sub_mlpeavgerror' class=toc>mlpeavgerror</a><br>
<a href='#sub_mlpeavgrelerror' class=toc>mlpeavgrelerror</a><br>
<a href='#sub_mlpecreate0' class=toc>mlpecreate0</a><br>
<a href='#sub_mlpecreate1' class=toc>mlpecreate1</a><br>
<a href='#sub_mlpecreate2' class=toc>mlpecreate2</a><br>
<a href='#sub_mlpecreateb0' class=toc>mlpecreateb0</a><br>
<a href='#sub_mlpecreateb1' class=toc>mlpecreateb1</a><br>
<a href='#sub_mlpecreateb2' class=toc>mlpecreateb2</a><br>
<a href='#sub_mlpecreatec0' class=toc>mlpecreatec0</a><br>
<a href='#sub_mlpecreatec1' class=toc>mlpecreatec1</a><br>
<a href='#sub_mlpecreatec2' class=toc>mlpecreatec2</a><br>
<a href='#sub_mlpecreatefromnetwork' class=toc>mlpecreatefromnetwork</a><br>
<a href='#sub_mlpecreater0' class=toc>mlpecreater0</a><br>
<a href='#sub_mlpecreater1' class=toc>mlpecreater1</a><br>
<a href='#sub_mlpecreater2' class=toc>mlpecreater2</a><br>
<a href='#sub_mlpeissoftmax' class=toc>mlpeissoftmax</a><br>
<a href='#sub_mlpeprocess' class=toc>mlpeprocess</a><br>
<a href='#sub_mlpeprocessi' class=toc>mlpeprocessi</a><br>
<a href='#sub_mlpeproperties' class=toc>mlpeproperties</a><br>
<a href='#sub_mlperandomize' class=toc>mlperandomize</a><br>
<a href='#sub_mlperelclserror' class=toc>mlperelclserror</a><br>
<a href='#sub_mlpermserror' class=toc>mlpermserror</a><br>
<a href='#sub_mlpeserialize' class=toc>mlpeserialize</a><br>
<a href='#sub_mlpeunserialize' class=toc>mlpeunserialize</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_mlpensemble'></a><h3 class=pageheader><code>mlpensemble</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Neural networks ensemble
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mlpensemble
{
};

</div></pre>
<a name='sub_mlpeavgce'></a><h3 class=pageheader><code>mlpeavgce</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average cross-entropy (in bits per element) on the test set

INPUT PARAMETERS:
    Ensemble-   ensemble
    XY      -   test set
    NPoints -   test set size

RESULT:
    CrossEntropy/(NPoints*LN(2)).
    Zero if ensemble solves regression task.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpeavgce(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpeavgerror'></a><h3 class=pageheader><code>mlpeavgerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average error on the test set

INPUT PARAMETERS:
    Ensemble-   ensemble
    XY      -   test set
    NPoints -   test set size

RESULT:
    Its meaning for regression task is obvious. As for classification task
it means average error when estimating posterior probabilities.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpeavgerror(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpeavgrelerror'></a><h3 class=pageheader><code>mlpeavgrelerror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Average relative error on the test set

INPUT PARAMETERS:
    Ensemble-   ensemble
    XY      -   test set
    NPoints -   test set size

RESULT:
    Its meaning for regression task is obvious. As for classification task
it means average relative error when estimating posterior probabilities.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpeavgrelerror(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpecreate0'></a><h3 class=pageheader><code>mlpecreate0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreate0, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreate0(
    ae_int_t nin,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreate1'></a><h3 class=pageheader><code>mlpecreate1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreate1, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreate1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreate2'></a><h3 class=pageheader><code>mlpecreate2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreate2, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreate2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreateb0'></a><h3 class=pageheader><code>mlpecreateb0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateB0, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreateb0(
    ae_int_t nin,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreateb1'></a><h3 class=pageheader><code>mlpecreateb1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateB1, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreateb1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreateb2'></a><h3 class=pageheader><code>mlpecreateb2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateB2, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreateb2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    <b>double</b> b,
    <b>double</b> d,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreatec0'></a><h3 class=pageheader><code>mlpecreatec0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateC0, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreatec0(
    ae_int_t nin,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreatec1'></a><h3 class=pageheader><code>mlpecreatec1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateC1, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreatec1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreatec2'></a><h3 class=pageheader><code>mlpecreatec2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateC2, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreatec2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreatefromnetwork'></a><h3 class=pageheader><code>mlpecreatefromnetwork</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creates ensemble from network. Only network geometry is copied.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreatefromnetwork(
    multilayerperceptron network,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreater0'></a><h3 class=pageheader><code>mlpecreater0</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateR0, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreater0(
    ae_int_t nin,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreater1'></a><h3 class=pageheader><code>mlpecreater1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateR1, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreater1(
    ae_int_t nin,
    ae_int_t nhid,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpecreater2'></a><h3 class=pageheader><code>mlpecreater2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Like MLPCreateR2, but for ensembles.

  -- ALGLIB --
     Copyright 18.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpecreater2(
    ae_int_t nin,
    ae_int_t nhid1,
    ae_int_t nhid2,
    ae_int_t nout,
    <b>double</b> a,
    <b>double</b> b,
    ae_int_t ensemblesize,
    mlpensemble&amp; ensemble);

</div></pre>
<a name='sub_mlpeissoftmax'></a><h3 class=pageheader><code>mlpeissoftmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Return normalization type (whether ensemble is SOFTMAX-normalized or not).

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::mlpeissoftmax(mlpensemble ensemble);

</div></pre>
<a name='sub_mlpeprocess'></a><h3 class=pageheader><code>mlpeprocess</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Procesing

INPUT PARAMETERS:
    Ensemble-   neural networks ensemble
    X       -   input vector,  array[0..NIn-1].
    Y       -   (possibly) preallocated buffer; if size of Y is less than
                NOut, it will be reallocated. If it is large enough, it
                is NOT reallocated, so we can save some time on reallocation.


OUTPUT PARAMETERS:
    Y       -   result. Regression estimate when solving regression  task,
                vector of posterior probabilities for classification task.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpeprocess(
    mlpensemble ensemble,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_mlpeprocessi'></a><h3 class=pageheader><code>mlpeprocessi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
'interactive'  variant  of  MLPEProcess  for  languages  like Python which
support constructs like &quot;Y = MLPEProcess(LM,X)&quot; and interactive mode of the
interpreter

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpeprocessi(
    mlpensemble ensemble,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='sub_mlpeproperties'></a><h3 class=pageheader><code>mlpeproperties</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Return ensemble properties (number of inputs and outputs).

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpeproperties(
    mlpensemble ensemble,
    ae_int_t&amp; nin,
    ae_int_t&amp; nout);

</div></pre>
<a name='sub_mlperandomize'></a><h3 class=pageheader><code>mlperandomize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Randomization of MLP ensemble

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlperandomize(mlpensemble ensemble);

</div></pre>
<a name='sub_mlperelclserror'></a><h3 class=pageheader><code>mlperelclserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Relative classification error on the test set

INPUT PARAMETERS:
    Ensemble-   ensemble
    XY      -   test set
    NPoints -   test set size

RESULT:
    percent of incorrectly classified cases.
    Works both for classifier betwork and for regression networks which
are used as classifiers.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlperelclserror(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpermserror'></a><h3 class=pageheader><code>mlpermserror</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RMS error on the test set

INPUT PARAMETERS:
    Ensemble-   ensemble
    XY      -   test set
    NPoints -   test set size

RESULT:
    root mean square error.
    Its meaning for regression task is obvious. As for classification task
RMS error means error when estimating posterior probabilities.

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::mlpermserror(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpeserialize'></a><h3 class=pageheader><code>mlpeserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function serializes data structure to string.

Important properties of s_out:
* it contains alphanumeric characters, dots, underscores, minus signs
* these symbols are grouped into words, which are separated by spaces
  and Windows-style (CR+LF) newlines
* although  serializer  uses  spaces and CR+LF as separators, you can 
  replace any separator character by arbitrary combination of spaces,
  tabs, Windows or Unix newlines. It allows flexible reformatting  of
  the  string  in  case you want to include it into text or XML file. 
  But you should not insert separators into the middle of the &quot;words&quot;
  nor you should change case of letters.
* s_out can be freely moved between 32-bit and 64-bit systems, little
  and big endian machines, and so on. You can serialize structure  on
  32-bit machine and unserialize it on 64-bit one (or vice versa), or
  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also 
  serialize  it  in  C++ version of ALGLIB and unserialize in C# one, 
  and vice versa.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> mlpeserialize(mlpensemble &amp;obj, std::string &amp;s_out);
</div></pre>
<a name='sub_mlpeunserialize'></a><h3 class=pageheader><code>mlpeunserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function unserializes data structure from string.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> mlpeunserialize(std::string &amp;s_in, mlpensemble &amp;obj);
</div></pre>
<a name=unit_mlptrain></a><h2 class=pageheader><code>mlptrain</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_mlpcvreport' class=toc>mlpcvreport</a><br>
<a href='#struct_mlpreport' class=toc>mlpreport</a><br>
<a href='#struct_mlptrainer' class=toc>mlptrainer</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_mlpcontinuetraining' class=toc>mlpcontinuetraining</a><br>
<a href='#sub_mlpcreatetrainer' class=toc>mlpcreatetrainer</a><br>
<a href='#sub_mlpcreatetrainercls' class=toc>mlpcreatetrainercls</a><br>
<a href='#sub_mlpebagginglbfgs' class=toc>mlpebagginglbfgs</a><br>
<a href='#sub_mlpebagginglm' class=toc>mlpebagginglm</a><br>
<a href='#sub_mlpetraines' class=toc>mlpetraines</a><br>
<a href='#sub_mlpkfoldcv' class=toc>mlpkfoldcv</a><br>
<a href='#sub_mlpkfoldcvlbfgs' class=toc>mlpkfoldcvlbfgs</a><br>
<a href='#sub_mlpkfoldcvlm' class=toc>mlpkfoldcvlm</a><br>
<a href='#sub_mlpsetalgobatch' class=toc>mlpsetalgobatch</a><br>
<a href='#sub_mlpsetcond' class=toc>mlpsetcond</a><br>
<a href='#sub_mlpsetdataset' class=toc>mlpsetdataset</a><br>
<a href='#sub_mlpsetdecay' class=toc>mlpsetdecay</a><br>
<a href='#sub_mlpsetsparsedataset' class=toc>mlpsetsparsedataset</a><br>
<a href='#sub_mlpstarttraining' class=toc>mlpstarttraining</a><br>
<a href='#sub_mlptrainensemblees' class=toc>mlptrainensemblees</a><br>
<a href='#sub_mlptraines' class=toc>mlptraines</a><br>
<a href='#sub_mlptrainlbfgs' class=toc>mlptrainlbfgs</a><br>
<a href='#sub_mlptrainlm' class=toc>mlptrainlm</a><br>
<a href='#sub_mlptrainnetwork' class=toc>mlptrainnetwork</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_nn_cls2' class=toc>nn_cls2</a></td><td width=15>&nbsp;</td><td>Binary classification problem</td></tr>
<tr align=left valign=top><td><a href='#example_nn_cls3' class=toc>nn_cls3</a></td><td width=15>&nbsp;</td><td>Multiclass classification problem</td></tr>
<tr align=left valign=top><td><a href='#example_nn_crossvalidation' class=toc>nn_crossvalidation</a></td><td width=15>&nbsp;</td><td>Cross-validation</td></tr>
<tr align=left valign=top><td><a href='#example_nn_ensembles_es' class=toc>nn_ensembles_es</a></td><td width=15>&nbsp;</td><td>Early stopping ensembles</td></tr>
<tr align=left valign=top><td><a href='#example_nn_parallel' class=toc>nn_parallel</a></td><td width=15>&nbsp;</td><td>Parallel training</td></tr>
<tr align=left valign=top><td><a href='#example_nn_regr' class=toc>nn_regr</a></td><td width=15>&nbsp;</td><td>Regression problem with one output (2=>1)</td></tr>
<tr align=left valign=top><td><a href='#example_nn_regr_n' class=toc>nn_regr_n</a></td><td width=15>&nbsp;</td><td>Regression problem with multiple outputs (2=>2)</td></tr>
<tr align=left valign=top><td><a href='#example_nn_trainerobject' class=toc>nn_trainerobject</a></td><td width=15>&nbsp;</td><td>Advanced example on trainer object</td></tr>
</table></div>
<a name='struct_mlpcvreport'></a><h3 class=pageheader><code>mlpcvreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cross-validation estimates of generalization error
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mlpcvreport
{
    <b>double</b>               relclserror;
    <b>double</b>               avgce;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
};

</div></pre>
<a name='struct_mlpreport'></a><h3 class=pageheader><code>mlpreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Training report:
    * RelCLSError   -   fraction of misclassified cases.
    * AvgCE         -   acerage cross-entropy
    * RMSError      -   root-mean-square error
    * AvgError      -   average error
    * AvgRelError   -   average relative error
    * NGrad         -   number of gradient calculations
    * NHess         -   number of Hessian calculations
    * NCholesky     -   number of Cholesky decompositions

NOTE 1: RelCLSError/AvgCE are zero on regression problems.

NOTE 2: on classification problems  RMSError/AvgError/AvgRelError  contain
        errors in prediction of posterior probabilities
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mlpreport
{
    <b>double</b>               relclserror;
    <b>double</b>               avgce;
    <b>double</b>               rmserror;
    <b>double</b>               avgerror;
    <b>double</b>               avgrelerror;
    ae_int_t             ngrad;
    ae_int_t             nhess;
    ae_int_t             ncholesky;
};

</div></pre>
<a name='struct_mlptrainer'></a><h3 class=pageheader><code>mlptrainer</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Trainer object for neural network.

You should not try to access fields of this object directly -  use  ALGLIB
functions to work with this object.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> mlptrainer
{
};

</div></pre>
<a name='sub_mlpcontinuetraining'></a><h3 class=pageheader><code>mlpcontinuetraining</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IMPORTANT: this is an &quot;expert&quot; version of the MLPTrain() function.  We  do
           not recommend you to use it unless you are pretty sure that you
           need ability to monitor training progress.

FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support (C++ computational core)
  !
  ! Second improvement gives constant  speedup (2-3X).  First  improvement
  ! gives  close-to-linear  speedup  on   multicore   systems.   Following
  ! operations can be executed in parallel:
  ! * gradient calculation over large dataset (if dataset is large enough)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.

This function performs step-by-step training of the neural  network.  Here
&quot;step-by-step&quot; means that training starts  with  MLPStartTraining()  call,
and then user subsequently calls MLPContinueTraining() to perform one more
iteration of the training.

This  function  performs  one  more  iteration of the training and returns
either True (training continues) or False (training stopped). In case True
was returned, Network weights are updated according to the  current  state
of the optimization progress. In case False was  returned,  no  additional
updates is performed (previous update of  the  network weights moved us to
the final point, and no additional updates is needed).

EXAMPLE:
    &gt;
    &gt; [initialize network and trainer object]
    &gt;
    &gt; MLPStartTraining(Trainer, Network, True)
    &gt; while MLPContinueTraining(Trainer, Network) do
    &gt;     [visualize training progress]
    &gt;

INPUT PARAMETERS:
    S           -   trainer object
    Network     -   neural  network  structure,  which  is  used to  store
                    current state of the training process.

OUTPUT PARAMETERS:
    Network     -   weights of the neural network  are  rewritten  by  the
                    current approximation.

NOTE: this method uses sum-of-squares error function for training.

NOTE: it is expected that trainer object settings are NOT  changed  during
      step-by-step training, i.e. no  one  changes  stopping  criteria  or
      training set during training. It is possible and there is no defense
      against  such  actions,  but  algorithm  behavior  in  such cases is
      undefined and can be unpredictable.

NOTE: It  is  expected that Network is the same one which  was  passed  to
      MLPStartTraining() function.  However,  THIS  function  checks  only
      following:
      * that number of network inputs is consistent with trainer object
        settings
      * that number of network outputs/classes is consistent with  trainer
        object settings
      * that number of network weights is the same as number of weights in
        the network passed to MLPStartTraining() function
      Exception is thrown when these conditions are violated.

      It is also expected that you do not change state of the  network  on
      your own - the only party who has right to change network during its
      training is a trainer object. Any attempt to interfere with  trainer
      may lead to unpredictable results.


  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::mlpcontinuetraining(
    mlptrainer s,
    multilayerperceptron network);
<b>bool</b> alglib::smp_mlpcontinuetraining(
    mlptrainer s,
    multilayerperceptron network);

</div></pre>
<a name='sub_mlpcreatetrainer'></a><h3 class=pageheader><code>mlpcreatetrainer</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creation of the network trainer object for regression networks

INPUT PARAMETERS:
    NIn         -   number of inputs, NIn&gt;=1
    NOut        -   number of outputs, NOut&gt;=1

OUTPUT PARAMETERS:
    S           -   neural network trainer object.
                    This structure can be used to train any regression
                    network with NIn inputs and NOut outputs.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreatetrainer(ae_int_t nin, ae_int_t nout, mlptrainer&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_regr' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_regr_n' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_nn_trainerobject' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_nn_crossvalidation' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_nn_ensembles_es' class=nav>[5]</a>&nbsp;&nbsp;<a href='#example_nn_parallel' class=nav>[6]</a>&nbsp;&nbsp;</p>
<a name='sub_mlpcreatetrainercls'></a><h3 class=pageheader><code>mlpcreatetrainercls</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Creation of the network trainer object for classification networks

INPUT PARAMETERS:
    NIn         -   number of inputs, NIn&gt;=1
    NClasses    -   number of classes, NClasses&gt;=2

OUTPUT PARAMETERS:
    S           -   neural network trainer object.
                    This structure can be used to train any classification
                    network with NIn inputs and NOut outputs.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpcreatetrainercls(
    ae_int_t nin,
    ae_int_t nclasses,
    mlptrainer&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_cls2' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_cls3' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mlpebagginglbfgs'></a><h3 class=pageheader><code>mlpebagginglbfgs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Training neural networks ensemble using  bootstrap  aggregating (bagging).
L-BFGS algorithm is used as base training method.

INPUT PARAMETERS:
    Ensemble    -   model with initialized geometry
    XY          -   training set
    NPoints     -   training set size
    Decay       -   weight decay coefficient, &gt;=0.001
    Restarts    -   restarts, &gt;0.
    WStep       -   stopping criterion, same as in MLPTrainLBFGS
    MaxIts      -   stopping criterion, same as in MLPTrainLBFGS

OUTPUT PARAMETERS:
    Ensemble    -   trained model
    Info        -   return code:
                    * -8, if both WStep=0 and MaxIts=0
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;0, Restarts&lt;1).
                    *  2, if task has been solved.
    Rep         -   training report.
    OOBErrors   -   out-of-bag generalization error estimate

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpebagginglbfgs(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    <b>double</b> wstep,
    ae_int_t maxits,
    ae_int_t&amp; info,
    mlpreport&amp; rep,
    mlpcvreport&amp; ooberrors);

</div></pre>
<a name='sub_mlpebagginglm'></a><h3 class=pageheader><code>mlpebagginglm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Training neural networks ensemble using  bootstrap  aggregating (bagging).
Modified Levenberg-Marquardt algorithm is used as base training method.

INPUT PARAMETERS:
    Ensemble    -   model with initialized geometry
    XY          -   training set
    NPoints     -   training set size
    Decay       -   weight decay coefficient, &gt;=0.001
    Restarts    -   restarts, &gt;0.

OUTPUT PARAMETERS:
    Ensemble    -   trained model
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;0, Restarts&lt;1).
                    *  2, if task has been solved.
    Rep         -   training report.
    OOBErrors   -   out-of-bag generalization error estimate

  -- ALGLIB --
     Copyright 17.02.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpebagginglm(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    ae_int_t&amp; info,
    mlpreport&amp; rep,
    mlpcvreport&amp; ooberrors);

</div></pre>
<a name='sub_mlpetraines'></a><h3 class=pageheader><code>mlpetraines</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Training neural networks ensemble using early stopping.

INPUT PARAMETERS:
    Ensemble    -   model with initialized geometry
    XY          -   training set
    NPoints     -   training set size
    Decay       -   weight decay coefficient, &gt;=0.001
    Restarts    -   restarts, &gt;0.

OUTPUT PARAMETERS:
    Ensemble    -   trained model
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NClasses-1].
                    * -1, if incorrect parameters was passed
                          (NPoints&lt;0, Restarts&lt;1).
                    *  6, if task has been solved.
    Rep         -   training report.
    OOBErrors   -   out-of-bag generalization error estimate

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpetraines(
    mlpensemble ensemble,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    ae_int_t&amp; info,
    mlpreport&amp; rep);

</div></pre>
<a name='sub_mlpkfoldcv'></a><h3 class=pageheader><code>mlpkfoldcv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function estimates generalization error using cross-validation on the
current dataset with current training settings.

FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support (C++ computational core)
  !
  ! Second improvement gives constant  speedup (2-3X).  First  improvement
  ! gives  close-to-linear  speedup  on   multicore   systems.   Following
  ! operations can be executed in parallel:
  ! * FoldsCount cross-validation rounds (always)
  ! * NRestarts training sessions performed within each of
  !   cross-validation rounds (if NRestarts&gt;1)
  ! * gradient calculation over large dataset (if dataset is large enough)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.

INPUT PARAMETERS:
    S           -   trainer object
    Network     -   neural network. It must have same number of inputs and
                    output/classes as was specified during creation of the
                    trainer object. Network is not changed  during  cross-
                    validation and is not trained - it  is  used  only  as
                    representative of its architecture. I.e., we  estimate
                    generalization properties of  ARCHITECTURE,  not  some
                    specific network.
    NRestarts   -   number of restarts, &gt;=0:
                    * NRestarts&gt;0  means  that  for  each cross-validation
                      round   specified  number   of  random  restarts  is
                      performed,  with  best  network  being  chosen after
                      training.
                    * NRestarts=0 is same as NRestarts=1
    FoldsCount  -   number of folds in k-fold cross-validation:
                    * 2&lt;=FoldsCount&lt;=size of dataset
                    * recommended value: 10.
                    * values larger than dataset size will be silently
                      truncated down to dataset size

OUTPUT PARAMETERS:
    Rep         -   structure which contains cross-validation estimates:
                    * Rep.RelCLSError - fraction of misclassified cases.
                    * Rep.AvgCE - acerage cross-entropy
                    * Rep.RMSError - root-mean-square error
                    * Rep.AvgError - average error
                    * Rep.AvgRelError - average relative error

NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
      or subset with only one point  was  given,  zeros  are  returned  as
      estimates.

NOTE: this method performs FoldsCount cross-validation  rounds,  each  one
      with NRestarts random starts.  Thus,  FoldsCount*NRestarts  networks
      are trained in total.

NOTE: Rep.RelCLSError/Rep.AvgCE are zero on regression problems.

NOTE: on classification problems Rep.RMSError/Rep.AvgError/Rep.AvgRelError
      contain errors in prediction of posterior probabilities.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpkfoldcv(
    mlptrainer s,
    multilayerperceptron network,
    ae_int_t nrestarts,
    ae_int_t foldscount,
    mlpreport&amp; rep);
<b>void</b> alglib::smp_mlpkfoldcv(
    mlptrainer s,
    multilayerperceptron network,
    ae_int_t nrestarts,
    ae_int_t foldscount,
    mlpreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_crossvalidation' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_parallel' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mlpkfoldcvlbfgs'></a><h3 class=pageheader><code>mlpkfoldcvlbfgs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cross-validation estimate of generalization error.

Base algorithm - L-BFGS.

INPUT PARAMETERS:
    Network     -   neural network with initialized geometry.   Network is
                    not changed during cross-validation -  it is used only
                    as a representative of its architecture.
    XY          -   training set.
    SSize       -   training set size
    Decay       -   weight  decay, same as in MLPTrainLBFGS
    Restarts    -   number of restarts, &gt;0.
                    restarts are counted for each partition separately, so
                    total number of restarts will be Restarts*FoldsCount.
    WStep       -   stopping criterion, same as in MLPTrainLBFGS
    MaxIts      -   stopping criterion, same as in MLPTrainLBFGS
    FoldsCount  -   number of folds in k-fold cross-validation,
                    2&lt;=FoldsCount&lt;=SSize.
                    recommended value: 10.

OUTPUT PARAMETERS:
    Info        -   return code, same as in MLPTrainLBFGS
    Rep         -   report, same as in MLPTrainLM/MLPTrainLBFGS
    CVRep       -   generalization error estimates

  -- ALGLIB --
     Copyright 09.12.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpkfoldcvlbfgs(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    <b>double</b> wstep,
    ae_int_t maxits,
    ae_int_t foldscount,
    ae_int_t&amp; info,
    mlpreport&amp; rep,
    mlpcvreport&amp; cvrep);

</div></pre>
<a name='sub_mlpkfoldcvlm'></a><h3 class=pageheader><code>mlpkfoldcvlm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cross-validation estimate of generalization error.

Base algorithm - Levenberg-Marquardt.

INPUT PARAMETERS:
    Network     -   neural network with initialized geometry.   Network is
                    not changed during cross-validation -  it is used only
                    as a representative of its architecture.
    XY          -   training set.
    SSize       -   training set size
    Decay       -   weight  decay, same as in MLPTrainLBFGS
    Restarts    -   number of restarts, &gt;0.
                    restarts are counted for each partition separately, so
                    total number of restarts will be Restarts*FoldsCount.
    FoldsCount  -   number of folds in k-fold cross-validation,
                    2&lt;=FoldsCount&lt;=SSize.
                    recommended value: 10.

OUTPUT PARAMETERS:
    Info        -   return code, same as in MLPTrainLBFGS
    Rep         -   report, same as in MLPTrainLM/MLPTrainLBFGS
    CVRep       -   generalization error estimates

  -- ALGLIB --
     Copyright 09.12.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpkfoldcvlm(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    ae_int_t foldscount,
    ae_int_t&amp; info,
    mlpreport&amp; rep,
    mlpcvreport&amp; cvrep);

</div></pre>
<a name='sub_mlpsetalgobatch'></a><h3 class=pageheader><code>mlpsetalgobatch</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets training algorithm: batch training using L-BFGS will be
used.

This algorithm:
* the most robust for small-scale problems, but may be too slow for  large
  scale ones.
* perfoms full pass through the dataset before performing step
* uses conditions specified by MLPSetCond() for stopping
* is default one used by trainer object

INPUT PARAMETERS:
    S           -   trainer object

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetalgobatch(mlptrainer s);

</div></pre>
<a name='sub_mlpsetcond'></a><h3 class=pageheader><code>mlpsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping criteria for the optimizer.

INPUT PARAMETERS:
    S           -   trainer object
    WStep       -   stopping criterion. Algorithm stops if  step  size  is
                    less than WStep. Recommended value - 0.01.  Zero  step
                    size means stopping after MaxIts iterations.
                    WStep&gt;=0.
    MaxIts      -   stopping   criterion.  Algorithm  stops  after  MaxIts
                    epochs (full passes over entire dataset).  Zero MaxIts
                    means stopping when step is sufficiently small.
                    MaxIts&gt;=0.

NOTE: by default, WStep=0.005 and MaxIts=0 are used. These values are also
      used when MLPSetCond() is called with WStep=0 and MaxIts=0.

NOTE: these stopping criteria are used for all kinds of neural training  -
      from &quot;conventional&quot; networks to early stopping ensembles. When  used
      for &quot;conventional&quot; networks, they are  used  as  the  only  stopping
      criteria. When combined with early stopping, they used as ADDITIONAL
      stopping criteria which can terminate early stopping algorithm.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetcond(mlptrainer s, <b>double</b> wstep, ae_int_t maxits);

</div></pre>
<a name='sub_mlpsetdataset'></a><h3 class=pageheader><code>mlpsetdataset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets &quot;current dataset&quot; of the trainer object to  one  passed
by user.

INPUT PARAMETERS:
    S           -   trainer object
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed.
    NPoints     -   points count, &gt;=0.

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
datasetformat is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetdataset(
    mlptrainer s,
    real_2d_array xy,
    ae_int_t npoints);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_regr' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_regr_n' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_nn_cls2' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_nn_cls3' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_nn_trainerobject' class=nav>[5]</a>&nbsp;&nbsp;<a href='#example_nn_crossvalidation' class=nav>[6]</a>&nbsp;&nbsp;<a href='#example_nn_ensembles_es' class=nav>[7]</a>&nbsp;&nbsp;<a href='#example_nn_parallel' class=nav>[8]</a>&nbsp;&nbsp;</p>
<a name='sub_mlpsetdecay'></a><h3 class=pageheader><code>mlpsetdecay</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets weight decay coefficient which is used for training.

INPUT PARAMETERS:
    S           -   trainer object
    Decay       -   weight  decay  coefficient,  &gt;=0.  Weight  decay  term
                    'Decay*||Weights||^2' is added to error  function.  If
                    you don't know what Decay to choose, use 1.0E-3.
                    Weight decay can be set to zero,  in this case network
                    is trained without weight decay.

NOTE: by default network uses some small nonzero value for weight decay.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetdecay(mlptrainer s, <b>double</b> decay);

</div></pre>
<a name='sub_mlpsetsparsedataset'></a><h3 class=pageheader><code>mlpsetsparsedataset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets &quot;current dataset&quot; of the trainer object to  one  passed
by user (sparse matrix is used to store dataset).

INPUT PARAMETERS:
    S           -   trainer object
    XY          -   training  set,  see  below  for  information  on   the
                    training set format. This function checks  correctness
                    of  the  dataset  (no  NANs/INFs,  class  numbers  are
                    correct) and throws exception when  incorrect  dataset
                    is passed. Any  sparse  storage  format  can be  used:
                    Hash-table, CRS...
    NPoints     -   points count, &gt;=0

DATASET FORMAT:

This  function  uses  two  different  dataset formats - one for regression
networks, another one for classification networks.

For regression networks with NIn inputs and NOut outputs following dataset
format is used:
* dataset is given by NPoints*(NIn+NOut) matrix
* each row corresponds to one example
* first NIn columns are inputs, next NOut columns are outputs

For classification networks with NIn inputs and NClasses clases  following
datasetformat is used:
* dataset is given by NPoints*(NIn+1) matrix
* each row corresponds to one example
* first NIn columns are inputs, last column stores class number (from 0 to
  NClasses-1).

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpsetsparsedataset(
    mlptrainer s,
    sparsematrix xy,
    ae_int_t npoints);

</div></pre>
<a name='sub_mlpstarttraining'></a><h3 class=pageheader><code>mlpstarttraining</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
IMPORTANT: this is an &quot;expert&quot; version of the MLPTrain() function.  We  do
           not recommend you to use it unless you are pretty sure that you
           need ability to monitor training progress.

This function performs step-by-step training of the neural  network.  Here
&quot;step-by-step&quot; means that training  starts  with  MLPStartTraining() call,
and then user subsequently calls MLPContinueTraining() to perform one more
iteration of the training.

After call to this function trainer object remembers network and  is ready
to  train  it.  However,  no  training  is  performed  until first call to
MLPContinueTraining() function. Subsequent calls  to MLPContinueTraining()
will advance training progress one iteration further.

EXAMPLE:
    &gt;
    &gt; ...initialize network and trainer object....
    &gt;
    &gt; MLPStartTraining(Trainer, Network, True)
    &gt; while MLPContinueTraining(Trainer, Network) do
    &gt;     ...visualize training progress...
    &gt;

INPUT PARAMETERS:
    S           -   trainer object
    Network     -   neural network. It must have same number of inputs and
                    output/classes as was specified during creation of the
                    trainer object.
    RandomStart -   randomize network before training or not:
                    * True  means  that  network  is  randomized  and  its
                      initial state (one which was passed to  the  trainer
                      object) is lost.
                    * False  means  that  training  is  started  from  the
                      current state of the network

OUTPUT PARAMETERS:
    Network     -   neural network which is ready to training (weights are
                    initialized, preprocessor is initialized using current
                    training set)

NOTE: this method uses sum-of-squares error function for training.

NOTE: it is expected that trainer object settings are NOT  changed  during
      step-by-step training, i.e. no  one  changes  stopping  criteria  or
      training set during training. It is possible and there is no defense
      against  such  actions,  but  algorithm  behavior  in  such cases is
      undefined and can be unpredictable.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlpstarttraining(
    mlptrainer s,
    multilayerperceptron network,
    <b>bool</b> randomstart);

</div></pre>
<a name='sub_mlptrainensemblees'></a><h3 class=pageheader><code>mlptrainensemblees</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function trains neural network ensemble passed to this function using
current dataset and early stopping training algorithm. Each early stopping
round performs NRestarts  random  restarts  (thus,  EnsembleSize*NRestarts
training rounds is performed in total).

FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support (C++ computational core)
  !
  ! Second improvement gives constant  speedup (2-3X).  First  improvement
  ! gives  close-to-linear  speedup  on   multicore   systems.   Following
  ! operations can be executed in parallel:
  ! * EnsembleSize  training  sessions  performed  for  each  of  ensemble
  !   members (always parallelized)
  ! * NRestarts  training  sessions  performed  within  each  of  training
  !   sessions (if NRestarts&gt;1)
  ! * gradient calculation over large dataset (if dataset is large enough)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.

INPUT PARAMETERS:
    S           -   trainer object;
    Ensemble    -   neural network ensemble. It must have same  number  of
                    inputs and outputs/classes  as  was  specified  during
                    creation of the trainer object.
    NRestarts   -   number of restarts, &gt;=0:
                    * NRestarts&gt;0 means that specified  number  of  random
                      restarts are performed during each ES round;
                    * NRestarts=0 is silently replaced by 1.

OUTPUT PARAMETERS:
    Ensemble    -   trained ensemble;
    Rep         -   it contains all type of errors.

NOTE: this training method uses BOTH early stopping and weight decay!  So,
      you should select weight decay before starting training just as  you
      select it before training &quot;conventional&quot; networks.

NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
      or  single-point  dataset  was  passed,  ensemble  is filled by zero
      values.

NOTE: this method uses sum-of-squares error function for training.

  -- ALGLIB --
     Copyright 22.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlptrainensemblees(
    mlptrainer s,
    mlpensemble ensemble,
    ae_int_t nrestarts,
    mlpreport&amp; rep);
<b>void</b> alglib::smp_mlptrainensemblees(
    mlptrainer s,
    mlpensemble ensemble,
    ae_int_t nrestarts,
    mlpreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_ensembles_es' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_parallel' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_mlptraines'></a><h3 class=pageheader><code>mlptraines</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Neural network training using early stopping (base algorithm - L-BFGS with
regularization).

INPUT PARAMETERS:
    Network     -   neural network with initialized geometry
    TrnXY       -   training set
    TrnSize     -   training set size, TrnSize&gt;0
    ValXY       -   validation set
    ValSize     -   validation set size, ValSize&gt;0
    Decay       -   weight decay constant, &gt;=0.001
                    Decay term 'Decay*||Weights||^2' is added to error
                    function.
                    If you don't know what Decay to choose, use 0.001.
    Restarts    -   number of restarts, either:
                    * strictly positive number - algorithm make specified
                      number of restarts from random position.
                    * -1, in which case algorithm makes exactly one run
                      from the initial state of the network (no randomization).
                    If you don't know what Restarts to choose, choose one
                    one the following:
                    * -1 (deterministic start)
                    * +1 (one random restart)
                    * +5 (moderate amount of random restarts)

OUTPUT PARAMETERS:
    Network     -   trained neural network.
    Info        -   return code:
                    * -2, if there is a point with class number
                          outside of [0..NOut-1].
                    * -1, if wrong parameters specified
                          (NPoints&lt;0, Restarts&lt;1, ...).
                    *  2, task has been solved, stopping  criterion  met -
                          sufficiently small step size.  Not expected  (we
                          use  EARLY  stopping)  but  possible  and not an
                          error.
                    *  6, task has been solved, stopping  criterion  met -
                          increasing of validation set error.
    Rep         -   training report

NOTE:

Algorithm stops if validation set error increases for  a  long  enough  or
step size is small enought  (there  are  task  where  validation  set  may
decrease for eternity). In any case solution returned corresponds  to  the
minimum of validation set error.

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlptraines(
    multilayerperceptron network,
    real_2d_array trnxy,
    ae_int_t trnsize,
    real_2d_array valxy,
    ae_int_t valsize,
    <b>double</b> decay,
    ae_int_t restarts,
    ae_int_t&amp; info,
    mlpreport&amp; rep);

</div></pre>
<a name='sub_mlptrainlbfgs'></a><h3 class=pageheader><code>mlptrainlbfgs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Neural  network  training  using  L-BFGS  algorithm  with  regularization.
Subroutine  trains  neural  network  with  restarts from random positions.
Algorithm  is  well  suited  for  problems  of  any dimensionality (memory
requirements and step complexity are linear by weights number).

INPUT PARAMETERS:
    Network     -   neural network with initialized geometry
    XY          -   training set
    NPoints     -   training set size
    Decay       -   weight decay constant, &gt;=0.001
                    Decay term 'Decay*||Weights||^2' is added to error
                    function.
                    If you don't know what Decay to choose, use 0.001.
    Restarts    -   number of restarts from random position, &gt;0.
                    If you don't know what Restarts to choose, use 2.
    WStep       -   stopping criterion. Algorithm stops if  step  size  is
                    less than WStep. Recommended value - 0.01.  Zero  step
                    size means stopping after MaxIts iterations.
    MaxIts      -   stopping   criterion.  Algorithm  stops  after  MaxIts
                    iterations (NOT gradient  calculations).  Zero  MaxIts
                    means stopping when step is sufficiently small.

OUTPUT PARAMETERS:
    Network     -   trained neural network.
    Info        -   return code:
                    * -8, if both WStep=0 and MaxIts=0
                    * -2, if there is a point with class number
                          outside of [0..NOut-1].
                    * -1, if wrong parameters specified
                          (NPoints&lt;0, Restarts&lt;1).
                    *  2, if task has been solved.
    Rep         -   training report

  -- ALGLIB --
     Copyright 09.12.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlptrainlbfgs(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    <b>double</b> wstep,
    ae_int_t maxits,
    ae_int_t&amp; info,
    mlpreport&amp; rep);

</div></pre>
<a name='sub_mlptrainlm'></a><h3 class=pageheader><code>mlptrainlm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Neural network training  using  modified  Levenberg-Marquardt  with  exact
Hessian calculation and regularization. Subroutine trains  neural  network
with restarts from random positions. Algorithm is well  suited  for  small
and medium scale problems (hundreds of weights).

INPUT PARAMETERS:
    Network     -   neural network with initialized geometry
    XY          -   training set
    NPoints     -   training set size
    Decay       -   weight decay constant, &gt;=0.001
                    Decay term 'Decay*||Weights||^2' is added to error
                    function.
                    If you don't know what Decay to choose, use 0.001.
    Restarts    -   number of restarts from random position, &gt;0.
                    If you don't know what Restarts to choose, use 2.

OUTPUT PARAMETERS:
    Network     -   trained neural network.
    Info        -   return code:
                    * -9, if internal matrix inverse subroutine failed
                    * -2, if there is a point with class number
                          outside of [0..NOut-1].
                    * -1, if wrong parameters specified
                          (NPoints&lt;0, Restarts&lt;1).
                    *  2, if task has been solved.
    Rep         -   training report

  -- ALGLIB --
     Copyright 10.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlptrainlm(
    multilayerperceptron network,
    real_2d_array xy,
    ae_int_t npoints,
    <b>double</b> decay,
    ae_int_t restarts,
    ae_int_t&amp; info,
    mlpreport&amp; rep);

</div></pre>
<a name='sub_mlptrainnetwork'></a><h3 class=pageheader><code>mlptrainnetwork</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function trains neural network passed to this function, using current
dataset (one which was passed to MLPSetDataset() or MLPSetSparseDataset())
and current training settings. Training  from  NRestarts  random  starting
positions is performed, best network is chosen.

Training is performed using current training algorithm.

FOR USERS OF COMMERCIAL EDITION:

  ! Commercial version of ALGLIB includes two  important  improvements  of
  ! this function:
  ! * multicore support (C++ and C# computational cores)
  ! * SSE support (C++ computational core)
  !
  ! Second improvement gives constant  speedup (2-3X).  First  improvement
  ! gives  close-to-linear  speedup  on   multicore   systems.   Following
  ! operations can be executed in parallel:
  ! * NRestarts training sessions performed within each of
  !   cross-validation rounds (if NRestarts&gt;1)
  ! * gradient calculation over large dataset (if dataset is large enough)
  !
  ! In order to use multicore features you have to:
  ! * use commercial version of ALGLIB
  ! * call  this  function  with  &quot;smp_&quot;  prefix,  which  indicates  that
  !   multicore code will be used (for multicore support)
  !
  ! In order to use SSE features you have to:
  ! * use commercial version of ALGLIB on Intel processors
  ! * use C++ computational core
  !
  ! This note is given for users of commercial edition; if  you  use  GPL
  ! edition, you still will be able to call smp-version of this function,
  ! but all computations will be done serially.
  !
  ! We recommend you to carefully read ALGLIB Reference  Manual,  section
  ! called 'SMP support', before using parallel version of this function.

INPUT PARAMETERS:
    S           -   trainer object
    Network     -   neural network. It must have same number of inputs and
                    output/classes as was specified during creation of the
                    trainer object.
    NRestarts   -   number of restarts, &gt;=0:
                    * NRestarts&gt;0 means that specified  number  of  random
                      restarts are performed, best network is chosen after
                      training
                    * NRestarts=0 means that current state of the  network
                      is used for training.

OUTPUT PARAMETERS:
    Network     -   trained network

NOTE: when no dataset was specified with MLPSetDataset/SetSparseDataset(),
      network  is  filled  by zero  values.  Same  behavior  for functions
      MLPStartTraining and MLPContinueTraining.

NOTE: this method uses sum-of-squares error function for training.

  -- ALGLIB --
     Copyright 23.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::mlptrainnetwork(
    mlptrainer s,
    multilayerperceptron network,
    ae_int_t nrestarts,
    mlpreport&amp; rep);
<b>void</b> alglib::smp_mlptrainnetwork(
    mlptrainer s,
    multilayerperceptron network,
    ae_int_t nrestarts,
    mlpreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nn_regr' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nn_regr_n' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_nn_cls2' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_nn_cls3' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_nn_trainerobject' class=nav>[5]</a>&nbsp;&nbsp;<a href='#example_nn_parallel' class=nav>[6]</a>&nbsp;&nbsp;</p>
<a name='example_nn_cls2'></a><h3 class=pageheader>nn_cls2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Suppose that we want to classify numbers as positive (<b>class</b> 0) and negative</font>
    <font color=navy>// (<b>class</b> 1). We have training set which includes several strictly positive</font>
    <font color=navy>// or negative numbers - and zero.</font>
    <font color=navy>//</font>
    <font color=navy>// The problem is that we are not sure how to classify zero, so from time to</font>
    <font color=navy>// time we mark it as positive or negative (with equal probability). Other</font>
    <font color=navy>// numbers are marked in pure deterministic setting. How will neural network</font>
    <font color=navy>// cope with such classification task?</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: we use network with excessive amount of neurons, which guarantees</font>
    <font color=navy>//       almost exact reproduction of the training set. Generalization ability</font>
    <font color=navy>//       of such network is rather low, but we are not concerned with such</font>
    <font color=navy>//       questions in this basic demo.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpreport rep;
    real_1d_array x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,0]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Training set. One row corresponds to one record [A =&gt; <b>class</b>(A)].</font>
    <font color=navy>//</font>
    <font color=navy>// Classes are denoted by numbers from 0 to 1, where 0 corresponds to positive</font>
    <font color=navy>// numbers and 1 to negative numbers.</font>
    <font color=navy>//</font>
    <font color=navy>// [ +1  0]</font>
    <font color=navy>// [ +2  0]</font>
    <font color=navy>// [ -1  1]</font>
    <font color=navy>// [ -2  1]</font>
    <font color=navy>// [  0  0]   !! sometimes we classify 0 as positive, sometimes as negative</font>
    <font color=navy>// [  0  1]   !!</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[+1,0],[+2,0],[-1,1],[-2,1],[0,0],[0,1]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>//</font>
    <font color=navy>// When we solve classification problems, everything is slightly different from</font>
    <font color=navy>// the regression ones:</font>
    <font color=navy>//</font>
    <font color=navy>// 1. Network is created. Because we solve classification problem, we use</font>
    <font color=navy>//    mlpcreatec1() function instead of mlpcreate1(). This function creates</font>
    <font color=navy>//    classifier network with SOFTMAX-normalized outputs. This network returns</font>
    <font color=navy>//    vector of <b>class</b> membership probabilities which are normalized to be</font>
    <font color=navy>//    non-negative and sum to 1.0</font>
    <font color=navy>//</font>
    <font color=navy>// 2. We use mlpcreatetrainercls() function instead of mlpcreatetrainer() to</font>
    <font color=navy>//    create trainer object. Trainer object process dataset and neural network</font>
    <font color=navy>//    slightly differently to account <b>for</b> specifics of the classification</font>
    <font color=navy>//    problems.</font>
    <font color=navy>//</font>
    <font color=navy>// 3. Dataset is attached to trainer object. Note that dataset format is slightly</font>
    <font color=navy>//    different from one used <b>for</b> regression.</font>
    <font color=navy>//</font>
    mlpcreatetrainercls(1, 2, trn);
    mlpcreatec1(1, 5, 2, network);
    mlpsetdataset(trn, xy, 6);

    <font color=navy>//</font>
    <font color=navy>// Network is trained with 5 restarts from random positions</font>
    <font color=navy>//</font>
    mlptrainnetwork(trn, network, 5, rep);

    <font color=navy>//</font>
    <font color=navy>// Test our neural network on strictly positive and strictly negative numbers.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT! Classifier network returns <b>class</b> membership probabilities instead</font>
    <font color=navy>// of <b>class</b> indexes. Network returns two values (probabilities) instead of one</font>
    <font color=navy>// (<b>class</b> index).</font>
    <font color=navy>//</font>
    <font color=navy>// Thus, <b>for</b> +1 we expect to get [P0,P1] = [1,0], where P0 is probability that</font>
    <font color=navy>// number is positive (belongs to <b>class</b> 0), and P1 is probability that number</font>
    <font color=navy>// is negative (belongs to <b>class</b> 1).</font>
    <font color=navy>//</font>
    <font color=navy>// For -1 we expect to get [P0,P1] = [0,1]</font>
    <font color=navy>//</font>
    <font color=navy>// Following properties are guaranteed by network architecture:</font>
    <font color=navy>// * P0&gt;=0, P1&gt;=0   non-negativity</font>
    <font color=navy>// * P0+P1=1        normalization</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[1]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.000,0.000]</font>
    x = <font color=blue><b>&quot;[-1]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [0.000,1.000]</font>

    <font color=navy>//</font>
    <font color=navy>// But what our network will <b>return</b> <b>for</b> 0, which is between classes 0 and 1?</font>
    <font color=navy>//</font>
    <font color=navy>// In our dataset it has two different marks assigned (<b>class</b> 0 AND <b>class</b> 1).</font>
    <font color=navy>// So network will <b>return</b> something average between <b>class</b> 0 and <b>class</b> 1:</font>
    <font color=navy>//     0 =&gt; [0.5, 0.5]</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [0.500,0.500]</font>
    <b>return</b> 0;
}


</pre><a name='example_nn_cls3'></a><h3 class=pageheader>nn_cls3 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Suppose that we want to classify numbers as positive (<b>class</b> 0) and negative</font>
    <font color=navy>// (<b>class</b> 1). We also have one more <b>class</b> <b>for</b> zero (<b>class</b> 2).</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: we use network with excessive amount of neurons, which guarantees</font>
    <font color=navy>//       almost exact reproduction of the training set. Generalization ability</font>
    <font color=navy>//       of such network is rather low, but we are not concerned with such</font>
    <font color=navy>//       questions in this basic demo.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpreport rep;
    real_1d_array x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,0,0]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Training set. One row corresponds to one record [A =&gt; <b>class</b>(A)].</font>
    <font color=navy>//</font>
    <font color=navy>// Classes are denoted by numbers from 0 to 2, where 0 corresponds to positive</font>
    <font color=navy>// numbers, 1 to negative numbers, 2 to zero</font>
    <font color=navy>//</font>
    <font color=navy>// [ +1  0]</font>
    <font color=navy>// [ +2  0]</font>
    <font color=navy>// [ -1  1]</font>
    <font color=navy>// [ -2  1]</font>
    <font color=navy>// [  0  2]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[+1,0],[+2,0],[-1,1],[-2,1],[0,2]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>//</font>
    <font color=navy>// When we solve classification problems, everything is slightly different from</font>
    <font color=navy>// the regression ones:</font>
    <font color=navy>//</font>
    <font color=navy>// 1. Network is created. Because we solve classification problem, we use</font>
    <font color=navy>//    mlpcreatec1() function instead of mlpcreate1(). This function creates</font>
    <font color=navy>//    classifier network with SOFTMAX-normalized outputs. This network returns</font>
    <font color=navy>//    vector of <b>class</b> membership probabilities which are normalized to be</font>
    <font color=navy>//    non-negative and sum to 1.0</font>
    <font color=navy>//</font>
    <font color=navy>// 2. We use mlpcreatetrainercls() function instead of mlpcreatetrainer() to</font>
    <font color=navy>//    create trainer object. Trainer object process dataset and neural network</font>
    <font color=navy>//    slightly differently to account <b>for</b> specifics of the classification</font>
    <font color=navy>//    problems.</font>
    <font color=navy>//</font>
    <font color=navy>// 3. Dataset is attached to trainer object. Note that dataset format is slightly</font>
    <font color=navy>//    different from one used <b>for</b> regression.</font>
    <font color=navy>//</font>
    mlpcreatetrainercls(1, 3, trn);
    mlpcreatec1(1, 5, 3, network);
    mlpsetdataset(trn, xy, 5);

    <font color=navy>//</font>
    <font color=navy>// Network is trained with 5 restarts from random positions</font>
    <font color=navy>//</font>
    mlptrainnetwork(trn, network, 5, rep);

    <font color=navy>//</font>
    <font color=navy>// Test our neural network on strictly positive and strictly negative numbers.</font>
    <font color=navy>//</font>
    <font color=navy>// IMPORTANT! Classifier network returns <b>class</b> membership probabilities instead</font>
    <font color=navy>// of <b>class</b> indexes. Network returns three values (probabilities) instead of one</font>
    <font color=navy>// (<b>class</b> index).</font>
    <font color=navy>//</font>
    <font color=navy>// Thus, <b>for</b> +1 we expect to get [P0,P1,P2] = [1,0,0],</font>
    <font color=navy>// <b>for</b> -1 we expect to get [P0,P1,P2] = [0,1,0],</font>
    <font color=navy>// and <b>for</b> 0 we will get [P0,P1,P2] = [0,0,1].</font>
    <font color=navy>//</font>
    <font color=navy>// Following properties are guaranteed by network architecture:</font>
    <font color=navy>// * P0&gt;=0, P1&gt;=0, P2&gt;=0    non-negativity</font>
    <font color=navy>// * P0+P1+P2=1             normalization</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[1]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [1.000,0.000,0.000]</font>
    x = <font color=blue><b>&quot;[-1]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [0.000,1.000,0.000]</font>
    x = <font color=blue><b>&quot;[0]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [0.000,0.000,1.000]</font>
    <b>return</b> 0;
}


</pre><a name='example_nn_crossvalidation'></a><h3 class=pageheader>nn_crossvalidation example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example shows how to perform cross-validation with ALGLIB</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpreport rep;

    <font color=navy>//</font>
    <font color=navy>// Training set: f(x)=1/(x^2+1)</font>
    <font color=navy>// One row corresponds to one record [x,f(x)]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[-2.0,0.2],[-1.6,0.3],[-1.3,0.4],[-1,0.5],[-0.6,0.7],[-0.3,0.9],[0,1],[2.0,0.2],[1.6,0.3],[1.3,0.4],[1,0.5],[0.6,0.7],[0.3,0.9]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Trainer object is created.</font>
    <font color=navy>// Dataset is attached to trainer object.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: it is not good idea to perform cross-validation on sample</font>
    <font color=navy>//       as small as ours (13 examples). It is done <b>for</b> demonstration</font>
    <font color=navy>//       purposes only. Generalization error estimates won't be</font>
    <font color=navy>//       precise enough <b>for</b> practical purposes.</font>
    <font color=navy>//</font>
    mlpcreatetrainer(1, 1, trn);
    mlpsetdataset(trn, xy, 13);

    <font color=navy>//</font>
    <font color=navy>// The key property of the cross-validation is that it estimates</font>
    <font color=navy>// generalization properties of neural ARCHITECTURE. It does NOT</font>
    <font color=navy>// estimates generalization error of some specific network which</font>
    <font color=navy>// is passed to the k-fold CV routine.</font>
    <font color=navy>//</font>
    <font color=navy>// In our example we create 1x4x1 neural network and pass it to</font>
    <font color=navy>// CV routine without training it. Original state of the network</font>
    <font color=navy>// is not used <b>for</b> cross-validation - each round is restarted from</font>
    <font color=navy>// random initial state. Only geometry of network matters.</font>
    <font color=navy>//</font>
    <font color=navy>// We perform 5 restarts from different random positions <b>for</b> each</font>
    <font color=navy>// of the 10 cross-validation rounds.</font>
    <font color=navy>//</font>
    mlpcreate1(1, 4, 1, network);
    mlpkfoldcv(trn, network, 5, 10, rep);

    <font color=navy>//</font>
    <font color=navy>// Cross-validation routine stores estimates of the generalization</font>
    <font color=navy>// error to MLP report structure. You may examine its fields and</font>
    <font color=navy>// see estimates of different errors (RMS, CE, Avg).</font>
    <font color=navy>//</font>
    <font color=navy>// Because cross-validation is non-deterministic, in our manual we</font>
    <font color=navy>// can not say what values will be stored to rep after call to</font>
    <font color=navy>// mlpkfoldcv(). Every CV round will <b>return</b> slightly different</font>
    <font color=navy>// estimates.</font>
    <font color=navy>//</font>
    <b>return</b> 0;
}


</pre><a name='example_nn_ensembles_es'></a><h3 class=pageheader>nn_ensembles_es example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example shows how to train early stopping ensebles.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    mlpensemble ensemble;
    mlpreport rep;

    <font color=navy>//</font>
    <font color=navy>// Training set: f(x)=1/(x^2+1)</font>
    <font color=navy>// One row corresponds to one record [x,f(x)]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[-2.0,0.2],[-1.6,0.3],[-1.3,0.4],[-1,0.5],[-0.6,0.7],[-0.3,0.9],[0,1],[2.0,0.2],[1.6,0.3],[1.3,0.4],[1,0.5],[0.6,0.7],[0.3,0.9]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Trainer object is created.</font>
    <font color=navy>// Dataset is attached to trainer object.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: it is not good idea to use early stopping ensemble on sample</font>
    <font color=navy>//       as small as ours (13 examples). It is done <b>for</b> demonstration</font>
    <font color=navy>//       purposes only. Ensemble training algorithm won't find good</font>
    <font color=navy>//       solution on such small sample.</font>
    <font color=navy>//</font>
    mlpcreatetrainer(1, 1, trn);
    mlpsetdataset(trn, xy, 13);

    <font color=navy>//</font>
    <font color=navy>// Ensemble is created and trained. Each of 50 network is trained</font>
    <font color=navy>// with 5 restarts.</font>
    <font color=navy>//</font>
    mlpecreate1(1, 4, 1, 50, ensemble);
    mlptrainensemblees(trn, ensemble, 5, rep);
    <b>return</b> 0;
}


</pre><a name='example_nn_parallel'></a><h3 class=pageheader>nn_parallel example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example shows how to use parallel functionality of ALGLIB.</font>
    <font color=navy>// We generate simple 1-dimensional regression problem and show how</font>
    <font color=navy>// to use parallel training, parallel cross-validation, parallel</font>
    <font color=navy>// training of neural ensembles.</font>
    <font color=navy>//</font>
    <font color=navy>// We assume that you already know how to use ALGLIB in serial mode</font>
    <font color=navy>// and concentrate on its parallel capabilities.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: it is not good idea to use parallel features on sample as small</font>
    <font color=navy>//       as ours (13 examples). It is done only <b>for</b> demonstration purposes.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpensemble ensemble;
    mlpreport rep;
    real_2d_array xy = <font color=blue><b>&quot;[[-2.0,0.2],[-1.6,0.3],[-1.3,0.4],[-1,0.5],[-0.6,0.7],[-0.3,0.9],[0,1],[2.0,0.2],[1.6,0.3],[1.3,0.4],[1,0.5],[0.6,0.7],[0.3,0.9]]&quot;</b></font>;
    mlpcreatetrainer(1, 1, trn);
    mlpsetdataset(trn, xy, 13);
    mlpcreate1(1, 4, 1, network);
    mlpecreate1(1, 4, 1, 50, ensemble);

    <font color=navy>//</font>
    <font color=navy>// Below we demonstrate how to perform:</font>
    <font color=navy>// * parallel training of individual networks</font>
    <font color=navy>// * parallel cross-validation</font>
    <font color=navy>// * parallel training of neural ensembles</font>
    <font color=navy>//</font>
    <font color=navy>// In order to use multithreading, you have to:</font>
    <font color=navy>// 1) Install SMP edition of ALGLIB.</font>
    <font color=navy>// 2) This step is specific <b>for</b> C++ users: you should activate OS-specific</font>
    <font color=navy>//    capabilities of ALGLIB by defining AE_OS=AE_POSIX (<b>for</b> *nix systems)</font>
    <font color=navy>//    or AE_OS=AE_WINDOWS (<b>for</b> Windows systems).</font>
    <font color=navy>//    C# users <b>do</b> not have to perform this step because C# programs are</font>
    <font color=navy>//    portable across different systems without OS-specific tuning.</font>
    <font color=navy>// 3) Allow ALGLIB to know about number of worker threads to use:</font>
    <font color=navy>//    a) autodetection (C++, C#):</font>
    <font color=navy>//          ALGLIB will automatically determine number of CPU cores and</font>
    <font color=navy>//          (by default) will use all cores except <b>for</b> one. Say, on 4-core</font>
    <font color=navy>//          system it will use three cores - unless you manually told it</font>
    <font color=navy>//          to use more or less. It will keep your system responsive during</font>
    <font color=navy>//          lengthy computations.</font>
    <font color=navy>//          Such behavior may be changed with setnworkers() call:</font>
    <font color=navy>//          * alglib::setnworkers(0)  = use all cores</font>
    <font color=navy>//          * alglib::setnworkers(-1) = leave one core unused</font>
    <font color=navy>//          * alglib::setnworkers(-2) = leave two cores unused</font>
    <font color=navy>//          * alglib::setnworkers(+2) = use 2 cores (even <b>if</b> you have more)</font>
    <font color=navy>//    b) manual specification (C++, C#):</font>
    <font color=navy>//          You may want to specify maximum number of worker threads during</font>
    <font color=navy>//          compile time by means of preprocessor definition AE_NWORKERS.</font>
    <font color=navy>//          For C++ it will be <font color=blue><b>&quot;AE_NWORKERS=X&quot;</b></font> where X can be any positive number.</font>
    <font color=navy>//          For C# it is <font color=blue><b>&quot;AE_NWORKERSX&quot;</b></font>, where X should be replaced by number of</font>
    <font color=navy>//          workers (AE_NWORKERS2, AE_NWORKERS3, AE_NWORKERS4, ...).</font>
    <font color=navy>//          You can add this definition to compiler command line or change</font>
    <font color=navy>//          corresponding project settings in your IDE.</font>
    <font color=navy>//</font>
    <font color=navy>// After you installed and configured SMP edition of ALGLIB, you may choose</font>
    <font color=navy>// between serial and multithreaded versions of SMP-capable functions:</font>
    <font color=navy>// * serial version works as usual, in the context of the calling thread</font>
    <font color=navy>// * multithreaded version (with <font color=blue><b>&quot;smp_&quot;</b></font> prefix) creates (or wakes up) worker</font>
    <font color=navy>//   threads, inserts task in the worker queue, and waits <b>for</b> completion of</font>
    <font color=navy>//   the task. All processing is done in context of worker thread(s).</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: because starting/stopping worker threads costs thousands of CPU cycles,</font>
    <font color=navy>//       you should not use multithreading <b>for</b> lightweight computational problems.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: some old POSIX-compatible operating systems <b>do</b> not support</font>
    <font color=navy>//       sysconf(_SC_NPROCESSORS_ONLN) system call which is required in order</font>
    <font color=navy>//       to automatically determine number of active cores. On these systems</font>
    <font color=navy>//       you should specify number of cores manually at compile time.</font>
    <font color=navy>//       Without it ALGLIB will run in single-threaded mode.</font>
    <font color=navy>//</font>

    <font color=navy>//</font>
    <font color=navy>// First, we perform parallel training of individual network with 5</font>
    <font color=navy>// restarts from random positions. These 5 rounds of  training  are</font>
    <font color=navy>// executed in parallel manner,  with  best  network  chosen  after</font>
    <font color=navy>// training.</font>
    <font color=navy>//</font>
    <font color=navy>// ALGLIB can use additional way to speed up computations -  divide</font>
    <font color=navy>// dataset   into   smaller   subsets   and   process these subsets</font>
    <font color=navy>// simultaneously. It allows us  to  efficiently  parallelize  even</font>
    <font color=navy>// single training round. This operation is performed automatically</font>
    <font color=navy>// <b>for</b> large datasets, but our toy dataset is too small.</font>
    <font color=navy>//</font>
    smp_mlptrainnetwork(trn, network, 5, rep);

    <font color=navy>//</font>
    <font color=navy>// Then, we perform parallel 10-fold cross-validation, with 5 random</font>
    <font color=navy>// restarts per each CV round. I.e., 5*10=50  networks  are trained</font>
    <font color=navy>// in total. All these operations can be parallelized.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: again, ALGLIB can parallelize  calculation   of   gradient</font>
    <font color=navy>//       over entire dataset - but our dataset is too small.</font>
    <font color=navy>//</font>
    smp_mlpkfoldcv(trn, network, 5, 10, rep);

    <font color=navy>//</font>
    <font color=navy>// Finally, we train early stopping ensemble of 50 neural networks,</font>
    <font color=navy>// each  of them is trained with 5 random restarts. I.e.,  5*50=250</font>
    <font color=navy>// networks aretrained in total.</font>
    <font color=navy>//</font>
    smp_mlptrainensemblees(trn, ensemble, 5, rep);
    <b>return</b> 0;
}


</pre><a name='example_nn_regr'></a><h3 class=pageheader>nn_regr example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// The very simple example on neural network: network is trained to reproduce</font>
    <font color=navy>// small 2x2 multiplication table.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: we use network with excessive amount of neurons, which guarantees</font>
    <font color=navy>//       almost exact reproduction of the training set. Generalization ability</font>
    <font color=navy>//       of such network is rather low, but we are not concerned with such</font>
    <font color=navy>//       questions in this basic demo.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpreport rep;

    <font color=navy>//</font>
    <font color=navy>// Training set:</font>
    <font color=navy>// * one row corresponds to one record A*B=C in the multiplication table</font>
    <font color=navy>// * first two columns store A and B, last column stores C</font>
    <font color=navy>//</font>
    <font color=navy>// [1 * 1 = 1]</font>
    <font color=navy>// [1 * 2 = 2]</font>
    <font color=navy>// [2 * 1 = 2]</font>
    <font color=navy>// [2 * 2 = 4]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[1,1,1],[1,2,2],[2,1,2],[2,2,4]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Network is created.</font>
    <font color=navy>// Trainer object is created.</font>
    <font color=navy>// Dataset is attached to trainer object.</font>
    <font color=navy>//</font>
    mlpcreatetrainer(2, 1, trn);
    mlpcreate1(2, 5, 1, network);
    mlpsetdataset(trn, xy, 4);

    <font color=navy>//</font>
    <font color=navy>// Network is trained with 5 restarts from random positions</font>
    <font color=navy>//</font>
    mlptrainnetwork(trn, network, 5, rep);

    <font color=navy>//</font>
    <font color=navy>// 2*2=?</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[2,2]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [4.000]</font>
    <b>return</b> 0;
}


</pre><a name='example_nn_regr_n'></a><h3 class=pageheader>nn_regr_n example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Network with 2 inputs and 2 outputs is trained to reproduce vector function:</font>
    <font color=navy>//     (x0,x1) =&gt; (x0+x1, x0*x1)</font>
    <font color=navy>//</font>
    <font color=navy>// Informally speaking, we want neural network to simultaneously calculate</font>
    <font color=navy>// both sum of two numbers and their product.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: we use network with excessive amount of neurons, which guarantees</font>
    <font color=navy>//       almost exact reproduction of the training set. Generalization ability</font>
    <font color=navy>//       of such network is rather low, but we are not concerned with such</font>
    <font color=navy>//       questions in this basic demo.</font>
    <font color=navy>//</font>
    mlptrainer trn;
    multilayerperceptron network;
    mlpreport rep;

    <font color=navy>//</font>
    <font color=navy>// Training set. One row corresponds to one record [A,B,A+B,A*B].</font>
    <font color=navy>//</font>
    <font color=navy>// [ 1   1  1+1  1*1 ]</font>
    <font color=navy>// [ 1   2  1+2  1*2 ]</font>
    <font color=navy>// [ 2   1  2+1  2*1 ]</font>
    <font color=navy>// [ 2   2  2+2  2*2 ]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[1,1,2,1],[1,2,3,2],[2,1,3,2],[2,2,4,4]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Network is created.</font>
    <font color=navy>// Trainer object is created.</font>
    <font color=navy>// Dataset is attached to trainer object.</font>
    <font color=navy>//</font>
    mlpcreatetrainer(2, 2, trn);
    mlpcreate1(2, 5, 2, network);
    mlpsetdataset(trn, xy, 4);

    <font color=navy>//</font>
    <font color=navy>// Network is trained with 5 restarts from random positions</font>
    <font color=navy>//</font>
    mlptrainnetwork(trn, network, 5, rep);

    <font color=navy>//</font>
    <font color=navy>// 2+1=?</font>
    <font color=navy>// 2*1=?</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[2,1]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,0]&quot;</b></font>;
    mlpprocess(network, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(1).c_str()); <font color=navy>// EXPECTED: [3.000,2.000]</font>
    <b>return</b> 0;
}


</pre><a name='example_nn_trainerobject'></a><h3 class=pageheader>nn_trainerobject example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;dataanalysis.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Trainer object is used to train network. It stores dataset, training settings,</font>
    <font color=navy>// and other information which is NOT part of neural network. You should use</font>
    <font color=navy>// trainer object as follows:</font>
    <font color=navy>// (1) you create trainer object and specify task type (classification/regression)</font>
    <font color=navy>//     and number of inputs/outputs</font>
    <font color=navy>// (2) you add dataset to the trainer object</font>
    <font color=navy>// (3) you may change training settings (stopping criteria or weight decay)</font>
    <font color=navy>// (4) finally, you may train one or more networks</font>
    <font color=navy>//</font>
    <font color=navy>// You may interleave stages 2...4 and repeat them many times. Trainer object</font>
    <font color=navy>// remembers its internal state and can be used several times after its creation</font>
    <font color=navy>// and initialization.</font>
    <font color=navy>//</font>
    mlptrainer trn;

    <font color=navy>//</font>
    <font color=navy>// Stage 1: object creation.</font>
    <font color=navy>//</font>
    <font color=navy>// We have to specify number of inputs and outputs. Trainer object can be used</font>
    <font color=navy>// only <b>for</b> problems with same number of inputs/outputs as was specified during</font>
    <font color=navy>// its creation.</font>
    <font color=navy>//</font>
    <font color=navy>// In case you want to train SOFTMAX-normalized network which solves classification</font>
    <font color=navy>// problems,  you  must  use  another  function  to  create  trainer  object:</font>
    <font color=navy>// mlpcreatetrainercls().</font>
    <font color=navy>//</font>
    <font color=navy>// Below we create trainer object which can be used to train regression networks</font>
    <font color=navy>// with 2 inputs and 1 output.</font>
    <font color=navy>//</font>
    mlpcreatetrainer(2, 1, trn);

    <font color=navy>//</font>
    <font color=navy>// Stage 2: specification of the training set</font>
    <font color=navy>//</font>
    <font color=navy>// By default trainer object stores empty dataset. So to solve your non-empty problem</font>
    <font color=navy>// you have to set dataset by passing to trainer dense or sparse matrix.</font>
    <font color=navy>//</font>
    <font color=navy>// One row of the matrix corresponds to one record A*B=C in the multiplication table.</font>
    <font color=navy>// First two columns store A and B, last column stores C</font>
    <font color=navy>//</font>
    <font color=navy>//     [1 * 1 = 1]   [ 1 1 1 ]</font>
    <font color=navy>//     [1 * 2 = 2]   [ 1 2 2 ]</font>
    <font color=navy>//     [2 * 1 = 2] = [ 2 1 2 ]</font>
    <font color=navy>//     [2 * 2 = 4]   [ 2 2 4 ]</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[1,1,1],[1,2,2],[2,1,2],[2,2,4]]&quot;</b></font>;
    mlpsetdataset(trn, xy, 4);

    <font color=navy>//</font>
    <font color=navy>// Stage 3: modification of the training parameters.</font>
    <font color=navy>//</font>
    <font color=navy>// You may modify parameters like weights decay or stopping criteria:</font>
    <font color=navy>// * we set moderate weight decay</font>
    <font color=navy>// * we choose iterations limit as stopping condition (another condition - step size -</font>
    <font color=navy>//   is zero, which means than this condition is not active)</font>
    <font color=navy>//</font>
    <b>double</b> wstep = 0.000;
    ae_int_t maxits = 100;
    mlpsetdecay(trn, 0.01);
    mlpsetcond(trn, wstep, maxits);

    <font color=navy>//</font>
    <font color=navy>// Stage 4: training.</font>
    <font color=navy>//</font>
    <font color=navy>// We will train several networks with different architecture using same trainer object.</font>
    <font color=navy>// We may change training parameters or even dataset, so different networks are trained</font>
    <font color=navy>// differently. But in this simple example we will train all networks with same settings.</font>
    <font color=navy>//</font>
    <font color=navy>// We create and train three networks:</font>
    <font color=navy>// * network 1 has 2x1 architecture     (2 inputs, no hidden neurons, 1 output)</font>
    <font color=navy>// * network 2 has 2x5x1 architecture   (2 inputs, 5 hidden neurons, 1 output)</font>
    <font color=navy>// * network 3 has 2x5x5x1 architecture (2 inputs, two hidden layers, 1 output)</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: these networks solve regression problems. For classification problems you</font>
    <font color=navy>//       should use mlpcreatec0/c1/c2 to create neural networks which have SOFTMAX-</font>
    <font color=navy>//       normalized outputs.</font>
    <font color=navy>//</font>
    multilayerperceptron net1;
    multilayerperceptron net2;
    multilayerperceptron net3;
    mlpreport rep;

    mlpcreate0(2, 1, net1);
    mlpcreate1(2, 5, 1, net2);
    mlpcreate2(2, 5, 5, 1, net3);

    mlptrainnetwork(trn, net1, 5, rep);
    mlptrainnetwork(trn, net2, 5, rep);
    mlptrainnetwork(trn, net3, 5, rep);
    <b>return</b> 0;
}


</pre><a name=unit_nearestneighbor></a><h2 class=pageheader><code>nearestneighbor</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_kdtree' class=toc>kdtree</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_kdtreebuild' class=toc>kdtreebuild</a><br>
<a href='#sub_kdtreebuildtagged' class=toc>kdtreebuildtagged</a><br>
<a href='#sub_kdtreequeryaknn' class=toc>kdtreequeryaknn</a><br>
<a href='#sub_kdtreequeryknn' class=toc>kdtreequeryknn</a><br>
<a href='#sub_kdtreequeryresultsdistances' class=toc>kdtreequeryresultsdistances</a><br>
<a href='#sub_kdtreequeryresultsdistancesi' class=toc>kdtreequeryresultsdistancesi</a><br>
<a href='#sub_kdtreequeryresultstags' class=toc>kdtreequeryresultstags</a><br>
<a href='#sub_kdtreequeryresultstagsi' class=toc>kdtreequeryresultstagsi</a><br>
<a href='#sub_kdtreequeryresultsx' class=toc>kdtreequeryresultsx</a><br>
<a href='#sub_kdtreequeryresultsxi' class=toc>kdtreequeryresultsxi</a><br>
<a href='#sub_kdtreequeryresultsxy' class=toc>kdtreequeryresultsxy</a><br>
<a href='#sub_kdtreequeryresultsxyi' class=toc>kdtreequeryresultsxyi</a><br>
<a href='#sub_kdtreequeryrnn' class=toc>kdtreequeryrnn</a><br>
<a href='#sub_kdtreeserialize' class=toc>kdtreeserialize</a><br>
<a href='#sub_kdtreeunserialize' class=toc>kdtreeunserialize</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_nneighbor_d_1' class=toc>nneighbor_d_1</a></td><td width=15>&nbsp;</td><td>Nearest neighbor search, KNN queries</td></tr>
<tr align=left valign=top><td><a href='#example_nneighbor_d_2' class=toc>nneighbor_d_2</a></td><td width=15>&nbsp;</td><td>Serialization of KD-trees</td></tr>
</table></div>
<a name='struct_kdtree'></a><h3 class=pageheader><code>kdtree</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> kdtree
{
};

</div></pre>
<a name='sub_kdtreebuild'></a><h3 class=pageheader><code>kdtreebuild</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
KD-tree creation

This subroutine creates KD-tree from set of X-values and optional Y-values

INPUT PARAMETERS
    XY      -   dataset, array[0..N-1,0..NX+NY-1].
                one row corresponds to one point.
                first NX columns contain X-values, next NY (NY may be zero)
                columns may contain associated Y-values
    N       -   number of points, N&gt;=0.
    NX      -   space dimension, NX&gt;=1.
    NY      -   number of optional Y-values, NY&gt;=0.
    NormType-   norm type:
                * 0 denotes infinity-norm
                * 1 denotes 1-norm
                * 2 denotes 2-norm (Euclidean norm)

OUTPUT PARAMETERS
    KDT     -   KD-tree


NOTES

1. KD-tree  creation  have O(N*logN) complexity and O(N*(2*NX+NY))  memory
   requirements.
2. Although KD-trees may be used with any combination of N  and  NX,  they
   are more efficient than brute-force search only when N &gt;&gt; 4^NX. So they
   are most useful in low-dimensional tasks (NX=2, NX=3). NX=1  is another
   inefficient case, because  simple  binary  search  (without  additional
   structures) is much more efficient in such tasks than KD-trees.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreebuild(
    real_2d_array xy,
    ae_int_t nx,
    ae_int_t ny,
    ae_int_t normtype,
    kdtree&amp; kdt);
<b>void</b> alglib::kdtreebuild(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t nx,
    ae_int_t ny,
    ae_int_t normtype,
    kdtree&amp; kdt);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_nneighbor_d_2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreebuildtagged'></a><h3 class=pageheader><code>kdtreebuildtagged</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
KD-tree creation

This  subroutine  creates  KD-tree  from set of X-values, integer tags and
optional Y-values

INPUT PARAMETERS
    XY      -   dataset, array[0..N-1,0..NX+NY-1].
                one row corresponds to one point.
                first NX columns contain X-values, next NY (NY may be zero)
                columns may contain associated Y-values
    Tags    -   tags, array[0..N-1], contains integer tags associated
                with points.
    N       -   number of points, N&gt;=0
    NX      -   space dimension, NX&gt;=1.
    NY      -   number of optional Y-values, NY&gt;=0.
    NormType-   norm type:
                * 0 denotes infinity-norm
                * 1 denotes 1-norm
                * 2 denotes 2-norm (Euclidean norm)

OUTPUT PARAMETERS
    KDT     -   KD-tree

NOTES

1. KD-tree  creation  have O(N*logN) complexity and O(N*(2*NX+NY))  memory
   requirements.
2. Although KD-trees may be used with any combination of N  and  NX,  they
   are more efficient than brute-force search only when N &gt;&gt; 4^NX. So they
   are most useful in low-dimensional tasks (NX=2, NX=3). NX=1  is another
   inefficient case, because  simple  binary  search  (without  additional
   structures) is much more efficient in such tasks than KD-trees.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreebuildtagged(
    real_2d_array xy,
    integer_1d_array tags,
    ae_int_t nx,
    ae_int_t ny,
    ae_int_t normtype,
    kdtree&amp; kdt);
<b>void</b> alglib::kdtreebuildtagged(
    real_2d_array xy,
    integer_1d_array tags,
    ae_int_t n,
    ae_int_t nx,
    ae_int_t ny,
    ae_int_t normtype,
    kdtree&amp; kdt);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryaknn'></a><h3 class=pageheader><code>kdtreequeryaknn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
K-NN query: approximate K nearest neighbors

INPUT PARAMETERS
    KDT         -   KD-tree
    X           -   point, array[0..NX-1].
    K           -   number of neighbors to return, K&gt;=1
    SelfMatch   -   whether self-matches are allowed:
                    * if True, nearest neighbor may be the point itself
                      (if it exists in original dataset)
                    * if False, then only points with non-zero distance
                      are returned
                    * if not given, considered True
    Eps         -   approximation factor, Eps&gt;=0. eps-approximate  nearest
                    neighbor  is  a  neighbor  whose distance from X is at
                    most (1+eps) times distance of true nearest neighbor.

RESULT
    number of actual neighbors found (either K or N, if K&gt;N).

NOTES
    significant performance gain may be achieved only when Eps  is  is  on
    the order of magnitude of 1 or larger.

This  subroutine  performs  query  and  stores  its result in the internal
structures of the KD-tree. You can use  following  subroutines  to  obtain
these results:
* KDTreeQueryResultsX() to get X-values
* KDTreeQueryResultsXY() to get X- and Y-values
* KDTreeQueryResultsTags() to get tag values
* KDTreeQueryResultsDistances() to get distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::kdtreequeryaknn(
    kdtree kdt,
    real_1d_array x,
    ae_int_t k,
    <b>double</b> eps);
ae_int_t alglib::kdtreequeryaknn(
    kdtree kdt,
    real_1d_array x,
    ae_int_t k,
    <b>bool</b> selfmatch,
    <b>double</b> eps);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryknn'></a><h3 class=pageheader><code>kdtreequeryknn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
K-NN query: K nearest neighbors

INPUT PARAMETERS
    KDT         -   KD-tree
    X           -   point, array[0..NX-1].
    K           -   number of neighbors to return, K&gt;=1
    SelfMatch   -   whether self-matches are allowed:
                    * if True, nearest neighbor may be the point itself
                      (if it exists in original dataset)
                    * if False, then only points with non-zero distance
                      are returned
                    * if not given, considered True

RESULT
    number of actual neighbors found (either K or N, if K&gt;N).

This  subroutine  performs  query  and  stores  its result in the internal
structures of the KD-tree. You can use  following  subroutines  to  obtain
these results:
* KDTreeQueryResultsX() to get X-values
* KDTreeQueryResultsXY() to get X- and Y-values
* KDTreeQueryResultsTags() to get tag values
* KDTreeQueryResultsDistances() to get distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::kdtreequeryknn(kdtree kdt, real_1d_array x, ae_int_t k);
ae_int_t alglib::kdtreequeryknn(
    kdtree kdt,
    real_1d_array x,
    ae_int_t k,
    <b>bool</b> selfmatch);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryresultsdistances'></a><h3 class=pageheader><code>kdtreequeryresultsdistances</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Distances from last query

INPUT PARAMETERS
    KDT     -   KD-tree
    R       -   possibly pre-allocated buffer. If X is too small to store
                result, it is resized. If size(X) is enough to store
                result, it is left unchanged.

OUTPUT PARAMETERS
    R       -   filled with distances (in corresponding norm)

NOTES
1. points are ordered by distance from the query point (first = closest)
2. if  XY is larger than required to store result, only leading part  will
   be overwritten; trailing part will be left unchanged. So  if  on  input
   XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
   XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
   you want function  to  resize  array  according  to  result  size,  use
   function with same name and suffix 'I'.

SEE ALSO
* KDTreeQueryResultsX()             X-values
* KDTreeQueryResultsXY()            X- and Y-values
* KDTreeQueryResultsTags()          tag values

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsdistances(kdtree kdt, real_1d_array&amp; r);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryresultsdistancesi'></a><h3 class=pageheader><code>kdtreequeryresultsdistancesi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Distances from last query; 'interactive' variant for languages like Python
which  support  constructs   like  &quot;R = KDTreeQueryResultsDistancesI(KDT)&quot;
and interactive mode of interpreter.

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsdistancesi(kdtree kdt, real_1d_array&amp; r);

</div></pre>
<a name='sub_kdtreequeryresultstags'></a><h3 class=pageheader><code>kdtreequeryresultstags</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Tags from last query

INPUT PARAMETERS
    KDT     -   KD-tree
    Tags    -   possibly pre-allocated buffer. If X is too small to store
                result, it is resized. If size(X) is enough to store
                result, it is left unchanged.

OUTPUT PARAMETERS
    Tags    -   filled with tags associated with points,
                or, when no tags were supplied, with zeros

NOTES
1. points are ordered by distance from the query point (first = closest)
2. if  XY is larger than required to store result, only leading part  will
   be overwritten; trailing part will be left unchanged. So  if  on  input
   XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
   XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
   you want function  to  resize  array  according  to  result  size,  use
   function with same name and suffix 'I'.

SEE ALSO
* KDTreeQueryResultsX()             X-values
* KDTreeQueryResultsXY()            X- and Y-values
* KDTreeQueryResultsDistances()     distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultstags(kdtree kdt, integer_1d_array&amp; tags);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryresultstagsi'></a><h3 class=pageheader><code>kdtreequeryresultstagsi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Tags  from  last  query;  'interactive' variant for languages like  Python
which  support  constructs  like &quot;Tags = KDTreeQueryResultsTagsI(KDT)&quot; and
interactive mode of interpreter.

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultstagsi(kdtree kdt, integer_1d_array&amp; tags);

</div></pre>
<a name='sub_kdtreequeryresultsx'></a><h3 class=pageheader><code>kdtreequeryresultsx</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
X-values from last query

INPUT PARAMETERS
    KDT     -   KD-tree
    X       -   possibly pre-allocated buffer. If X is too small to store
                result, it is resized. If size(X) is enough to store
                result, it is left unchanged.

OUTPUT PARAMETERS
    X       -   rows are filled with X-values

NOTES
1. points are ordered by distance from the query point (first = closest)
2. if  XY is larger than required to store result, only leading part  will
   be overwritten; trailing part will be left unchanged. So  if  on  input
   XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
   XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
   you want function  to  resize  array  according  to  result  size,  use
   function with same name and suffix 'I'.

SEE ALSO
* KDTreeQueryResultsXY()            X- and Y-values
* KDTreeQueryResultsTags()          tag values
* KDTreeQueryResultsDistances()     distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsx(kdtree kdt, real_2d_array&amp; x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryresultsxi'></a><h3 class=pageheader><code>kdtreequeryresultsxi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
X-values from last query; 'interactive' variant for languages like  Python
which   support    constructs   like  &quot;X = KDTreeQueryResultsXI(KDT)&quot;  and
interactive mode of interpreter.

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsxi(kdtree kdt, real_2d_array&amp; x);

</div></pre>
<a name='sub_kdtreequeryresultsxy'></a><h3 class=pageheader><code>kdtreequeryresultsxy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
X- and Y-values from last query

INPUT PARAMETERS
    KDT     -   KD-tree
    XY      -   possibly pre-allocated buffer. If XY is too small to store
                result, it is resized. If size(XY) is enough to store
                result, it is left unchanged.

OUTPUT PARAMETERS
    XY      -   rows are filled with points: first NX columns with
                X-values, next NY columns - with Y-values.

NOTES
1. points are ordered by distance from the query point (first = closest)
2. if  XY is larger than required to store result, only leading part  will
   be overwritten; trailing part will be left unchanged. So  if  on  input
   XY = [[A,B],[C,D]], and result is [1,2],  then  on  exit  we  will  get
   XY = [[1,2],[C,D]]. This is done purposely to increase performance;  if
   you want function  to  resize  array  according  to  result  size,  use
   function with same name and suffix 'I'.

SEE ALSO
* KDTreeQueryResultsX()             X-values
* KDTreeQueryResultsTags()          tag values
* KDTreeQueryResultsDistances()     distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsxy(kdtree kdt, real_2d_array&amp; xy);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreequeryresultsxyi'></a><h3 class=pageheader><code>kdtreequeryresultsxyi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
XY-values from last query; 'interactive' variant for languages like Python
which   support    constructs   like &quot;XY = KDTreeQueryResultsXYI(KDT)&quot; and
interactive mode of interpreter.

This function allocates new array on each call,  so  it  is  significantly
slower than its 'non-interactive' counterpart, but it is  more  convenient
when you call it from command line.

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::kdtreequeryresultsxyi(kdtree kdt, real_2d_array&amp; xy);

</div></pre>
<a name='sub_kdtreequeryrnn'></a><h3 class=pageheader><code>kdtreequeryrnn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
R-NN query: all points within R-sphere centered at X

INPUT PARAMETERS
    KDT         -   KD-tree
    X           -   point, array[0..NX-1].
    R           -   radius of sphere (in corresponding norm), R&gt;0
    SelfMatch   -   whether self-matches are allowed:
                    * if True, nearest neighbor may be the point itself
                      (if it exists in original dataset)
                    * if False, then only points with non-zero distance
                      are returned
                    * if not given, considered True

RESULT
    number of neighbors found, &gt;=0

This  subroutine  performs  query  and  stores  its result in the internal
structures of the KD-tree. You can use  following  subroutines  to  obtain
actual results:
* KDTreeQueryResultsX() to get X-values
* KDTreeQueryResultsXY() to get X- and Y-values
* KDTreeQueryResultsTags() to get tag values
* KDTreeQueryResultsDistances() to get distances

  -- ALGLIB --
     Copyright 28.02.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::kdtreequeryrnn(kdtree kdt, real_1d_array x, <b>double</b> r);
ae_int_t alglib::kdtreequeryrnn(
    kdtree kdt,
    real_1d_array x,
    <b>double</b> r,
    <b>bool</b> selfmatch);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_nneighbor_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_kdtreeserialize'></a><h3 class=pageheader><code>kdtreeserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function serializes data structure to string.

Important properties of s_out:
* it contains alphanumeric characters, dots, underscores, minus signs
* these symbols are grouped into words, which are separated by spaces
  and Windows-style (CR+LF) newlines
* although  serializer  uses  spaces and CR+LF as separators, you can 
  replace any separator character by arbitrary combination of spaces,
  tabs, Windows or Unix newlines. It allows flexible reformatting  of
  the  string  in  case you want to include it into text or XML file. 
  But you should not insert separators into the middle of the &quot;words&quot;
  nor you should change case of letters.
* s_out can be freely moved between 32-bit and 64-bit systems, little
  and big endian machines, and so on. You can serialize structure  on
  32-bit machine and unserialize it on 64-bit one (or vice versa), or
  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also 
  serialize  it  in  C++ version of ALGLIB and unserialize in C# one, 
  and vice versa.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> kdtreeserialize(kdtree &amp;obj, std::string &amp;s_out);
</div></pre>
<a name='sub_kdtreeunserialize'></a><h3 class=pageheader><code>kdtreeunserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function unserializes data structure from string.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> kdtreeunserialize(std::string &amp;s_in, kdtree &amp;obj);
</div></pre>
<a name='example_nneighbor_d_1'></a><h3 class=pageheader>nneighbor_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;alglibmisc.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array a = <font color=blue><b>&quot;[[0,0],[0,1],[1,0],[1,1]]&quot;</b></font>;
    ae_int_t nx = 2;
    ae_int_t ny = 0;
    ae_int_t normtype = 2;
    kdtree kdt;
    real_1d_array x;
    real_2d_array r = <font color=blue><b>&quot;[[]]&quot;</b></font>;
    ae_int_t k;
    kdtreebuild(a, nx, ny, normtype, kdt);
    x = <font color=blue><b>&quot;[-1,0]&quot;</b></font>;
    k = kdtreequeryknn(kdt, x, 1);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(k)); <font color=navy>// EXPECTED: 1</font>
    kdtreequeryresultsx(kdt, r);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, r.tostring(1).c_str()); <font color=navy>// EXPECTED: [[0,0]]</font>
    <b>return</b> 0;
}


</pre><a name='example_nneighbor_d_2'></a><h3 class=pageheader>nneighbor_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;alglibmisc.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_2d_array a = <font color=blue><b>&quot;[[0,0],[0,1],[1,0],[1,1]]&quot;</b></font>;
    ae_int_t nx = 2;
    ae_int_t ny = 0;
    ae_int_t normtype = 2;
    kdtree kdt0;
    kdtree kdt1;
    std::string s;
    real_1d_array x;
    real_2d_array r0 = <font color=blue><b>&quot;[[]]&quot;</b></font>;
    real_2d_array r1 = <font color=blue><b>&quot;[[]]&quot;</b></font>;

    <font color=navy>//</font>
    <font color=navy>// Build tree and serialize it</font>
    <font color=navy>//</font>
    kdtreebuild(a, nx, ny, normtype, kdt0);
    alglib::kdtreeserialize(kdt0, s);
    alglib::kdtreeunserialize(s, kdt1);

    <font color=navy>//</font>
    <font color=navy>// Compare results from KNN queries</font>
    <font color=navy>//</font>
    x = <font color=blue><b>&quot;[-1,0]&quot;</b></font>;
    kdtreequeryknn(kdt0, x, 1);
    kdtreequeryresultsx(kdt0, r0);
    kdtreequeryknn(kdt1, x, 1);
    kdtreequeryresultsx(kdt1, r1);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, r0.tostring(1).c_str()); <font color=navy>// EXPECTED: [[0,0]]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, r1.tostring(1).c_str()); <font color=navy>// EXPECTED: [[0,0]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_nleq></a><h2 class=pageheader><code>nleq</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_nleqreport' class=toc>nleqreport</a><br>
<a href='#struct_nleqstate' class=toc>nleqstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_nleqcreatelm' class=toc>nleqcreatelm</a><br>
<a href='#sub_nleqrestartfrom' class=toc>nleqrestartfrom</a><br>
<a href='#sub_nleqresults' class=toc>nleqresults</a><br>
<a href='#sub_nleqresultsbuf' class=toc>nleqresultsbuf</a><br>
<a href='#sub_nleqsetcond' class=toc>nleqsetcond</a><br>
<a href='#sub_nleqsetstpmax' class=toc>nleqsetstpmax</a><br>
<a href='#sub_nleqsetxrep' class=toc>nleqsetxrep</a><br>
<a href='#sub_nleqsolve' class=toc>nleqsolve</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_nleqreport'></a><h3 class=pageheader><code>nleqreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> nleqreport
{
    ae_int_t             iterationscount;
    ae_int_t             nfunc;
    ae_int_t             njac;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_nleqstate'></a><h3 class=pageheader><code>nleqstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> nleqstate
{
};

</div></pre>
<a name='sub_nleqcreatelm'></a><h3 class=pageheader><code>nleqcreatelm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
                LEVENBERG-MARQUARDT-LIKE NONLINEAR SOLVER

DESCRIPTION:
This algorithm solves system of nonlinear equations
    F[0](x[0], ..., x[n-1])   = 0
    F[1](x[0], ..., x[n-1])   = 0
    ...
    F[M-1](x[0], ..., x[n-1]) = 0
with M/N do not necessarily coincide.  Algorithm  converges  quadratically
under following conditions:
    * the solution set XS is nonempty
    * for some xs in XS there exist such neighbourhood N(xs) that:
      * vector function F(x) and its Jacobian J(x) are continuously
        differentiable on N
      * ||F(x)|| provides local error bound on N, i.e. there  exists  such
        c1, that ||F(x)||&gt;c1*distance(x,XS)
Note that these conditions are much more weaker than usual non-singularity
conditions. For example, algorithm will converge for any  affine  function
F (whether its Jacobian singular or not).


REQUIREMENTS:
Algorithm will request following information during its operation:
* function vector F[] and Jacobian matrix at given point X
* value of merit function f(x)=F[0]^2(x)+...+F[M-1]^2(x) at given point X


USAGE:
1. User initializes algorithm state with NLEQCreateLM() call
2. User tunes solver parameters with  NLEQSetCond(),  NLEQSetStpMax()  and
   other functions
3. User  calls  NLEQSolve()  function  which  takes  algorithm  state  and
   pointers (delegates, etc.) to callback functions which calculate  merit
   function value and Jacobian.
4. User calls NLEQResults() to get solution
5. Optionally, user may call NLEQRestartFrom() to  solve  another  problem
   with same parameters (N/M) but another starting  point  and/or  another
   function vector. NLEQRestartFrom() allows to reuse already  initialized
   structure.


INPUT PARAMETERS:
    N       -   space dimension, N&gt;1:
                * if provided, only leading N elements of X are used
                * if not provided, determined automatically from size of X
    M       -   system size
    X       -   starting point


OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state


NOTES:
1. you may tune stopping conditions with NLEQSetCond() function
2. if target function contains exp() or other fast growing functions,  and
   optimization algorithm makes too large steps which leads  to  overflow,
   use NLEQSetStpMax() function to bound algorithm's steps.
3. this  algorithm  is  a  slightly  modified implementation of the method
   described  in  'Levenberg-Marquardt  method  for constrained  nonlinear
   equations with strong local convergence properties' by Christian Kanzow
   Nobuo Yamashita and Masao Fukushima and further  developed  in  'On the
   convergence of a New Levenberg-Marquardt Method'  by  Jin-yan  Fan  and
   Ya-Xiang Yuan.


  -- ALGLIB --
     Copyright 20.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqcreatelm(ae_int_t m, real_1d_array x, nleqstate&amp; state);
<b>void</b> alglib::nleqcreatelm(
    ae_int_t n,
    ae_int_t m,
    real_1d_array x,
    nleqstate&amp; state);

</div></pre>
<a name='sub_nleqrestartfrom'></a><h3 class=pageheader><code>nleqrestartfrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine  restarts  CG  algorithm from new point. All optimization
parameters are left unchanged.

This  function  allows  to  solve multiple  optimization  problems  (which
must have same number of dimensions) without object reallocation penalty.

INPUT PARAMETERS:
    State   -   structure used for reverse communication previously
                allocated with MinCGCreate call.
    X       -   new starting point.
    BndL    -   new lower bounds
    BndU    -   new upper bounds

  -- ALGLIB --
     Copyright 30.07.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqrestartfrom(nleqstate state, real_1d_array x);

</div></pre>
<a name='sub_nleqresults'></a><h3 class=pageheader><code>nleqresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
NLEQ solver results

INPUT PARAMETERS:
    State   -   algorithm state.

OUTPUT PARAMETERS:
    X       -   array[0..N-1], solution
    Rep     -   optimization report:
                * Rep.TerminationType completetion code:
                    * -4    ERROR:  algorithm   has   converged   to   the
                            stationary point Xf which is local minimum  of
                            f=F[0]^2+...+F[m-1]^2, but is not solution  of
                            nonlinear system.
                    *  1    sqrt(f)&lt;=EpsF.
                    *  5    MaxIts steps was taken
                    *  7    stopping conditions are too stringent,
                            further improvement is impossible
                * Rep.IterationsCount contains iterations count
                * NFEV countains number of function calculations
                * ActiveConstraints contains number of active constraints

  -- ALGLIB --
     Copyright 20.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqresults(
    nleqstate state,
    real_1d_array&amp; x,
    nleqreport&amp; rep);

</div></pre>
<a name='sub_nleqresultsbuf'></a><h3 class=pageheader><code>nleqresultsbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
NLEQ solver results

Buffered implementation of NLEQResults(), which uses pre-allocated  buffer
to store X[]. If buffer size is  too  small,  it  resizes  buffer.  It  is
intended to be used in the inner cycles of performance critical algorithms
where array reallocation penalty is too large to be ignored.

  -- ALGLIB --
     Copyright 20.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqresultsbuf(
    nleqstate state,
    real_1d_array&amp; x,
    nleqreport&amp; rep);

</div></pre>
<a name='sub_nleqsetcond'></a><h3 class=pageheader><code>nleqsetcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets stopping conditions for the nonlinear solver

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    EpsF    -   &gt;=0
                The subroutine finishes  its work if on k+1-th iteration
                the condition ||F||&lt;=EpsF is satisfied
    MaxIts  -   maximum number of iterations. If MaxIts=0, the  number  of
                iterations is unlimited.

Passing EpsF=0 and MaxIts=0 simultaneously will lead to  automatic
stopping criterion selection (small EpsF).

NOTES:

  -- ALGLIB --
     Copyright 20.08.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqsetcond(nleqstate state, <b>double</b> epsf, ae_int_t maxits);

</div></pre>
<a name='sub_nleqsetstpmax'></a><h3 class=pageheader><code>nleqsetstpmax</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets maximum step length

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    StpMax  -   maximum step length, &gt;=0. Set StpMax to 0.0,  if you don't
                want to limit step length.

Use this subroutine when target function  contains  exp()  or  other  fast
growing functions, and algorithm makes  too  large  steps  which  lead  to
overflow. This function allows us to reject steps that are too large  (and
therefore expose us to the possible overflow) without actually calculating
function value at the x+stp*d.

  -- ALGLIB --
     Copyright 20.08.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqsetstpmax(nleqstate state, <b>double</b> stpmax);

</div></pre>
<a name='sub_nleqsetxrep'></a><h3 class=pageheader><code>nleqsetxrep</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function turns on/off reporting.

INPUT PARAMETERS:
    State   -   structure which stores algorithm state
    NeedXRep-   whether iteration reports are needed or not

If NeedXRep is True, algorithm will call rep() callback function if  it is
provided to NLEQSolve().

  -- ALGLIB --
     Copyright 20.08.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::nleqsetxrep(nleqstate state, <b>bool</b> needxrep);

</div></pre>
<a name='sub_nleqsolve'></a><h3 class=pageheader><code>nleqsolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This family of functions is used to launcn iterations of nonlinear solver

These functions accept following parameters:
    state   -   algorithm state
    func    -   callback which calculates function (or merit function)
                value func at given point x
    jac     -   callback which calculates function vector fi[]
                and Jacobian jac at given point x
    rep     -   optional callback which is called after each iteration
                can be NULL
    ptr     -   optional pointer which is passed to func/grad/hess/jac/rep
                can be NULL


  -- ALGLIB --
     Copyright 20.03.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> nleqsolve(nleqstate &amp;state,
    <b>void</b> (*func)(<b>const</b> real_1d_array &amp;x, <b>double</b> &amp;func, <b>void</b> *ptr),
    <b>void</b>  (*jac)(<b>const</b> real_1d_array &amp;x, real_1d_array &amp;fi, real_2d_array &amp;jac, <b>void</b> *ptr),
    <b>void</b>  (*rep)(<b>const</b> real_1d_array &amp;x, <b>double</b> func, <b>void</b> *ptr) = NULL,
    <b>void</b> *ptr = NULL);
</div></pre>
<a name=unit_normaldistr></a><h2 class=pageheader><code>normaldistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_errorfunction' class=toc>errorfunction</a><br>
<a href='#sub_errorfunctionc' class=toc>errorfunctionc</a><br>
<a href='#sub_inverf' class=toc>inverf</a><br>
<a href='#sub_invnormaldistribution' class=toc>invnormaldistribution</a><br>
<a href='#sub_normaldistribution' class=toc>normaldistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_errorfunction'></a><h3 class=pageheader><code>errorfunction</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Error function

The integral is

                          x
                           -
                2         | |          2
  erf(x)  =  --------     |    exp( - t  ) dt.
             sqrt(pi)   | |
                         -
                          0

For 0 &lt;= |x| &lt; 1, erf(x) = x * P4(x**2)/Q5(x**2); otherwise
erf(x) = 1 - erfc(x).


ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,1         30000       3.7e-16     1.0e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::errorfunction(<b>double</b> x);

</div></pre>
<a name='sub_errorfunctionc'></a><h3 class=pageheader><code>errorfunctionc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complementary error function

 1 - erf(x) =

                          inf.
                            -
                 2         | |          2
  erfc(x)  =  --------     |    exp( - t  ) dt
              sqrt(pi)   | |
                          -
                           x


For small x, erfc(x) = 1 - erf(x); otherwise rational
approximations are computed.


ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE      0,26.6417   30000       5.7e-14     1.5e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::errorfunctionc(<b>double</b> x);

</div></pre>
<a name='sub_inverf'></a><h3 class=pageheader><code>inverf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of the error function

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::inverf(<b>double</b> e);

</div></pre>
<a name='sub_invnormaldistribution'></a><h3 class=pageheader><code>invnormaldistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse of Normal distribution function

Returns the argument, x, for which the area under the
Gaussian probability density function (integrated from
minus infinity to x) is equal to y.


For small arguments 0 &lt; y &lt; exp(-2), the program computes
z = sqrt( -2.0 * log(y) );  then the approximation is
x = z - log(z)/z  - (1/z) P(1/z) / Q(1/z).
There are two rational functions P/Q, one for 0 &lt; y &lt; exp(-32)
and the other for y up to exp(-2).  For larger arguments,
w = y - 0.5, and  x/sqrt(2pi) = w + w**3 R(w**2)/S(w**2)).

ACCURACY:

                     Relative error:
arithmetic   domain        # trials      peak         rms
   IEEE     0.125, 1        20000       7.2e-16     1.3e-16
   IEEE     3e-308, 0.135   50000       4.6e-16     9.8e-17

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invnormaldistribution(<b>double</b> y0);

</div></pre>
<a name='sub_normaldistribution'></a><h3 class=pageheader><code>normaldistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Normal distribution function

Returns the area under the Gaussian probability density
function, integrated from minus infinity to x:

                           x
                            -
                  1        | |          2
   ndtr(x)  = ---------    |    exp( - t /2 ) dt
              sqrt(2pi)  | |
                          -
                         -inf.

            =  ( 1 + erf(z) ) / 2
            =  erfc(z) / 2

where z = x/sqrt(2). Computation is via the functions
erf and erfc.


ACCURACY:

                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE     -13,0        30000       3.4e-14     6.7e-15

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::normaldistribution(<b>double</b> x);

</div></pre>
<a name=unit_normestimator></a><h2 class=pageheader><code>normestimator</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_normestimatorstate' class=toc>normestimatorstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_normestimatorcreate' class=toc>normestimatorcreate</a><br>
<a href='#sub_normestimatorestimatesparse' class=toc>normestimatorestimatesparse</a><br>
<a href='#sub_normestimatorresults' class=toc>normestimatorresults</a><br>
<a href='#sub_normestimatorsetseed' class=toc>normestimatorsetseed</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_normestimatorstate'></a><h3 class=pageheader><code>normestimatorstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This object stores state of the iterative norm estimation algorithm.

You should use ALGLIB functions to work with this object.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> normestimatorstate
{
};

</div></pre>
<a name='sub_normestimatorcreate'></a><h3 class=pageheader><code>normestimatorcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This procedure initializes matrix norm estimator.

USAGE:
1. User initializes algorithm state with NormEstimatorCreate() call
2. User calls NormEstimatorEstimateSparse() (or NormEstimatorIteration())
3. User calls NormEstimatorResults() to get solution.

INPUT PARAMETERS:
    M       -   number of rows in the matrix being estimated, M&gt;0
    N       -   number of columns in the matrix being estimated, N&gt;0
    NStart  -   number of random starting vectors
                recommended value - at least 5.
    NIts    -   number of iterations to do with best starting vector
                recommended value - at least 5.

OUTPUT PARAMETERS:
    State   -   structure which stores algorithm state


NOTE: this algorithm is effectively deterministic, i.e. it always  returns
same result when repeatedly called for the same matrix. In fact, algorithm
uses randomized starting vectors, but internal  random  numbers  generator
always generates same sequence of the random values (it is a  feature, not
bug).

Algorithm can be made non-deterministic with NormEstimatorSetSeed(0) call.

  -- ALGLIB --
     Copyright 06.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::normestimatorcreate(
    ae_int_t m,
    ae_int_t n,
    ae_int_t nstart,
    ae_int_t nits,
    normestimatorstate&amp; state);

</div></pre>
<a name='sub_normestimatorestimatesparse'></a><h3 class=pageheader><code>normestimatorestimatesparse</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function estimates norm of the sparse M*N matrix A.

INPUT PARAMETERS:
    State       -   norm estimator state, must be initialized with a  call
                    to NormEstimatorCreate()
    A           -   sparse M*N matrix, must be converted to CRS format
                    prior to calling this function.

After this function  is  over  you can call NormEstimatorResults() to get
estimate of the norm(A).

  -- ALGLIB --
     Copyright 06.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::normestimatorestimatesparse(
    normestimatorstate state,
    sparsematrix a);

</div></pre>
<a name='sub_normestimatorresults'></a><h3 class=pageheader><code>normestimatorresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Matrix norm estimation results

INPUT PARAMETERS:
    State   -   algorithm state

OUTPUT PARAMETERS:
    Nrm     -   estimate of the matrix norm, Nrm&gt;=0

  -- ALGLIB --
     Copyright 06.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::normestimatorresults(normestimatorstate state, <b>double</b>&amp; nrm);

</div></pre>
<a name='sub_normestimatorsetseed'></a><h3 class=pageheader><code>normestimatorsetseed</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function changes seed value used by algorithm. In some cases we  need
deterministic processing, i.e. subsequent calls must return equal results,
in other cases we need non-deterministic algorithm which returns different
results for the same matrix on every pass.

Setting zero seed will lead to non-deterministic algorithm, while non-zero
value will make our algorithm deterministic.

INPUT PARAMETERS:
    State       -   norm estimator state, must be initialized with a  call
                    to NormEstimatorCreate()
    SeedVal     -   seed value, &gt;=0. Zero value = non-deterministic algo.

  -- ALGLIB --
     Copyright 06.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::normestimatorsetseed(
    normestimatorstate state,
    ae_int_t seedval);

</div></pre>
<a name=unit_odesolver></a><h2 class=pageheader><code>odesolver</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_odesolverreport' class=toc>odesolverreport</a><br>
<a href='#struct_odesolverstate' class=toc>odesolverstate</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_odesolverresults' class=toc>odesolverresults</a><br>
<a href='#sub_odesolverrkck' class=toc>odesolverrkck</a><br>
<a href='#sub_odesolversolve' class=toc>odesolversolve</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_odesolver_d1' class=toc>odesolver_d1</a></td><td width=15>&nbsp;</td><td>Solving y'=-y with ODE solver</td></tr>
</table></div>
<a name='struct_odesolverreport'></a><h3 class=pageheader><code>odesolverreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> odesolverreport
{
    ae_int_t             nfev;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='struct_odesolverstate'></a><h3 class=pageheader><code>odesolverstate</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************

*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> odesolverstate
{
};

</div></pre>
<a name='sub_odesolverresults'></a><h3 class=pageheader><code>odesolverresults</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
ODE solver results

Called after OdeSolverIteration returned False.

INPUT PARAMETERS:
    State   -   algorithm state (used by OdeSolverIteration).

OUTPUT PARAMETERS:
    M       -   number of tabulated values, M&gt;=1
    XTbl    -   array[0..M-1], values of X
    YTbl    -   array[0..M-1,0..N-1], values of Y in X[i]
    Rep     -   solver report:
                * Rep.TerminationType completetion code:
                    * -2    X is not ordered  by  ascending/descending  or
                            there are non-distinct X[],  i.e.  X[i]=X[i+1]
                    * -1    incorrect parameters were specified
                    *  1    task has been solved
                * Rep.NFEV contains number of function calculations

  -- ALGLIB --
     Copyright 01.09.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::odesolverresults(
    odesolverstate state,
    ae_int_t&amp; m,
    real_1d_array&amp; xtbl,
    real_2d_array&amp; ytbl,
    odesolverreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_odesolver_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_odesolverrkck'></a><h3 class=pageheader><code>odesolverrkck</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cash-Karp adaptive ODE solver.

This subroutine solves ODE  Y'=f(Y,x)  with  initial  conditions  Y(xs)=Ys
(here Y may be single variable or vector of N variables).

INPUT PARAMETERS:
    Y       -   initial conditions, array[0..N-1].
                contains values of Y[] at X[0]
    N       -   system size
    X       -   points at which Y should be tabulated, array[0..M-1]
                integrations starts at X[0], ends at X[M-1],  intermediate
                values at X[i] are returned too.
                SHOULD BE ORDERED BY ASCENDING OR BY DESCENDING!!!!
    M       -   number of intermediate points + first point + last point:
                * M&gt;2 means that you need both Y(X[M-1]) and M-2 values at
                  intermediate points
                * M=2 means that you want just to integrate from  X[0]  to
                  X[1] and don't interested in intermediate values.
                * M=1 means that you don't want to integrate :)
                  it is degenerate case, but it will be handled correctly.
                * M&lt;1 means error
    Eps     -   tolerance (absolute/relative error on each  step  will  be
                less than Eps). When passing:
                * Eps&gt;0, it means desired ABSOLUTE error
                * Eps&lt;0, it means desired RELATIVE error.  Relative errors
                  are calculated with respect to maximum values of  Y seen
                  so far. Be careful to use this criterion  when  starting
                  from Y[] that are close to zero.
    H       -   initial  step  lenth,  it  will  be adjusted automatically
                after the first  step.  If  H=0,  step  will  be  selected
                automatically  (usualy  it  will  be  equal  to  0.001  of
                min(x[i]-x[j])).

OUTPUT PARAMETERS
    State   -   structure which stores algorithm state between  subsequent
                calls of OdeSolverIteration. Used for reverse communication.
                This structure should be passed  to the OdeSolverIteration
                subroutine.

SEE ALSO
    AutoGKSmoothW, AutoGKSingular, AutoGKIteration, AutoGKResults.


  -- ALGLIB --
     Copyright 01.09.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::odesolverrkck(
    real_1d_array y,
    real_1d_array x,
    <b>double</b> eps,
    <b>double</b> h,
    odesolverstate&amp; state);
<b>void</b> alglib::odesolverrkck(
    real_1d_array y,
    ae_int_t n,
    real_1d_array x,
    ae_int_t m,
    <b>double</b> eps,
    <b>double</b> h,
    odesolverstate&amp; state);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_odesolver_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_odesolversolve'></a><h3 class=pageheader><code>odesolversolve</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function is used to launcn iterations of ODE solver

It accepts following parameters:
    diff    -   callback which calculates dy/dx for given y and x
    ptr     -   optional pointer which is passed to diff; can be NULL


  -- ALGLIB --
     Copyright 01.09.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> odesolversolve(odesolverstate &amp;state,
    <b>void</b> (*diff)(<b>const</b> real_1d_array &amp;y, <b>double</b> x, real_1d_array &amp;dy, <b>void</b> *ptr),
    <b>void</b> *ptr = NULL);
</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_odesolver_d1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_odesolver_d1'></a><h3 class=pageheader>odesolver_d1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;diffequations.h&quot;</b></font>

using namespace alglib;
<b>void</b> ode_function_1_diff(<b>const</b> real_1d_array &amp;y, <b>double</b> x, real_1d_array &amp;dy, <b>void</b> *ptr) 
{
    <font color=navy>// this callback calculates f(y[],x)=-y[0]</font>
    dy[0] = -y[0];
}

<b>int</b> main(<b>int</b> argc, char **argv)
{
    real_1d_array y = <font color=blue><b>&quot;[1]&quot;</b></font>;
    real_1d_array x = <font color=blue><b>&quot;[0, 1, 2, 3]&quot;</b></font>;
    <b>double</b> eps = 0.00001;
    <b>double</b> h = 0;
    odesolverstate s;
    ae_int_t m;
    real_1d_array xtbl;
    real_2d_array ytbl;
    odesolverreport rep;
    odesolverrkck(y, x, eps, h, s);
    alglib::odesolversolve(s, ode_function_1_diff);
    odesolverresults(s, m, xtbl, ytbl, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(m)); <font color=navy>// EXPECTED: 4</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, xtbl.tostring(2).c_str()); <font color=navy>// EXPECTED: [0, 1, 2, 3]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, ytbl.tostring(2).c_str()); <font color=navy>// EXPECTED: [[1], [0.367], [0.135], [0.050]]</font>
    <b>return</b> 0;
}


</pre><a name=unit_ortfac></a><h2 class=pageheader><code>ortfac</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlq' class=toc>cmatrixlq</a><br>
<a href='#sub_cmatrixlqunpackl' class=toc>cmatrixlqunpackl</a><br>
<a href='#sub_cmatrixlqunpackq' class=toc>cmatrixlqunpackq</a><br>
<a href='#sub_cmatrixqr' class=toc>cmatrixqr</a><br>
<a href='#sub_cmatrixqrunpackq' class=toc>cmatrixqrunpackq</a><br>
<a href='#sub_cmatrixqrunpackr' class=toc>cmatrixqrunpackr</a><br>
<a href='#sub_hmatrixtd' class=toc>hmatrixtd</a><br>
<a href='#sub_hmatrixtdunpackq' class=toc>hmatrixtdunpackq</a><br>
<a href='#sub_rmatrixbd' class=toc>rmatrixbd</a><br>
<a href='#sub_rmatrixbdmultiplybyp' class=toc>rmatrixbdmultiplybyp</a><br>
<a href='#sub_rmatrixbdmultiplybyq' class=toc>rmatrixbdmultiplybyq</a><br>
<a href='#sub_rmatrixbdunpackdiagonals' class=toc>rmatrixbdunpackdiagonals</a><br>
<a href='#sub_rmatrixbdunpackpt' class=toc>rmatrixbdunpackpt</a><br>
<a href='#sub_rmatrixbdunpackq' class=toc>rmatrixbdunpackq</a><br>
<a href='#sub_rmatrixhessenberg' class=toc>rmatrixhessenberg</a><br>
<a href='#sub_rmatrixhessenbergunpackh' class=toc>rmatrixhessenbergunpackh</a><br>
<a href='#sub_rmatrixhessenbergunpackq' class=toc>rmatrixhessenbergunpackq</a><br>
<a href='#sub_rmatrixlq' class=toc>rmatrixlq</a><br>
<a href='#sub_rmatrixlqunpackl' class=toc>rmatrixlqunpackl</a><br>
<a href='#sub_rmatrixlqunpackq' class=toc>rmatrixlqunpackq</a><br>
<a href='#sub_rmatrixqr' class=toc>rmatrixqr</a><br>
<a href='#sub_rmatrixqrunpackq' class=toc>rmatrixqrunpackq</a><br>
<a href='#sub_rmatrixqrunpackr' class=toc>rmatrixqrunpackr</a><br>
<a href='#sub_smatrixtd' class=toc>smatrixtd</a><br>
<a href='#sub_smatrixtdunpackq' class=toc>smatrixtdunpackq</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlq'></a><h3 class=pageheader><code>cmatrixlq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LQ decomposition of a rectangular complex matrix of size MxN

Input parameters:
    A   -   matrix A whose indexes range within [0..M-1, 0..N-1]
    M   -   number of rows in matrix A.
    N   -   number of columns in matrix A.

Output parameters:
    A   -   matrices Q and L in compact form
    Tau -   array of scalar factors which are used to form matrix Q. Array
            whose indexes range within [0.. Min(M,N)-1]

Matrix A is represented as A = LQ, where Q is an orthogonal matrix of size
MxM, L - lower triangular (or lower trapezoid) matrix of size MxN.

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     September 30, 1994
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlq(
    complex_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    complex_1d_array&amp; tau);

</div></pre>
<a name='sub_cmatrixlqunpackl'></a><h3 class=pageheader><code>cmatrixlqunpackl</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking of matrix L from the LQ decomposition of a matrix A

Input parameters:
    A       -   matrices Q and L in compact form.
                Output of CMatrixLQ subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.

Output parameters:
    L       -   matrix L, array[0..M-1, 0..N-1].

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlqunpackl(
    complex_2d_array a,
    ae_int_t m,
    ae_int_t n,
    complex_2d_array&amp; l);

</div></pre>
<a name='sub_cmatrixlqunpackq'></a><h3 class=pageheader><code>cmatrixlqunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Partial unpacking of matrix Q from LQ decomposition of a complex matrix A.

Input parameters:
    A           -   matrices Q and R in compact form.
                    Output of CMatrixLQ subroutine .
    M           -   number of rows in matrix A. M&gt;=0.
    N           -   number of columns in matrix A. N&gt;=0.
    Tau         -   scalar factors which are used to form Q.
                    Output of CMatrixLQ subroutine .
    QRows       -   required number of rows in matrix Q. N&gt;=QColumns&gt;=0.

Output parameters:
    Q           -   first QRows rows of matrix Q.
                    Array whose index ranges within [0..QRows-1, 0..N-1].
                    If QRows=0, array isn't changed.

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlqunpackq(
    complex_2d_array a,
    ae_int_t m,
    ae_int_t n,
    complex_1d_array tau,
    ae_int_t qrows,
    complex_2d_array&amp; q);

</div></pre>
<a name='sub_cmatrixqr'></a><h3 class=pageheader><code>cmatrixqr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
QR decomposition of a rectangular complex matrix of size MxN

Input parameters:
    A   -   matrix A whose indexes range within [0..M-1, 0..N-1]
    M   -   number of rows in matrix A.
    N   -   number of columns in matrix A.

Output parameters:
    A   -   matrices Q and R in compact form
    Tau -   array of scalar factors which are used to form matrix Q. Array
            whose indexes range within [0.. Min(M,N)-1]

Matrix A is represented as A = QR, where Q is an orthogonal matrix of size
MxM, R - upper triangular (or upper trapezoid) matrix of size MxN.

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     September 30, 1994
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixqr(
    complex_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    complex_1d_array&amp; tau);

</div></pre>
<a name='sub_cmatrixqrunpackq'></a><h3 class=pageheader><code>cmatrixqrunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Partial unpacking of matrix Q from QR decomposition of a complex matrix A.

Input parameters:
    A           -   matrices Q and R in compact form.
                    Output of CMatrixQR subroutine .
    M           -   number of rows in matrix A. M&gt;=0.
    N           -   number of columns in matrix A. N&gt;=0.
    Tau         -   scalar factors which are used to form Q.
                    Output of CMatrixQR subroutine .
    QColumns    -   required number of columns in matrix Q. M&gt;=QColumns&gt;=0.

Output parameters:
    Q           -   first QColumns columns of matrix Q.
                    Array whose index ranges within [0..M-1, 0..QColumns-1].
                    If QColumns=0, array isn't changed.

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixqrunpackq(
    complex_2d_array a,
    ae_int_t m,
    ae_int_t n,
    complex_1d_array tau,
    ae_int_t qcolumns,
    complex_2d_array&amp; q);

</div></pre>
<a name='sub_cmatrixqrunpackr'></a><h3 class=pageheader><code>cmatrixqrunpackr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking of matrix R from the QR decomposition of a matrix A

Input parameters:
    A       -   matrices Q and R in compact form.
                Output of CMatrixQR subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.

Output parameters:
    R       -   matrix R, array[0..M-1, 0..N-1].

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixqrunpackr(
    complex_2d_array a,
    ae_int_t m,
    ae_int_t n,
    complex_2d_array&amp; r);

</div></pre>
<a name='sub_hmatrixtd'></a><h3 class=pageheader><code>hmatrixtd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Reduction of a Hermitian matrix which is given  by  its  higher  or  lower
triangular part to a real  tridiagonal  matrix  using  unitary  similarity
transformation: Q'*A*Q = T.

Input parameters:
    A       -   matrix to be transformed
                array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   storage format. If IsUpper = True, then matrix A is  given
                by its upper triangle, and the lower triangle is not  used
                and not modified by the algorithm, and vice versa
                if IsUpper = False.

Output parameters:
    A       -   matrices T and Q in  compact form (see lower)
    Tau     -   array of factors which are forming matrices H(i)
                array with elements [0..N-2].
    D       -   main diagonal of real symmetric matrix T.
                array with elements [0..N-1].
    E       -   secondary diagonal of real symmetric matrix T.
                array with elements [0..N-2].


  If IsUpper=True, the matrix Q is represented as a product of elementary
  reflectors

     Q = H(n-2) . . . H(2) H(0).

  Each H(i) has the form

     H(i) = I - tau * v * v'

  where tau is a complex scalar, and v is a complex vector with
  v(i+1:n-1) = 0, v(i) = 1, v(0:i-1) is stored on exit in
  A(0:i-1,i+1), and tau in TAU(i).

  If IsUpper=False, the matrix Q is represented as a product of elementary
  reflectors

     Q = H(0) H(2) . . . H(n-2).

  Each H(i) has the form

     H(i) = I - tau * v * v'

  where tau is a complex scalar, and v is a complex vector with
  v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) is stored on exit in A(i+2:n-1,i),
  and tau in TAU(i).

  The contents of A on exit are illustrated by the following examples
  with n = 5:

  if UPLO = 'U':                       if UPLO = 'L':

    (  d   e   v1  v2  v3 )              (  d                  )
    (      d   e   v2  v3 )              (  e   d              )
    (          d   e   v3 )              (  v0  e   d          )
    (              d   e  )              (  v0  v1  e   d      )
    (                  d  )              (  v0  v1  v2  e   d  )

where d and e denote diagonal and off-diagonal elements of T, and vi
denotes an element of the vector defining H(i).

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     October 31, 1992
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hmatrixtd(
    complex_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_1d_array&amp; tau,
    real_1d_array&amp; d,
    real_1d_array&amp; e);

</div></pre>
<a name='sub_hmatrixtdunpackq'></a><h3 class=pageheader><code>hmatrixtdunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix Q which reduces a Hermitian matrix to a real  tridiagonal
form.

Input parameters:
    A       -   the result of a HMatrixTD subroutine
    N       -   size of matrix A.
    IsUpper -   storage format (a parameter of HMatrixTD subroutine)
    Tau     -   the result of a HMatrixTD subroutine

Output parameters:
    Q       -   transformation matrix.
                array with elements [0..N-1, 0..N-1].

  -- ALGLIB --
     Copyright 2005-2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hmatrixtdunpackq(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    complex_1d_array tau,
    complex_2d_array&amp; q);

</div></pre>
<a name='sub_rmatrixbd'></a><h3 class=pageheader><code>rmatrixbd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Reduction of a rectangular matrix to  bidiagonal form

The algorithm reduces the rectangular matrix A to  bidiagonal form by
orthogonal transformations P and Q: A = Q*B*P.

Input parameters:
    A       -   source matrix. array[0..M-1, 0..N-1]
    M       -   number of rows in matrix A.
    N       -   number of columns in matrix A.

Output parameters:
    A       -   matrices Q, B, P in compact form (see below).
    TauQ    -   scalar factors which are used to form matrix Q.
    TauP    -   scalar factors which are used to form matrix P.

The main diagonal and one of the  secondary  diagonals  of  matrix  A  are
replaced with bidiagonal  matrix  B.  Other  elements  contain  elementary
reflections which form MxM matrix Q and NxN matrix P, respectively.

If M&gt;=N, B is the upper  bidiagonal  MxN  matrix  and  is  stored  in  the
corresponding  elements  of  matrix  A.  Matrix  Q  is  represented  as  a
product   of   elementary   reflections   Q = H(0)*H(1)*...*H(n-1),  where
H(i) = 1-tau*v*v'. Here tau is a scalar which is stored  in  TauQ[i],  and
vector v has the following  structure:  v(0:i-1)=0, v(i)=1, v(i+1:m-1)  is
stored   in   elements   A(i+1:m-1,i).   Matrix   P  is  as  follows:  P =
G(0)*G(1)*...*G(n-2), where G(i) = 1 - tau*u*u'. Tau is stored in TauP[i],
u(0:i)=0, u(i+1)=1, u(i+2:n-1) is stored in elements A(i,i+2:n-1).

If M&lt;N, B is the  lower  bidiagonal  MxN  matrix  and  is  stored  in  the
corresponding   elements  of  matrix  A.  Q = H(0)*H(1)*...*H(m-2),  where
H(i) = 1 - tau*v*v', tau is stored in TauQ, v(0:i)=0, v(i+1)=1, v(i+2:m-1)
is    stored    in   elements   A(i+2:m-1,i).    P = G(0)*G(1)*...*G(m-1),
G(i) = 1-tau*u*u', tau is stored in  TauP,  u(0:i-1)=0, u(i)=1, u(i+1:n-1)
is stored in A(i,i+1:n-1).

EXAMPLE:

m=6, n=5 (m &gt; n):               m=5, n=6 (m &lt; n):

(  d   e   u1  u1  u1 )         (  d   u1  u1  u1  u1  u1 )
(  v1  d   e   u2  u2 )         (  e   d   u2  u2  u2  u2 )
(  v1  v2  d   e   u3 )         (  v1  e   d   u3  u3  u3 )
(  v1  v2  v3  d   e  )         (  v1  v2  e   d   u4  u4 )
(  v1  v2  v3  v4  d  )         (  v1  v2  v3  e   d   u5 )
(  v1  v2  v3  v4  v5 )

Here vi and ui are vectors which form H(i) and G(i), and d and e -
are the diagonal and off-diagonal elements of matrix B.

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     September 30, 1994.
     Sergey Bochkanov, ALGLIB project, translation from FORTRAN to
     pseudocode, 2007-2010.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbd(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    real_1d_array&amp; tauq,
    real_1d_array&amp; taup);

</div></pre>
<a name='sub_rmatrixbdmultiplybyp'></a><h3 class=pageheader><code>rmatrixbdmultiplybyp</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication by matrix P which reduces matrix A to  bidiagonal form.

The algorithm allows pre- or post-multiply by P or P'.

Input parameters:
    QP          -   matrices Q and P in compact form.
                    Output of RMatrixBD subroutine.
    M           -   number of rows in matrix A.
    N           -   number of columns in matrix A.
    TAUP        -   scalar factors which are used to form P.
                    Output of RMatrixBD subroutine.
    Z           -   multiplied matrix.
                    Array whose indexes range within [0..ZRows-1,0..ZColumns-1].
    ZRows       -   number of rows in matrix Z. If FromTheRight=False,
                    ZRows=N, otherwise ZRows can be arbitrary.
    ZColumns    -   number of columns in matrix Z. If FromTheRight=True,
                    ZColumns=N, otherwise ZColumns can be arbitrary.
    FromTheRight -  pre- or post-multiply.
    DoTranspose -   multiply by P or P'.

Output parameters:
    Z - product of Z and P.
                Array whose indexes range within [0..ZRows-1,0..ZColumns-1].
                If ZRows=0 or ZColumns=0, the array is not modified.

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbdmultiplybyp(
    real_2d_array qp,
    ae_int_t m,
    ae_int_t n,
    real_1d_array taup,
    real_2d_array&amp; z,
    ae_int_t zrows,
    ae_int_t zcolumns,
    <b>bool</b> fromtheright,
    <b>bool</b> dotranspose);

</div></pre>
<a name='sub_rmatrixbdmultiplybyq'></a><h3 class=pageheader><code>rmatrixbdmultiplybyq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Multiplication by matrix Q which reduces matrix A to  bidiagonal form.

The algorithm allows pre- or post-multiply by Q or Q'.

Input parameters:
    QP          -   matrices Q and P in compact form.
                    Output of ToBidiagonal subroutine.
    M           -   number of rows in matrix A.
    N           -   number of columns in matrix A.
    TAUQ        -   scalar factors which are used to form Q.
                    Output of ToBidiagonal subroutine.
    Z           -   multiplied matrix.
                    array[0..ZRows-1,0..ZColumns-1]
    ZRows       -   number of rows in matrix Z. If FromTheRight=False,
                    ZRows=M, otherwise ZRows can be arbitrary.
    ZColumns    -   number of columns in matrix Z. If FromTheRight=True,
                    ZColumns=M, otherwise ZColumns can be arbitrary.
    FromTheRight -  pre- or post-multiply.
    DoTranspose -   multiply by Q or Q'.

Output parameters:
    Z           -   product of Z and Q.
                    Array[0..ZRows-1,0..ZColumns-1]
                    If ZRows=0 or ZColumns=0, the array is not modified.

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbdmultiplybyq(
    real_2d_array qp,
    ae_int_t m,
    ae_int_t n,
    real_1d_array tauq,
    real_2d_array&amp; z,
    ae_int_t zrows,
    ae_int_t zcolumns,
    <b>bool</b> fromtheright,
    <b>bool</b> dotranspose);

</div></pre>
<a name='sub_rmatrixbdunpackdiagonals'></a><h3 class=pageheader><code>rmatrixbdunpackdiagonals</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking of the main and secondary diagonals of bidiagonal decomposition
of matrix A.

Input parameters:
    B   -   output of RMatrixBD subroutine.
    M   -   number of rows in matrix B.
    N   -   number of columns in matrix B.

Output parameters:
    IsUpper -   True, if the matrix is upper bidiagonal.
                otherwise IsUpper is False.
    D       -   the main diagonal.
                Array whose index ranges within [0..Min(M,N)-1].
    E       -   the secondary diagonal (upper or lower, depending on
                the value of IsUpper).
                Array index ranges within [0..Min(M,N)-1], the last
                element is not used.

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbdunpackdiagonals(
    real_2d_array b,
    ae_int_t m,
    ae_int_t n,
    <b>bool</b>&amp; isupper,
    real_1d_array&amp; d,
    real_1d_array&amp; e);

</div></pre>
<a name='sub_rmatrixbdunpackpt'></a><h3 class=pageheader><code>rmatrixbdunpackpt</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix P which reduces matrix A to bidiagonal form.
The subroutine returns transposed matrix P.

Input parameters:
    QP      -   matrices Q and P in compact form.
                Output of ToBidiagonal subroutine.
    M       -   number of rows in matrix A.
    N       -   number of columns in matrix A.
    TAUP    -   scalar factors which are used to form P.
                Output of ToBidiagonal subroutine.
    PTRows  -   required number of rows of matrix P^T. N &gt;= PTRows &gt;= 0.

Output parameters:
    PT      -   first PTRows columns of matrix P^T
                Array[0..PTRows-1, 0..N-1]
                If PTRows=0, the array is not modified.

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbdunpackpt(
    real_2d_array qp,
    ae_int_t m,
    ae_int_t n,
    real_1d_array taup,
    ae_int_t ptrows,
    real_2d_array&amp; pt);

</div></pre>
<a name='sub_rmatrixbdunpackq'></a><h3 class=pageheader><code>rmatrixbdunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix Q which reduces a matrix to bidiagonal form.

Input parameters:
    QP          -   matrices Q and P in compact form.
                    Output of ToBidiagonal subroutine.
    M           -   number of rows in matrix A.
    N           -   number of columns in matrix A.
    TAUQ        -   scalar factors which are used to form Q.
                    Output of ToBidiagonal subroutine.
    QColumns    -   required number of columns in matrix Q.
                    M&gt;=QColumns&gt;=0.

Output parameters:
    Q           -   first QColumns columns of matrix Q.
                    Array[0..M-1, 0..QColumns-1]
                    If QColumns=0, the array is not modified.

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixbdunpackq(
    real_2d_array qp,
    ae_int_t m,
    ae_int_t n,
    real_1d_array tauq,
    ae_int_t qcolumns,
    real_2d_array&amp; q);

</div></pre>
<a name='sub_rmatrixhessenberg'></a><h3 class=pageheader><code>rmatrixhessenberg</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Reduction of a square matrix to  upper Hessenberg form: Q'*A*Q = H,
where Q is an orthogonal matrix, H - Hessenberg matrix.

Input parameters:
    A       -   matrix A with elements [0..N-1, 0..N-1]
    N       -   size of matrix A.

Output parameters:
    A       -   matrices Q and P in  compact form (see below).
    Tau     -   array of scalar factors which are used to form matrix Q.
                Array whose index ranges within [0..N-2]

Matrix H is located on the main diagonal, on the lower secondary  diagonal
and above the main diagonal of matrix A. The elements which are used to
form matrix Q are situated in array Tau and below the lower secondary
diagonal of matrix A as follows:

Matrix Q is represented as a product of elementary reflections

Q = H(0)*H(2)*...*H(n-2),

where each H(i) is given by

H(i) = 1 - tau * v * (v^T)

where tau is a scalar stored in Tau[I]; v - is a real vector,
so that v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) stored in A(i+2:n-1,i).

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     October 31, 1992
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixhessenberg(
    real_2d_array&amp; a,
    ae_int_t n,
    real_1d_array&amp; tau);

</div></pre>
<a name='sub_rmatrixhessenbergunpackh'></a><h3 class=pageheader><code>rmatrixhessenbergunpackh</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix H (the result of matrix A reduction to upper Hessenberg form)

Input parameters:
    A   -   output of RMatrixHessenberg subroutine.
    N   -   size of matrix A.

Output parameters:
    H   -   matrix H. Array whose indexes range within [0..N-1, 0..N-1].

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixhessenbergunpackh(
    real_2d_array a,
    ae_int_t n,
    real_2d_array&amp; h);

</div></pre>
<a name='sub_rmatrixhessenbergunpackq'></a><h3 class=pageheader><code>rmatrixhessenbergunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix Q which reduces matrix A to upper Hessenberg form

Input parameters:
    A   -   output of RMatrixHessenberg subroutine.
    N   -   size of matrix A.
    Tau -   scalar factors which are used to form Q.
            Output of RMatrixHessenberg subroutine.

Output parameters:
    Q   -   matrix Q.
            Array whose indexes range within [0..N-1, 0..N-1].

  -- ALGLIB --
     2005-2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixhessenbergunpackq(
    real_2d_array a,
    ae_int_t n,
    real_1d_array tau,
    real_2d_array&amp; q);

</div></pre>
<a name='sub_rmatrixlq'></a><h3 class=pageheader><code>rmatrixlq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LQ decomposition of a rectangular matrix of size MxN

Input parameters:
    A   -   matrix A whose indexes range within [0..M-1, 0..N-1].
    M   -   number of rows in matrix A.
    N   -   number of columns in matrix A.

Output parameters:
    A   -   matrices L and Q in compact form (see below)
    Tau -   array of scalar factors which are used to form
            matrix Q. Array whose index ranges within [0..Min(M,N)-1].

Matrix A is represented as A = LQ, where Q is an orthogonal matrix of size
MxM, L - lower triangular (or lower trapezoid) matrix of size M x N.

The elements of matrix L are located on and below  the  main  diagonal  of
matrix A. The elements which are located in Tau array and above  the  main
diagonal of matrix A are used to form matrix Q as follows:

Matrix Q is represented as a product of elementary reflections

Q = H(k-1)*H(k-2)*...*H(1)*H(0),

where k = min(m,n), and each H(i) is of the form

H(i) = 1 - tau * v * (v^T)

where tau is a scalar stored in Tau[I]; v - real vector, so that v(0:i-1)=0,
v(i) = 1, v(i+1:n-1) stored in A(i,i+1:n-1).

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlq(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    real_1d_array&amp; tau);

</div></pre>
<a name='sub_rmatrixlqunpackl'></a><h3 class=pageheader><code>rmatrixlqunpackl</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking of matrix L from the LQ decomposition of a matrix A

Input parameters:
    A       -   matrices Q and L in compact form.
                Output of RMatrixLQ subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.

Output parameters:
    L       -   matrix L, array[0..M-1, 0..N-1].

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlqunpackl(
    real_2d_array a,
    ae_int_t m,
    ae_int_t n,
    real_2d_array&amp; l);

</div></pre>
<a name='sub_rmatrixlqunpackq'></a><h3 class=pageheader><code>rmatrixlqunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Partial unpacking of matrix Q from the LQ decomposition of a matrix A

Input parameters:
    A       -   matrices L and Q in compact form.
                Output of RMatrixLQ subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.
    Tau     -   scalar factors which are used to form Q.
                Output of the RMatrixLQ subroutine.
    QRows   -   required number of rows in matrix Q. N&gt;=QRows&gt;=0.

Output parameters:
    Q       -   first QRows rows of matrix Q. Array whose indexes range
                within [0..QRows-1, 0..N-1]. If QRows=0, the array remains
                unchanged.

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlqunpackq(
    real_2d_array a,
    ae_int_t m,
    ae_int_t n,
    real_1d_array tau,
    ae_int_t qrows,
    real_2d_array&amp; q);

</div></pre>
<a name='sub_rmatrixqr'></a><h3 class=pageheader><code>rmatrixqr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
QR decomposition of a rectangular matrix of size MxN

Input parameters:
    A   -   matrix A whose indexes range within [0..M-1, 0..N-1].
    M   -   number of rows in matrix A.
    N   -   number of columns in matrix A.

Output parameters:
    A   -   matrices Q and R in compact form (see below).
    Tau -   array of scalar factors which are used to form
            matrix Q. Array whose index ranges within [0.. Min(M-1,N-1)].

Matrix A is represented as A = QR, where Q is an orthogonal matrix of size
MxM, R - upper triangular (or upper trapezoid) matrix of size M x N.

The elements of matrix R are located on and above the main diagonal of
matrix A. The elements which are located in Tau array and below the main
diagonal of matrix A are used to form matrix Q as follows:

Matrix Q is represented as a product of elementary reflections

Q = H(0)*H(2)*...*H(k-1),

where k = min(m,n), and each H(i) is in the form

H(i) = 1 - tau * v * (v^T)

where tau is a scalar stored in Tau[I]; v - real vector,
so that v(0:i-1) = 0, v(i) = 1, v(i+1:m-1) stored in A(i+1:m-1,i).

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixqr(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    real_1d_array&amp; tau);

</div></pre>
<a name='sub_rmatrixqrunpackq'></a><h3 class=pageheader><code>rmatrixqrunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Partial unpacking of matrix Q from the QR decomposition of a matrix A

Input parameters:
    A       -   matrices Q and R in compact form.
                Output of RMatrixQR subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.
    Tau     -   scalar factors which are used to form Q.
                Output of the RMatrixQR subroutine.
    QColumns -  required number of columns of matrix Q. M&gt;=QColumns&gt;=0.

Output parameters:
    Q       -   first QColumns columns of matrix Q.
                Array whose indexes range within [0..M-1, 0..QColumns-1].
                If QColumns=0, the array remains unchanged.

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixqrunpackq(
    real_2d_array a,
    ae_int_t m,
    ae_int_t n,
    real_1d_array tau,
    ae_int_t qcolumns,
    real_2d_array&amp; q);

</div></pre>
<a name='sub_rmatrixqrunpackr'></a><h3 class=pageheader><code>rmatrixqrunpackr</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking of matrix R from the QR decomposition of a matrix A

Input parameters:
    A       -   matrices Q and R in compact form.
                Output of RMatrixQR subroutine.
    M       -   number of rows in given matrix A. M&gt;=0.
    N       -   number of columns in given matrix A. N&gt;=0.

Output parameters:
    R       -   matrix R, array[0..M-1, 0..N-1].

  -- ALGLIB routine --
     17.02.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixqrunpackr(
    real_2d_array a,
    ae_int_t m,
    ae_int_t n,
    real_2d_array&amp; r);

</div></pre>
<a name='sub_smatrixtd'></a><h3 class=pageheader><code>smatrixtd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Reduction of a symmetric matrix which is given by its higher or lower
triangular part to a tridiagonal matrix using orthogonal similarity
transformation: Q'*A*Q=T.

Input parameters:
    A       -   matrix to be transformed
                array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   storage format. If IsUpper = True, then matrix A is given
                by its upper triangle, and the lower triangle is not used
                and not modified by the algorithm, and vice versa
                if IsUpper = False.

Output parameters:
    A       -   matrices T and Q in  compact form (see lower)
    Tau     -   array of factors which are forming matrices H(i)
                array with elements [0..N-2].
    D       -   main diagonal of symmetric matrix T.
                array with elements [0..N-1].
    E       -   secondary diagonal of symmetric matrix T.
                array with elements [0..N-2].


  If IsUpper=True, the matrix Q is represented as a product of elementary
  reflectors

     Q = H(n-2) . . . H(2) H(0).

  Each H(i) has the form

     H(i) = I - tau * v * v'

  where tau is a real scalar, and v is a real vector with
  v(i+1:n-1) = 0, v(i) = 1, v(0:i-1) is stored on exit in
  A(0:i-1,i+1), and tau in TAU(i).

  If IsUpper=False, the matrix Q is represented as a product of elementary
  reflectors

     Q = H(0) H(2) . . . H(n-2).

  Each H(i) has the form

     H(i) = I - tau * v * v'

  where tau is a real scalar, and v is a real vector with
  v(0:i) = 0, v(i+1) = 1, v(i+2:n-1) is stored on exit in A(i+2:n-1,i),
  and tau in TAU(i).

  The contents of A on exit are illustrated by the following examples
  with n = 5:

  if UPLO = 'U':                       if UPLO = 'L':

    (  d   e   v1  v2  v3 )              (  d                  )
    (      d   e   v2  v3 )              (  e   d              )
    (          d   e   v3 )              (  v0  e   d          )
    (              d   e  )              (  v0  v1  e   d      )
    (                  d  )              (  v0  v1  v2  e   d  )

  where d and e denote diagonal and off-diagonal elements of T, and vi
  denotes an element of the vector defining H(i).

  -- LAPACK routine (version 3.0) --
     Univ. of Tennessee, Univ. of California Berkeley, NAG Ltd.,
     Courant Institute, Argonne National Lab, and Rice University
     October 31, 1992
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::smatrixtd(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper,
    real_1d_array&amp; tau,
    real_1d_array&amp; d,
    real_1d_array&amp; e);

</div></pre>
<a name='sub_smatrixtdunpackq'></a><h3 class=pageheader><code>smatrixtdunpackq</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Unpacking matrix Q which reduces symmetric matrix to a tridiagonal
form.

Input parameters:
    A       -   the result of a SMatrixTD subroutine
    N       -   size of matrix A.
    IsUpper -   storage format (a parameter of SMatrixTD subroutine)
    Tau     -   the result of a SMatrixTD subroutine

Output parameters:
    Q       -   transformation matrix.
                array with elements [0..N-1, 0..N-1].

  -- ALGLIB --
     Copyright 2005-2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::smatrixtdunpackq(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    real_1d_array tau,
    real_2d_array&amp; q);

</div></pre>
<a name=unit_pca></a><h2 class=pageheader><code>pca</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_pcabuildbasis' class=toc>pcabuildbasis</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_pcabuildbasis'></a><h3 class=pageheader><code>pcabuildbasis</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Principal components analysis

Subroutine  builds  orthogonal  basis  where  first  axis  corresponds  to
direction with maximum variance, second axis maximizes variance in subspace
orthogonal to first axis and so on.

It should be noted that, unlike LDA, PCA does not use class labels.

INPUT PARAMETERS:
    X           -   dataset, array[0..NPoints-1,0..NVars-1].
                    matrix contains ONLY INDEPENDENT VARIABLES.
    NPoints     -   dataset size, NPoints&gt;=0
    NVars       -   number of independent variables, NVars&gt;=1

 :
    Info        -   return code:
                    * -4, if SVD subroutine haven't converged
                    * -1, if wrong parameters has been passed (NPoints&lt;0,
                          NVars&lt;1)
                    *  1, if task is solved
    S2          -   array[0..NVars-1]. variance values corresponding
                    to basis vectors.
    V           -   array[0..NVars-1,0..NVars-1]
                    matrix, whose columns store basis vectors.

  -- ALGLIB --
     Copyright 25.08.2008 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pcabuildbasis(
    real_2d_array x,
    ae_int_t npoints,
    ae_int_t nvars,
    ae_int_t&amp; info,
    real_1d_array&amp; s2,
    real_2d_array&amp; v);

</div></pre>
<a name=unit_poissondistr></a><h2 class=pageheader><code>poissondistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_invpoissondistribution' class=toc>invpoissondistribution</a><br>
<a href='#sub_poissoncdistribution' class=toc>poissoncdistribution</a><br>
<a href='#sub_poissondistribution' class=toc>poissondistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_invpoissondistribution'></a><h3 class=pageheader><code>invpoissondistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Inverse Poisson distribution

Finds the Poisson variable x such that the integral
from 0 to x of the Poisson density is equal to the
given probability y.

This is accomplished using the inverse gamma integral
function and the relation

   m = igami( k+1, y ).

ACCURACY:

See inverse incomplete gamma function

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invpoissondistribution(ae_int_t k, <b>double</b> y);

</div></pre>
<a name='sub_poissoncdistribution'></a><h3 class=pageheader><code>poissoncdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Complemented Poisson distribution

Returns the sum of the terms k+1 to infinity of the Poisson
distribution:

 inf.       j
  --   -m  m
  &gt;   e    --
  --       j!
 j=k+1

The terms are not summed directly; instead the incomplete
gamma integral is employed, according to the formula

y = pdtrc( k, m ) = igam( k+1, m ).

The arguments must both be positive.

ACCURACY:

See incomplete gamma function

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::poissoncdistribution(ae_int_t k, <b>double</b> m);

</div></pre>
<a name='sub_poissondistribution'></a><h3 class=pageheader><code>poissondistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Poisson distribution

Returns the sum of the first k+1 terms of the Poisson
distribution:

  k         j
  --   -m  m
  &gt;   e    --
  --       j!
 j=0

The terms are not summed directly; instead the incomplete
gamma integral is employed, according to the relation

y = pdtr( k, m ) = igamc( k+1, m ).

The arguments must both be positive.
ACCURACY:

See incomplete gamma function

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::poissondistribution(ae_int_t k, <b>double</b> m);

</div></pre>
<a name=unit_polint></a><h2 class=pageheader><code>polint</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_polynomialbar2cheb' class=toc>polynomialbar2cheb</a><br>
<a href='#sub_polynomialbar2pow' class=toc>polynomialbar2pow</a><br>
<a href='#sub_polynomialbuild' class=toc>polynomialbuild</a><br>
<a href='#sub_polynomialbuildcheb1' class=toc>polynomialbuildcheb1</a><br>
<a href='#sub_polynomialbuildcheb2' class=toc>polynomialbuildcheb2</a><br>
<a href='#sub_polynomialbuildeqdist' class=toc>polynomialbuildeqdist</a><br>
<a href='#sub_polynomialcalccheb1' class=toc>polynomialcalccheb1</a><br>
<a href='#sub_polynomialcalccheb2' class=toc>polynomialcalccheb2</a><br>
<a href='#sub_polynomialcalceqdist' class=toc>polynomialcalceqdist</a><br>
<a href='#sub_polynomialcheb2bar' class=toc>polynomialcheb2bar</a><br>
<a href='#sub_polynomialpow2bar' class=toc>polynomialpow2bar</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_polint_d_calcdiff' class=toc>polint_d_calcdiff</a></td><td width=15>&nbsp;</td><td>Interpolation and differentiation using barycentric representation</td></tr>
<tr align=left valign=top><td><a href='#example_polint_d_conv' class=toc>polint_d_conv</a></td><td width=15>&nbsp;</td><td>Conversion between power basis and barycentric representation</td></tr>
<tr align=left valign=top><td><a href='#example_polint_d_spec' class=toc>polint_d_spec</a></td><td width=15>&nbsp;</td><td>Polynomial interpolation on special grids (equidistant, Chebyshev I/II)</td></tr>
</table></div>
<a name='sub_polynomialbar2cheb'></a><h3 class=pageheader><code>polynomialbar2cheb</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conversion from barycentric representation to Chebyshev basis.
This function has O(N^2) complexity.

INPUT PARAMETERS:
    P   -   polynomial in barycentric form
    A,B -   base interval for Chebyshev polynomials (see below)
            A&lt;&gt;B

OUTPUT PARAMETERS
    T   -   coefficients of Chebyshev representation;
            P(x) = sum { T[i]*Ti(2*(x-A)/(B-A)-1), i=0..N-1 },
            where Ti - I-th Chebyshev polynomial.

NOTES:
    barycentric interpolant passed as P may be either polynomial  obtained
    from  polynomial  interpolation/ fitting or rational function which is
    NOT polynomial. We can't distinguish between these two cases, and this
    algorithm just tries to work assuming that P IS a polynomial.  If not,
    algorithm will return results, but they won't have any meaning.

  -- ALGLIB --
     Copyright 30.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbar2cheb(
    barycentricinterpolant p,
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array&amp; t);

</div></pre>
<a name='sub_polynomialbar2pow'></a><h3 class=pageheader><code>polynomialbar2pow</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conversion from barycentric representation to power basis.
This function has O(N^2) complexity.

INPUT PARAMETERS:
    P   -   polynomial in barycentric form
    C   -   offset (see below); 0.0 is used as default value.
    S   -   scale (see below);  1.0 is used as default value. S&lt;&gt;0.

OUTPUT PARAMETERS
    A   -   coefficients, P(x) = sum { A[i]*((X-C)/S)^i, i=0..N-1 }
    N   -   number of coefficients (polynomial degree plus 1)

NOTES:
1.  this function accepts offset and scale, which can be  set  to  improve
    numerical properties of polynomial. For example, if P was obtained  as
    result of interpolation on [-1,+1],  you  can  set  C=0  and  S=1  and
    represent  P  as sum of 1, x, x^2, x^3 and so on. In most cases you it
    is exactly what you need.

    However, if your interpolation model was built on [999,1001], you will
    see significant growth of numerical errors when using {1, x, x^2, x^3}
    as basis. Representing P as sum of 1, (x-1000), (x-1000)^2, (x-1000)^3
    will be better option. Such representation can be  obtained  by  using
    1000.0 as offset C and 1.0 as scale S.

2.  power basis is ill-conditioned and tricks described above can't  solve
    this problem completely. This function  will  return  coefficients  in
    any  case,  but  for  N&gt;8  they  will  become unreliable. However, N's
    less than 5 are pretty safe.

3.  barycentric interpolant passed as P may be either polynomial  obtained
    from  polynomial  interpolation/ fitting or rational function which is
    NOT polynomial. We can't distinguish between these two cases, and this
    algorithm just tries to work assuming that P IS a polynomial.  If not,
    algorithm will return results, but they won't have any meaning.

  -- ALGLIB --
     Copyright 30.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbar2pow(
    barycentricinterpolant p,
    real_1d_array&amp; a);
<b>void</b> alglib::polynomialbar2pow(
    barycentricinterpolant p,
    <b>double</b> c,
    <b>double</b> s,
    real_1d_array&amp; a);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_conv' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialbuild'></a><h3 class=pageheader><code>polynomialbuild</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Lagrange intepolant: generation of the model on the general grid.
This function has O(N^2) complexity.

INPUT PARAMETERS:
    X   -   abscissas, array[0..N-1]
    Y   -   function values, array[0..N-1]
    N   -   number of points, N&gt;=1

OUTPUT PARAMETERS
    P   -   barycentric model which represents Lagrange interpolant
            (see ratint unit info and BarycentricCalc() description for
            more information).

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbuild(
    real_1d_array x,
    real_1d_array y,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialbuild(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    barycentricinterpolant&amp; p);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_calcdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialbuildcheb1'></a><h3 class=pageheader><code>polynomialbuildcheb1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Lagrange intepolant on Chebyshev grid (first kind).
This function has O(N) complexity.

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    Y   -   function values at the nodes, array[0..N-1],
            Y[I] = Y(0.5*(B+A) + 0.5*(B-A)*Cos(PI*(2*i+1)/(2*n)))
    N   -   number of points, N&gt;=1
            for N=1 a constant model is constructed.

OUTPUT PARAMETERS
    P   -   barycentric model which represents Lagrange interpolant
            (see ratint unit info and BarycentricCalc() description for
            more information).

  -- ALGLIB --
     Copyright 03.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbuildcheb1(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialbuildcheb1(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    ae_int_t n,
    barycentricinterpolant&amp; p);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialbuildcheb2'></a><h3 class=pageheader><code>polynomialbuildcheb2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Lagrange intepolant on Chebyshev grid (second kind).
This function has O(N) complexity.

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    Y   -   function values at the nodes, array[0..N-1],
            Y[I] = Y(0.5*(B+A) + 0.5*(B-A)*Cos(PI*i/(n-1)))
    N   -   number of points, N&gt;=1
            for N=1 a constant model is constructed.

OUTPUT PARAMETERS
    P   -   barycentric model which represents Lagrange interpolant
            (see ratint unit info and BarycentricCalc() description for
            more information).

  -- ALGLIB --
     Copyright 03.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbuildcheb2(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialbuildcheb2(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    ae_int_t n,
    barycentricinterpolant&amp; p);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialbuildeqdist'></a><h3 class=pageheader><code>polynomialbuildeqdist</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Lagrange intepolant: generation of the model on equidistant grid.
This function has O(N) complexity.

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    Y   -   function values at the nodes, array[0..N-1]
    N   -   number of points, N&gt;=1
            for N=1 a constant model is constructed.

OUTPUT PARAMETERS
    P   -   barycentric model which represents Lagrange interpolant
            (see ratint unit info and BarycentricCalc() description for
            more information).

  -- ALGLIB --
     Copyright 03.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialbuildeqdist(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialbuildeqdist(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array y,
    ae_int_t n,
    barycentricinterpolant&amp; p);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialcalccheb1'></a><h3 class=pageheader><code>polynomialcalccheb1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Fast polynomial interpolation function on Chebyshev points (first kind)
with O(N) complexity.

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    F   -   function values, array[0..N-1]
    N   -   number of points on Chebyshev grid (first kind),
            X[i] = 0.5*(B+A) + 0.5*(B-A)*Cos(PI*(2*i+1)/(2*n))
            for N=1 a constant model is constructed.
    T   -   position where P(x) is calculated

RESULT
    value of the Lagrange interpolant at T

IMPORTANT
    this function provides fast interface which is not overflow-safe
    nor it is very precise.
    the best option is to use  PolIntBuildCheb1()/BarycentricCalc()
    subroutines unless you are pretty sure that your data will not result
    in overflow.

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::polynomialcalccheb1(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    <b>double</b> t);
<b>double</b> alglib::polynomialcalccheb1(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    ae_int_t n,
    <b>double</b> t);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialcalccheb2'></a><h3 class=pageheader><code>polynomialcalccheb2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Fast polynomial interpolation function on Chebyshev points (second kind)
with O(N) complexity.

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    F   -   function values, array[0..N-1]
    N   -   number of points on Chebyshev grid (second kind),
            X[i] = 0.5*(B+A) + 0.5*(B-A)*Cos(PI*i/(n-1))
            for N=1 a constant model is constructed.
    T   -   position where P(x) is calculated

RESULT
    value of the Lagrange interpolant at T

IMPORTANT
    this function provides fast interface which is not overflow-safe
    nor it is very precise.
    the best option is to use PolIntBuildCheb2()/BarycentricCalc()
    subroutines unless you are pretty sure that your data will not result
    in overflow.

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::polynomialcalccheb2(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    <b>double</b> t);
<b>double</b> alglib::polynomialcalccheb2(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    ae_int_t n,
    <b>double</b> t);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialcalceqdist'></a><h3 class=pageheader><code>polynomialcalceqdist</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Fast equidistant polynomial interpolation function with O(N) complexity

INPUT PARAMETERS:
    A   -   left boundary of [A,B]
    B   -   right boundary of [A,B]
    F   -   function values, array[0..N-1]
    N   -   number of points on equidistant grid, N&gt;=1
            for N=1 a constant model is constructed.
    T   -   position where P(x) is calculated

RESULT
    value of the Lagrange interpolant at T

IMPORTANT
    this function provides fast interface which is not overflow-safe
    nor it is very precise.
    the best option is to use  PolynomialBuildEqDist()/BarycentricCalc()
    subroutines unless you are pretty sure that your data will not result
    in overflow.

  -- ALGLIB --
     Copyright 02.12.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::polynomialcalceqdist(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    <b>double</b> t);
<b>double</b> alglib::polynomialcalceqdist(
    <b>double</b> a,
    <b>double</b> b,
    real_1d_array f,
    ae_int_t n,
    <b>double</b> t);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_spec' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_polynomialcheb2bar'></a><h3 class=pageheader><code>polynomialcheb2bar</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conversion from Chebyshev basis to barycentric representation.
This function has O(N^2) complexity.

INPUT PARAMETERS:
    T   -   coefficients of Chebyshev representation;
            P(x) = sum { T[i]*Ti(2*(x-A)/(B-A)-1), i=0..N },
            where Ti - I-th Chebyshev polynomial.
    N   -   number of coefficients:
            * if given, only leading N elements of T are used
            * if not given, automatically determined from size of T
    A,B -   base interval for Chebyshev polynomials (see above)
            A&lt;B

OUTPUT PARAMETERS
    P   -   polynomial in barycentric form

  -- ALGLIB --
     Copyright 30.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialcheb2bar(
    real_1d_array t,
    <b>double</b> a,
    <b>double</b> b,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialcheb2bar(
    real_1d_array t,
    ae_int_t n,
    <b>double</b> a,
    <b>double</b> b,
    barycentricinterpolant&amp; p);

</div></pre>
<a name='sub_polynomialpow2bar'></a><h3 class=pageheader><code>polynomialpow2bar</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Conversion from power basis to barycentric representation.
This function has O(N^2) complexity.

INPUT PARAMETERS:
    A   -   coefficients, P(x) = sum { A[i]*((X-C)/S)^i, i=0..N-1 }
    N   -   number of coefficients (polynomial degree plus 1)
            * if given, only leading N elements of A are used
            * if not given, automatically determined from size of A
    C   -   offset (see below); 0.0 is used as default value.
    S   -   scale (see below);  1.0 is used as default value. S&lt;&gt;0.

OUTPUT PARAMETERS
    P   -   polynomial in barycentric form


NOTES:
1.  this function accepts offset and scale, which can be  set  to  improve
    numerical properties of polynomial. For example, if you interpolate on
    [-1,+1],  you  can  set C=0 and S=1 and convert from sum of 1, x, x^2,
    x^3 and so on. In most cases you it is exactly what you need.

    However, if your interpolation model was built on [999,1001], you will
    see significant growth of numerical errors when using {1, x, x^2, x^3}
    as  input  basis.  Converting  from  sum  of  1, (x-1000), (x-1000)^2,
    (x-1000)^3 will be better option (you have to specify 1000.0 as offset
    C and 1.0 as scale S).

2.  power basis is ill-conditioned and tricks described above can't  solve
    this problem completely. This function  will  return barycentric model
    in any case, but for N&gt;8 accuracy well degrade. However, N's less than
    5 are pretty safe.

  -- ALGLIB --
     Copyright 30.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::polynomialpow2bar(
    real_1d_array a,
    barycentricinterpolant&amp; p);
<b>void</b> alglib::polynomialpow2bar(
    real_1d_array a,
    ae_int_t n,
    <b>double</b> c,
    <b>double</b> s,
    barycentricinterpolant&amp; p);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_polint_d_conv' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_polint_d_calcdiff'></a><h3 class=pageheader>polint_d_calcdiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate polynomial interpolation and differentiation</font>
    <font color=navy>// of y=x^2-x sampled at [0,1,2]. Barycentric representation of polynomial is used.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,1,2]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,0,2]&quot;</b></font>;
    <b>double</b> t = -1;
    <b>double</b> v;
    <b>double</b> dv;
    <b>double</b> d2v;
    barycentricinterpolant p;

    <font color=navy>// barycentric model is created</font>
    polynomialbuild(x, y, p);

    <font color=navy>// barycentric interpolation is demonstrated</font>
    v = barycentriccalc(p, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0</font>

    <font color=navy>// barycentric differentation is demonstrated</font>
    barycentricdiff1(p, t, v, dv);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(dv)); <font color=navy>// EXPECTED: -3.0</font>

    <font color=navy>// second derivatives with barycentric representation</font>
    barycentricdiff1(p, t, v, dv);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(dv)); <font color=navy>// EXPECTED: -3.0</font>
    barycentricdiff2(p, t, v, dv, d2v);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(dv)); <font color=navy>// EXPECTED: -3.0</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(d2v)); <font color=navy>// EXPECTED: 2.0</font>
    <b>return</b> 0;
}


</pre><a name='example_polint_d_conv'></a><h3 class=pageheader>polint_d_conv example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Here we demonstrate conversion of y=x^2-x</font>
    <font color=navy>// between power basis and barycentric representation.</font>
    <font color=navy>//</font>
    real_1d_array a = <font color=blue><b>&quot;[0,-1,+1]&quot;</b></font>;
    <b>double</b> t = 2;
    real_1d_array a2;
    <b>double</b> v;
    barycentricinterpolant p;

    <font color=navy>//</font>
    <font color=navy>// a=[0,-1,+1] is decomposition of y=x^2-x in the power basis:</font>
    <font color=navy>//</font>
    <font color=navy>//     y = 0 - 1*x + 1*x^2</font>
    <font color=navy>//</font>
    <font color=navy>// We convert it to the barycentric form.</font>
    <font color=navy>//</font>
    polynomialpow2bar(a, p);

    <font color=navy>// now we have barycentric interpolation; we can use it <b>for</b> interpolation</font>
    v = barycentriccalc(p, t);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0</font>

    <font color=navy>// we can also convert back from barycentric representation to power basis</font>
    polynomialbar2pow(p, a2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a2.tostring(2).c_str()); <font color=navy>// EXPECTED: [0,-1,+1]</font>
    <b>return</b> 0;
}


</pre><a name='example_polint_d_spec'></a><h3 class=pageheader>polint_d_spec example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Temporaries:</font>
    <font color=navy>// * values of y=x^2-x sampled at three special grids:</font>
    <font color=navy>//   * equdistant grid spanning [0,2],     x[i] = 2*i/(N-1), i=0..N-1</font>
    <font color=navy>//   * Chebyshev-I grid spanning [-1,+1],  x[i] = 1 + Cos(PI*(2*i+1)/(2*n)), i=0..N-1</font>
    <font color=navy>//   * Chebyshev-II grid spanning [-1,+1], x[i] = 1 + Cos(PI*i/(n-1)), i=0..N-1</font>
    <font color=navy>// * barycentric interpolants <b>for</b> these three grids</font>
    <font color=navy>// * vectors to store coefficients of quadratic representation</font>
    <font color=navy>//</font>
    real_1d_array y_eqdist = <font color=blue><b>&quot;[0,0,2]&quot;</b></font>;
    real_1d_array y_cheb1 = <font color=blue><b>&quot;[-0.116025,0.000000,1.616025]&quot;</b></font>;
    real_1d_array y_cheb2 = <font color=blue><b>&quot;[0,0,2]&quot;</b></font>;
    barycentricinterpolant p_eqdist;
    barycentricinterpolant p_cheb1;
    barycentricinterpolant p_cheb2;
    real_1d_array a_eqdist;
    real_1d_array a_cheb1;
    real_1d_array a_cheb2;

    <font color=navy>//</font>
    <font color=navy>// First, we demonstrate construction of barycentric interpolants on</font>
    <font color=navy>// special grids. We unpack power representation to ensure that</font>
    <font color=navy>// interpolant was built correctly.</font>
    <font color=navy>//</font>
    <font color=navy>// In all three cases we should get same quadratic function.</font>
    <font color=navy>//</font>
    polynomialbuildeqdist(0.0, 2.0, y_eqdist, p_eqdist);
    polynomialbar2pow(p_eqdist, a_eqdist);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a_eqdist.tostring(4).c_str()); <font color=navy>// EXPECTED: [0,-1,+1]</font>

    polynomialbuildcheb1(-1, +1, y_cheb1, p_cheb1);
    polynomialbar2pow(p_cheb1, a_cheb1);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a_cheb1.tostring(4).c_str()); <font color=navy>// EXPECTED: [0,-1,+1]</font>

    polynomialbuildcheb2(-1, +1, y_cheb2, p_cheb2);
    polynomialbar2pow(p_cheb2, a_cheb2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, a_cheb2.tostring(4).c_str()); <font color=navy>// EXPECTED: [0,-1,+1]</font>

    <font color=navy>//</font>
    <font color=navy>// Now we demonstrate polynomial interpolation without construction </font>
    <font color=navy>// of the barycentricinterpolant structure.</font>
    <font color=navy>//</font>
    <font color=navy>// We calculate interpolant value at x=-2.</font>
    <font color=navy>// In all three cases we should get same f=6</font>
    <font color=navy>//</font>
    <b>double</b> t = -2;
    <b>double</b> v;
    v = polynomialcalceqdist(0.0, 2.0, y_eqdist, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 6.0</font>

    v = polynomialcalccheb1(-1, +1, y_cheb1, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 6.0</font>

    v = polynomialcalccheb2(-1, +1, y_cheb2, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 6.0</font>
    <b>return</b> 0;
}


</pre><a name=unit_psif></a><h2 class=pageheader><code>psif</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_psi' class=toc>psi</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_psi'></a><h3 class=pageheader><code>psi</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Psi (digamma) function

             d      -
  psi(x)  =  -- ln | (x)
             dx

is the logarithmic derivative of the gamma function.
For integer x,
                  n-1
                   -
psi(n) = -EUL  +   &gt;  1/k.
                   -
                  k=1

This formula is used for 0 &lt; n &lt;= 10.  If x is negative, it
is transformed to a positive argument by the reflection
formula  psi(1-x) = psi(x) + pi cot(pi x).
For general positive x, the argument is made greater than 10
using the recurrence  psi(x+1) = psi(x) + 1/x.
Then the following asymptotic expansion is applied:

                          inf.   B
                           -      2k
psi(x) = log(x) - 1/2x -   &gt;   -------
                           -        2k
                          k=1   2k x

where the B2k are Bernoulli numbers.

ACCURACY:
   Relative error (except absolute when |psi| &lt; 1):
arithmetic   domain     # trials      peak         rms
   IEEE      0,30        30000       1.3e-15     1.4e-16
   IEEE      -30,0       40000       1.5e-15     2.2e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1992, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::psi(<b>double</b> x);

</div></pre>
<a name=unit_pspline></a><h2 class=pageheader><code>pspline</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_pspline2interpolant' class=toc>pspline2interpolant</a><br>
<a href='#struct_pspline3interpolant' class=toc>pspline3interpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_pspline2arclength' class=toc>pspline2arclength</a><br>
<a href='#sub_pspline2build' class=toc>pspline2build</a><br>
<a href='#sub_pspline2buildperiodic' class=toc>pspline2buildperiodic</a><br>
<a href='#sub_pspline2calc' class=toc>pspline2calc</a><br>
<a href='#sub_pspline2diff' class=toc>pspline2diff</a><br>
<a href='#sub_pspline2diff2' class=toc>pspline2diff2</a><br>
<a href='#sub_pspline2parametervalues' class=toc>pspline2parametervalues</a><br>
<a href='#sub_pspline2tangent' class=toc>pspline2tangent</a><br>
<a href='#sub_pspline3arclength' class=toc>pspline3arclength</a><br>
<a href='#sub_pspline3build' class=toc>pspline3build</a><br>
<a href='#sub_pspline3buildperiodic' class=toc>pspline3buildperiodic</a><br>
<a href='#sub_pspline3calc' class=toc>pspline3calc</a><br>
<a href='#sub_pspline3diff' class=toc>pspline3diff</a><br>
<a href='#sub_pspline3diff2' class=toc>pspline3diff2</a><br>
<a href='#sub_pspline3parametervalues' class=toc>pspline3parametervalues</a><br>
<a href='#sub_pspline3tangent' class=toc>pspline3tangent</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_pspline2interpolant'></a><h3 class=pageheader><code>pspline2interpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Parametric spline inteprolant: 2-dimensional curve.

You should not try to access its members directly - use PSpline2XXXXXXXX()
functions instead.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> pspline2interpolant
{
};

</div></pre>
<a name='struct_pspline3interpolant'></a><h3 class=pageheader><code>pspline3interpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Parametric spline inteprolant: 3-dimensional curve.

You should not try to access its members directly - use PSpline3XXXXXXXX()
functions instead.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> pspline3interpolant
{
};

</div></pre>
<a name='sub_pspline2arclength'></a><h3 class=pageheader><code>pspline2arclength</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  arc length, i.e. length of  curve  between  t=a
and t=b.

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    A,B -   parameter values corresponding to arc ends:
            * B&gt;A will result in positive length returned
            * B&lt;A will result in negative length returned

RESULT:
    length of arc starting at T=A and ending at T=B.


  -- ALGLIB PROJECT --
     Copyright 30.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::pspline2arclength(
    pspline2interpolant p,
    <b>double</b> a,
    <b>double</b> b);

</div></pre>
<a name='sub_pspline2build'></a><h3 class=pageheader><code>pspline2build</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  builds  non-periodic 2-dimensional parametric spline  which
starts at (X[0],Y[0]) and ends at (X[N-1],Y[N-1]).

INPUT PARAMETERS:
    XY  -   points, array[0..N-1,0..1].
            XY[I,0:1] corresponds to the Ith point.
            Order of points is important!
    N   -   points count, N&gt;=5 for Akima splines, N&gt;=2 for other types  of
            splines.
    ST  -   spline type:
            * 0     Akima spline
            * 1     parabolically terminated Catmull-Rom spline (Tension=0)
            * 2     parabolically terminated cubic spline
    PT  -   parameterization type:
            * 0     uniform
            * 1     chord length
            * 2     centripetal

OUTPUT PARAMETERS:
    P   -   parametric spline interpolant


NOTES:
* this function  assumes  that  there all consequent points  are distinct.
  I.e. (x0,y0)&lt;&gt;(x1,y1),  (x1,y1)&lt;&gt;(x2,y2),  (x2,y2)&lt;&gt;(x3,y3)  and  so on.
  However, non-consequent points may coincide, i.e. we can  have  (x0,y0)=
  =(x2,y2).

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2build(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t st,
    ae_int_t pt,
    pspline2interpolant&amp; p);

</div></pre>
<a name='sub_pspline2buildperiodic'></a><h3 class=pageheader><code>pspline2buildperiodic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  builds  periodic  2-dimensional  parametric  spline  which
starts at (X[0],Y[0]), goes through all points to (X[N-1],Y[N-1]) and then
back to (X[0],Y[0]).

INPUT PARAMETERS:
    XY  -   points, array[0..N-1,0..1].
            XY[I,0:1] corresponds to the Ith point.
            XY[N-1,0:1] must be different from XY[0,0:1].
            Order of points is important!
    N   -   points count, N&gt;=3 for other types of splines.
    ST  -   spline type:
            * 1     Catmull-Rom spline (Tension=0) with cyclic boundary conditions
            * 2     cubic spline with cyclic boundary conditions
    PT  -   parameterization type:
            * 0     uniform
            * 1     chord length
            * 2     centripetal

OUTPUT PARAMETERS:
    P   -   parametric spline interpolant


NOTES:
* this function  assumes  that there all consequent points  are  distinct.
  I.e. (x0,y0)&lt;&gt;(x1,y1), (x1,y1)&lt;&gt;(x2,y2),  (x2,y2)&lt;&gt;(x3,y3)  and  so  on.
  However, non-consequent points may coincide, i.e. we can  have  (x0,y0)=
  =(x2,y2).
* last point of sequence is NOT equal to the first  point.  You  shouldn't
  make curve &quot;explicitly periodic&quot; by making them equal.

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2buildperiodic(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t st,
    ae_int_t pt,
    pspline2interpolant&amp; p);

</div></pre>
<a name='sub_pspline2calc'></a><h3 class=pageheader><code>pspline2calc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  the value of the parametric spline for a  given
value of parameter T

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-position
    Y   -   Y-position


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2calc(
    pspline2interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; y);

</div></pre>
<a name='sub_pspline2diff'></a><h3 class=pageheader><code>pspline2diff</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates derivative, i.e. it returns (dX/dT,dY/dT).

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-value
    DX  -   X-derivative
    Y   -   Y-value
    DY  -   Y-derivative


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2diff(
    pspline2interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; dx,
    <b>double</b>&amp; y,
    <b>double</b>&amp; dy);

</div></pre>
<a name='sub_pspline2diff2'></a><h3 class=pageheader><code>pspline2diff2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates first and second derivative with respect to T.

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-value
    DX  -   derivative
    D2X -   second derivative
    Y   -   Y-value
    DY  -   derivative
    D2Y -   second derivative


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2diff2(
    pspline2interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; dx,
    <b>double</b>&amp; d2x,
    <b>double</b>&amp; y,
    <b>double</b>&amp; dy,
    <b>double</b>&amp; d2y);

</div></pre>
<a name='sub_pspline2parametervalues'></a><h3 class=pageheader><code>pspline2parametervalues</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns vector of parameter values correspoding to points.

I.e. for P created from (X[0],Y[0])...(X[N-1],Y[N-1]) and U=TValues(P)  we
have
    (X[0],Y[0]) = PSpline2Calc(P,U[0]),
    (X[1],Y[1]) = PSpline2Calc(P,U[1]),
    (X[2],Y[2]) = PSpline2Calc(P,U[2]),
    ...

INPUT PARAMETERS:
    P   -   parametric spline interpolant

OUTPUT PARAMETERS:
    N   -   array size
    T   -   array[0..N-1]


NOTES:
* for non-periodic splines U[0]=0, U[0]&lt;U[1]&lt;...&lt;U[N-1], U[N-1]=1
* for periodic splines     U[0]=0, U[0]&lt;U[1]&lt;...&lt;U[N-1], U[N-1]&lt;1

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2parametervalues(
    pspline2interpolant p,
    ae_int_t&amp; n,
    real_1d_array&amp; t);

</div></pre>
<a name='sub_pspline2tangent'></a><h3 class=pageheader><code>pspline2tangent</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  tangent vector for a given value of parameter T

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X    -   X-component of tangent vector (normalized)
    Y    -   Y-component of tangent vector (normalized)

NOTE:
    X^2+Y^2 is either 1 (for non-zero tangent vector) or 0.


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline2tangent(
    pspline2interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; y);

</div></pre>
<a name='sub_pspline3arclength'></a><h3 class=pageheader><code>pspline3arclength</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  arc length, i.e. length of  curve  between  t=a
and t=b.

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    A,B -   parameter values corresponding to arc ends:
            * B&gt;A will result in positive length returned
            * B&lt;A will result in negative length returned

RESULT:
    length of arc starting at T=A and ending at T=B.


  -- ALGLIB PROJECT --
     Copyright 30.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::pspline3arclength(
    pspline3interpolant p,
    <b>double</b> a,
    <b>double</b> b);

</div></pre>
<a name='sub_pspline3build'></a><h3 class=pageheader><code>pspline3build</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  builds  non-periodic 3-dimensional parametric spline  which
starts at (X[0],Y[0],Z[0]) and ends at (X[N-1],Y[N-1],Z[N-1]).

Same as PSpline2Build() function, but for 3D, so we  won't  duplicate  its
description here.

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3build(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t st,
    ae_int_t pt,
    pspline3interpolant&amp; p);

</div></pre>
<a name='sub_pspline3buildperiodic'></a><h3 class=pageheader><code>pspline3buildperiodic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  builds  periodic  3-dimensional  parametric  spline  which
starts at (X[0],Y[0],Z[0]), goes through all points to (X[N-1],Y[N-1],Z[N-1])
and then back to (X[0],Y[0],Z[0]).

Same as PSpline2Build() function, but for 3D, so we  won't  duplicate  its
description here.

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3buildperiodic(
    real_2d_array xy,
    ae_int_t n,
    ae_int_t st,
    ae_int_t pt,
    pspline3interpolant&amp; p);

</div></pre>
<a name='sub_pspline3calc'></a><h3 class=pageheader><code>pspline3calc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  the value of the parametric spline for a  given
value of parameter T.

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-position
    Y   -   Y-position
    Z   -   Z-position


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3calc(
    pspline3interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; y,
    <b>double</b>&amp; z);

</div></pre>
<a name='sub_pspline3diff'></a><h3 class=pageheader><code>pspline3diff</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates derivative, i.e. it returns (dX/dT,dY/dT,dZ/dT).

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-value
    DX  -   X-derivative
    Y   -   Y-value
    DY  -   Y-derivative
    Z   -   Z-value
    DZ  -   Z-derivative


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3diff(
    pspline3interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; dx,
    <b>double</b>&amp; y,
    <b>double</b>&amp; dy,
    <b>double</b>&amp; z,
    <b>double</b>&amp; dz);

</div></pre>
<a name='sub_pspline3diff2'></a><h3 class=pageheader><code>pspline3diff2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates first and second derivative with respect to T.

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X   -   X-value
    DX  -   derivative
    D2X -   second derivative
    Y   -   Y-value
    DY  -   derivative
    D2Y -   second derivative
    Z   -   Z-value
    DZ  -   derivative
    D2Z -   second derivative


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3diff2(
    pspline3interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; dx,
    <b>double</b>&amp; d2x,
    <b>double</b>&amp; y,
    <b>double</b>&amp; dy,
    <b>double</b>&amp; d2y,
    <b>double</b>&amp; z,
    <b>double</b>&amp; dz,
    <b>double</b>&amp; d2z);

</div></pre>
<a name='sub_pspline3parametervalues'></a><h3 class=pageheader><code>pspline3parametervalues</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns vector of parameter values correspoding to points.

Same as PSpline2ParameterValues(), but for 3D.

  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3parametervalues(
    pspline3interpolant p,
    ae_int_t&amp; n,
    real_1d_array&amp; t);

</div></pre>
<a name='sub_pspline3tangent'></a><h3 class=pageheader><code>pspline3tangent</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function  calculates  tangent vector for a given value of parameter T

INPUT PARAMETERS:
    P   -   parametric spline interpolant
    T   -   point:
            * T in [0,1] corresponds to interval spanned by points
            * for non-periodic splines T&lt;0 (or T&gt;1) correspond to parts of
              the curve before the first (after the last) point
            * for periodic splines T&lt;0 (or T&gt;1) are projected  into  [0,1]
              by making T=T-floor(T).

OUTPUT PARAMETERS:
    X    -   X-component of tangent vector (normalized)
    Y    -   Y-component of tangent vector (normalized)
    Z    -   Z-component of tangent vector (normalized)

NOTE:
    X^2+Y^2+Z^2 is either 1 (for non-zero tangent vector) or 0.


  -- ALGLIB PROJECT --
     Copyright 28.05.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::pspline3tangent(
    pspline3interpolant p,
    <b>double</b> t,
    <b>double</b>&amp; x,
    <b>double</b>&amp; y,
    <b>double</b>&amp; z);

</div></pre>
<a name=unit_ratint></a><h2 class=pageheader><code>ratint</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_barycentricinterpolant' class=toc>barycentricinterpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_barycentricbuildfloaterhormann' class=toc>barycentricbuildfloaterhormann</a><br>
<a href='#sub_barycentricbuildxyw' class=toc>barycentricbuildxyw</a><br>
<a href='#sub_barycentriccalc' class=toc>barycentriccalc</a><br>
<a href='#sub_barycentricdiff1' class=toc>barycentricdiff1</a><br>
<a href='#sub_barycentricdiff2' class=toc>barycentricdiff2</a><br>
<a href='#sub_barycentriclintransx' class=toc>barycentriclintransx</a><br>
<a href='#sub_barycentriclintransy' class=toc>barycentriclintransy</a><br>
<a href='#sub_barycentricunpack' class=toc>barycentricunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='struct_barycentricinterpolant'></a><h3 class=pageheader><code>barycentricinterpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Barycentric interpolant.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> barycentricinterpolant
{
};

</div></pre>
<a name='sub_barycentricbuildfloaterhormann'></a><h3 class=pageheader><code>barycentricbuildfloaterhormann</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rational interpolant without poles

The subroutine constructs the rational interpolating function without real
poles  (see  'Barycentric rational interpolation with no  poles  and  high
rates of approximation', Michael S. Floater. and  Kai  Hormann,  for  more
information on this subject).

Input parameters:
    X   -   interpolation nodes, array[0..N-1].
    Y   -   function values, array[0..N-1].
    N   -   number of nodes, N&gt;0.
    D   -   order of the interpolation scheme, 0 &lt;= D &lt;= N-1.
            D&lt;0 will cause an error.
            D&gt;=N it will be replaced with D=N-1.
            if you don't know what D to choose, use small value about 3-5.

Output parameters:
    B   -   barycentric interpolant.

Note:
    this algorithm always succeeds and calculates the weights  with  close
    to machine precision.

  -- ALGLIB PROJECT --
     Copyright 17.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricbuildfloaterhormann(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t d,
    barycentricinterpolant&amp; b);

</div></pre>
<a name='sub_barycentricbuildxyw'></a><h3 class=pageheader><code>barycentricbuildxyw</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rational interpolant from X/Y/W arrays

F(t) = SUM(i=0,n-1,w[i]*f[i]/(t-x[i])) / SUM(i=0,n-1,w[i]/(t-x[i]))

INPUT PARAMETERS:
    X   -   interpolation nodes, array[0..N-1]
    F   -   function values, array[0..N-1]
    W   -   barycentric weights, array[0..N-1]
    N   -   nodes count, N&gt;0

OUTPUT PARAMETERS:
    B   -   barycentric interpolant built from (X, Y, W)

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricbuildxyw(
    real_1d_array x,
    real_1d_array y,
    real_1d_array w,
    ae_int_t n,
    barycentricinterpolant&amp; b);

</div></pre>
<a name='sub_barycentriccalc'></a><h3 class=pageheader><code>barycentriccalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Rational interpolation using barycentric formula

F(t) = SUM(i=0,n-1,w[i]*f[i]/(t-x[i])) / SUM(i=0,n-1,w[i]/(t-x[i]))

Input parameters:
    B   -   barycentric interpolant built with one of model building
            subroutines.
    T   -   interpolation point

Result:
    barycentric interpolant F(t)

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::barycentriccalc(barycentricinterpolant b, <b>double</b> t);

</div></pre>
<a name='sub_barycentricdiff1'></a><h3 class=pageheader><code>barycentricdiff1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Differentiation of barycentric interpolant: first derivative.

Algorithm used in this subroutine is very robust and should not fail until
provided with values too close to MaxRealNumber  (usually  MaxRealNumber/N
or greater will overflow).

INPUT PARAMETERS:
    B   -   barycentric interpolant built with one of model building
            subroutines.
    T   -   interpolation point

OUTPUT PARAMETERS:
    F   -   barycentric interpolant at T
    DF  -   first derivative

NOTE


  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricdiff1(
    barycentricinterpolant b,
    <b>double</b> t,
    <b>double</b>&amp; f,
    <b>double</b>&amp; df);

</div></pre>
<a name='sub_barycentricdiff2'></a><h3 class=pageheader><code>barycentricdiff2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Differentiation of barycentric interpolant: first/second derivatives.

INPUT PARAMETERS:
    B   -   barycentric interpolant built with one of model building
            subroutines.
    T   -   interpolation point

OUTPUT PARAMETERS:
    F   -   barycentric interpolant at T
    DF  -   first derivative
    D2F -   second derivative

NOTE: this algorithm may fail due to overflow/underflor if  used  on  data
whose values are close to MaxRealNumber or MinRealNumber.  Use more robust
BarycentricDiff1() subroutine in such cases.


  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricdiff2(
    barycentricinterpolant b,
    <b>double</b> t,
    <b>double</b>&amp; f,
    <b>double</b>&amp; df,
    <b>double</b>&amp; d2f);

</div></pre>
<a name='sub_barycentriclintransx'></a><h3 class=pageheader><code>barycentriclintransx</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the argument.

INPUT PARAMETERS:
    B       -   rational interpolant in barycentric form
    CA, CB  -   transformation coefficients: x = CA*t + CB

OUTPUT PARAMETERS:
    B       -   transformed interpolant with X replaced by T

  -- ALGLIB PROJECT --
     Copyright 19.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentriclintransx(
    barycentricinterpolant b,
    <b>double</b> ca,
    <b>double</b> cb);

</div></pre>
<a name='sub_barycentriclintransy'></a><h3 class=pageheader><code>barycentriclintransy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  subroutine   performs   linear  transformation  of  the  barycentric
interpolant.

INPUT PARAMETERS:
    B       -   rational interpolant in barycentric form
    CA, CB  -   transformation coefficients: B2(x) = CA*B(x) + CB

OUTPUT PARAMETERS:
    B       -   transformed interpolant

  -- ALGLIB PROJECT --
     Copyright 19.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentriclintransy(
    barycentricinterpolant b,
    <b>double</b> ca,
    <b>double</b> cb);

</div></pre>
<a name='sub_barycentricunpack'></a><h3 class=pageheader><code>barycentricunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Extracts X/Y/W arrays from rational interpolant

INPUT PARAMETERS:
    B   -   barycentric interpolant

OUTPUT PARAMETERS:
    N   -   nodes count, N&gt;0
    X   -   interpolation nodes, array[0..N-1]
    F   -   function values, array[0..N-1]
    W   -   barycentric weights, array[0..N-1]

  -- ALGLIB --
     Copyright 17.08.2009 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::barycentricunpack(
    barycentricinterpolant b,
    ae_int_t&amp; n,
    real_1d_array&amp; x,
    real_1d_array&amp; y,
    real_1d_array&amp; w);

</div></pre>
<a name=unit_rbf></a><h2 class=pageheader><code>rbf</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_rbfmodel' class=toc>rbfmodel</a><br>
<a href='#struct_rbfreport' class=toc>rbfreport</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rbfbuildmodel' class=toc>rbfbuildmodel</a><br>
<a href='#sub_rbfcalc' class=toc>rbfcalc</a><br>
<a href='#sub_rbfcalc2' class=toc>rbfcalc2</a><br>
<a href='#sub_rbfcalc3' class=toc>rbfcalc3</a><br>
<a href='#sub_rbfcalcbuf' class=toc>rbfcalcbuf</a><br>
<a href='#sub_rbfcreate' class=toc>rbfcreate</a><br>
<a href='#sub_rbfgridcalc2' class=toc>rbfgridcalc2</a><br>
<a href='#sub_rbfserialize' class=toc>rbfserialize</a><br>
<a href='#sub_rbfsetalgomultilayer' class=toc>rbfsetalgomultilayer</a><br>
<a href='#sub_rbfsetalgoqnn' class=toc>rbfsetalgoqnn</a><br>
<a href='#sub_rbfsetconstterm' class=toc>rbfsetconstterm</a><br>
<a href='#sub_rbfsetlinterm' class=toc>rbfsetlinterm</a><br>
<a href='#sub_rbfsetpoints' class=toc>rbfsetpoints</a><br>
<a href='#sub_rbfsetzeroterm' class=toc>rbfsetzeroterm</a><br>
<a href='#sub_rbfunpack' class=toc>rbfunpack</a><br>
<a href='#sub_rbfunserialize' class=toc>rbfunserialize</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_rbf_d_ml_ls' class=toc>rbf_d_ml_ls</a></td><td width=15>&nbsp;</td><td>Least squares problem solved with RBF-ML algorithm</td></tr>
<tr align=left valign=top><td><a href='#example_rbf_d_ml_simple' class=toc>rbf_d_ml_simple</a></td><td width=15>&nbsp;</td><td>Simple model built with RBF-ML algorithm</td></tr>
<tr align=left valign=top><td><a href='#example_rbf_d_polterm' class=toc>rbf_d_polterm</a></td><td width=15>&nbsp;</td><td>RBF models - working with polynomial term</td></tr>
<tr align=left valign=top><td><a href='#example_rbf_d_qnn' class=toc>rbf_d_qnn</a></td><td width=15>&nbsp;</td><td>Simple model built with RBF-QNN algorithm</td></tr>
<tr align=left valign=top><td><a href='#example_rbf_d_serialize' class=toc>rbf_d_serialize</a></td><td width=15>&nbsp;</td><td>Serialization/unserialization</td></tr>
<tr align=left valign=top><td><a href='#example_rbf_d_vector' class=toc>rbf_d_vector</a></td><td width=15>&nbsp;</td><td>Working with vector functions</td></tr>
</table></div>
<a name='struct_rbfmodel'></a><h3 class=pageheader><code>rbfmodel</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RBF model.

Never try to directly work with fields of this object - always use  ALGLIB
functions to use this object.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> rbfmodel
{
};

</div></pre>
<a name='struct_rbfreport'></a><h3 class=pageheader><code>rbfreport</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
RBF solution report:
* TerminationType   -   termination type, positive values - success,
                        non-positive - failure.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> rbfreport
{
    ae_int_t             arows;
    ae_int_t             acols;
    ae_int_t             annz;
    ae_int_t             iterationscount;
    ae_int_t             nmv;
    ae_int_t             terminationtype;
};

</div></pre>
<a name='sub_rbfbuildmodel'></a><h3 class=pageheader><code>rbfbuildmodel</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This   function  builds  RBF  model  and  returns  report  (contains  some
information which can be used for evaluation of the algorithm properties).

Call to this function modifies RBF model by calculating its centers/radii/
weights  and  saving  them  into  RBFModel  structure.  Initially RBFModel
contain zero coefficients, but after call to this function  we  will  have
coefficients which were calculated in order to fit our dataset.

After you called this function you can call RBFCalc(),  RBFGridCalc()  and
other model calculation functions.

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call
    Rep     -   report:
                * Rep.TerminationType:
                  * -5 - non-distinct basis function centers were detected,
                         interpolation aborted
                  * -4 - nonconvergence of the internal SVD solver
                  *  1 - successful termination
                Fields are used for debugging purposes:
                * Rep.IterationsCount - iterations count of the LSQR solver
                * Rep.NMV - number of matrix-vector products
                * Rep.ARows - rows count for the system matrix
                * Rep.ACols - columns count for the system matrix
                * Rep.ANNZ - number of significantly non-zero elements
                  (elements above some algorithm-determined threshold)

NOTE:  failure  to  build  model will leave current state of the structure
unchanged.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfbuildmodel(rbfmodel s, rbfreport&amp; rep);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_qnn' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_vector' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_simple' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_ls' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfcalc'></a><h3 class=pageheader><code>rbfcalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates values of the RBF model at the given point.

This is general function which can be used for arbitrary NX (dimension  of
the space of arguments) and NY (dimension of the function itself). However
when  you  have  NY=1  you  may  find more convenient to use RBFCalc2() or
RBFCalc3().

This function returns 0.0 when model is not initialized.

INPUT PARAMETERS:
    S       -   RBF model
    X       -   coordinates, array[NX].
                X may have more than NX elements, in this case only
                leading NX will be used.

OUTPUT PARAMETERS:
    Y       -   function value, array[NY]. Y is out-parameter and
                reallocated after call to this function. In case you  want
                to reuse previously allocated Y, you may use RBFCalcBuf(),
                which reallocates Y only when it is too small.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfcalc(rbfmodel s, real_1d_array x, real_1d_array&amp; y);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_vector' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfcalc2'></a><h3 class=pageheader><code>rbfcalc2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates values of the RBF model in the given point.

This function should be used when we have NY=1 (scalar function) and  NX=2
(2-dimensional space). If you have 3-dimensional space, use RBFCalc3(). If
you have general situation (NX-dimensional space, NY-dimensional function)
you should use general, less efficient implementation RBFCalc().

If  you  want  to  calculate  function  values  many times, consider using
RBFGridCalc2(), which is far more efficient than many subsequent calls  to
RBFCalc2().

This function returns 0.0 when:
* model is not initialized
* NX&lt;&gt;2
 *NY&lt;&gt;1

INPUT PARAMETERS:
    S       -   RBF model
    X0      -   first coordinate, finite number
    X1      -   second coordinate, finite number

RESULT:
    value of the model or 0.0 (as defined above)

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rbfcalc2(rbfmodel s, <b>double</b> x0, <b>double</b> x1);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_qnn' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_simple' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_ls' class=nav>[4]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfcalc3'></a><h3 class=pageheader><code>rbfcalc3</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates values of the RBF model in the given point.

This function should be used when we have NY=1 (scalar function) and  NX=3
(3-dimensional space). If you have 2-dimensional space, use RBFCalc2(). If
you have general situation (NX-dimensional space, NY-dimensional function)
you should use general, less efficient implementation RBFCalc().

This function returns 0.0 when:
* model is not initialized
* NX&lt;&gt;3
 *NY&lt;&gt;1

INPUT PARAMETERS:
    S       -   RBF model
    X0      -   first coordinate, finite number
    X1      -   second coordinate, finite number
    X2      -   third coordinate, finite number

RESULT:
    value of the model or 0.0 (as defined above)

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rbfcalc3(rbfmodel s, <b>double</b> x0, <b>double</b> x1, <b>double</b> x2);

</div></pre>
<a name='sub_rbfcalcbuf'></a><h3 class=pageheader><code>rbfcalcbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates values of the RBF model at the given point.

Same as RBFCalc(), but does not reallocate Y when in is large enough to
store function values.

INPUT PARAMETERS:
    S       -   RBF model
    X       -   coordinates, array[NX].
                X may have more than NX elements, in this case only
                leading NX will be used.
    Y       -   possibly preallocated array

OUTPUT PARAMETERS:
    Y       -   function value, array[NY]. Y is not reallocated when it
                is larger than NY.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfcalcbuf(rbfmodel s, real_1d_array x, real_1d_array&amp; y);

</div></pre>
<a name='sub_rbfcreate'></a><h3 class=pageheader><code>rbfcreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function creates RBF  model  for  a  scalar (NY=1)  or  vector (NY&gt;1)
function in a NX-dimensional space (NX=2 or NX=3).

Newly created model is empty. It can be used for interpolation right after
creation, but it just returns zeros. You have to add points to the  model,
tune interpolation settings, and then  call  model  construction  function
RBFBuildModel() which will update model according to your specification.

USAGE:
1. User creates model with RBFCreate()
2. User adds dataset with RBFSetPoints() (points do NOT have to  be  on  a
   regular grid)
3. (OPTIONAL) User chooses polynomial term by calling:
   * RBFLinTerm() to set linear term
   * RBFConstTerm() to set constant term
   * RBFZeroTerm() to set zero term
   By default, linear term is used.
4. User chooses specific RBF algorithm to use: either QNN (RBFSetAlgoQNN)
   or ML (RBFSetAlgoMultiLayer).
5. User calls RBFBuildModel() function which rebuilds model  according  to
   the specification
6. User may call RBFCalc() to calculate model value at the specified point,
   RBFGridCalc() to  calculate   model  values at the points of the regular
   grid. User may extract model coefficients with RBFUnpack() call.

INPUT PARAMETERS:
    NX      -   dimension of the space, NX=2 or NX=3
    NY      -   function dimension, NY&gt;=1

OUTPUT PARAMETERS:
    S       -   RBF model (initially equals to zero)

NOTE 1: memory requirements. RBF models require amount of memory  which is
        proportional  to  the  number  of data points. Memory is allocated
        during model construction, but most of this memory is freed  after
        model coefficients are calculated.

        Some approximate estimates for N centers with default settings are
        given below:
        * about 250*N*(sizeof(double)+2*sizeof(int)) bytes  of  memory  is
          needed during model construction stage.
        * about 15*N*sizeof(double) bytes is needed after model is built.
        For example, for N=100000 we may need 0.6 GB of memory  to  build
        model, but just about 0.012 GB to store it.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfcreate(ae_int_t nx, ae_int_t ny, rbfmodel&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_qnn' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_vector' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_rbf_d_serialize' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_simple' class=nav>[5]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_ls' class=nav>[6]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfgridcalc2'></a><h3 class=pageheader><code>rbfgridcalc2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates values of the RBF model at the regular grid.

Grid have N0*N1 points, with Point[I,J] = (X0[I], X1[J])

This function returns 0.0 when:
* model is not initialized
* NX&lt;&gt;2
 *NY&lt;&gt;1

INPUT PARAMETERS:
    S       -   RBF model
    X0      -   array of grid nodes, first coordinates, array[N0]
    N0      -   grid size (number of nodes) in the first dimension
    X1      -   array of grid nodes, second coordinates, array[N1]
    N1      -   grid size (number of nodes) in the second dimension

OUTPUT PARAMETERS:
    Y       -   function values, array[N0,N1]. Y is out-variable and
                is reallocated by this function.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfgridcalc2(
    rbfmodel s,
    real_1d_array x0,
    ae_int_t n0,
    real_1d_array x1,
    ae_int_t n1,
    real_2d_array&amp; y);

</div></pre>
<a name='sub_rbfserialize'></a><h3 class=pageheader><code>rbfserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function serializes data structure to string.

Important properties of s_out:
* it contains alphanumeric characters, dots, underscores, minus signs
* these symbols are grouped into words, which are separated by spaces
  and Windows-style (CR+LF) newlines
* although  serializer  uses  spaces and CR+LF as separators, you can 
  replace any separator character by arbitrary combination of spaces,
  tabs, Windows or Unix newlines. It allows flexible reformatting  of
  the  string  in  case you want to include it into text or XML file. 
  But you should not insert separators into the middle of the &quot;words&quot;
  nor you should change case of letters.
* s_out can be freely moved between 32-bit and 64-bit systems, little
  and big endian machines, and so on. You can serialize structure  on
  32-bit machine and unserialize it on 64-bit one (or vice versa), or
  serialize  it  on  SPARC  and  unserialize  on  x86.  You  can also 
  serialize  it  in  C++ version of ALGLIB and unserialize in C# one, 
  and vice versa.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> rbfserialize(rbfmodel &amp;obj, std::string &amp;s_out);
</div></pre>
<a name='sub_rbfsetalgomultilayer'></a><h3 class=pageheader><code>rbfsetalgomultilayer</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets  RBF interpolation algorithm. ALGLIB supports several
RBF algorithms with different properties.

This  algorithm is called RBF-ML. It builds  multilayer  RBF  model,  i.e.
model with subsequently decreasing  radii,  which  allows  us  to  combine
smoothness (due to  large radii of  the first layers) with  exactness (due
to small radii of the last layers) and fast convergence.

Internally RBF-ML uses many different  means  of acceleration, from sparse
matrices  to  KD-trees,  which  results in algorithm whose working time is
roughly proportional to N*log(N)*Density*RBase^2*NLayers,  where  N  is  a
number of points, Density is an average density if points per unit of  the
interpolation space, RBase is an initial radius, NLayers is  a  number  of
layers.

RBF-ML is good for following kinds of interpolation problems:
1. &quot;exact&quot; problems (perfect fit) with well separated points
2. least squares problems with arbitrary distribution of points (algorithm
   gives  perfect  fit  where it is possible, and resorts to least squares
   fit in the hard areas).
3. noisy problems where  we  want  to  apply  some  controlled  amount  of
   smoothing.

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call
    RBase   -   RBase parameter, RBase&gt;0
    NLayers -   NLayers parameter, NLayers&gt;0, recommended value  to  start
                with - about 5.
    LambdaV -   regularization value, can be useful when  solving  problem
                in the least squares sense.  Optimal  lambda  is  problem-
                dependent and require trial and error. In our  experience,
                good lambda can be as large as 0.1, and you can use  0.001
                as initial guess.
                Default  value  - 0.01, which is used when LambdaV is  not
                given.  You  can  specify  zero  value,  but  it  is   not
                recommended to do so.

TUNING ALGORITHM

In order to use this algorithm you have to choose three parameters:
* initial radius RBase
* number of layers in the model NLayers
* regularization coefficient LambdaV

Initial radius is easy to choose - you can pick any number  several  times
larger  than  the  average  distance between points. Algorithm won't break
down if you choose radius which is too large (model construction time will
increase, but model will be built correctly).

Choose such number of layers that RLast=RBase/2^(NLayers-1)  (radius  used
by  the  last  layer)  will  be  smaller than the typical distance between
points.  In  case  model  error  is  too large, you can increase number of
layers.  Having  more  layers  will make model construction and evaluation
proportionally slower, but it will allow you to have model which precisely
fits your data. From the other side, if you want to  suppress  noise,  you
can DECREASE number of layers to make your model less flexible.

Regularization coefficient LambdaV controls smoothness of  the  individual
models built for each layer. We recommend you to use default value in case
you don't want to tune this parameter,  because  having  non-zero  LambdaV
accelerates and stabilizes internal iterative algorithm. In case you  want
to suppress noise you can use  LambdaV  as  additional  parameter  (larger
value = more smoothness) to tune.

TYPICAL ERRORS

1. Using  initial  radius  which is too large. Memory requirements  of the
   RBF-ML are roughly proportional to N*Density*RBase^2 (where Density  is
   an average density of points per unit of the interpolation  space).  In
   the extreme case of the very large RBase we will need O(N^2)  units  of
   memory - and many layers in order to decrease radius to some reasonably
   small value.

2. Using too small number of layers - RBF models with large radius are not
   flexible enough to reproduce small variations in the  target  function.
   You  need  many  layers  with  different radii, from large to small, in
   order to have good model.

3. Using  initial  radius  which  is  too  small.  You will get model with
   &quot;holes&quot; in the areas which are too far away from interpolation centers.
   However, algorithm will work correctly (and quickly) in this case.

4. Using too many layers - you will get too large and too slow model. This
   model  will  perfectly  reproduce  your function, but maybe you will be
   able to achieve similar results with less layers (and less memory).

  -- ALGLIB --
     Copyright 02.03.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetalgomultilayer(
    rbfmodel s,
    <b>double</b> rbase,
    ae_int_t nlayers);
<b>void</b> alglib::rbfsetalgomultilayer(
    rbfmodel s,
    <b>double</b> rbase,
    ae_int_t nlayers,
    <b>double</b> lambdav);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_ml_simple' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_ls' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfsetalgoqnn'></a><h3 class=pageheader><code>rbfsetalgoqnn</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets  RBF interpolation algorithm. ALGLIB supports several
RBF algorithms with different properties.

This algorithm is called RBF-QNN and  it  is  good  for  point  sets  with
following properties:
a) all points are distinct
b) all points are well separated.
c) points  distribution  is  approximately  uniform.  There is no &quot;contour
   lines&quot;, clusters of points, or other small-scale structures.

Algorithm description:
1) interpolation centers are allocated to data points
2) interpolation radii are calculated as distances to the  nearest centers
   times Q coefficient (where Q is a value from [0.75,1.50]).
3) after  performing (2) radii are transformed in order to avoid situation
   when single outlier has very large radius and  influences  many  points
   across all dataset. Transformation has following form:
       new_r[i] = min(r[i],Z*median(r[]))
   where r[i] is I-th radius, median()  is a median  radius across  entire
   dataset, Z is user-specified value which controls amount  of  deviation
   from median radius.

When (a) is violated,  we  will  be unable to build RBF model. When (b) or
(c) are violated, model will be built, but interpolation quality  will  be
low. See http://www.alglib.net/interpolation/ for more information on this
subject.

This algorithm is used by default.

Additional Q parameter controls smoothness properties of the RBF basis:
* Q&lt;0.75 will give perfectly conditioned basis,  but  terrible  smoothness
  properties (RBF interpolant will have sharp peaks around function values)
* Q around 1.0 gives good balance between smoothness and condition number
* Q&gt;1.5 will lead to badly conditioned systems and slow convergence of the
  underlying linear solver (although smoothness will be very good)
* Q&gt;2.0 will effectively make optimizer useless because it won't  converge
  within reasonable amount of iterations. It is possible to set such large
  Q, but it is advised not to do so.

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call
    Q       -   Q parameter, Q&gt;0, recommended value - 1.0
    Z       -   Z parameter, Z&gt;0, recommended value - 5.0

NOTE: this   function  has   some   serialization-related  subtleties.  We
      recommend you to study serialization examples from ALGLIB  Reference
      Manual if you want to perform serialization of your models.


  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetalgoqnn(rbfmodel s);
<b>void</b> alglib::rbfsetalgoqnn(rbfmodel s, <b>double</b> q, <b>double</b> z);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_qnn' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_vector' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfsetconstterm'></a><h3 class=pageheader><code>rbfsetconstterm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets constant term (model is a sum of radial basis functions
plus constant).  This  function  won't  have  effect  until  next  call to
RBFBuildModel().

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call

NOTE: this   function  has   some   serialization-related  subtleties.  We
      recommend you to study serialization examples from ALGLIB  Reference
      Manual if you want to perform serialization of your models.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetconstterm(rbfmodel s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfsetlinterm'></a><h3 class=pageheader><code>rbfsetlinterm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function sets linear term (model is a sum of radial  basis  functions
plus linear polynomial). This function won't have effect until  next  call
to RBFBuildModel().

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call

NOTE: this   function  has   some   serialization-related  subtleties.  We
      recommend you to study serialization examples from ALGLIB  Reference
      Manual if you want to perform serialization of your models.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetlinterm(rbfmodel s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfsetpoints'></a><h3 class=pageheader><code>rbfsetpoints</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function adds dataset.

This function overrides results of the previous calls, i.e. multiple calls
of this function will result in only the last set being added.

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call.
    XY      -   points, array[N,NX+NY]. One row corresponds to  one  point
                in the dataset. First NX elements  are  coordinates,  next
                NY elements are function values. Array may  be larger than
                specific,  in  this  case  only leading [N,NX+NY] elements
                will be used.
    N       -   number of points in the dataset

After you've added dataset and (optionally) tuned algorithm  settings  you
should call RBFBuildModel() in order to build a model for you.

NOTE: this   function  has   some   serialization-related  subtleties.  We
      recommend you to study serialization examples from ALGLIB  Reference
      Manual if you want to perform serialization of your models.


  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetpoints(rbfmodel s, real_2d_array xy);
<b>void</b> alglib::rbfsetpoints(rbfmodel s, real_2d_array xy, ae_int_t n);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_qnn' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_rbf_d_vector' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[3]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_simple' class=nav>[4]</a>&nbsp;&nbsp;<a href='#example_rbf_d_ml_ls' class=nav>[5]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfsetzeroterm'></a><h3 class=pageheader><code>rbfsetzeroterm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  sets  zero  term (model is a sum of radial basis functions
without polynomial term). This function won't have effect until next  call
to RBFBuildModel().

INPUT PARAMETERS:
    S       -   RBF model, initialized by RBFCreate() call

NOTE: this   function  has   some   serialization-related  subtleties.  We
      recommend you to study serialization examples from ALGLIB  Reference
      Manual if you want to perform serialization of your models.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfsetzeroterm(rbfmodel s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfunpack'></a><h3 class=pageheader><code>rbfunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function &quot;unpacks&quot; RBF model by extracting its coefficients.

INPUT PARAMETERS:
    S       -   RBF model

OUTPUT PARAMETERS:
    NX      -   dimensionality of argument
    NY      -   dimensionality of the target function
    XWR     -   model information, array[NC,NX+NY+1].
                One row of the array corresponds to one basis function:
                * first NX columns  - coordinates of the center
                * next NY columns   - weights, one per dimension of the
                                      function being modelled
                * last column       - radius, same for all dimensions of
                                      the function being modelled
    NC      -   number of the centers
    V       -   polynomial  term , array[NY,NX+1]. One row per one
                dimension of the function being modelled. First NX
                elements are linear coefficients, V[NX] is equal to the
                constant part.

  -- ALGLIB --
     Copyright 13.12.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rbfunpack(
    rbfmodel s,
    ae_int_t&amp; nx,
    ae_int_t&amp; ny,
    real_2d_array&amp; xwr,
    ae_int_t&amp; nc,
    real_2d_array&amp; v);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_rbf_d_polterm' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_rbfunserialize'></a><h3 class=pageheader><code>rbfunserialize</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function unserializes data structure from string.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> rbfunserialize(std::string &amp;s_in, rbfmodel &amp;obj);
</div></pre>
<a name='example_rbf_d_ml_ls'></a><h3 class=pageheader>rbf_d_ml_ls example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example shows how to solve least squares problems with RBF-ML algorithm.</font>
    <font color=navy>// Below we assume that you already know basic concepts shown in the RBF_D_QNN and</font>
    <font color=navy>// RBF_D_ML_SIMPLE examples.</font>
    <font color=navy>//</font>
    rbfmodel model;
    rbfreport rep;
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// We have 2-dimensional space and very simple fitting problem - all points</font>
    <font color=navy>// except <b>for</b> two are well separated and located at straight line. Two</font>
    <font color=navy>// <font color=blue><b>&quot;exceptional&quot;</b></font> points are very close, with distance between them as small</font>
    <font color=navy>// as 0.01. RBF-QNN algorithm will have many difficulties with such distribution</font>
    <font color=navy>// of points:</font>
    <font color=navy>//     X        Y</font>
    <font color=navy>//     -2       1</font>
    <font color=navy>//     -1       0</font>
    <font color=navy>//     -0.005   1</font>
    <font color=navy>//     +0.005   2</font>
    <font color=navy>//     +1      -1</font>
    <font color=navy>//     +2       1</font>
    <font color=navy>// How will RBF-ML handle such problem?</font>
    <font color=navy>//</font>
    rbfcreate(2, 1, model);
    real_2d_array xy0 = <font color=blue><b>&quot;[[-2,0,1],[-1,0,0],[-0.005,0,1],[+0.005,0,2],[+1,0,-1],[+2,0,1]]&quot;</b></font>;
    rbfsetpoints(model, xy0);

    <font color=navy>// First, we try to use R=5.0 with single layer (NLayers=1) and moderate amount</font>
    <font color=navy>// of regularization. Well, we already expected that results will be bad:</font>
    <font color=navy>//     Model(x=-2,y=0)=0.8407    (instead of 1.0)</font>
    <font color=navy>//     Model(x=0.005,y=0)=0.6584 (instead of 2.0)</font>
    <font color=navy>// We need more layers to show better results.</font>
    rbfsetalgomultilayer(model, 5.0, 1, 1.0e-3);
    rbfbuildmodel(model, rep);
    v = rbfcalc2(model, -2.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.8407981659</font>
    v = rbfcalc2(model, 0.005, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.6584267649</font>

    <font color=navy>// With 4 layers we got better result at x=-2 (point which is well separated</font>
    <font color=navy>// from its neighbors). Model is now many times closer to the original data</font>
    <font color=navy>//     Model(x=-2,y=0)=0.9992    (instead of 1.0)</font>
    <font color=navy>//     Model(x=0.005,y=0)=1.5534 (instead of 2.0)</font>
    <font color=navy>// We may see that at x=0.005 result is a bit closer to 2.0, but does not</font>
    <font color=navy>// reproduce function value precisely because of close neighbor located at</font>
    <font color=navy>// at x=-0.005. Let's add two layers...</font>
    rbfsetalgomultilayer(model, 5.0, 4, 1.0e-3);
    rbfbuildmodel(model, rep);
    v = rbfcalc2(model, -2.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.9992673278</font>
    v = rbfcalc2(model, 0.005, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.5534666012</font>

    <font color=navy>// With 6 layers we got almost perfect fit:</font>
    <font color=navy>//     Model(x=-2,y=0)=1.000    (perfect fit)</font>
    <font color=navy>//     Model(x=0.005,y=0)=1.996 (instead of 2.0)</font>
    <font color=navy>// Of course, we can reduce error at x=0.005 down to zero by adding more</font>
    <font color=navy>// layers. But <b>do</b> we really need it?</font>
    rbfsetalgomultilayer(model, 5.0, 6, 1.0e-3);
    rbfbuildmodel(model, rep);
    v = rbfcalc2(model, -2.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000000000</font>
    v = rbfcalc2(model, 0.005, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.9965775952</font>

    <font color=navy>// Do we really need zero error? We have f(+0.005)=2 and f(-0.005)=1.</font>
    <font color=navy>// Two points are very close, and in real life situations it often means</font>
    <font color=navy>// that difference in function values can be explained by noise in the</font>
    <font color=navy>// data. Thus, true value of the underlying function should be close to</font>
    <font color=navy>// 1.5 (halfway between 1.0 and 2.0).</font>
    <font color=navy>//</font>
    <font color=navy>// How can we get such result with RBF-ML? Well, we can:</font>
    <font color=navy>// a) reduce number of layers (make model less flexible)</font>
    <font color=navy>// b) increase regularization coefficient (another way of reducing flexibility)</font>
    <font color=navy>//</font>
    <font color=navy>// Having NLayers=5 and LambdaV=0.1 gives us good least squares fit to the data:</font>
    <font color=navy>//     Model(x=-2,y=0)=1.000</font>
    <font color=navy>//     Model(x=-0.005,y=0)=1.504</font>
    <font color=navy>//     Model(x=+0.005,y=0)=1.496</font>
    rbfsetalgomultilayer(model, 5.0, 5, 1.0e-1);
    rbfbuildmodel(model, rep);
    v = rbfcalc2(model, -2.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000001620</font>
    v = rbfcalc2(model, -0.005, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.5042954378</font>
    v = rbfcalc2(model, 0.005, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.4957042013</font>
    <b>return</b> 0;
}


</pre><a name='example_rbf_d_ml_simple'></a><h3 class=pageheader>rbf_d_ml_simple example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example shows how to build models with RBF-ML algorithm. Below</font>
    <font color=navy>// we assume that you already know basic concepts shown in the example</font>
    <font color=navy>// on RBF-QNN algorithm.</font>
    <font color=navy>//</font>
    <font color=navy>// RBF-ML is a multilayer RBF algorithm, which fits a sequence of models</font>
    <font color=navy>// with decreasing radii. Each model is fitted with fixed number of</font>
    <font color=navy>// iterations of linear solver. First layers give only inexact approximation</font>
    <font color=navy>// of the target function, because RBF problems with large radii are</font>
    <font color=navy>// ill-conditioned. However, as we add more and more layers with smaller</font>
    <font color=navy>// and smaller radii, we get better conditioned systems - and more precise models.</font>
    <font color=navy>//</font>
    rbfmodel model;
    rbfreport rep;
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// We have 2-dimensional space and very simple interpolation problem - all</font>
    <font color=navy>// points are distinct and located at straight line. We want to solve it</font>
    <font color=navy>// with RBF-ML algorithm. This problem is very simple, and RBF-QNN will</font>
    <font color=navy>// solve it too, but we want to evaluate RBF-ML and to start from the simple</font>
    <font color=navy>// problem.</font>
    <font color=navy>//     X        Y</font>
    <font color=navy>//     -2       1</font>
    <font color=navy>//     -1       0</font>
    <font color=navy>//      0       1</font>
    <font color=navy>//     +1      -1</font>
    <font color=navy>//     +2       1</font>
    <font color=navy>//</font>
    rbfcreate(2, 1, model);
    real_2d_array xy0 = <font color=blue><b>&quot;[[-2,0,1],[-1,0,0],[0,0,1],[+1,0,-1],[+2,0,1]]&quot;</b></font>;
    rbfsetpoints(model, xy0);

    <font color=navy>// First, we try to use R=5.0 with single layer (NLayers=1) and moderate amount</font>
    <font color=navy>// of regularization.... but results are disappointing: Model(x=0,y=0)=-0.02,</font>
    <font color=navy>// and we need 1.0 at (x,y)=(0,0). Why?</font>
    <font color=navy>//</font>
    <font color=navy>// Because first layer gives very smooth and imprecise approximation of the</font>
    <font color=navy>// function. Average distance between points is 1.0, and R=5.0 is too large</font>
    <font color=navy>// to give us flexible model. It can give smoothness, but can't give precision.</font>
    <font color=navy>// So we need more layers with smaller radii.</font>
    rbfsetalgomultilayer(model, 5.0, 1, 1.0e-3);
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    v = rbfcalc2(model, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: -0.021690</font>

    <font color=navy>// Now we know that single layer is not enough. We still want to start with</font>
    <font color=navy>// R=5.0 because it has good smoothness properties, but we will add more layers,</font>
    <font color=navy>// each with R[i+1]=R[i]/2. We think that 4 layers is enough, because last layer</font>
    <font color=navy>// will have R = 5.0/2^3 = 5/8 ~ 0.63, which is smaller than the average distance</font>
    <font color=navy>// between points. And it works!</font>
    rbfsetalgomultilayer(model, 5.0, 4, 1.0e-3);
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    v = rbfcalc2(model, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.000000</font>

    <font color=navy>// BTW, <b>if</b> you look at v, you will see that it is equal to 0.9999999997, not to 1.</font>
    <font color=navy>// This small error can be fixed by adding one more layer.</font>
    <b>return</b> 0;
}


</pre><a name='example_rbf_d_polterm'></a><h3 class=pageheader>rbf_d_polterm example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example show how to work with polynomial term</font>
    <font color=navy>// </font>
    <font color=navy>// Suppose that we have set of 2-dimensional points with associated</font>
    <font color=navy>// scalar function values, and we want to build a RBF model using</font>
    <font color=navy>// our data.</font>
    <font color=navy>//</font>
    <b>double</b> v;
    rbfmodel model;
    real_2d_array xy = <font color=blue><b>&quot;[[-1,0,2],[+1,0,3]]&quot;</b></font>;
    rbfreport rep;

    rbfcreate(2, 1, model);
    rbfsetpoints(model, xy);
    rbfsetalgoqnn(model);

    <font color=navy>//</font>
    <font color=navy>// By default, RBF model uses linear term. It means that model</font>
    <font color=navy>// looks like</font>
    <font color=navy>//     f(x,y) = SUM(RBF[i]) + a*x + b*y + c</font>
    <font color=navy>// where RBF[i] is I-th radial basis function and a*x+by+c is a</font>
    <font color=navy>// linear term. Having linear terms in a model gives us:</font>
    <font color=navy>// (1) improved extrapolation properties</font>
    <font color=navy>// (2) linearity of the model when data can be perfectly fitted</font>
    <font color=navy>//     by the linear function</font>
    <font color=navy>// (3) linear asymptotic behavior</font>
    <font color=navy>//</font>
    <font color=navy>// Our simple dataset can be modelled by the linear function</font>
    <font color=navy>//     f(x,y) = 0.5*x + 2.5</font>
    <font color=navy>// and rbfbuildmodel() with default settings should preserve this</font>
    <font color=navy>// linearity.</font>
    <font color=navy>//</font>
    ae_int_t nx;
    ae_int_t ny;
    ae_int_t nc;
    real_2d_array xwr;
    real_2d_array c;
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    rbfunpack(model, nx, ny, xwr, nc, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(2).c_str()); <font color=navy>// EXPECTED: [[0.500,0.000,2.500]]</font>

    <font color=navy>// asymptotic behavior of our function is linear</font>
    v = rbfcalc2(model, 1000.0, 0.0);
    printf(<font color=blue><b>&quot;%.1f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 502.50</font>

    <font color=navy>//</font>
    <font color=navy>// Instead of linear term we can use constant term. In this case</font>
    <font color=navy>// we will get model which has form</font>
    <font color=navy>//     f(x,y) = SUM(RBF[i]) + c</font>
    <font color=navy>// where RBF[i] is I-th radial basis function and c is a constant,</font>
    <font color=navy>// which is equal to the average function value on the dataset.</font>
    <font color=navy>//</font>
    <font color=navy>// Because we've already attached dataset to the model the only</font>
    <font color=navy>// thing we have to <b>do</b> is to call rbfsetconstterm() and then</font>
    <font color=navy>// rebuild model with rbfbuildmodel().</font>
    <font color=navy>//</font>
    rbfsetconstterm(model);
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    rbfunpack(model, nx, ny, xwr, nc, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(2).c_str()); <font color=navy>// EXPECTED: [[0.000,0.000,2.500]]</font>

    <font color=navy>// asymptotic behavior of our function is constant</font>
    v = rbfcalc2(model, 1000.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>

    <font color=navy>//</font>
    <font color=navy>// Finally, we can use zero term. Just plain RBF without polynomial</font>
    <font color=navy>// part:</font>
    <font color=navy>//     f(x,y) = SUM(RBF[i])</font>
    <font color=navy>// where RBF[i] is I-th radial basis function.</font>
    <font color=navy>//</font>
    rbfsetzeroterm(model);
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>
    rbfunpack(model, nx, ny, xwr, nc, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(2).c_str()); <font color=navy>// EXPECTED: [[0.000,0.000,0.000]]</font>

    <font color=navy>// asymptotic behavior of our function is just zero constant</font>
    v = rbfcalc2(model, 1000.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.000</font>
    <b>return</b> 0;
}


</pre><a name='example_rbf_d_qnn'></a><h3 class=pageheader>rbf_d_qnn example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example illustrates basic concepts of the RBF models: creation, modification,</font>
    <font color=navy>// evaluation.</font>
    <font color=navy>// </font>
    <font color=navy>// Suppose that we have set of 2-dimensional points with associated</font>
    <font color=navy>// scalar function values, and we want to build a RBF model using</font>
    <font color=navy>// our data.</font>
    <font color=navy>// </font>
    <font color=navy>// NOTE: we can work with 3D models too :)</font>
    <font color=navy>// </font>
    <font color=navy>// Typical sequence of steps is given below:</font>
    <font color=navy>// 1. we create RBF model object</font>
    <font color=navy>// 2. we attach our dataset to the RBF model and tune algorithm settings</font>
    <font color=navy>// 3. we rebuild RBF model using QNN algorithm on new data</font>
    <font color=navy>// 4. we use RBF model (evaluate, serialize, etc.)</font>
    <font color=navy>//</font>
    <b>double</b> v;

    <font color=navy>//</font>
    <font color=navy>// Step 1: RBF model creation.</font>
    <font color=navy>//</font>
    <font color=navy>// We have to specify dimensionality of the space (2 or 3) and</font>
    <font color=navy>// dimensionality of the function (scalar or vector).</font>
    <font color=navy>//</font>
    rbfmodel model;
    rbfcreate(2, 1, model);

    <font color=navy>// New model is empty - it can be evaluated,</font>
    <font color=navy>// but we just get zero value at any point.</font>
    v = rbfcalc2(model, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.000</font>

    <font color=navy>//</font>
    <font color=navy>// Step 2: we add dataset.</font>
    <font color=navy>//</font>
    <font color=navy>// XY arrays containt two points - x0=(-1,0) and x1=(+1,0) -</font>
    <font color=navy>// and two function values f(x0)=2, f(x1)=3.</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[-1,0,2],[+1,0,3]]&quot;</b></font>;
    rbfsetpoints(model, xy);

    <font color=navy>// We added points, but model was not rebuild yet.</font>
    <font color=navy>// If we call rbfcalc2(), we still will get 0.0 as result.</font>
    v = rbfcalc2(model, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.000</font>

    <font color=navy>//</font>
    <font color=navy>// Step 3: rebuild model</font>
    <font color=navy>//</font>
    <font color=navy>// After we've configured model, we should rebuild it -</font>
    <font color=navy>// it will change coefficients stored internally in the</font>
    <font color=navy>// rbfmodel structure.</font>
    <font color=navy>//</font>
    <font color=navy>// By default, RBF uses QNN algorithm, which works well with</font>
    <font color=navy>// relatively uniform datasets (all points are well separated,</font>
    <font color=navy>// average distance is approximately same <b>for</b> all points).</font>
    <font color=navy>// This default algorithm is perfectly suited <b>for</b> our simple</font>
    <font color=navy>// made up data.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: we recommend you to take a look at example of RBF-ML,</font>
    <font color=navy>// multilayer RBF algorithm, which sometimes is a better</font>
    <font color=navy>// option than QNN.</font>
    <font color=navy>//</font>
    rbfreport rep;
    rbfsetalgoqnn(model);
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>

    <font color=navy>//</font>
    <font color=navy>// Step 4: model was built</font>
    <font color=navy>//</font>
    <font color=navy>// After call of rbfbuildmodel(), rbfcalc2() will <b>return</b></font>
    <font color=navy>// value of the new model.</font>
    <font color=navy>//</font>
    v = rbfcalc2(model, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>
    <b>return</b> 0;
}


</pre><a name='example_rbf_d_serialize'></a><h3 class=pageheader>rbf_d_serialize example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example show how to serialize and unserialize RBF model</font>
    <font color=navy>// </font>
    <font color=navy>// Suppose that we have set of 2-dimensional points with associated</font>
    <font color=navy>// scalar function values, and we want to build a RBF model using</font>
    <font color=navy>// our data. Then we want to serialize it to string and to unserialize</font>
    <font color=navy>// from string, loading to another instance of RBF model.</font>
    <font color=navy>//</font>
    <font color=navy>// Here we assume that you already know how to create RBF models.</font>
    <font color=navy>//</font>
    std::string s;
    <b>double</b> v;
    rbfmodel model0;
    rbfmodel model1;
    real_2d_array xy = <font color=blue><b>&quot;[[-1,0,2],[+1,0,3]]&quot;</b></font>;
    rbfreport rep;

    <font color=navy>// model initialization</font>
    rbfcreate(2, 1, model0);
    rbfsetpoints(model0, xy);
    rbfsetalgoqnn(model0);
    rbfbuildmodel(model0, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>

    <font color=navy>//</font>
    <font color=navy>// Serialization - it looks easy,</font>
    <font color=navy>// but you should carefully read next section.</font>
    <font color=navy>//</font>
    alglib::rbfserialize(model0, s);
    alglib::rbfunserialize(s, model1);

    <font color=navy>// both models <b>return</b> same value</font>
    v = rbfcalc2(model0, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>
    v = rbfcalc2(model1, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>

    <font color=navy>//</font>
    <font color=navy>// Previous section shows that model state is saved/restored during</font>
    <font color=navy>// serialization. However, some properties are NOT serialized.</font>
    <font color=navy>//</font>
    <font color=navy>// Serialization saves/restores RBF model, but it does NOT saves/restores</font>
    <font color=navy>// settings which were used to build current model. In particular, dataset</font>
    <font color=navy>// which were used to build model, is not preserved.</font>
    <font color=navy>//</font>
    <font color=navy>// What does it mean in <b>for</b> us?</font>
    <font color=navy>//</font>
    <font color=navy>// Do you remember this sequence: rbfcreate-rbfsetpoints-rbfbuildmodel?</font>
    <font color=navy>// First step creates model, second step adds dataset and tunes model</font>
    <font color=navy>// settings, third step builds model using current dataset and model</font>
    <font color=navy>// construction settings.</font>
    <font color=navy>//</font>
    <font color=navy>// If you call rbfbuildmodel() without calling rbfsetpoints() first, you</font>
    <font color=navy>// will get empty (zero) RBF model. In our example, model0 contains</font>
    <font color=navy>// dataset which was added by rbfsetpoints() call. However, model1 does</font>
    <font color=navy>// NOT contain dataset - because dataset is NOT serialized.</font>
    <font color=navy>//</font>
    <font color=navy>// This, <b>if</b> we call rbfbuildmodel(model0,rep), we will get same model,</font>
    <font color=navy>// which returns 2.5 at (x,y)=(0,0). However, after same call model1 will</font>
    <font color=navy>// <b>return</b> zero - because it contains RBF model (coefficients), but does NOT</font>
    <font color=navy>// contain dataset which was used to build this model.</font>
    <font color=navy>//</font>
    <font color=navy>// Basically, it means that:</font>
    <font color=navy>// * serialization of the RBF model preserves anything related to the model</font>
    <font color=navy>//   EVALUATION</font>
    <font color=navy>// * but it does NOT creates perfect copy of the original object.</font>
    <font color=navy>//</font>
    rbfbuildmodel(model0, rep);
    v = rbfcalc2(model0, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>

    rbfbuildmodel(model1, rep);
    v = rbfcalc2(model1, 0.0, 0.0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.000</font>
    <b>return</b> 0;
}


</pre><a name='example_rbf_d_vector'></a><h3 class=pageheader>rbf_d_vector example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Suppose that we have set of 2-dimensional points with associated VECTOR</font>
    <font color=navy>// function values, and we want to build a RBF model using our data.</font>
    <font color=navy>// </font>
    <font color=navy>// Typical sequence of steps is given below:</font>
    <font color=navy>// 1. we create RBF model object</font>
    <font color=navy>// 2. we attach our dataset to the RBF model and tune algorithm settings</font>
    <font color=navy>// 3. we rebuild RBF model using new data</font>
    <font color=navy>// 4. we use RBF model (evaluate, serialize, etc.)</font>
    <font color=navy>//</font>
    real_1d_array x;
    real_1d_array y;

    <font color=navy>//</font>
    <font color=navy>// Step 1: RBF model creation.</font>
    <font color=navy>//</font>
    <font color=navy>// We have to specify dimensionality of the space (equal to 2) and</font>
    <font color=navy>// dimensionality of the function (2-dimensional vector function).</font>
    <font color=navy>//</font>
    rbfmodel model;
    rbfcreate(2, 2, model);

    <font color=navy>// New model is empty - it can be evaluated,</font>
    <font color=navy>// but we just get zero value at any point.</font>
    x = <font color=blue><b>&quot;[+1,+1]&quot;</b></font>;
    rbfcalc(model, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(2).c_str()); <font color=navy>// EXPECTED: [0.000,0.000]</font>

    <font color=navy>//</font>
    <font color=navy>// Step 2: we add dataset.</font>
    <font color=navy>//</font>
    <font color=navy>// XY arrays containt four points:</font>
    <font color=navy>// * (x0,y0) = (+1,+1), f(x0,y0)=(0,-1)</font>
    <font color=navy>// * (x1,y1) = (+1,-1), f(x1,y1)=(-1,0)</font>
    <font color=navy>// * (x2,y2) = (-1,-1), f(x2,y2)=(0,+1)</font>
    <font color=navy>// * (x3,y3) = (-1,+1), f(x3,y3)=(+1,0)</font>
    <font color=navy>//</font>
    <font color=navy>// By default, RBF uses QNN algorithm, which works well with</font>
    <font color=navy>// relatively uniform datasets (all points are well separated,</font>
    <font color=navy>// average distance is approximately same <b>for</b> all points).</font>
    <font color=navy>//</font>
    <font color=navy>// This default algorithm is perfectly suited <b>for</b> our simple</font>
    <font color=navy>// made up data.</font>
    <font color=navy>//</font>
    real_2d_array xy = <font color=blue><b>&quot;[[+1,+1,0,-1],[+1,-1,-1,0],[-1,-1,0,+1],[-1,+1,+1,0]]&quot;</b></font>;
    rbfsetpoints(model, xy);

    <font color=navy>// We added points, but model was not rebuild yet.</font>
    <font color=navy>// If we call rbfcalc(), we still will get 0.0 as result.</font>
    rbfcalc(model, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(2).c_str()); <font color=navy>// EXPECTED: [0.000,0.000]</font>

    <font color=navy>//</font>
    <font color=navy>// Step 3: rebuild model</font>
    <font color=navy>//</font>
    <font color=navy>// After we've configured model, we should rebuild it -</font>
    <font color=navy>// it will change coefficients stored internally in the</font>
    <font color=navy>// rbfmodel structure.</font>
    <font color=navy>//</font>
    rbfreport rep;
    rbfbuildmodel(model, rep);
    printf(<font color=blue><b>&quot;%d\n&quot;</b></font>, <b>int</b>(rep.terminationtype)); <font color=navy>// EXPECTED: 1</font>

    <font color=navy>//</font>
    <font color=navy>// Step 4: model was built</font>
    <font color=navy>//</font>
    <font color=navy>// After call of rbfbuildmodel(), rbfcalc() will <b>return</b></font>
    <font color=navy>// value of the new model.</font>
    <font color=navy>//</font>
    rbfcalc(model, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(2).c_str()); <font color=navy>// EXPECTED: [0.000,-1.000]</font>
    <b>return</b> 0;
}


</pre><a name=unit_rcond></a><h2 class=pageheader><code>rcond</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlurcond1' class=toc>cmatrixlurcond1</a><br>
<a href='#sub_cmatrixlurcondinf' class=toc>cmatrixlurcondinf</a><br>
<a href='#sub_cmatrixrcond1' class=toc>cmatrixrcond1</a><br>
<a href='#sub_cmatrixrcondinf' class=toc>cmatrixrcondinf</a><br>
<a href='#sub_cmatrixtrrcond1' class=toc>cmatrixtrrcond1</a><br>
<a href='#sub_cmatrixtrrcondinf' class=toc>cmatrixtrrcondinf</a><br>
<a href='#sub_hpdmatrixcholeskyrcond' class=toc>hpdmatrixcholeskyrcond</a><br>
<a href='#sub_hpdmatrixrcond' class=toc>hpdmatrixrcond</a><br>
<a href='#sub_rmatrixlurcond1' class=toc>rmatrixlurcond1</a><br>
<a href='#sub_rmatrixlurcondinf' class=toc>rmatrixlurcondinf</a><br>
<a href='#sub_rmatrixrcond1' class=toc>rmatrixrcond1</a><br>
<a href='#sub_rmatrixrcondinf' class=toc>rmatrixrcondinf</a><br>
<a href='#sub_rmatrixtrrcond1' class=toc>rmatrixtrrcond1</a><br>
<a href='#sub_rmatrixtrrcondinf' class=toc>rmatrixtrrcondinf</a><br>
<a href='#sub_spdmatrixcholeskyrcond' class=toc>spdmatrixcholeskyrcond</a><br>
<a href='#sub_spdmatrixrcond' class=toc>spdmatrixrcond</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlurcond1'></a><h3 class=pageheader><code>cmatrixlurcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of the condition number of a matrix given by its LU decomposition (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    LUA         -   LU decomposition of a matrix in compact form. Output of
                    the CMatrixLU subroutine.
    N           -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixlurcond1(complex_2d_array lua, ae_int_t n);

</div></pre>
<a name='sub_cmatrixlurcondinf'></a><h3 class=pageheader><code>cmatrixlurcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of the condition number of a matrix given by its LU decomposition
(infinity norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    LUA     -   LU decomposition of a matrix in compact form. Output of
                the CMatrixLU subroutine.
    N       -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixlurcondinf(complex_2d_array lua, ae_int_t n);

</div></pre>
<a name='sub_cmatrixrcond1'></a><h3 class=pageheader><code>cmatrixrcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of a matrix condition number (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixrcond1(complex_2d_array a, ae_int_t n);

</div></pre>
<a name='sub_cmatrixrcondinf'></a><h3 class=pageheader><code>cmatrixrcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of a matrix condition number (infinity-norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixrcondinf(complex_2d_array a, ae_int_t n);

</div></pre>
<a name='sub_cmatrixtrrcond1'></a><h3 class=pageheader><code>cmatrixtrrcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix: estimate of a condition number (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A       -   matrix. Array[0..N-1, 0..N-1].
    N       -   size of A.
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   True, if the matrix has a unit diagonal.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixtrrcond1(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit);

</div></pre>
<a name='sub_cmatrixtrrcondinf'></a><h3 class=pageheader><code>cmatrixtrrcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix: estimate of a matrix condition number (infinity-norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   True, if the matrix has a unit diagonal.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::cmatrixtrrcondinf(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit);

</div></pre>
<a name='sub_hpdmatrixcholeskyrcond'></a><h3 class=pageheader><code>hpdmatrixcholeskyrcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Condition number estimate of a Hermitian positive definite matrix given by
Cholesky decomposition.

The algorithm calculates a lower bound of the condition number. In this
case, the algorithm does not return a lower bound of the condition number,
but an inverse number (to avoid an overflow in case of a singular matrix).

It should be noted that 1-norm and inf-norm condition numbers of symmetric
matrices are equal, so the algorithm doesn't take into account the
differences between these types of norms.

Input parameters:
    CD  - Cholesky decomposition of matrix A,
          output of SMatrixCholesky subroutine.
    N   - size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hpdmatrixcholeskyrcond(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_hpdmatrixrcond'></a><h3 class=pageheader><code>hpdmatrixrcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Condition number estimate of a Hermitian positive definite matrix.

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

It should be noted that 1-norm and inf-norm of condition numbers of symmetric
matrices are equal, so the algorithm doesn't take into account the
differences between these types of norms.

Input parameters:
    A       -   Hermitian positive definite matrix which is given by its
                upper or lower triangle depending on the value of
                IsUpper. Array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   storage format.

Result:
    1/LowerBound(cond(A)), if matrix A is positive definite,
   -1, if matrix A is not positive definite, and its condition number
    could not be found by this algorithm.

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::hpdmatrixrcond(
    complex_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_rmatrixlurcond1'></a><h3 class=pageheader><code>rmatrixlurcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of the condition number of a matrix given by its LU decomposition (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    LUA         -   LU decomposition of a matrix in compact form. Output of
                    the RMatrixLU subroutine.
    N           -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixlurcond1(real_2d_array lua, ae_int_t n);

</div></pre>
<a name='sub_rmatrixlurcondinf'></a><h3 class=pageheader><code>rmatrixlurcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of the condition number of a matrix given by its LU decomposition
(infinity norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    LUA     -   LU decomposition of a matrix in compact form. Output of
                the RMatrixLU subroutine.
    N       -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixlurcondinf(real_2d_array lua, ae_int_t n);

</div></pre>
<a name='sub_rmatrixrcond1'></a><h3 class=pageheader><code>rmatrixrcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of a matrix condition number (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixrcond1(real_2d_array a, ae_int_t n);

</div></pre>
<a name='sub_rmatrixrcondinf'></a><h3 class=pageheader><code>rmatrixrcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Estimate of a matrix condition number (infinity-norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixrcondinf(real_2d_array a, ae_int_t n);

</div></pre>
<a name='sub_rmatrixtrrcond1'></a><h3 class=pageheader><code>rmatrixtrrcond1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix: estimate of a condition number (1-norm)

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A       -   matrix. Array[0..N-1, 0..N-1].
    N       -   size of A.
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   True, if the matrix has a unit diagonal.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixtrrcond1(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit);

</div></pre>
<a name='sub_rmatrixtrrcondinf'></a><h3 class=pageheader><code>rmatrixtrrcondinf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Triangular matrix: estimate of a matrix condition number (infinity-norm).

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

Input parameters:
    A   -   matrix. Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of matrix A.
    IsUpper -   True, if the matrix is upper triangular.
    IsUnit  -   True, if the matrix has a unit diagonal.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::rmatrixtrrcondinf(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper,
    <b>bool</b> isunit);

</div></pre>
<a name='sub_spdmatrixcholeskyrcond'></a><h3 class=pageheader><code>spdmatrixcholeskyrcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Condition number estimate of a symmetric positive definite matrix given by
Cholesky decomposition.

The algorithm calculates a lower bound of the condition number. In this
case, the algorithm does not return a lower bound of the condition number,
but an inverse number (to avoid an overflow in case of a singular matrix).

It should be noted that 1-norm and inf-norm condition numbers of symmetric
matrices are equal, so the algorithm doesn't take into account the
differences between these types of norms.

Input parameters:
    CD  - Cholesky decomposition of matrix A,
          output of SMatrixCholesky subroutine.
    N   - size of matrix A.

Result: 1/LowerBound(cond(A))

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spdmatrixcholeskyrcond(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_spdmatrixrcond'></a><h3 class=pageheader><code>spdmatrixrcond</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Condition number estimate of a symmetric positive definite matrix.

The algorithm calculates a lower bound of the condition number. In this case,
the algorithm does not return a lower bound of the condition number, but an
inverse number (to avoid an overflow in case of a singular matrix).

It should be noted that 1-norm and inf-norm of condition numbers of symmetric
matrices are equal, so the algorithm doesn't take into account the
differences between these types of norms.

Input parameters:
    A       -   symmetric positive definite matrix which is given by its
                upper or lower triangle depending on the value of
                IsUpper. Array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   storage format.

Result:
    1/LowerBound(cond(A)), if matrix A is positive definite,
   -1, if matrix A is not positive definite, and its condition number
    could not be found by this algorithm.

NOTE:
    if k(A) is very large, then matrix is  assumed  degenerate,  k(A)=INF,
    0.0 is returned in such cases.
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spdmatrixrcond(real_2d_array a, ae_int_t n, <b>bool</b> isupper);

</div></pre>
<a name=unit_schur></a><h2 class=pageheader><code>schur</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixschur' class=toc>rmatrixschur</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixschur'></a><h3 class=pageheader><code>rmatrixschur</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Subroutine performing the Schur decomposition of a general matrix by using
the QR algorithm with multiple shifts.

The source matrix A is represented as S'*A*S = T, where S is an orthogonal
matrix (Schur vectors), T - upper quasi-triangular matrix (with blocks of
sizes 1x1 and 2x2 on the main diagonal).

Input parameters:
    A   -   matrix to be decomposed.
            Array whose indexes range within [0..N-1, 0..N-1].
    N   -   size of A, N&gt;=0.


Output parameters:
    A   -   contains matrix T.
            Array whose indexes range within [0..N-1, 0..N-1].
    S   -   contains Schur vectors.
            Array whose indexes range within [0..N-1, 0..N-1].

Note 1:
    The block structure of matrix T can be easily recognized: since all
    the elements below the blocks are zeros, the elements a[i+1,i] which
    are equal to 0 show the block border.

Note 2:
    The algorithm performance depends on the value of the internal parameter
    NS of the InternalSchurDecomposition subroutine which defines the number
    of shifts in the QR algorithm (similarly to the block width in block-matrix
    algorithms in linear algebra). If you require maximum performance on
    your machine, it is recommended to adjust this parameter manually.

Result:
    True,
        if the algorithm has converged and parameters A and S contain the result.
    False,
        if the algorithm has not converged.

Algorithm implemented on the basis of the DHSEQR subroutine (LAPACK 3.0 library).
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::rmatrixschur(real_2d_array&amp; a, ae_int_t n, real_2d_array&amp; s);

</div></pre>
<a name=unit_sparse></a><h2 class=pageheader><code>sparse</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_sparsematrix' class=toc>sparsematrix</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_sparseadd' class=toc>sparseadd</a><br>
<a href='#sub_sparseconverttocrs' class=toc>sparseconverttocrs</a><br>
<a href='#sub_sparseconverttohash' class=toc>sparseconverttohash</a><br>
<a href='#sub_sparsecopy' class=toc>sparsecopy</a><br>
<a href='#sub_sparsecopytocrs' class=toc>sparsecopytocrs</a><br>
<a href='#sub_sparsecopytohash' class=toc>sparsecopytohash</a><br>
<a href='#sub_sparsecreate' class=toc>sparsecreate</a><br>
<a href='#sub_sparsecreatecrs' class=toc>sparsecreatecrs</a><br>
<a href='#sub_sparseenumerate' class=toc>sparseenumerate</a><br>
<a href='#sub_sparsefree' class=toc>sparsefree</a><br>
<a href='#sub_sparseget' class=toc>sparseget</a><br>
<a href='#sub_sparsegetdiagonal' class=toc>sparsegetdiagonal</a><br>
<a href='#sub_sparsegetmatrixtype' class=toc>sparsegetmatrixtype</a><br>
<a href='#sub_sparsegetncols' class=toc>sparsegetncols</a><br>
<a href='#sub_sparsegetnrows' class=toc>sparsegetnrows</a><br>
<a href='#sub_sparsegetrow' class=toc>sparsegetrow</a><br>
<a href='#sub_sparseiscrs' class=toc>sparseiscrs</a><br>
<a href='#sub_sparseishash' class=toc>sparseishash</a><br>
<a href='#sub_sparsemm' class=toc>sparsemm</a><br>
<a href='#sub_sparsemm2' class=toc>sparsemm2</a><br>
<a href='#sub_sparsemtm' class=toc>sparsemtm</a><br>
<a href='#sub_sparsemtv' class=toc>sparsemtv</a><br>
<a href='#sub_sparsemv' class=toc>sparsemv</a><br>
<a href='#sub_sparsemv2' class=toc>sparsemv2</a><br>
<a href='#sub_sparseresizematrix' class=toc>sparseresizematrix</a><br>
<a href='#sub_sparserewriteexisting' class=toc>sparserewriteexisting</a><br>
<a href='#sub_sparseset' class=toc>sparseset</a><br>
<a href='#sub_sparsesmm' class=toc>sparsesmm</a><br>
<a href='#sub_sparsesmv' class=toc>sparsesmv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_sparse_d_1' class=toc>sparse_d_1</a></td><td width=15>&nbsp;</td><td>Basic operations with sparse matrices</td></tr>
<tr align=left valign=top><td><a href='#example_sparse_d_2' class=toc>sparse_d_2</a></td><td width=15>&nbsp;</td><td>Advanced topic: creation in the CRS format.</td></tr>
</table></div>
<a name='struct_sparsematrix'></a><h3 class=pageheader><code>sparsematrix</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Sparse matrix

You should use ALGLIB functions to work with sparse matrix.
Never try to access its fields directly!
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> sparsematrix
{
};

</div></pre>
<a name='sub_sparseadd'></a><h3 class=pageheader><code>sparseadd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function adds value to S[i,j] - element of the sparse matrix. Matrix
must be in a Hash-Table mode.

In case S[i,j] already exists in the table, V i added to  its  value.  In
case  S[i,j]  is  non-existent,  it  is  inserted  in  the  table.  Table
automatically grows when necessary.

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table representation.
                    Exception will be thrown for CRS matrix.
    I           -   row index of the element to modify, 0&lt;=I&lt;M
    J           -   column index of the element to modify, 0&lt;=J&lt;N
    V           -   value to add, must be finite number

OUTPUT PARAMETERS
    S           -   modified matrix

NOTE 1:  when  S[i,j]  is exactly zero after modification, it is  deleted
from the table.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparseadd(sparsematrix s, ae_int_t i, ae_int_t j, <b>double</b> v);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_sparseconverttocrs'></a><h3 class=pageheader><code>sparseconverttocrs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function converts matrix to CRS format.

Some  algorithms  (linear  algebra ones, for example) require matrices in
CRS format.

INPUT PARAMETERS
    S           -   sparse M*N matrix in any format

OUTPUT PARAMETERS
    S           -   matrix in CRS format

NOTE:  this  function  has  no  effect  when  called with matrix which is
already in CRS mode.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparseconverttocrs(sparsematrix s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_sparseconverttohash'></a><h3 class=pageheader><code>sparseconverttohash</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function performs in-place conversion from CRS format to  Hash  table
storage.

INPUT PARAMETERS
    S           -   sparse matrix in CRS format.

OUTPUT PARAMETERS
    S           -   sparse matrix in Hash table format.

NOTE:  this  function  has  no  effect  when  called with matrix which is
already in Hash table mode.

  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparseconverttohash(sparsematrix s);

</div></pre>
<a name='sub_sparsecopy'></a><h3 class=pageheader><code>sparsecopy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function copies S0 to S1.

NOTE:  this  function  does  not verify its arguments, it just copies all
fields of the structure.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsecopy(sparsematrix s0, sparsematrix&amp; s1);

</div></pre>
<a name='sub_sparsecopytocrs'></a><h3 class=pageheader><code>sparsecopytocrs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  performs  out-of-place  conversion  to  CRS format.  S0 is
copied to S1 and converted on-the-fly.

INPUT PARAMETERS
    S0          -   sparse matrix in any format.

OUTPUT PARAMETERS
    S1          -   sparse matrix in CRS format.

NOTE: if S0 is stored as CRS, it is just copied without conversion.

  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsecopytocrs(sparsematrix s0, sparsematrix&amp; s1);

</div></pre>
<a name='sub_sparsecopytohash'></a><h3 class=pageheader><code>sparsecopytohash</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  performs  out-of-place  conversion  to  Hash table storage
format. S0 is copied to S1 and converted on-the-fly.

INPUT PARAMETERS
    S0          -   sparse matrix in any format.

OUTPUT PARAMETERS
    S1          -   sparse matrix in Hash table format.

NOTE: if S0 is stored as Hash-table, it is just copied without conversion.

  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsecopytohash(sparsematrix s0, sparsematrix&amp; s1);

</div></pre>
<a name='sub_sparsecreate'></a><h3 class=pageheader><code>sparsecreate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function creates sparse matrix in a Hash-Table format.

This function creates Hast-Table matrix, which can be  converted  to  CRS
format after its initialization is over. Typical  usage  scenario  for  a
sparse matrix is:
1. creation in a Hash-Table format
2. insertion of the matrix elements
3. conversion to the CRS representation
4. matrix is passed to some linear algebra algorithm

Some  information  about  different matrix formats can be found below, in
the &quot;NOTES&quot; section.

INPUT PARAMETERS
    M           -   number of rows in a matrix, M&gt;=1
    N           -   number of columns in a matrix, N&gt;=1
    K           -   K&gt;=0, expected number of non-zero elements in a matrix.
                    K can be inexact approximation, can be less than actual
                    number  of  elements  (table will grow when needed) or
                    even zero).
                    It is important to understand that although hash-table
                    may grow automatically, it is better to  provide  good
                    estimate of data size.

OUTPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table representation.
                    All elements of the matrix are zero.

NOTE 1.

Sparse matrices can be stored using either Hash-Table  representation  or
Compressed  Row  Storage  representation. Hast-table is better suited for
querying   and   dynamic   operations   (thus,  it  is  used  for  matrix
initialization), but it is inefficient when you want to make some  linear
algebra operations.

From the other side, CRS is better suited for linear algebra  operations,
but initialization is less convenient - you have to tell row sizes at the
initialization,  and  you  can  fill matrix only row by row, from left to
right. CRS is also very inefficient when you want to find matrix  element
by its index.

Thus,  Hash-Table  representation   does   not   support  linear  algebra
operations, while CRS format does not support modification of the  table.
Tables below outline information about these two formats:

    OPERATIONS WITH MATRIX      HASH        CRS
    create                      +           +
    read element                +           +
    modify element              +
    add value to element        +
    A*x  (dense vector)                     +
    A'*x (dense vector)                     +
    A*X  (dense matrix)                     +
    A'*X (dense matrix)                     +

NOTE 2.

Hash-tables use memory inefficiently, and they have to keep  some  amount
of the &quot;spare memory&quot; in order to have good performance. Hash  table  for
matrix with K non-zero elements will  need  C*K*(8+2*sizeof(int))  bytes,
where C is a small constant, about 1.5-2 in magnitude.

CRS storage, from the other side, is  more  memory-efficient,  and  needs
just K*(8+sizeof(int))+M*sizeof(int) bytes, where M is a number  of  rows
in a matrix.

When you convert from the Hash-Table to CRS  representation, all unneeded
memory will be freed.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsecreate(ae_int_t m, ae_int_t n, sparsematrix&amp; s);
<b>void</b> alglib::sparsecreate(
    ae_int_t m,
    ae_int_t n,
    ae_int_t k,
    sparsematrix&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_sparsecreatecrs'></a><h3 class=pageheader><code>sparsecreatecrs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function creates sparse matrix in a CRS format (expert function for
situations when you are running out of memory).

This function creates CRS matrix. Typical usage scenario for a CRS matrix
is:
1. creation (you have to tell number of non-zero elements at each row  at
   this moment)
2. insertion of the matrix elements (row by row, from left to right)
3. matrix is passed to some linear algebra algorithm

This function is a memory-efficient alternative to SparseCreate(), but it
is more complex because it requires you to know in advance how large your
matrix is. Some  information about  different matrix formats can be found
below, in the &quot;NOTES&quot; section.

INPUT PARAMETERS
    M           -   number of rows in a matrix, M&gt;=1
    N           -   number of columns in a matrix, N&gt;=1
    NER         -   number of elements at each row, array[M], NER[I]&gt;=0

OUTPUT PARAMETERS
    S           -   sparse M*N matrix in CRS representation.
                    You have to fill ALL non-zero elements by calling
                    SparseSet() BEFORE you try to use this matrix.

NOTE 1.

Sparse matrices can be stored using either Hash-Table  representation  or
Compressed  Row  Storage  representation. Hast-table is better suited for
querying   and   dynamic   operations   (thus,  it  is  used  for  matrix
initialization), but it is inefficient when you want to make some  linear
algebra operations.

From the other side, CRS is better suited for linear algebra  operations,
but initialization is less convenient - you have to tell row sizes at the
initialization,  and  you  can  fill matrix only row by row, from left to
right. CRS is also very inefficient when you want to find matrix  element
by its index.

Thus,  Hash-Table  representation   does   not   support  linear  algebra
operations, while CRS format does not support modification of the  table.
Tables below outline information about these two formats:

    OPERATIONS WITH MATRIX      HASH        CRS
    create                      +           +
    read element                +           +
    modify element              +
    add value to element        +
    A*x  (dense vector)                     +
    A'*x (dense vector)                     +
    A*X  (dense matrix)                     +
    A'*X (dense matrix)                     +

NOTE 2.

Hash-tables use memory inefficiently, and they have to keep  some  amount
of the &quot;spare memory&quot; in order to have good performance. Hash  table  for
matrix with K non-zero elements will  need  C*K*(8+2*sizeof(int))  bytes,
where C is a small constant, about 1.5-2 in magnitude.

CRS storage, from the other side, is  more  memory-efficient,  and  needs
just K*(8+sizeof(int))+M*sizeof(int) bytes, where M is a number  of  rows
in a matrix.

When you convert from the Hash-Table to CRS  representation, all unneeded
memory will be freed.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsecreatecrs(
    ae_int_t m,
    ae_int_t n,
    integer_1d_array ner,
    sparsematrix&amp; s);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_2' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_sparseenumerate'></a><h3 class=pageheader><code>sparseenumerate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This  function  is  used  to enumerate all elements of the sparse matrix.
Before  first  call  user  initializes  T0 and T1 counters by zero. These
counters are used to remember current position in a  matrix;  after  each
call they are updated by the function.

Subsequent calls to this function return non-zero elements of the  sparse
matrix, one by one. If you enumerate CRS matrix, matrix is traversed from
left to right, from top to bottom. In case you enumerate matrix stored as
Hash table, elements are returned in random order.

EXAMPLE
    &gt; T0=0
    &gt; T1=0
    &gt; while SparseEnumerate(S,T0,T1,I,J,V) do
    &gt;     ....do something with I,J,V

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table or CRS representation.
    T0          -   internal counter
    T1          -   internal counter

OUTPUT PARAMETERS
    T0          -   new value of the internal counter
    T1          -   new value of the internal counter
    I           -   row index of non-zero element, 0&lt;=I&lt;M.
    J           -   column index of non-zero element, 0&lt;=J&lt;N
    V           -   value of the T-th element

RESULT
    True in case of success (next non-zero element was retrieved)
    False in case all non-zero elements were enumerated

  -- ALGLIB PROJECT --
     Copyright 14.03.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::sparseenumerate(
    sparsematrix s,
    ae_int_t&amp; t0,
    ae_int_t&amp; t1,
    ae_int_t&amp; i,
    ae_int_t&amp; j,
    <b>double</b>&amp; v);

</div></pre>
<a name='sub_sparsefree'></a><h3 class=pageheader><code>sparsefree</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The function frees all memory occupied by  sparse  matrix.  Sparse  matrix
structure becomes unusable after this call.

OUTPUT PARAMETERS
    S   -   sparse matrix to delete

  -- ALGLIB PROJECT --
     Copyright 24.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsefree(sparsematrix&amp; s);

</div></pre>
<a name='sub_sparseget'></a><h3 class=pageheader><code>sparseget</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns S[i,j] - element of the sparse matrix.  Matrix  can
be in any mode (Hash-Table or CRS), but this function is  less  efficient
for CRS matrices.  Hash-Table  matrices can  find element  in O(1)  time,
while  CRS  matrices  need O(log(RS)) time, where RS is an number of non-
zero elements in a row.

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table representation.
                    Exception will be thrown for CRS matrix.
    I           -   row index of the element to modify, 0&lt;=I&lt;M
    J           -   column index of the element to modify, 0&lt;=J&lt;N

RESULT
    value of S[I,J] or zero (in case no element with such index is found)

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::sparseget(sparsematrix s, ae_int_t i, ae_int_t j);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_sparse_d_2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_sparsegetdiagonal'></a><h3 class=pageheader><code>sparsegetdiagonal</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns I-th diagonal element of the sparse matrix.

Matrix can be in any mode (Hash-Table or CRS storage), but this  function
is most efficient for CRS matrices - it requires less than 50 CPU  cycles
to extract diagonal element. For Hash-Table matrices we still  have  O(1)
query time, but function is many times slower.

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table representation.
                    Exception will be thrown for CRS matrix.
    I           -   index of the element to modify, 0&lt;=I&lt;min(M,N)

RESULT
    value of S[I,I] or zero (in case no element with such index is found)

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::sparsegetdiagonal(sparsematrix s, ae_int_t i);

</div></pre>
<a name='sub_sparsegetmatrixtype'></a><h3 class=pageheader><code>sparsegetmatrixtype</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns type of the matrix storage format.

INPUT PARAMETERS:
    S           -   sparse matrix.

RESULT:
    sparse storage format used by matrix:
        0   -   Hash-table
        1   -   CRS-format

NOTE: future  versions  of  ALGLIB  may  include additional sparse storage
      formats.


  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::sparsegetmatrixtype(sparsematrix s);

</div></pre>
<a name='sub_sparsegetncols'></a><h3 class=pageheader><code>sparsegetncols</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The function returns number of columns of a sparse matrix.

RESULT: number of columns of a sparse matrix.

  -- ALGLIB PROJECT --
     Copyright 23.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::sparsegetncols(sparsematrix s);

</div></pre>
<a name='sub_sparsegetnrows'></a><h3 class=pageheader><code>sparsegetnrows</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
The function returns number of rows of a sparse matrix.

RESULT: number of rows of a sparse matrix.

  -- ALGLIB PROJECT --
     Copyright 23.08.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'>ae_int_t alglib::sparsegetnrows(sparsematrix s);

</div></pre>
<a name='sub_sparsegetrow'></a><h3 class=pageheader><code>sparsegetrow</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function returns I-th row of the sparse matrix stored in CRS format.

NOTE: when  incorrect  I  (outside  of  [0,M-1]) or  matrix (non-CRS)  are
      passed, this function throws exception.

INPUT PARAMETERS:
    S           -   sparse M*N matrix in CRS format
    I           -   row index, 0&lt;=I&lt;M
    IRow        -   output buffer, can be  preallocated.  In  case  buffer
                    size  is  too  small  to  store  I-th   row,   it   is
                    automatically reallocated.

OUTPUT PARAMETERS:
    IRow        -   array[M], I-th row.


  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsegetrow(
    sparsematrix s,
    ae_int_t i,
    real_1d_array&amp; irow);

</div></pre>
<a name='sub_sparseiscrs'></a><h3 class=pageheader><code>sparseiscrs</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function checks matrix storage format and returns True when matrix is
stored using CRS representation.

INPUT PARAMETERS:
    S   -   sparse matrix.

RESULT:
    True if matrix type is CRS
    False if matrix type is not CRS

  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::sparseiscrs(sparsematrix s);

</div></pre>
<a name='sub_sparseishash'></a><h3 class=pageheader><code>sparseishash</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function checks matrix storage format and returns True when matrix is
stored using Hash table representation.

INPUT PARAMETERS:
    S   -   sparse matrix.

RESULT:
    True if matrix type is Hash table
    False if matrix type is not Hash table

  -- ALGLIB PROJECT --
     Copyright 20.07.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::sparseishash(sparsematrix s);

</div></pre>
<a name='sub_sparsemm'></a><h3 class=pageheader><code>sparsemm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-matrix product  S*A.  Matrix  S  must  be
stored in CRS format (exception will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    A           -   array[N][K], input dense matrix. For  performance reasons
                    we make only quick checks - we check that array size
                    is at least N, but we do not check for NAN's or INF's.
    K           -   number of columns of matrix (A).
    B           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    B           -   array[M][K], S*A

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemm(
    sparsematrix s,
    real_2d_array a,
    ae_int_t k,
    real_2d_array&amp; b);

</div></pre>
<a name='sub_sparsemm2'></a><h3 class=pageheader><code>sparsemm2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function simultaneously calculates two matrix-matrix products:
    S*A and S^T*A.
S must be square (non-rectangular) matrix stored in CRS format (exception
will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse N*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    A           -   array[N][K], input dense matrix. For performance reasons
                    we make only quick checks - we check that array size  is
                    at least N, but we do not check for NAN's or INF's.
    K           -   number of columns of matrix (A).
    B0          -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.
    B1          -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    B0          -   array[N][K], S*A
    B1          -   array[N][K], S^T*A

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function. It also throws exception when S is non-square.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemm2(
    sparsematrix s,
    real_2d_array a,
    ae_int_t k,
    real_2d_array&amp; b0,
    real_2d_array&amp; b1);

</div></pre>
<a name='sub_sparsemtm'></a><h3 class=pageheader><code>sparsemtm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-matrix product  S^T*A. Matrix S  must  be
stored in CRS format (exception will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    A           -   array[M][K], input dense matrix. For performance reasons
                    we make only quick checks - we check that array size  is
                    at least M, but we do not check for NAN's or INF's.
    K           -   number of columns of matrix (A).
    B           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    B           -   array[N][K], S^T*A

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemtm(
    sparsematrix s,
    real_2d_array a,
    ae_int_t k,
    real_2d_array&amp; b);

</div></pre>
<a name='sub_sparsemtv'></a><h3 class=pageheader><code>sparsemtv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-vector product  S^T*x. Matrix S  must  be
stored in CRS format (exception will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    X           -   array[M], input vector. For  performance  reasons  we
                    make only quick checks - we check that array size  is
                    at least M, but we do not check for NAN's or INF's.
    Y           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    Y           -   array[N], S^T*x

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemtv(sparsematrix s, real_1d_array x, real_1d_array&amp; y);

</div></pre>
<a name='sub_sparsemv'></a><h3 class=pageheader><code>sparsemv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-vector product  S*x.  Matrix  S  must  be
stored in CRS format (exception will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    X           -   array[N], input vector. For  performance  reasons  we
                    make only quick checks - we check that array size  is
                    at least N, but we do not check for NAN's or INF's.
    Y           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    Y           -   array[M], S*x

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemv(sparsematrix s, real_1d_array x, real_1d_array&amp; y);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_sparse_d_2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_sparsemv2'></a><h3 class=pageheader><code>sparsemv2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function simultaneously calculates two matrix-vector products:
    S*x and S^T*x.
S must be square (non-rectangular) matrix stored in CRS format (exception
will be thrown otherwise).

INPUT PARAMETERS
    S           -   sparse N*N matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    X           -   array[N], input vector. For  performance  reasons  we
                    make only quick checks - we check that array size  is
                    at least N, but we do not check for NAN's or INF's.
    Y0          -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.
    Y1          -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    Y0          -   array[N], S*x
    Y1          -   array[N], S^T*x

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function. It also throws exception when S is non-square.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsemv2(
    sparsematrix s,
    real_1d_array x,
    real_1d_array&amp; y0,
    real_1d_array&amp; y1);

</div></pre>
<a name='sub_sparseresizematrix'></a><h3 class=pageheader><code>sparseresizematrix</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This procedure resizes Hash-Table matrix. It can be called when you  have
deleted too many elements from the matrix, and you want to  free unneeded
memory.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparseresizematrix(sparsematrix s);

</div></pre>
<a name='sub_sparserewriteexisting'></a><h3 class=pageheader><code>sparserewriteexisting</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function rewrites existing (non-zero) element. It  returns  True   if
element  exists  or  False,  when  it  is  called for non-existing  (zero)
element.

The purpose of this function is to provide convenient thread-safe  way  to
modify  sparse  matrix.  Such  modification  (already  existing element is
rewritten) is guaranteed to be thread-safe without any synchronization, as
long as different threads modify different elements.

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table or CRS representation.
    I           -   row index of non-zero element to modify, 0&lt;=I&lt;M
    J           -   column index of non-zero element to modify, 0&lt;=J&lt;N
    V           -   value to rewrite, must be finite number

OUTPUT PARAMETERS
    S           -   modified matrix
RESULT
    True in case when element exists
    False in case when element doesn't exist or it is zero

  -- ALGLIB PROJECT --
     Copyright 14.03.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::sparserewriteexisting(
    sparsematrix s,
    ae_int_t i,
    ae_int_t j,
    <b>double</b> v);

</div></pre>
<a name='sub_sparseset'></a><h3 class=pageheader><code>sparseset</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function modifies S[i,j] - element of the sparse matrix.

For Hash-based storage format:
* new value can be zero or non-zero.  In case new value of S[i,j] is zero,
  this element is deleted from the table.
* this  function  has  no  effect when called with zero V for non-existent
  element.

For CRS-bases storage format:
* new value MUST be non-zero. Exception will be thrown for zero V.
* elements must be initialized in correct order -  from top row to bottom,
  within row - from left to right.

INPUT PARAMETERS
    S           -   sparse M*N matrix in Hash-Table or CRS representation.
    I           -   row index of the element to modify, 0&lt;=I&lt;M
    J           -   column index of the element to modify, 0&lt;=J&lt;N
    V           -   value to set, must be finite number, can be zero

OUTPUT PARAMETERS
    S           -   modified matrix

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparseset(sparsematrix s, ae_int_t i, ae_int_t j, <b>double</b> v);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_sparse_d_1' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_sparse_d_2' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_sparsesmm'></a><h3 class=pageheader><code>sparsesmm</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-matrix product  S*A, when S  is  symmetric
matrix.  Matrix  S  must  be stored  in  CRS  format  (exception  will  be
thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*M matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    IsUpper     -   whether upper or lower triangle of S is given:
                    * if upper triangle is given,  only   S[i,j] for j&gt;=i
                      are used, and lower triangle is ignored (it can  be
                      empty - these elements are not referenced at all).
                    * if lower triangle is given,  only   S[i,j] for j&lt;=i
                      are used, and upper triangle is ignored.
    A           -   array[N][K], input dense matrix. For performance reasons
                    we make only quick checks - we check that array size is
                    at least N, but we do not check for NAN's or INF's.
    K           -   number of columns of matrix (A).
    B           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    B           -   array[M][K], S*A

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsesmm(
    sparsematrix s,
    <b>bool</b> isupper,
    real_2d_array a,
    ae_int_t k,
    real_2d_array&amp; b);

</div></pre>
<a name='sub_sparsesmv'></a><h3 class=pageheader><code>sparsesmv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function calculates matrix-vector product  S*x, when S is  symmetric
matrix.  Matrix  S  must  be stored in  CRS  format  (exception  will  be
thrown otherwise).

INPUT PARAMETERS
    S           -   sparse M*M matrix in CRS format (you MUST convert  it
                    to CRS before calling this function).
    IsUpper     -   whether upper or lower triangle of S is given:
                    * if upper triangle is given,  only   S[i,j] for j&gt;=i
                      are used, and lower triangle is ignored (it can  be
                      empty - these elements are not referenced at all).
                    * if lower triangle is given,  only   S[i,j] for j&lt;=i
                      are used, and upper triangle is ignored.
    X           -   array[N], input vector. For  performance  reasons  we
                    make only quick checks - we check that array size  is
                    at least N, but we do not check for NAN's or INF's.
    Y           -   output buffer, possibly preallocated. In case  buffer
                    size is too small to store  result,  this  buffer  is
                    automatically resized.

OUTPUT PARAMETERS
    Y           -   array[M], S*x

NOTE: this function throws exception when called for non-CRS matrix.  You
must convert your matrix  with  SparseConvertToCRS()  before  using  this
function.

  -- ALGLIB PROJECT --
     Copyright 14.10.2011 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sparsesmv(
    sparsematrix s,
    <b>bool</b> isupper,
    real_1d_array x,
    real_1d_array&amp; y);

</div></pre>
<a name='example_sparse_d_1'></a><h3 class=pageheader>sparse_d_1 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates creation/initialization of the sparse matrix</font>
    <font color=navy>// and matrix-vector multiplication.</font>
    <font color=navy>//</font>
    <font color=navy>// First, we have to create matrix and initialize it. Matrix is initially created</font>
    <font color=navy>// in the Hash-Table format, which allows convenient initialization. We can modify</font>
    <font color=navy>// Hash-Table matrix with sparseset() and sparseadd() functions.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: Unlike CRS format, Hash-Table representation allows you to initialize</font>
    <font color=navy>// elements in the arbitrary order. You may see that we initialize a[0][0] first,</font>
    <font color=navy>// then move to the second row, and then move back to the first row.</font>
    <font color=navy>//</font>
    sparsematrix s;
    sparsecreate(2, 2, s);
    sparseset(s, 0, 0, 2.0);
    sparseset(s, 1, 1, 1.0);
    sparseset(s, 0, 1, 1.0);

    sparseadd(s, 1, 1, 4.0);

    <font color=navy>//</font>
    <font color=navy>// Now S is equal to</font>
    <font color=navy>//   [ 2 1 ]</font>
    <font color=navy>//   [   5 ]</font>
    <font color=navy>// Lets check it by reading matrix contents with sparseget().</font>
    <font color=navy>// You may see that with sparseget() you may read both non-zero</font>
    <font color=navy>// and zero elements.</font>
    <font color=navy>//</font>
    <b>double</b> v;
    v = sparseget(s, 0, 0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0000</font>
    v = sparseget(s, 0, 1);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000</font>
    v = sparseget(s, 1, 0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0000</font>
    v = sparseget(s, 1, 1);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 5.0000</font>

    <font color=navy>//</font>
    <font color=navy>// After successful creation we can use our matrix <b>for</b> linear operations.</font>
    <font color=navy>//</font>
    <font color=navy>// However, there is one more thing we MUST <b>do</b> before using S in linear</font>
    <font color=navy>// operations: we have to convert it from HashTable representation (used <b>for</b></font>
    <font color=navy>// initialization and dynamic operations) to CRS format with sparseconverttocrs()</font>
    <font color=navy>// call. If you omit this call, ALGLIB will generate exception on the first</font>
    <font color=navy>// attempt to use S in linear operations. </font>
    <font color=navy>//</font>
    sparseconverttocrs(s);

    <font color=navy>//</font>
    <font color=navy>// Now S is in the CRS format and we are ready to <b>do</b> linear operations.</font>
    <font color=navy>// Lets calculate A*x <b>for</b> some x.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[1,-1]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[]&quot;</b></font>;
    sparsemv(s, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(2).c_str()); <font color=navy>// EXPECTED: [1.000,-5.000]</font>
    <b>return</b> 0;
}


</pre><a name='example_sparse_d_2'></a><h3 class=pageheader>sparse_d_2 example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;linalg.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// This example demonstrates creation/initialization of the sparse matrix in the</font>
    <font color=navy>// CRS format.</font>
    <font color=navy>//</font>
    <font color=navy>// Hash-Table format used by default is very convenient (it allows easy</font>
    <font color=navy>// insertion of elements, automatic memory reallocation), but has</font>
    <font color=navy>// significant memory and performance overhead. Insertion of one element </font>
    <font color=navy>// costs hundreds of CPU cycles, and memory consumption is several times</font>
    <font color=navy>// higher than that of CRS.</font>
    <font color=navy>//</font>
    <font color=navy>// When you work with really large matrices and when you can tell in </font>
    <font color=navy>// advance how many elements EXACTLY you need, it can be beneficial to </font>
    <font color=navy>// create matrix in the CRS format from the very beginning.</font>
    <font color=navy>//</font>
    <font color=navy>// If you want to create matrix in the CRS format, you should:</font>
    <font color=navy>// * use sparsecreatecrs() function</font>
    <font color=navy>// * know row sizes in advance (number of non-zero entries in the each row)</font>
    <font color=navy>// * initialize matrix with sparseset() - another function, sparseadd(), is not allowed</font>
    <font color=navy>// * initialize elements from left to right, from top to bottom, each</font>
    <font color=navy>//   element is initialized only once.</font>
    <font color=navy>//</font>
    sparsematrix s;
    integer_1d_array row_sizes = <font color=blue><b>&quot;[2,2,2,1]&quot;</b></font>;
    sparsecreatecrs(4, 4, row_sizes, s);
    sparseset(s, 0, 0, 2.0);
    sparseset(s, 0, 1, 1.0);
    sparseset(s, 1, 1, 4.0);
    sparseset(s, 1, 2, 2.0);
    sparseset(s, 2, 2, 3.0);
    sparseset(s, 2, 3, 1.0);
    sparseset(s, 3, 3, 9.0);

    <font color=navy>//</font>
    <font color=navy>// Now S is equal to</font>
    <font color=navy>//   [ 2 1     ]</font>
    <font color=navy>//   [   4 2   ]</font>
    <font color=navy>//   [     3 1 ]</font>
    <font color=navy>//   [       9 ]</font>
    <font color=navy>//</font>
    <font color=navy>// We should point that we have initialized S elements from left to right,</font>
    <font color=navy>// from top to bottom. CRS representation does NOT allow you to <b>do</b> so in</font>
    <font color=navy>// the different order. Try to change order of the sparseset() calls above,</font>
    <font color=navy>// and you will see that your program generates exception.</font>
    <font color=navy>//</font>
    <font color=navy>// We can check it by reading matrix contents with sparseget().</font>
    <font color=navy>// However, you should remember that sparseget() is inefficient on</font>
    <font color=navy>// CRS matrices (it may have to pass through all elements of the row </font>
    <font color=navy>// until it finds element you need).</font>
    <font color=navy>//</font>
    <b>double</b> v;
    v = sparseget(s, 0, 0);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.0000</font>
    v = sparseget(s, 2, 3);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000</font>

    <font color=navy>// you may see that you can read zero elements (which are not stored) with sparseget()</font>
    v = sparseget(s, 3, 2);
    printf(<font color=blue><b>&quot;%.2f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0000</font>

    <font color=navy>//</font>
    <font color=navy>// After successful creation we can use our matrix <b>for</b> linear operations.</font>
    <font color=navy>// Lets calculate A*x <b>for</b> some x.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[1,-1,1,-1]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[]&quot;</b></font>;
    sparsemv(s, x, y);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y.tostring(2).c_str()); <font color=navy>// EXPECTED: [1.000,-2.000,2.000,-9]</font>
    <b>return</b> 0;
}


</pre><a name=unit_spdgevd></a><h2 class=pageheader><code>spdgevd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_smatrixgevd' class=toc>smatrixgevd</a><br>
<a href='#sub_smatrixgevdreduce' class=toc>smatrixgevdreduce</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_smatrixgevd'></a><h3 class=pageheader><code>smatrixgevd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Algorithm for solving the following generalized symmetric positive-definite
eigenproblem:
    A*x = lambda*B*x (1) or
    A*B*x = lambda*x (2) or
    B*A*x = lambda*x (3).
where A is a symmetric matrix, B - symmetric positive-definite matrix.
The problem is solved by reducing it to an ordinary  symmetric  eigenvalue
problem.

Input parameters:
    A           -   symmetric matrix which is given by its upper or lower
                    triangular part.
                    Array whose indexes range within [0..N-1, 0..N-1].
    N           -   size of matrices A and B.
    IsUpperA    -   storage format of matrix A.
    B           -   symmetric positive-definite matrix which is given by
                    its upper or lower triangular part.
                    Array whose indexes range within [0..N-1, 0..N-1].
    IsUpperB    -   storage format of matrix B.
    ZNeeded     -   if ZNeeded is equal to:
                     * 0, the eigenvectors are not returned;
                     * 1, the eigenvectors are returned.
    ProblemType -   if ProblemType is equal to:
                     * 1, the following problem is solved: A*x = lambda*B*x;
                     * 2, the following problem is solved: A*B*x = lambda*x;
                     * 3, the following problem is solved: B*A*x = lambda*x.

Output parameters:
    D           -   eigenvalues in ascending order.
                    Array whose index ranges within [0..N-1].
    Z           -   if ZNeeded is equal to:
                     * 0, Z hasnt changed;
                     * 1, Z contains eigenvectors.
                    Array whose indexes range within [0..N-1, 0..N-1].
                    The eigenvectors are stored in matrix columns. It should
                    be noted that the eigenvectors in such problems do not
                    form an orthogonal system.

Result:
    True, if the problem was solved successfully.
    False, if the error occurred during the Cholesky decomposition of matrix
    B (the matrix isnt positive-definite) or during the work of the iterative
    algorithm for solving the symmetric eigenproblem.

See also the GeneralizedSymmetricDefiniteEVDReduce subroutine.

  -- ALGLIB --
     Copyright 1.28.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixgevd(
    real_2d_array a,
    ae_int_t n,
    <b>bool</b> isuppera,
    real_2d_array b,
    <b>bool</b> isupperb,
    ae_int_t zneeded,
    ae_int_t problemtype,
    real_1d_array&amp; d,
    real_2d_array&amp; z);

</div></pre>
<a name='sub_smatrixgevdreduce'></a><h3 class=pageheader><code>smatrixgevdreduce</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Algorithm for reduction of the following generalized symmetric positive-
definite eigenvalue problem:
    A*x = lambda*B*x (1) or
    A*B*x = lambda*x (2) or
    B*A*x = lambda*x (3)
to the symmetric eigenvalues problem C*y = lambda*y (eigenvalues of this and
the given problems are the same, and the eigenvectors of the given problem
could be obtained by multiplying the obtained eigenvectors by the
transformation matrix x = R*y).

Here A is a symmetric matrix, B - symmetric positive-definite matrix.

Input parameters:
    A           -   symmetric matrix which is given by its upper or lower
                    triangular part.
                    Array whose indexes range within [0..N-1, 0..N-1].
    N           -   size of matrices A and B.
    IsUpperA    -   storage format of matrix A.
    B           -   symmetric positive-definite matrix which is given by
                    its upper or lower triangular part.
                    Array whose indexes range within [0..N-1, 0..N-1].
    IsUpperB    -   storage format of matrix B.
    ProblemType -   if ProblemType is equal to:
                     * 1, the following problem is solved: A*x = lambda*B*x;
                     * 2, the following problem is solved: A*B*x = lambda*x;
                     * 3, the following problem is solved: B*A*x = lambda*x.

Output parameters:
    A           -   symmetric matrix which is given by its upper or lower
                    triangle depending on IsUpperA. Contains matrix C.
                    Array whose indexes range within [0..N-1, 0..N-1].
    R           -   upper triangular or low triangular transformation matrix
                    which is used to obtain the eigenvectors of a given problem
                    as the product of eigenvectors of C (from the right) and
                    matrix R (from the left). If the matrix is upper
                    triangular, the elements below the main diagonal
                    are equal to 0 (and vice versa). Thus, we can perform
                    the multiplication without taking into account the
                    internal structure (which is an easier though less
                    effective way).
                    Array whose indexes range within [0..N-1, 0..N-1].
    IsUpperR    -   type of matrix R (upper or lower triangular).

Result:
    True, if the problem was reduced successfully.
    False, if the error occurred during the Cholesky decomposition of
        matrix B (the matrix is not positive-definite).

  -- ALGLIB --
     Copyright 1.28.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::smatrixgevdreduce(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isuppera,
    real_2d_array b,
    <b>bool</b> isupperb,
    ae_int_t problemtype,
    real_2d_array&amp; r,
    <b>bool</b>&amp; isupperr);

</div></pre>
<a name=unit_spline1d></a><h2 class=pageheader><code>spline1d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_spline1dinterpolant' class=toc>spline1dinterpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline1dbuildakima' class=toc>spline1dbuildakima</a><br>
<a href='#sub_spline1dbuildcatmullrom' class=toc>spline1dbuildcatmullrom</a><br>
<a href='#sub_spline1dbuildcubic' class=toc>spline1dbuildcubic</a><br>
<a href='#sub_spline1dbuildhermite' class=toc>spline1dbuildhermite</a><br>
<a href='#sub_spline1dbuildlinear' class=toc>spline1dbuildlinear</a><br>
<a href='#sub_spline1dbuildmonotone' class=toc>spline1dbuildmonotone</a><br>
<a href='#sub_spline1dcalc' class=toc>spline1dcalc</a><br>
<a href='#sub_spline1dconvcubic' class=toc>spline1dconvcubic</a><br>
<a href='#sub_spline1dconvdiff2cubic' class=toc>spline1dconvdiff2cubic</a><br>
<a href='#sub_spline1dconvdiffcubic' class=toc>spline1dconvdiffcubic</a><br>
<a href='#sub_spline1ddiff' class=toc>spline1ddiff</a><br>
<a href='#sub_spline1dgriddiff2cubic' class=toc>spline1dgriddiff2cubic</a><br>
<a href='#sub_spline1dgriddiffcubic' class=toc>spline1dgriddiffcubic</a><br>
<a href='#sub_spline1dintegrate' class=toc>spline1dintegrate</a><br>
<a href='#sub_spline1dlintransx' class=toc>spline1dlintransx</a><br>
<a href='#sub_spline1dlintransy' class=toc>spline1dlintransy</a><br>
<a href='#sub_spline1dunpack' class=toc>spline1dunpack</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_spline1d_d_convdiff' class=toc>spline1d_d_convdiff</a></td><td width=15>&nbsp;</td><td>Resampling using cubic splines</td></tr>
<tr align=left valign=top><td><a href='#example_spline1d_d_cubic' class=toc>spline1d_d_cubic</a></td><td width=15>&nbsp;</td><td>Cubic spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#example_spline1d_d_griddiff' class=toc>spline1d_d_griddiff</a></td><td width=15>&nbsp;</td><td>Differentiation on the grid using cubic splines</td></tr>
<tr align=left valign=top><td><a href='#example_spline1d_d_linear' class=toc>spline1d_d_linear</a></td><td width=15>&nbsp;</td><td>Piecewise linear spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#example_spline1d_d_monotone' class=toc>spline1d_d_monotone</a></td><td width=15>&nbsp;</td><td>Monotone interpolation</td></tr>
</table></div>
<a name='struct_spline1dinterpolant'></a><h3 class=pageheader><code>spline1dinterpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
1-dimensional spline interpolant
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> spline1dinterpolant
{
};

</div></pre>
<a name='sub_spline1dbuildakima'></a><h3 class=pageheader><code>spline1dbuildakima</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds Akima spline interpolant

INPUT PARAMETERS:
    X           -   spline nodes, array[0..N-1]
    Y           -   function values, array[0..N-1]
    N           -   points count (optional):
                    * N&gt;=2
                    * if given, only first N points are used to build spline
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))

OUTPUT PARAMETERS:
    C           -   spline interpolant


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

  -- ALGLIB PROJECT --
     Copyright 24.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildakima(
    real_1d_array x,
    real_1d_array y,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildakima(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    spline1dinterpolant&amp; c);

</div></pre>
<a name='sub_spline1dbuildcatmullrom'></a><h3 class=pageheader><code>spline1dbuildcatmullrom</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds Catmull-Rom spline interpolant.

INPUT PARAMETERS:
    X           -   spline nodes, array[0..N-1].
    Y           -   function values, array[0..N-1].

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points are used to build spline
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundType   -   boundary condition type:
                    * -1 for periodic boundary condition
                    *  0 for parabolically terminated spline (default)
    Tension     -   tension parameter:
                    * tension=0   corresponds to classic Catmull-Rom spline (default)
                    * 0&lt;tension&lt;1 corresponds to more general form - cardinal spline

OUTPUT PARAMETERS:
    C           -   spline interpolant


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 23.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildcatmullrom(
    real_1d_array x,
    real_1d_array y,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildcatmullrom(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundtype,
    <b>double</b> tension,
    spline1dinterpolant&amp; c);

</div></pre>
<a name='sub_spline1dbuildcubic'></a><h3 class=pageheader><code>spline1dbuildcubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds cubic spline interpolant.

INPUT PARAMETERS:
    X           -   spline nodes, array[0..N-1].
    Y           -   function values, array[0..N-1].

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points are used to build spline
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)

OUTPUT PARAMETERS:
    C           -   spline interpolant

ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 23.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildcubic(
    real_1d_array x,
    real_1d_array y,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    spline1dinterpolant&amp; c);

</div></pre>
<a name='sub_spline1dbuildhermite'></a><h3 class=pageheader><code>spline1dbuildhermite</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds Hermite spline interpolant.

INPUT PARAMETERS:
    X           -   spline nodes, array[0..N-1]
    Y           -   function values, array[0..N-1]
    D           -   derivatives, array[0..N-1]
    N           -   points count (optional):
                    * N&gt;=2
                    * if given, only first N points are used to build spline
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))

OUTPUT PARAMETERS:
    C           -   spline interpolant.


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

  -- ALGLIB PROJECT --
     Copyright 23.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildhermite(
    real_1d_array x,
    real_1d_array y,
    real_1d_array d,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildhermite(
    real_1d_array x,
    real_1d_array y,
    real_1d_array d,
    ae_int_t n,
    spline1dinterpolant&amp; c);

</div></pre>
<a name='sub_spline1dbuildlinear'></a><h3 class=pageheader><code>spline1dbuildlinear</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds linear spline interpolant

INPUT PARAMETERS:
    X   -   spline nodes, array[0..N-1]
    Y   -   function values, array[0..N-1]
    N   -   points count (optional):
            * N&gt;=2
            * if given, only first N points are used to build spline
            * if not given, automatically detected from X/Y sizes
              (len(X) must be equal to len(Y))

OUTPUT PARAMETERS:
    C   -   spline interpolant


ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.

  -- ALGLIB PROJECT --
     Copyright 24.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildlinear(
    real_1d_array x,
    real_1d_array y,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildlinear(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    spline1dinterpolant&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_linear' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_spline1d_d_cubic' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dbuildmonotone'></a><h3 class=pageheader><code>spline1dbuildmonotone</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function builds monotone cubic Hermite interpolant. This interpolant
is monotonic in [x(0),x(n-1)] and is constant outside of this interval.

In  case  y[]  form  non-monotonic  sequence,  interpolant  is  piecewise
monotonic.  Say, for x=(0,1,2,3,4)  and  y=(0,1,2,1,0)  interpolant  will
monotonically grow at [0..2] and monotonically decrease at [2..4].

INPUT PARAMETERS:
    X           -   spline nodes, array[0..N-1]. Subroutine automatically
                    sorts points, so caller may pass unsorted array.
    Y           -   function values, array[0..N-1]
    N           -   the number of points(N&gt;=2).

OUTPUT PARAMETERS:
    C           -   spline interpolant.

 -- ALGLIB PROJECT --
     Copyright 21.06.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dbuildmonotone(
    real_1d_array x,
    real_1d_array y,
    spline1dinterpolant&amp; c);
<b>void</b> alglib::spline1dbuildmonotone(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    spline1dinterpolant&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_monotone' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dcalc'></a><h3 class=pageheader><code>spline1dcalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates the value of the spline at the given point X.

INPUT PARAMETERS:
    C   -   spline interpolant
    X   -   point

Result:
    S(x)

  -- ALGLIB PROJECT --
     Copyright 23.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spline1dcalc(spline1dinterpolant c, <b>double</b> x);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_linear' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_spline1d_d_cubic' class=nav>[2]</a>&nbsp;&nbsp;<a href='#example_spline1d_d_monotone' class=nav>[3]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dconvcubic'></a><h3 class=pageheader><code>spline1dconvcubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves following problem: given table y[] of function values
at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
function values y2[] (calculated at x2[]).

This function yields same result as Spline1DBuildCubic() call followed  by
sequence of Spline1DDiff() calls, but it can be several times faster  when
called for ordered X[] and X2[].

INPUT PARAMETERS:
    X           -   old spline nodes
    Y           -   function values
    X2           -  new spline nodes

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points from X/Y are used
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)
    N2          -   new points count:
                    * N2&gt;=2
                    * if given, only first N2 points from X2 are used
                    * if not given, automatically detected from X2 size

OUTPUT PARAMETERS:
    F2          -   function values at X2[]

ORDER OF POINTS

Subroutine automatically sorts points, so caller  may pass unsorted array.
Function  values  are correctly reordered on  return, so F2[I]  is  always
equal to S(X2[I]) independently of points order.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 03.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dconvcubic(
    real_1d_array x,
    real_1d_array y,
    real_1d_array x2,
    real_1d_array&amp; y2);
<b>void</b> alglib::spline1dconvcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    real_1d_array x2,
    ae_int_t n2,
    real_1d_array&amp; y2);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_convdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dconvdiff2cubic'></a><h3 class=pageheader><code>spline1dconvdiff2cubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves following problem: given table y[] of function values
at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
function  values  y2[],  first  and  second  derivatives  d2[]  and  dd2[]
(calculated at x2[]).

This function yields same result as Spline1DBuildCubic() call followed  by
sequence of Spline1DDiff() calls, but it can be several times faster  when
called for ordered X[] and X2[].

INPUT PARAMETERS:
    X           -   old spline nodes
    Y           -   function values
    X2           -  new spline nodes

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points from X/Y are used
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)
    N2          -   new points count:
                    * N2&gt;=2
                    * if given, only first N2 points from X2 are used
                    * if not given, automatically detected from X2 size

OUTPUT PARAMETERS:
    F2          -   function values at X2[]
    D2          -   first derivatives at X2[]
    DD2         -   second derivatives at X2[]

ORDER OF POINTS

Subroutine automatically sorts points, so caller  may pass unsorted array.
Function  values  are correctly reordered on  return, so F2[I]  is  always
equal to S(X2[I]) independently of points order.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 03.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dconvdiff2cubic(
    real_1d_array x,
    real_1d_array y,
    real_1d_array x2,
    real_1d_array&amp; y2,
    real_1d_array&amp; d2,
    real_1d_array&amp; dd2);
<b>void</b> alglib::spline1dconvdiff2cubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    real_1d_array x2,
    ae_int_t n2,
    real_1d_array&amp; y2,
    real_1d_array&amp; d2,
    real_1d_array&amp; dd2);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_convdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dconvdiffcubic'></a><h3 class=pageheader><code>spline1dconvdiffcubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves following problem: given table y[] of function values
at old nodes x[]  and new nodes  x2[],  it calculates and returns table of
function values y2[] and derivatives d2[] (calculated at x2[]).

This function yields same result as Spline1DBuildCubic() call followed  by
sequence of Spline1DDiff() calls, but it can be several times faster  when
called for ordered X[] and X2[].

INPUT PARAMETERS:
    X           -   old spline nodes
    Y           -   function values
    X2           -  new spline nodes

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points from X/Y are used
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)
    N2          -   new points count:
                    * N2&gt;=2
                    * if given, only first N2 points from X2 are used
                    * if not given, automatically detected from X2 size

OUTPUT PARAMETERS:
    F2          -   function values at X2[]
    D2          -   first derivatives at X2[]

ORDER OF POINTS

Subroutine automatically sorts points, so caller  may pass unsorted array.
Function  values  are correctly reordered on  return, so F2[I]  is  always
equal to S(X2[I]) independently of points order.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 03.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dconvdiffcubic(
    real_1d_array x,
    real_1d_array y,
    real_1d_array x2,
    real_1d_array&amp; y2,
    real_1d_array&amp; d2);
<b>void</b> alglib::spline1dconvdiffcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    real_1d_array x2,
    ae_int_t n2,
    real_1d_array&amp; y2,
    real_1d_array&amp; d2);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_convdiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1ddiff'></a><h3 class=pageheader><code>spline1ddiff</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine differentiates the spline.

INPUT PARAMETERS:
    C   -   spline interpolant.
    X   -   point

Result:
    S   -   S(x)
    DS  -   S'(x)
    D2S -   S''(x)

  -- ALGLIB PROJECT --
     Copyright 24.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1ddiff(
    spline1dinterpolant c,
    <b>double</b> x,
    <b>double</b>&amp; s,
    <b>double</b>&amp; ds,
    <b>double</b>&amp; d2s);

</div></pre>
<a name='sub_spline1dgriddiff2cubic'></a><h3 class=pageheader><code>spline1dgriddiff2cubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves following problem: given table y[] of function values
at  nodes  x[],  it  calculates  and  returns  tables  of first and second
function derivatives d1[] and d2[] (calculated at the same nodes x[]).

This function yields same result as Spline1DBuildCubic() call followed  by
sequence of Spline1DDiff() calls, but it can be several times faster  when
called for ordered X[] and X2[].

INPUT PARAMETERS:
    X           -   spline nodes
    Y           -   function values

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points are used
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)

OUTPUT PARAMETERS:
    D1          -   S' values at X[]
    D2          -   S'' values at X[]

ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.
Derivative values are correctly reordered on return, so  D[I]  is  always
equal to S'(X[I]) independently of points order.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 03.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dgriddiff2cubic(
    real_1d_array x,
    real_1d_array y,
    real_1d_array&amp; d1,
    real_1d_array&amp; d2);
<b>void</b> alglib::spline1dgriddiff2cubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    real_1d_array&amp; d1,
    real_1d_array&amp; d2);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_griddiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dgriddiffcubic'></a><h3 class=pageheader><code>spline1dgriddiffcubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This function solves following problem: given table y[] of function values
at nodes x[], it calculates and returns table of function derivatives  d[]
(calculated at the same nodes x[]).

This function yields same result as Spline1DBuildCubic() call followed  by
sequence of Spline1DDiff() calls, but it can be several times faster  when
called for ordered X[] and X2[].

INPUT PARAMETERS:
    X           -   spline nodes
    Y           -   function values

OPTIONAL PARAMETERS:
    N           -   points count:
                    * N&gt;=2
                    * if given, only first N points are used
                    * if not given, automatically detected from X/Y sizes
                      (len(X) must be equal to len(Y))
    BoundLType  -   boundary condition type for the left boundary
    BoundL      -   left boundary condition (first or second derivative,
                    depending on the BoundLType)
    BoundRType  -   boundary condition type for the right boundary
    BoundR      -   right boundary condition (first or second derivative,
                    depending on the BoundRType)

OUTPUT PARAMETERS:
    D           -   derivative values at X[]

ORDER OF POINTS

Subroutine automatically sorts points, so caller may pass unsorted array.
Derivative values are correctly reordered on return, so  D[I]  is  always
equal to S'(X[I]) independently of points order.

SETTING BOUNDARY VALUES:

The BoundLType/BoundRType parameters can have the following values:
    * -1, which corresonds to the periodic (cyclic) boundary conditions.
          In this case:
          * both BoundLType and BoundRType must be equal to -1.
          * BoundL/BoundR are ignored
          * Y[last] is ignored (it is assumed to be equal to Y[first]).
    *  0, which  corresponds  to  the  parabolically   terminated  spline
          (BoundL and/or BoundR are ignored).
    *  1, which corresponds to the first derivative boundary condition
    *  2, which corresponds to the second derivative boundary condition
    *  by default, BoundType=0 is used

PROBLEMS WITH PERIODIC BOUNDARY CONDITIONS:

Problems with periodic boundary conditions have Y[first_point]=Y[last_point].
However, this subroutine doesn't require you to specify equal  values  for
the first and last points - it automatically forces them  to  be  equal by
copying  Y[first_point]  (corresponds  to the leftmost,  minimal  X[])  to
Y[last_point]. However it is recommended to pass consistent values of Y[],
i.e. to make Y[first_point]=Y[last_point].

  -- ALGLIB PROJECT --
     Copyright 03.09.2010 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dgriddiffcubic(
    real_1d_array x,
    real_1d_array y,
    real_1d_array&amp; d);
<b>void</b> alglib::spline1dgriddiffcubic(
    real_1d_array x,
    real_1d_array y,
    ae_int_t n,
    ae_int_t boundltype,
    <b>double</b> boundl,
    ae_int_t boundrtype,
    <b>double</b> boundr,
    real_1d_array&amp; d);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline1d_d_griddiff' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline1dintegrate'></a><h3 class=pageheader><code>spline1dintegrate</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine integrates the spline.

INPUT PARAMETERS:
    C   -   spline interpolant.
    X   -   right bound of the integration interval [a, x],
            here 'a' denotes min(x[])
Result:
    integral(S(t)dt,a,x)

  -- ALGLIB PROJECT --
     Copyright 23.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spline1dintegrate(spline1dinterpolant c, <b>double</b> x);

</div></pre>
<a name='sub_spline1dlintransx'></a><h3 class=pageheader><code>spline1dlintransx</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline argument.

INPUT PARAMETERS:
    C   -   spline interpolant.
    A, B-   transformation coefficients: x = A*t + B
Result:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 30.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dlintransx(spline1dinterpolant c, <b>double</b> a, <b>double</b> b);

</div></pre>
<a name='sub_spline1dlintransy'></a><h3 class=pageheader><code>spline1dlintransy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline.

INPUT PARAMETERS:
    C   -   spline interpolant.
    A, B-   transformation coefficients: S2(x) = A*S(x) + B
Result:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 30.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dlintransy(spline1dinterpolant c, <b>double</b> a, <b>double</b> b);

</div></pre>
<a name='sub_spline1dunpack'></a><h3 class=pageheader><code>spline1dunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine unpacks the spline into the coefficients table.

INPUT PARAMETERS:
    C   -   spline interpolant.
    X   -   point

OUTPUT PARAMETERS:
    Tbl -   coefficients table, unpacked format, array[0..N-2, 0..5].
            For I = 0...N-2:
                Tbl[I,0] = X[i]
                Tbl[I,1] = X[i+1]
                Tbl[I,2] = C0
                Tbl[I,3] = C1
                Tbl[I,4] = C2
                Tbl[I,5] = C3
            On [x[i], x[i+1]] spline is equals to:
                S(x) = C0 + C1*t + C2*t^2 + C3*t^3
                t = x-x[i]

NOTE:
    You  can rebuild spline with  Spline1DBuildHermite()  function,  which
    accepts as inputs function values and derivatives at nodes, which  are
    easy to calculate when you have coefficients.

  -- ALGLIB PROJECT --
     Copyright 29.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline1dunpack(
    spline1dinterpolant c,
    ae_int_t&amp; n,
    real_2d_array&amp; tbl);

</div></pre>
<a name='example_spline1d_d_convdiff'></a><h3 class=pageheader>spline1d_d_convdiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use cubic spline to <b>do</b> resampling, i.e. having</font>
    <font color=navy>// values of f(x)=x^2 sampled at 5 equidistant nodes on [-1,+1]</font>
    <font color=navy>// we calculate values/derivatives of cubic spline on </font>
    <font color=navy>// another grid (equidistant with 9 nodes on [-1,+1])</font>
    <font color=navy>// WITHOUT CONSTRUCTION OF SPLINE OBJECT.</font>
    <font color=navy>//</font>
    <font color=navy>// There are efficient functions spline1dconvcubic(),</font>
    <font color=navy>// spline1dconvdiffcubic() and spline1dconvdiff2cubic() </font>
    <font color=navy>// <b>for</b> such calculations.</font>
    <font color=navy>//</font>
    <font color=navy>// We use default boundary conditions (&quot;parabolically terminated</font>
    <font color=navy>// spline&quot;) because cubic spline built with such boundary conditions </font>
    <font color=navy>// will exactly reproduce any quadratic f(x).</font>
    <font color=navy>//</font>
    <font color=navy>// Actually, we could use natural conditions, but we feel that </font>
    <font color=navy>// spline which exactly reproduces f() will show us more </font>
    <font color=navy>// understandable results.</font>
    <font color=navy>//</font>
    real_1d_array x_old = <font color=blue><b>&quot;[-1.0,-0.5,0.0,+0.5,+1.0]&quot;</b></font>;
    real_1d_array y_old = <font color=blue><b>&quot;[+1.0,0.25,0.0,0.25,+1.0]&quot;</b></font>;
    real_1d_array x_new = <font color=blue><b>&quot;[-1.00,-0.75,-0.50,-0.25,0.00,+0.25,+0.50,+0.75,+1.00]&quot;</b></font>;
    real_1d_array y_new;
    real_1d_array d1_new;
    real_1d_array d2_new;

    <font color=navy>//</font>
    <font color=navy>// First, conversion without differentiation.</font>
    <font color=navy>//</font>
    <font color=navy>//</font>
    spline1dconvcubic(x_old, y_old, x_new, y_new);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [1.0000, 0.5625, 0.2500, 0.0625, 0.0000, 0.0625, 0.2500, 0.5625, 1.0000]</font>

    <font color=navy>//</font>
    <font color=navy>// Then, conversion with differentiation (first derivatives only)</font>
    <font color=navy>//</font>
    <font color=navy>//</font>
    spline1dconvdiffcubic(x_old, y_old, x_new, y_new, d1_new);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [1.0000, 0.5625, 0.2500, 0.0625, 0.0000, 0.0625, 0.2500, 0.5625, 1.0000]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d1_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]</font>

    <font color=navy>//</font>
    <font color=navy>// Finally, conversion with first and second derivatives</font>
    <font color=navy>//</font>
    <font color=navy>//</font>
    spline1dconvdiff2cubic(x_old, y_old, x_new, y_new, d1_new, d2_new);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, y_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [1.0000, 0.5625, 0.2500, 0.0625, 0.0000, 0.0625, 0.2500, 0.5625, 1.0000]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d1_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d2_new.tostring(3).c_str()); <font color=navy>// EXPECTED: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</font>
    <b>return</b> 0;
}


</pre><a name='example_spline1d_d_cubic'></a><h3 class=pageheader>spline1d_d_cubic example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use cubic spline to interpolate f(x)=x^2 sampled </font>
    <font color=navy>// at 5 equidistant nodes on [-1,+1].</font>
    <font color=navy>//</font>
    <font color=navy>// First, we use default boundary conditions (&quot;parabolically terminated</font>
    <font color=navy>// spline&quot;) because cubic spline built with such boundary conditions </font>
    <font color=navy>// will exactly reproduce any quadratic f(x).</font>
    <font color=navy>//</font>
    <font color=navy>// Then we try to use natural boundary conditions</font>
    <font color=navy>//     d2S(-1)/dx^2 = 0.0</font>
    <font color=navy>//     d2S(+1)/dx^2 = 0.0</font>
    <font color=navy>// and see that such spline interpolated f(x) with small error.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[-1.0,-0.5,0.0,+0.5,+1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[+1.0,0.25,0.0,0.25,+1.0]&quot;</b></font>;
    <b>double</b> t = 0.25;
    <b>double</b> v;
    spline1dinterpolant s;
    ae_int_t natural_bound_type = 2;
    <font color=navy>//</font>
    <font color=navy>// Test exact boundary conditions: build S(x), calculare S(0.25)</font>
    <font color=navy>// (almost same as original function)</font>
    <font color=navy>//</font>
    spline1dbuildcubic(x, y, s);
    v = spline1dcalc(s, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0625</font>

    <font color=navy>//</font>
    <font color=navy>// Test natural boundary conditions: build S(x), calculare S(0.25)</font>
    <font color=navy>// (small interpolation error)</font>
    <font color=navy>//</font>
    spline1dbuildcubic(x, y, 5, natural_bound_type, 0.0, natural_bound_type, 0.0, s);
    v = spline1dcalc(s, t);
    printf(<font color=blue><b>&quot;%.3f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0580</font>
    <b>return</b> 0;
}


</pre><a name='example_spline1d_d_griddiff'></a><h3 class=pageheader>spline1d_d_griddiff example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use cubic spline to <b>do</b> grid differentiation, i.e. having</font>
    <font color=navy>// values of f(x)=x^2 sampled at 5 equidistant nodes on [-1,+1]</font>
    <font color=navy>// we calculate derivatives of cubic spline at nodes WITHOUT</font>
    <font color=navy>// CONSTRUCTION OF SPLINE OBJECT.</font>
    <font color=navy>//</font>
    <font color=navy>// There are efficient functions spline1dgriddiffcubic() and</font>
    <font color=navy>// spline1dgriddiff2cubic() <b>for</b> such calculations.</font>
    <font color=navy>//</font>
    <font color=navy>// We use default boundary conditions (&quot;parabolically terminated</font>
    <font color=navy>// spline&quot;) because cubic spline built with such boundary conditions </font>
    <font color=navy>// will exactly reproduce any quadratic f(x).</font>
    <font color=navy>//</font>
    <font color=navy>// Actually, we could use natural conditions, but we feel that </font>
    <font color=navy>// spline which exactly reproduces f() will show us more </font>
    <font color=navy>// understandable results.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[-1.0,-0.5,0.0,+0.5,+1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[+1.0,0.25,0.0,0.25,+1.0]&quot;</b></font>;
    real_1d_array d1;
    real_1d_array d2;

    <font color=navy>//</font>
    <font color=navy>// We calculate first derivatives: they must be equal to 2*x</font>
    <font color=navy>//</font>
    spline1dgriddiffcubic(x, y, d1);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d1.tostring(3).c_str()); <font color=navy>// EXPECTED: [-2.0, -1.0, 0.0, +1.0, +2.0]</font>

    <font color=navy>//</font>
    <font color=navy>// Now test griddiff2, which returns first AND second derivatives.</font>
    <font color=navy>// First derivative is 2*x, second is equal to 2.0</font>
    <font color=navy>//</font>
    spline1dgriddiff2cubic(x, y, d1, d2);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d1.tostring(3).c_str()); <font color=navy>// EXPECTED: [-2.0, -1.0, 0.0, +1.0, +2.0]</font>
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, d2.tostring(3).c_str()); <font color=navy>// EXPECTED: [ 2.0,  2.0, 2.0,  2.0,  2.0]</font>
    <b>return</b> 0;
}


</pre><a name='example_spline1d_d_linear'></a><h3 class=pageheader>spline1d_d_linear example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use piecewise linear spline to interpolate f(x)=x^2 sampled </font>
    <font color=navy>// at 5 equidistant nodes on [-1,+1].</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[-1.0,-0.5,0.0,+0.5,+1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[+1.0,0.25,0.0,0.25,+1.0]&quot;</b></font>;
    <b>double</b> t = 0.25;
    <b>double</b> v;
    spline1dinterpolant s;

    <font color=navy>// build spline</font>
    spline1dbuildlinear(x, y, s);

    <font color=navy>// calculate S(0.25) - it is quite different from 0.25^2=0.0625</font>
    v = spline1dcalc(s, t);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.125</font>
    <b>return</b> 0;
}


</pre><a name='example_spline1d_d_monotone'></a><h3 class=pageheader>spline1d_d_monotone example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// Spline built witn spline1dbuildcubic() can be non-monotone even when</font>
    <font color=navy>// Y-values form monotone sequence. Say, <b>for</b> x=[0,1,2] and y=[0,1,1]</font>
    <font color=navy>// cubic spline will monotonically grow until x=1.5 and then start</font>
    <font color=navy>// decreasing.</font>
    <font color=navy>//</font>
    <font color=navy>// That's why ALGLIB provides special spline construction function</font>
    <font color=navy>// which builds spline which preserves monotonicity of the original</font>
    <font color=navy>// dataset.</font>
    <font color=navy>//</font>
    <font color=navy>// NOTE: in case original dataset is non-monotonic, ALGLIB splits it</font>
    <font color=navy>// into monotone subsequences and builds piecewise monotonic spline.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0,1,2]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0,1,1]&quot;</b></font>;
    spline1dinterpolant s;

    <font color=navy>// build spline</font>
    spline1dbuildmonotone(x, y, s);

    <font color=navy>// calculate S at x = [-0.5, 0.0, 0.5, 1.0, 1.5, 2.0]</font>
    <font color=navy>// you may see that spline is really monotonic</font>
    <b>double</b> v;
    v = spline1dcalc(s, -0.5);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0000</font>
    v = spline1dcalc(s, 0.0);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.0000</font>
    v = spline1dcalc(s, +0.5);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 0.5000</font>
    v = spline1dcalc(s, 1.0);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000</font>
    v = spline1dcalc(s, 1.5);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000</font>
    v = spline1dcalc(s, 2.0);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0000</font>
    <b>return</b> 0;
}


</pre><a name=unit_spline2d></a><h2 class=pageheader><code>spline2d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_spline2dinterpolant' class=toc>spline2dinterpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline2dbuildbicubic' class=toc>spline2dbuildbicubic</a><br>
<a href='#sub_spline2dbuildbicubicv' class=toc>spline2dbuildbicubicv</a><br>
<a href='#sub_spline2dbuildbilinear' class=toc>spline2dbuildbilinear</a><br>
<a href='#sub_spline2dbuildbilinearv' class=toc>spline2dbuildbilinearv</a><br>
<a href='#sub_spline2dcalc' class=toc>spline2dcalc</a><br>
<a href='#sub_spline2dcalcv' class=toc>spline2dcalcv</a><br>
<a href='#sub_spline2dcalcvbuf' class=toc>spline2dcalcvbuf</a><br>
<a href='#sub_spline2dcopy' class=toc>spline2dcopy</a><br>
<a href='#sub_spline2ddiff' class=toc>spline2ddiff</a><br>
<a href='#sub_spline2dlintransf' class=toc>spline2dlintransf</a><br>
<a href='#sub_spline2dlintransxy' class=toc>spline2dlintransxy</a><br>
<a href='#sub_spline2dresamplebicubic' class=toc>spline2dresamplebicubic</a><br>
<a href='#sub_spline2dresamplebilinear' class=toc>spline2dresamplebilinear</a><br>
<a href='#sub_spline2dunpack' class=toc>spline2dunpack</a><br>
<a href='#sub_spline2dunpackv' class=toc>spline2dunpackv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_spline2d_bicubic' class=toc>spline2d_bicubic</a></td><td width=15>&nbsp;</td><td>Bilinear spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#example_spline2d_bilinear' class=toc>spline2d_bilinear</a></td><td width=15>&nbsp;</td><td>Bilinear spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#example_spline2d_copytrans' class=toc>spline2d_copytrans</a></td><td width=15>&nbsp;</td><td>Copy and transform</td></tr>
<tr align=left valign=top><td><a href='#example_spline2d_unpack' class=toc>spline2d_unpack</a></td><td width=15>&nbsp;</td><td>Unpacking bilinear spline</td></tr>
<tr align=left valign=top><td><a href='#example_spline2d_vector' class=toc>spline2d_vector</a></td><td width=15>&nbsp;</td><td>Copy and transform</td></tr>
</table></div>
<a name='struct_spline2dinterpolant'></a><h3 class=pageheader><code>spline2dinterpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
2-dimensional spline inteprolant
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> spline2dinterpolant
{
};

</div></pre>
<a name='sub_spline2dbuildbicubic'></a><h3 class=pageheader><code>spline2dbuildbicubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine was deprecated in ALGLIB 3.6.0

We recommend you to switch  to  Spline2DBuildBicubicV(),  which  is  more
flexible and accepts its arguments in more convenient order.

  -- ALGLIB PROJECT --
     Copyright 05.07.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dbuildbicubic(
    real_1d_array x,
    real_1d_array y,
    real_2d_array f,
    ae_int_t m,
    ae_int_t n,
    spline2dinterpolant&amp; c);

</div></pre>
<a name='sub_spline2dbuildbicubicv'></a><h3 class=pageheader><code>spline2dbuildbicubicv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds bicubic vector-valued spline.

Input parameters:
    X   -   spline abscissas, array[0..N-1]
    Y   -   spline ordinates, array[0..M-1]
    F   -   function values, array[0..M*N*D-1]:
            * first D elements store D values at (X[0],Y[0])
            * next D elements store D values at (X[1],Y[0])
            * general form - D function values at (X[i],Y[j]) are stored
              at F[D*(J*N+I)...D*(J*N+I)+D-1].
    M,N -   grid size, M&gt;=2, N&gt;=2
    D   -   vector dimension, D&gt;=1

Output parameters:
    C   -   spline interpolant

  -- ALGLIB PROJECT --
     Copyright 16.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dbuildbicubicv(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    real_1d_array f,
    ae_int_t d,
    spline2dinterpolant&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_bicubic' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dbuildbilinear'></a><h3 class=pageheader><code>spline2dbuildbilinear</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine was deprecated in ALGLIB 3.6.0

We recommend you to switch  to  Spline2DBuildBilinearV(),  which  is  more
flexible and accepts its arguments in more convenient order.

  -- ALGLIB PROJECT --
     Copyright 05.07.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dbuildbilinear(
    real_1d_array x,
    real_1d_array y,
    real_2d_array f,
    ae_int_t m,
    ae_int_t n,
    spline2dinterpolant&amp; c);

</div></pre>
<a name='sub_spline2dbuildbilinearv'></a><h3 class=pageheader><code>spline2dbuildbilinearv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds bilinear vector-valued spline.

Input parameters:
    X   -   spline abscissas, array[0..N-1]
    Y   -   spline ordinates, array[0..M-1]
    F   -   function values, array[0..M*N*D-1]:
            * first D elements store D values at (X[0],Y[0])
            * next D elements store D values at (X[1],Y[0])
            * general form - D function values at (X[i],Y[j]) are stored
              at F[D*(J*N+I)...D*(J*N+I)+D-1].
    M,N -   grid size, M&gt;=2, N&gt;=2
    D   -   vector dimension, D&gt;=1

Output parameters:
    C   -   spline interpolant

  -- ALGLIB PROJECT --
     Copyright 16.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dbuildbilinearv(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    real_1d_array f,
    ae_int_t d,
    spline2dinterpolant&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_bilinear' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_spline2d_vector' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dcalc'></a><h3 class=pageheader><code>spline2dcalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates the value of the bilinear or bicubic spline  at
the given point X.

Input parameters:
    C   -   coefficients table.
            Built by BuildBilinearSpline or BuildBicubicSpline.
    X, Y-   point

Result:
    S(x,y)

  -- ALGLIB PROJECT --
     Copyright 05.07.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spline2dcalc(spline2dinterpolant c, <b>double</b> x, <b>double</b> y);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_bilinear' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_spline2d_bicubic' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dcalcv'></a><h3 class=pageheader><code>spline2dcalcv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates bilinear or bicubic vector-valued spline at the
given point (X,Y).

INPUT PARAMETERS:
    C   -   spline interpolant.
    X, Y-   point

OUTPUT PARAMETERS:
    F   -   array[D] which stores function values.  F is out-parameter and
            it  is  reallocated  after  call to this function. In case you
            want  to    reuse  previously  allocated  F,   you   may   use
            Spline2DCalcVBuf(),  which  reallocates  F only when it is too
            small.

  -- ALGLIB PROJECT --
     Copyright 16.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dcalcv(
    spline2dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    real_1d_array&amp; f);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_vector' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dcalcvbuf'></a><h3 class=pageheader><code>spline2dcalcvbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates bilinear or bicubic vector-valued spline at the
given point (X,Y).

INPUT PARAMETERS:
    C   -   spline interpolant.
    X, Y-   point
    F   -   output buffer, possibly preallocated array. In case array size
            is large enough to store result, it is not reallocated.  Array
            which is too short will be reallocated

OUTPUT PARAMETERS:
    F   -   array[D] (or larger) which stores function values

  -- ALGLIB PROJECT --
     Copyright 16.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dcalcvbuf(
    spline2dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    real_1d_array&amp; f);

</div></pre>
<a name='sub_spline2dcopy'></a><h3 class=pageheader><code>spline2dcopy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine makes the copy of the spline model.

Input parameters:
    C   -   spline interpolant

Output parameters:
    CC  -   spline copy

  -- ALGLIB PROJECT --
     Copyright 29.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dcopy(spline2dinterpolant c, spline2dinterpolant&amp; cc);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_copytrans' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2ddiff'></a><h3 class=pageheader><code>spline2ddiff</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates the value of the bilinear or bicubic spline  at
the given point X and its derivatives.

Input parameters:
    C   -   spline interpolant.
    X, Y-   point

Output parameters:
    F   -   S(x,y)
    FX  -   dS(x,y)/dX
    FY  -   dS(x,y)/dY
    FXY -   d2S(x,y)/dXdY

  -- ALGLIB PROJECT --
     Copyright 05.07.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2ddiff(
    spline2dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    <b>double</b>&amp; f,
    <b>double</b>&amp; fx,
    <b>double</b>&amp; fy,
    <b>double</b>&amp; fxy);

</div></pre>
<a name='sub_spline2dlintransf'></a><h3 class=pageheader><code>spline2dlintransf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline.

Input parameters:
    C   -   spline interpolant.
    A, B-   transformation coefficients: S2(x,y) = A*S(x,y) + B

Output parameters:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 30.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dlintransf(spline2dinterpolant c, <b>double</b> a, <b>double</b> b);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_copytrans' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dlintransxy'></a><h3 class=pageheader><code>spline2dlintransxy</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline argument.

Input parameters:
    C       -   spline interpolant
    AX, BX  -   transformation coefficients: x = A*t + B
    AY, BY  -   transformation coefficients: y = A*u + B
Result:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 30.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dlintransxy(
    spline2dinterpolant c,
    <b>double</b> ax,
    <b>double</b> bx,
    <b>double</b> ay,
    <b>double</b> by);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_copytrans' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline2dresamplebicubic'></a><h3 class=pageheader><code>spline2dresamplebicubic</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bicubic spline resampling

Input parameters:
    A           -   function values at the old grid,
                    array[0..OldHeight-1, 0..OldWidth-1]
    OldHeight   -   old grid height, OldHeight&gt;1
    OldWidth    -   old grid width, OldWidth&gt;1
    NewHeight   -   new grid height, NewHeight&gt;1
    NewWidth    -   new grid width, NewWidth&gt;1

Output parameters:
    B           -   function values at the new grid,
                    array[0..NewHeight-1, 0..NewWidth-1]

  -- ALGLIB routine --
     15 May, 2007
     Copyright by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dresamplebicubic(
    real_2d_array a,
    ae_int_t oldheight,
    ae_int_t oldwidth,
    real_2d_array&amp; b,
    ae_int_t newheight,
    ae_int_t newwidth);

</div></pre>
<a name='sub_spline2dresamplebilinear'></a><h3 class=pageheader><code>spline2dresamplebilinear</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Bilinear spline resampling

Input parameters:
    A           -   function values at the old grid,
                    array[0..OldHeight-1, 0..OldWidth-1]
    OldHeight   -   old grid height, OldHeight&gt;1
    OldWidth    -   old grid width, OldWidth&gt;1
    NewHeight   -   new grid height, NewHeight&gt;1
    NewWidth    -   new grid width, NewWidth&gt;1

Output parameters:
    B           -   function values at the new grid,
                    array[0..NewHeight-1, 0..NewWidth-1]

  -- ALGLIB routine --
     09.07.2007
     Copyright by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dresamplebilinear(
    real_2d_array a,
    ae_int_t oldheight,
    ae_int_t oldwidth,
    real_2d_array&amp; b,
    ae_int_t newheight,
    ae_int_t newwidth);

</div></pre>
<a name='sub_spline2dunpack'></a><h3 class=pageheader><code>spline2dunpack</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine was deprecated in ALGLIB 3.6.0

We recommend you to switch  to  Spline2DUnpackV(),  which is more flexible
and accepts its arguments in more convenient order.

  -- ALGLIB PROJECT --
     Copyright 29.06.2007 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dunpack(
    spline2dinterpolant c,
    ae_int_t&amp; m,
    ae_int_t&amp; n,
    real_2d_array&amp; tbl);

</div></pre>
<a name='sub_spline2dunpackv'></a><h3 class=pageheader><code>spline2dunpackv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine unpacks two-dimensional spline into the coefficients table

Input parameters:
    C   -   spline interpolant.

Result:
    M, N-   grid size (x-axis and y-axis)
    D   -   number of components
    Tbl -   coefficients table, unpacked format,
            D - components: [0..(N-1)*(M-1)*D-1, 0..19].
            For T=0..D-1 (component index), I = 0...N-2 (x index),
            J=0..M-2 (y index):
                K :=  T + I*D + J*D*(N-1)

                K-th row stores decomposition for T-th component of the
                vector-valued function

                Tbl[K,0] = X[i]
                Tbl[K,1] = X[i+1]
                Tbl[K,2] = Y[j]
                Tbl[K,3] = Y[j+1]
                Tbl[K,4] = C00
                Tbl[K,5] = C01
                Tbl[K,6] = C02
                Tbl[K,7] = C03
                Tbl[K,8] = C10
                Tbl[K,9] = C11
                ...
                Tbl[K,19] = C33
            On each grid square spline is equals to:
                S(x) = SUM(c[i,j]*(t^i)*(u^j), i=0..3, j=0..3)
                t = x-x[j]
                u = y-y[i]

  -- ALGLIB PROJECT --
     Copyright 16.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline2dunpackv(
    spline2dinterpolant c,
    ae_int_t&amp; m,
    ae_int_t&amp; n,
    ae_int_t&amp; d,
    real_2d_array&amp; tbl);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline2d_unpack' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='example_spline2d_bicubic'></a><h3 class=pageheader>spline2d_bicubic example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use bilinear spline to interpolate f(x,y)=x^2+2*y^2 sampled </font>
    <font color=navy>// at (x,y) from [0.0, 0.5, 1.0] X [0.0, 1.0].</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 0.5, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0.00,0.25,1.00,2.00,2.25,3.00]&quot;</b></font>;
    <b>double</b> vx = 0.25;
    <b>double</b> vy = 0.50;
    <b>double</b> v;
    <b>double</b> dx;
    <b>double</b> dy;
    <b>double</b> dxy;
    spline2dinterpolant s;

    <font color=navy>// build spline</font>
    spline2dbuildbicubicv(x, 3, y, 2, f, 1, s);

    <font color=navy>// calculate S(0.25,0.50)</font>
    v = spline2dcalc(s, vx, vy);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0625</font>

    <font color=navy>// calculate derivatives</font>
    spline2ddiff(s, vx, vy, v, dx, dy, dxy);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.0625</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(dx)); <font color=navy>// EXPECTED: 0.5000</font>
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(dy)); <font color=navy>// EXPECTED: 2.0000</font>
    <b>return</b> 0;
}


</pre><a name='example_spline2d_bilinear'></a><h3 class=pageheader>spline2d_bilinear example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use bilinear spline to interpolate f(x,y)=x^2+2*y^2 sampled </font>
    <font color=navy>// at (x,y) from [0.0, 0.5, 1.0] X [0.0, 1.0].</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 0.5, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0.00,0.25,1.00,2.00,2.25,3.00]&quot;</b></font>;
    <b>double</b> vx = 0.25;
    <b>double</b> vy = 0.50;
    <b>double</b> v;
    spline2dinterpolant s;

    <font color=navy>// build spline</font>
    spline2dbuildbilinearv(x, 3, y, 2, f, 1, s);

    <font color=navy>// calculate S(0.25,0.50)</font>
    v = spline2dcalc(s, vx, vy);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.1250</font>
    <b>return</b> 0;
}


</pre><a name='example_spline2d_copytrans'></a><h3 class=pageheader>spline2d_copytrans example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We build bilinear spline <b>for</b> f(x,y)=x+2*y <b>for</b> (x,y) in [0,1].</font>
    <font color=navy>// Then we apply several transformations to this spline.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0.00,1.00,2.00,3.00]&quot;</b></font>;
    spline2dinterpolant s;
    spline2dinterpolant snew;
    <b>double</b> v;
    spline2dbuildbilinearv(x, 2, y, 2, f, 1, s);

    <font color=navy>// copy spline, apply transformation x:=2*xnew, y:=4*ynew</font>
    <font color=navy>// evaluate at (xnew,ynew) = (0.25,0.25) - should be same as (x,y)=(0.5,1.0)</font>
    spline2dcopy(s, snew);
    spline2dlintransxy(snew, 2.0, 0.0, 4.0, 0.0);
    v = spline2dcalc(snew, 0.25, 0.25);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 2.500</font>

    <font color=navy>// copy spline, apply transformation SNew:=2*S+3</font>
    spline2dcopy(s, snew);
    spline2dlintransf(snew, 2.0, 3.0);
    v = spline2dcalc(snew, 0.5, 1.0);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 8.000</font>

    <font color=navy>//</font>
    <font color=navy>// Same example, but <b>for</b> vector spline (f0,f1) = {x+2*y, 2*x+y}</font>
    <font color=navy>//</font>
    real_1d_array f2 = <font color=blue><b>&quot;[0.00,0.00, 1.00,2.00, 2.00,1.00, 3.00,3.00]&quot;</b></font>;
    real_1d_array vr;
    spline2dbuildbilinearv(x, 2, y, 2, f2, 2, s);

    <font color=navy>// copy spline, apply transformation x:=2*xnew, y:=4*ynew</font>
    spline2dcopy(s, snew);
    spline2dlintransxy(snew, 2.0, 0.0, 4.0, 0.0);
    spline2dcalcv(snew, 0.25, 0.25, vr);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, vr.tostring(4).c_str()); <font color=navy>// EXPECTED: [2.500,2.000]</font>

    <font color=navy>// copy spline, apply transformation SNew:=2*S+3</font>
    spline2dcopy(s, snew);
    spline2dlintransf(snew, 2.0, 3.0);
    spline2dcalcv(snew, 0.5, 1.0, vr);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, vr.tostring(4).c_str()); <font color=navy>// EXPECTED: [8.000,7.000]</font>
    <b>return</b> 0;
}


</pre><a name='example_spline2d_unpack'></a><h3 class=pageheader>spline2d_unpack example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We build bilinear spline <b>for</b> f(x,y)=x+2*y+3*xy <b>for</b> (x,y) in [0,1].</font>
    <font color=navy>// Then we demonstrate how to unpack it.</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0.00,1.00,2.00,6.00]&quot;</b></font>;
    real_2d_array c;
    ae_int_t m;
    ae_int_t n;
    ae_int_t d;
    spline2dinterpolant s;

    <font color=navy>// build spline</font>
    spline2dbuildbilinearv(x, 2, y, 2, f, 1, s);

    <font color=navy>// unpack and test</font>
    spline2dunpackv(s, m, n, d, c);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, c.tostring(4).c_str()); <font color=navy>// EXPECTED: [[0, 1, 0, 1, 0,2,0,0, 1,3,0,0, 0,0,0,0, 0,0,0,0 ]]</font>
    <b>return</b> 0;
}


</pre><a name='example_spline2d_vector'></a><h3 class=pageheader>spline2d_vector example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We build bilinear vector-valued spline (f0,f1) = {x+2*y, 2*x+y}</font>
    <font color=navy>// Spline is built using function values at 2x2 grid: (x,y)=[0,1]*[0,1]</font>
    <font color=navy>// Then we perform evaluation at (x,y)=(0.1,0.3)</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0.00,0.00, 1.00,2.00, 2.00,1.00, 3.00,3.00]&quot;</b></font>;
    spline2dinterpolant s;
    real_1d_array vr;
    spline2dbuildbilinearv(x, 2, y, 2, f, 2, s);
    spline2dcalcv(s, 0.1, 0.3, vr);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, vr.tostring(4).c_str()); <font color=navy>// EXPECTED: [0.700,0.500]</font>
    <b>return</b> 0;
}


</pre><a name=unit_spline3d></a><h2 class=pageheader><code>spline3d</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Classes</h3>
<a href='#struct_spline3dinterpolant' class=toc>spline3dinterpolant</a><br>
<h3 class=pageheader>Functions</h3>
<a href='#sub_spline3dbuildtrilinearv' class=toc>spline3dbuildtrilinearv</a><br>
<a href='#sub_spline3dcalc' class=toc>spline3dcalc</a><br>
<a href='#sub_spline3dcalcv' class=toc>spline3dcalcv</a><br>
<a href='#sub_spline3dcalcvbuf' class=toc>spline3dcalcvbuf</a><br>
<a href='#sub_spline3dlintransf' class=toc>spline3dlintransf</a><br>
<a href='#sub_spline3dlintransxyz' class=toc>spline3dlintransxyz</a><br>
<a href='#sub_spline3dresampletrilinear' class=toc>spline3dresampletrilinear</a><br>
<a href='#sub_spline3dunpackv' class=toc>spline3dunpackv</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
<tr align=left valign=top><td><a href='#example_spline3d_trilinear' class=toc>spline3d_trilinear</a></td><td width=15>&nbsp;</td><td>Trilinear spline interpolation</td></tr>
<tr align=left valign=top><td><a href='#example_spline3d_vector' class=toc>spline3d_vector</a></td><td width=15>&nbsp;</td><td>Vector-valued trilinear spline interpolation</td></tr>
</table></div>
<a name='struct_spline3dinterpolant'></a><h3 class=pageheader><code>spline3dinterpolant</code> class</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
3-dimensional spline inteprolant
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>class</b> spline3dinterpolant
{
};

</div></pre>
<a name='sub_spline3dbuildtrilinearv'></a><h3 class=pageheader><code>spline3dbuildtrilinearv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine builds trilinear vector-valued spline.

INPUT PARAMETERS:
    X   -   spline abscissas,  array[0..N-1]
    Y   -   spline ordinates,  array[0..M-1]
    Z   -   spline applicates, array[0..L-1]
    F   -   function values, array[0..M*N*L*D-1]:
            * first D elements store D values at (X[0],Y[0],Z[0])
            * next D elements store D values at (X[1],Y[0],Z[0])
            * next D elements store D values at (X[2],Y[0],Z[0])
            * ...
            * next D elements store D values at (X[0],Y[1],Z[0])
            * next D elements store D values at (X[1],Y[1],Z[0])
            * next D elements store D values at (X[2],Y[1],Z[0])
            * ...
            * next D elements store D values at (X[0],Y[0],Z[1])
            * next D elements store D values at (X[1],Y[0],Z[1])
            * next D elements store D values at (X[2],Y[0],Z[1])
            * ...
            * general form - D function values at (X[i],Y[j]) are stored
              at F[D*(N*(M*K+J)+I)...D*(N*(M*K+J)+I)+D-1].
    M,N,
    L   -   grid size, M&gt;=2, N&gt;=2, L&gt;=2
    D   -   vector dimension, D&gt;=1

OUTPUT PARAMETERS:
    C   -   spline interpolant

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dbuildtrilinearv(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    real_1d_array z,
    ae_int_t l,
    real_1d_array f,
    ae_int_t d,
    spline3dinterpolant&amp; c);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline3d_trilinear' class=nav>[1]</a>&nbsp;&nbsp;<a href='#example_spline3d_vector' class=nav>[2]</a>&nbsp;&nbsp;</p>
<a name='sub_spline3dcalc'></a><h3 class=pageheader><code>spline3dcalc</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates the value of the trilinear or tricubic spline at
the given point (X,Y,Z).

INPUT PARAMETERS:
    C   -   coefficients table.
            Built by BuildBilinearSpline or BuildBicubicSpline.
    X, Y,
    Z   -   point

Result:
    S(x,y,z)

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::spline3dcalc(
    spline3dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    <b>double</b> z);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline3d_trilinear' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline3dcalcv'></a><h3 class=pageheader><code>spline3dcalcv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates trilinear or tricubic vector-valued spline at the
given point (X,Y,Z).

INPUT PARAMETERS:
    C   -   spline interpolant.
    X, Y,
    Z   -   point

OUTPUT PARAMETERS:
    F   -   array[D] which stores function values.  F is out-parameter and
            it  is  reallocated  after  call to this function. In case you
            want  to    reuse  previously  allocated  F,   you   may   use
            Spline2DCalcVBuf(),  which  reallocates  F only when it is too
            small.

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dcalcv(
    spline3dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    <b>double</b> z,
    real_1d_array&amp; f);

</div></pre>
<p align=left class=pagecontent><span class=inlineheader>Examples:</span>&nbsp;&nbsp;&nbsp;<a href='#example_spline3d_vector' class=nav>[1]</a>&nbsp;&nbsp;</p>
<a name='sub_spline3dcalcvbuf'></a><h3 class=pageheader><code>spline3dcalcvbuf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine calculates bilinear or bicubic vector-valued spline at the
given point (X,Y,Z).

INPUT PARAMETERS:
    C   -   spline interpolant.
    X, Y,
    Z   -   point
    F   -   output buffer, possibly preallocated array. In case array size
            is large enough to store result, it is not reallocated.  Array
            which is too short will be reallocated

OUTPUT PARAMETERS:
    F   -   array[D] (or larger) which stores function values

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dcalcvbuf(
    spline3dinterpolant c,
    <b>double</b> x,
    <b>double</b> y,
    <b>double</b> z,
    real_1d_array&amp; f);

</div></pre>
<a name='sub_spline3dlintransf'></a><h3 class=pageheader><code>spline3dlintransf</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline.

INPUT PARAMETERS:
    C   -   spline interpolant.
    A, B-   transformation coefficients: S2(x,y) = A*S(x,y,z) + B

OUTPUT PARAMETERS:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dlintransf(spline3dinterpolant c, <b>double</b> a, <b>double</b> b);

</div></pre>
<a name='sub_spline3dlintransxyz'></a><h3 class=pageheader><code>spline3dlintransxyz</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine performs linear transformation of the spline argument.

INPUT PARAMETERS:
    C       -   spline interpolant
    AX, BX  -   transformation coefficients: x = A*u + B
    AY, BY  -   transformation coefficients: y = A*v + B
    AZ, BZ  -   transformation coefficients: z = A*w + B

OUTPUT PARAMETERS:
    C   -   transformed spline

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dlintransxyz(
    spline3dinterpolant c,
    <b>double</b> ax,
    <b>double</b> bx,
    <b>double</b> ay,
    <b>double</b> by,
    <b>double</b> az,
    <b>double</b> bz);

</div></pre>
<a name='sub_spline3dresampletrilinear'></a><h3 class=pageheader><code>spline3dresampletrilinear</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Trilinear spline resampling

INPUT PARAMETERS:
    A           -   array[0..OldXCount*OldYCount*OldZCount-1], function
                    values at the old grid, :
                        A[0]        x=0,y=0,z=0
                        A[1]        x=1,y=0,z=0
                        A[..]       ...
                        A[..]       x=oldxcount-1,y=0,z=0
                        A[..]       x=0,y=1,z=0
                        A[..]       ...
                        ...
    OldZCount   -   old Z-count, OldZCount&gt;1
    OldYCount   -   old Y-count, OldYCount&gt;1
    OldXCount   -   old X-count, OldXCount&gt;1
    NewZCount   -   new Z-count, NewZCount&gt;1
    NewYCount   -   new Y-count, NewYCount&gt;1
    NewXCount   -   new X-count, NewXCount&gt;1

OUTPUT PARAMETERS:
    B           -   array[0..NewXCount*NewYCount*NewZCount-1], function
                    values at the new grid:
                        B[0]        x=0,y=0,z=0
                        B[1]        x=1,y=0,z=0
                        B[..]       ...
                        B[..]       x=newxcount-1,y=0,z=0
                        B[..]       x=0,y=1,z=0
                        B[..]       ...
                        ...

  -- ALGLIB routine --
     26.04.2012
     Copyright by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dresampletrilinear(
    real_1d_array a,
    ae_int_t oldzcount,
    ae_int_t oldycount,
    ae_int_t oldxcount,
    ae_int_t newzcount,
    ae_int_t newycount,
    ae_int_t newxcount,
    real_1d_array&amp; b);

</div></pre>
<a name='sub_spline3dunpackv'></a><h3 class=pageheader><code>spline3dunpackv</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
This subroutine unpacks tri-dimensional spline into the coefficients table

INPUT PARAMETERS:
    C   -   spline interpolant.

Result:
    N   -   grid size (X)
    M   -   grid size (Y)
    L   -   grid size (Z)
    D   -   number of components
    SType-  spline type. Currently, only one spline type is supported:
            trilinear spline, as indicated by SType=1.
    Tbl -   spline coefficients: [0..(N-1)*(M-1)*(L-1)*D-1, 0..13].
            For T=0..D-1 (component index), I = 0...N-2 (x index),
            J=0..M-2 (y index), K=0..L-2 (z index):
                Q := T + I*D + J*D*(N-1) + K*D*(N-1)*(M-1),

                Q-th row stores decomposition for T-th component of the
                vector-valued function

                Tbl[Q,0] = X[i]
                Tbl[Q,1] = X[i+1]
                Tbl[Q,2] = Y[j]
                Tbl[Q,3] = Y[j+1]
                Tbl[Q,4] = Z[k]
                Tbl[Q,5] = Z[k+1]

                Tbl[Q,6] = C000
                Tbl[Q,7] = C100
                Tbl[Q,8] = C010
                Tbl[Q,9] = C110
                Tbl[Q,10]= C001
                Tbl[Q,11]= C101
                Tbl[Q,12]= C011
                Tbl[Q,13]= C111
            On each grid square spline is equals to:
                S(x) = SUM(c[i,j,k]*(x^i)*(y^j)*(z^k), i=0..1, j=0..1, k=0..1)
                t = x-x[j]
                u = y-y[i]
                v = z-z[k]

            NOTE: format of Tbl is given for SType=1. Future versions of
                  ALGLIB can use different formats for different values of
                  SType.

  -- ALGLIB PROJECT --
     Copyright 26.04.2012 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::spline3dunpackv(
    spline3dinterpolant c,
    ae_int_t&amp; n,
    ae_int_t&amp; m,
    ae_int_t&amp; l,
    ae_int_t&amp; d,
    ae_int_t&amp; stype,
    real_2d_array&amp; tbl);

</div></pre>
<a name='example_spline3d_trilinear'></a><h3 class=pageheader>spline3d_trilinear example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use trilinear spline to interpolate f(x,y,z)=x+xy+z sampled </font>
    <font color=navy>// at (x,y,z) from [0.0, 1.0] X [0.0, 1.0] X [0.0, 1.0].</font>
    <font color=navy>//</font>
    <font color=navy>// We store x, y and z-values at local arrays with same names.</font>
    <font color=navy>// Function values are stored in the array F as follows:</font>
    <font color=navy>//     f[0]     (x,y,z) = (0,0,0)</font>
    <font color=navy>//     f[1]     (x,y,z) = (1,0,0)</font>
    <font color=navy>//     f[2]     (x,y,z) = (0,1,0)</font>
    <font color=navy>//     f[3]     (x,y,z) = (1,1,0)</font>
    <font color=navy>//     f[4]     (x,y,z) = (0,0,1)</font>
    <font color=navy>//     f[5]     (x,y,z) = (1,0,1)</font>
    <font color=navy>//     f[6]     (x,y,z) = (0,1,1)</font>
    <font color=navy>//     f[7]     (x,y,z) = (1,1,1)</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array z = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0,1,0,2,1,2,1,3]&quot;</b></font>;
    <b>double</b> vx = 0.50;
    <b>double</b> vy = 0.50;
    <b>double</b> vz = 0.50;
    <b>double</b> v;
    spline3dinterpolant s;

    <font color=navy>// build spline</font>
    spline3dbuildtrilinearv(x, 2, y, 2, z, 2, f, 1, s);

    <font color=navy>// calculate S(0.5,0.5,0.5)</font>
    v = spline3dcalc(s, vx, vy, vz);
    printf(<font color=blue><b>&quot;%.4f\n&quot;</b></font>, <b>double</b>(v)); <font color=navy>// EXPECTED: 1.2500</font>
    <b>return</b> 0;
}


</pre><a name='example_spline3d_vector'></a><h3 class=pageheader>spline3d_vector example</h3>
<pre class=source>
#include <font color=blue><b>&quot;stdafx.h&quot;</b></font>
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;math.h&gt;
#include <font color=blue><b>&quot;interpolation.h&quot;</b></font>

using namespace alglib;


<b>int</b> main(<b>int</b> argc, char **argv)
{
    <font color=navy>//</font>
    <font color=navy>// We use trilinear vector-valued spline to interpolate {f0,f1}={x+xy+z,x+xy+yz+z}</font>
    <font color=navy>// sampled at (x,y,z) from [0.0, 1.0] X [0.0, 1.0] X [0.0, 1.0].</font>
    <font color=navy>//</font>
    <font color=navy>// We store x, y and z-values at local arrays with same names.</font>
    <font color=navy>// Function values are stored in the array F as follows:</font>
    <font color=navy>//     f[0]     f0, (x,y,z) = (0,0,0)</font>
    <font color=navy>//     f[1]     f1, (x,y,z) = (0,0,0)</font>
    <font color=navy>//     f[2]     f0, (x,y,z) = (1,0,0)</font>
    <font color=navy>//     f[3]     f1, (x,y,z) = (1,0,0)</font>
    <font color=navy>//     f[4]     f0, (x,y,z) = (0,1,0)</font>
    <font color=navy>//     f[5]     f1, (x,y,z) = (0,1,0)</font>
    <font color=navy>//     f[6]     f0, (x,y,z) = (1,1,0)</font>
    <font color=navy>//     f[7]     f1, (x,y,z) = (1,1,0)</font>
    <font color=navy>//     f[8]     f0, (x,y,z) = (0,0,1)</font>
    <font color=navy>//     f[9]     f1, (x,y,z) = (0,0,1)</font>
    <font color=navy>//     f[10]    f0, (x,y,z) = (1,0,1)</font>
    <font color=navy>//     f[11]    f1, (x,y,z) = (1,0,1)</font>
    <font color=navy>//     f[12]    f0, (x,y,z) = (0,1,1)</font>
    <font color=navy>//     f[13]    f1, (x,y,z) = (0,1,1)</font>
    <font color=navy>//     f[14]    f0, (x,y,z) = (1,1,1)</font>
    <font color=navy>//     f[15]    f1, (x,y,z) = (1,1,1)</font>
    <font color=navy>//</font>
    real_1d_array x = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array y = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array z = <font color=blue><b>&quot;[0.0, 1.0]&quot;</b></font>;
    real_1d_array f = <font color=blue><b>&quot;[0,0, 1,1, 0,0, 2,2, 1,1, 2,2, 1,2, 3,4]&quot;</b></font>;
    <b>double</b> vx = 0.50;
    <b>double</b> vy = 0.50;
    <b>double</b> vz = 0.50;
    spline3dinterpolant s;

    <font color=navy>// build spline</font>
    spline3dbuildtrilinearv(x, 2, y, 2, z, 2, f, 2, s);

    <font color=navy>// calculate S(0.5,0.5,0.5) - we have vector of values instead of single value</font>
    real_1d_array v;
    spline3dcalcv(s, vx, vy, vz, v);
    printf(<font color=blue><b>&quot;%s\n&quot;</b></font>, v.tostring(4).c_str()); <font color=navy>// EXPECTED: [1.2500,1.5000]</font>
    <b>return</b> 0;
}


</pre><a name=unit_stest></a><h2 class=pageheader><code>stest</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_onesamplesigntest' class=toc>onesamplesigntest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_onesamplesigntest'></a><h3 class=pageheader><code>onesamplesigntest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Sign test

This test checks three hypotheses about the median of  the  given  sample.
The following tests are performed:
    * two-tailed test (null hypothesis - the median is equal to the  given
      value)
    * left-tailed test (null hypothesis - the median is  greater  than  or
      equal to the given value)
    * right-tailed test (null hypothesis - the  median  is  less  than  or
      equal to the given value)

Requirements:
    * the scale of measurement should be ordinal, interval or ratio  (i.e.
      the test could not be applied to nominal variables).

The test is non-parametric and doesn't require distribution X to be normal

Input parameters:
    X       -   sample. Array whose index goes from 0 to N-1.
    N       -   size of the sample.
    Median  -   assumed median value.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

While   calculating   p-values   high-precision   binomial    distribution
approximation is used, so significance levels have about 15 exact digits.

  -- ALGLIB --
     Copyright 08.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::onesamplesigntest(
    real_1d_array x,
    ae_int_t n,
    <b>double</b> median,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name=unit_studenttdistr></a><h2 class=pageheader><code>studenttdistr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_invstudenttdistribution' class=toc>invstudenttdistribution</a><br>
<a href='#sub_studenttdistribution' class=toc>studenttdistribution</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_invstudenttdistribution'></a><h3 class=pageheader><code>invstudenttdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Functional inverse of Student's t distribution

Given probability p, finds the argument t such that stdtr(k,t)
is equal to p.

ACCURACY:

Tested at random 1 &lt;= k &lt;= 100.  The &quot;domain&quot; refers to p:
                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE    .001,.999     25000       5.7e-15     8.0e-16
   IEEE    10^-6,.001    25000       2.0e-12     2.9e-14

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::invstudenttdistribution(ae_int_t k, <b>double</b> p);

</div></pre>
<a name='sub_studenttdistribution'></a><h3 class=pageheader><code>studenttdistribution</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Student's t distribution

Computes the integral from minus infinity to t of the Student
t distribution with integer k &gt; 0 degrees of freedom:

                                     t
                                     -
                                    | |
             -                      |         2   -(k+1)/2
            | ( (k+1)/2 )           |  (     x   )
      ----------------------        |  ( 1 + --- )        dx
                    -               |  (      k  )
      sqrt( k pi ) | ( k/2 )        |
                                  | |
                                   -
                                  -inf.

Relation to incomplete beta integral:

       1 - stdtr(k,t) = 0.5 * incbet( k/2, 1/2, z )
where
       z = k/(k + t**2).

For t &lt; -2, this is the method of computation.  For higher t,
a direct method is derived from integration by parts.
Since the function is symmetric about t=0, the area under the
right tail of the density is found by calling the function
with -t instead of t.

ACCURACY:

Tested at random 1 &lt;= k &lt;= 25.  The &quot;domain&quot; refers to t.
                     Relative error:
arithmetic   domain     # trials      peak         rms
   IEEE     -100,-2      50000       5.9e-15     1.4e-15
   IEEE     -2,100      500000       2.7e-15     4.9e-17

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 1995, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>double</b> alglib::studenttdistribution(ae_int_t k, <b>double</b> t);

</div></pre>
<a name=unit_studentttests></a><h2 class=pageheader><code>studentttests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_studentttest1' class=toc>studentttest1</a><br>
<a href='#sub_studentttest2' class=toc>studentttest2</a><br>
<a href='#sub_unequalvariancettest' class=toc>unequalvariancettest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_studentttest1'></a><h3 class=pageheader><code>studentttest1</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
One-sample t-test

This test checks three hypotheses about the mean of the given sample.  The
following tests are performed:
    * two-tailed test (null hypothesis - the mean is equal  to  the  given
      value)
    * left-tailed test (null hypothesis - the  mean  is  greater  than  or
      equal to the given value)
    * right-tailed test (null hypothesis - the mean is less than or  equal
      to the given value).

The test is based on the assumption that  a  given  sample  has  a  normal
distribution and  an  unknown  dispersion.  If  the  distribution  sharply
differs from normal, the test will work incorrectly.

INPUT PARAMETERS:
    X       -   sample. Array whose index goes from 0 to N-1.
    N       -   size of sample, N&gt;=0
    Mean    -   assumed value of the mean.

OUTPUT PARAMETERS:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

NOTE: this function correctly handles degenerate cases:
      * when N=0, all p-values are set to 1.0
      * when variance of X[] is exactly zero, p-values are set
        to 1.0 or 0.0, depending on difference between sample mean and
        value of mean being tested.


  -- ALGLIB --
     Copyright 08.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::studentttest1(
    real_1d_array x,
    ae_int_t n,
    <b>double</b> mean,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name='sub_studentttest2'></a><h3 class=pageheader><code>studentttest2</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Two-sample pooled test

This test checks three hypotheses about the mean of the given samples. The
following tests are performed:
    * two-tailed test (null hypothesis - the means are equal)
    * left-tailed test (null hypothesis - the mean of the first sample  is
      greater than or equal to the mean of the second sample)
    * right-tailed test (null hypothesis - the mean of the first sample is
      less than or equal to the mean of the second sample).

Test is based on the following assumptions:
    * given samples have normal distributions
    * dispersions are equal
    * samples are independent.

Input parameters:
    X       -   sample 1. Array whose index goes from 0 to N-1.
    N       -   size of sample.
    Y       -   sample 2. Array whose index goes from 0 to M-1.
    M       -   size of sample.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

NOTE: this function correctly handles degenerate cases:
      * when N=0 or M=0, all p-values are set to 1.0
      * when both samples has exactly zero variance, p-values are set
        to 1.0 or 0.0, depending on difference between means.

  -- ALGLIB --
     Copyright 18.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::studentttest2(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name='sub_unequalvariancettest'></a><h3 class=pageheader><code>unequalvariancettest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Two-sample unpooled test

This test checks three hypotheses about the mean of the given samples. The
following tests are performed:
    * two-tailed test (null hypothesis - the means are equal)
    * left-tailed test (null hypothesis - the mean of the first sample  is
      greater than or equal to the mean of the second sample)
    * right-tailed test (null hypothesis - the mean of the first sample is
      less than or equal to the mean of the second sample).

Test is based on the following assumptions:
    * given samples have normal distributions
    * samples are independent.
Equality of variances is NOT required.

Input parameters:
    X - sample 1. Array whose index goes from 0 to N-1.
    N - size of the sample.
    Y - sample 2. Array whose index goes from 0 to M-1.
    M - size of the sample.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

NOTE: this function correctly handles degenerate cases:
      * when N=0 or M=0, all p-values are set to 1.0
      * when both samples has zero variance, p-values are set
        to 1.0 or 0.0, depending on difference between means.
      * when only one sample has zero variance, test reduces to 1-sample
        version.

  -- ALGLIB --
     Copyright 18.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::unequalvariancettest(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name=unit_svd></a><h2 class=pageheader><code>svd</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_rmatrixsvd' class=toc>rmatrixsvd</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_rmatrixsvd'></a><h3 class=pageheader><code>rmatrixsvd</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Singular value decomposition of a rectangular matrix.

The algorithm calculates the singular value decomposition of a matrix of
size MxN: A = U * S * V^T

The algorithm finds the singular values and, optionally, matrices U and V^T.
The algorithm can find both first min(M,N) columns of matrix U and rows of
matrix V^T (singular vectors), and matrices U and V^T wholly (of sizes MxM
and NxN respectively).

Take into account that the subroutine does not return matrix V but V^T.

Input parameters:
    A           -   matrix to be decomposed.
                    Array whose indexes range within [0..M-1, 0..N-1].
    M           -   number of rows in matrix A.
    N           -   number of columns in matrix A.
    UNeeded     -   0, 1 or 2. See the description of the parameter U.
    VTNeeded    -   0, 1 or 2. See the description of the parameter VT.
    AdditionalMemory -
                    If the parameter:
                     * equals 0, the algorithm doesnt use additional
                       memory (lower requirements, lower performance).
                     * equals 1, the algorithm uses additional
                       memory of size min(M,N)*min(M,N) of real numbers.
                       It often speeds up the algorithm.
                     * equals 2, the algorithm uses additional
                       memory of size M*min(M,N) of real numbers.
                       It allows to get a maximum performance.
                    The recommended value of the parameter is 2.

Output parameters:
    W           -   contains singular values in descending order.
    U           -   if UNeeded=0, U isn't changed, the left singular vectors
                    are not calculated.
                    if Uneeded=1, U contains left singular vectors (first
                    min(M,N) columns of matrix U). Array whose indexes range
                    within [0..M-1, 0..Min(M,N)-1].
                    if UNeeded=2, U contains matrix U wholly. Array whose
                    indexes range within [0..M-1, 0..M-1].
    VT          -   if VTNeeded=0, VT isnt changed, the right singular vectors
                    are not calculated.
                    if VTNeeded=1, VT contains right singular vectors (first
                    min(M,N) rows of matrix V^T). Array whose indexes range
                    within [0..min(M,N)-1, 0..N-1].
                    if VTNeeded=2, VT contains matrix V^T wholly. Array whose
                    indexes range within [0..N-1, 0..N-1].

  -- ALGLIB --
     Copyright 2005 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::rmatrixsvd(
    real_2d_array a,
    ae_int_t m,
    ae_int_t n,
    ae_int_t uneeded,
    ae_int_t vtneeded,
    ae_int_t additionalmemory,
    real_1d_array&amp; w,
    real_2d_array&amp; u,
    real_2d_array&amp; vt);

</div></pre>
<a name=unit_trfac></a><h2 class=pageheader><code>trfac</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_cmatrixlu' class=toc>cmatrixlu</a><br>
<a href='#sub_hpdmatrixcholesky' class=toc>hpdmatrixcholesky</a><br>
<a href='#sub_rmatrixlu' class=toc>rmatrixlu</a><br>
<a href='#sub_spdmatrixcholesky' class=toc>spdmatrixcholesky</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_cmatrixlu'></a><h3 class=pageheader><code>cmatrixlu</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LU decomposition of a general complex matrix with row pivoting

A is represented as A = P*L*U, where:
* L is lower unitriangular matrix
* U is upper triangular matrix
* P = P0*P1*...*PK, K=min(M,N)-1,
  Pi - permutation matrix for I and Pivots[I]

This is cache-oblivous implementation of LU decomposition. It is optimized
for square matrices. As for rectangular matrices:
* best case - M&gt;&gt;N
* worst case - N&gt;&gt;M, small M, large N, matrix does not fit in CPU cache

INPUT PARAMETERS:
    A       -   array[0..M-1, 0..N-1].
    M       -   number of rows in matrix A.
    N       -   number of columns in matrix A.


OUTPUT PARAMETERS:
    A       -   matrices L and U in compact form:
                * L is stored under main diagonal
                * U is stored on and above main diagonal
    Pivots  -   permutation matrix in compact form.
                array[0..Min(M-1,N-1)].

  -- ALGLIB routine --
     10.01.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::cmatrixlu(
    complex_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    integer_1d_array&amp; pivots);

</div></pre>
<a name='sub_hpdmatrixcholesky'></a><h3 class=pageheader><code>hpdmatrixcholesky</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cache-oblivious Cholesky decomposition

The algorithm computes Cholesky decomposition  of  a  Hermitian  positive-
definite matrix. The result of an algorithm is a representation  of  A  as
A=U'*U  or A=L*L' (here X' detones conj(X^T)).

INPUT PARAMETERS:
    A       -   upper or lower triangle of a factorized matrix.
                array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   if IsUpper=True, then A contains an upper triangle of
                a symmetric matrix, otherwise A contains a lower one.

OUTPUT PARAMETERS:
    A       -   the result of factorization. If IsUpper=True, then
                the upper triangle contains matrix U, so that A = U'*U,
                and the elements below the main diagonal are not modified.
                Similarly, if IsUpper = False.

RESULT:
    If  the  matrix  is  positive-definite,  the  function  returns  True.
    Otherwise, the function returns False. Contents of A is not determined
    in such case.

  -- ALGLIB routine --
     15.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::hpdmatrixcholesky(
    complex_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name='sub_rmatrixlu'></a><h3 class=pageheader><code>rmatrixlu</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
LU decomposition of a general real matrix with row pivoting

A is represented as A = P*L*U, where:
* L is lower unitriangular matrix
* U is upper triangular matrix
* P = P0*P1*...*PK, K=min(M,N)-1,
  Pi - permutation matrix for I and Pivots[I]

This is cache-oblivous implementation of LU decomposition.
It is optimized for square matrices. As for rectangular matrices:
* best case - M&gt;&gt;N
* worst case - N&gt;&gt;M, small M, large N, matrix does not fit in CPU cache

INPUT PARAMETERS:
    A       -   array[0..M-1, 0..N-1].
    M       -   number of rows in matrix A.
    N       -   number of columns in matrix A.


OUTPUT PARAMETERS:
    A       -   matrices L and U in compact form:
                * L is stored under main diagonal
                * U is stored on and above main diagonal
    Pivots  -   permutation matrix in compact form.
                array[0..Min(M-1,N-1)].

  -- ALGLIB routine --
     10.01.2010
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::rmatrixlu(
    real_2d_array&amp; a,
    ae_int_t m,
    ae_int_t n,
    integer_1d_array&amp; pivots);

</div></pre>
<a name='sub_spdmatrixcholesky'></a><h3 class=pageheader><code>spdmatrixcholesky</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Cache-oblivious Cholesky decomposition

The algorithm computes Cholesky decomposition  of  a  symmetric  positive-
definite matrix. The result of an algorithm is a representation  of  A  as
A=U^T*U  or A=L*L^T

INPUT PARAMETERS:
    A       -   upper or lower triangle of a factorized matrix.
                array with elements [0..N-1, 0..N-1].
    N       -   size of matrix A.
    IsUpper -   if IsUpper=True, then A contains an upper triangle of
                a symmetric matrix, otherwise A contains a lower one.

OUTPUT PARAMETERS:
    A       -   the result of factorization. If IsUpper=True, then
                the upper triangle contains matrix U, so that A = U^T*U,
                and the elements below the main diagonal are not modified.
                Similarly, if IsUpper = False.

RESULT:
    If  the  matrix  is  positive-definite,  the  function  returns  True.
    Otherwise, the function returns False. Contents of A is not determined
    in such case.

  -- ALGLIB routine --
     15.12.2009
     Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>bool</b> alglib::spdmatrixcholesky(
    real_2d_array&amp; a,
    ae_int_t n,
    <b>bool</b> isupper);

</div></pre>
<a name=unit_trigintegrals></a><h2 class=pageheader><code>trigintegrals</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_hyperbolicsinecosineintegrals' class=toc>hyperbolicsinecosineintegrals</a><br>
<a href='#sub_sinecosineintegrals' class=toc>sinecosineintegrals</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_hyperbolicsinecosineintegrals'></a><h3 class=pageheader><code>hyperbolicsinecosineintegrals</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Hyperbolic sine and cosine integrals

Approximates the integrals

                           x
                           -
                          | |   cosh t - 1
  Chi(x) = eul + ln x +   |    -----------  dt,
                        | |          t
                         -
                         0

              x
              -
             | |  sinh t
  Shi(x) =   |    ------  dt
           | |       t
            -
            0

where eul = 0.57721566490153286061 is Euler's constant.
The integrals are evaluated by power series for x &lt; 8
and by Chebyshev expansions for x between 8 and 88.
For large x, both functions approach exp(x)/2x.
Arguments greater than 88 in magnitude return MAXNUM.


ACCURACY:

Test interval 0 to 88.
                     Relative error:
arithmetic   function  # trials      peak         rms
   IEEE         Shi      30000       6.9e-16     1.6e-16
       Absolute error, except relative when |Chi| &gt; 1:
   IEEE         Chi      30000       8.4e-16     1.4e-16

Cephes Math Library Release 2.8:  June, 2000
Copyright 1984, 1987, 2000 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::hyperbolicsinecosineintegrals(
    <b>double</b> x,
    <b>double</b>&amp; shi,
    <b>double</b>&amp; chi);

</div></pre>
<a name='sub_sinecosineintegrals'></a><h3 class=pageheader><code>sinecosineintegrals</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Sine and cosine integrals

Evaluates the integrals

                         x
                         -
                        |  cos t - 1
  Ci(x) = eul + ln x +  |  --------- dt,
                        |      t
                       -
                        0
            x
            -
           |  sin t
  Si(x) =  |  ----- dt
           |    t
          -
           0

where eul = 0.57721566490153286061 is Euler's constant.
The integrals are approximated by rational functions.
For x &gt; 8 auxiliary functions f(x) and g(x) are employed
such that

Ci(x) = f(x) sin(x) - g(x) cos(x)
Si(x) = pi/2 - f(x) cos(x) - g(x) sin(x)


ACCURACY:
   Test interval = [0,50].
Absolute error, except relative when &gt; 1:
arithmetic   function   # trials      peak         rms
   IEEE        Si        30000       4.4e-16     7.3e-17
   IEEE        Ci        30000       6.9e-16     5.1e-17

Cephes Math Library Release 2.1:  January, 1989
Copyright 1984, 1987, 1989 by Stephen L. Moshier
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::sinecosineintegrals(<b>double</b> x, <b>double</b>&amp; si, <b>double</b>&amp; ci);

</div></pre>
<a name=unit_variancetests></a><h2 class=pageheader><code>variancetests</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_ftest' class=toc>ftest</a><br>
<a href='#sub_onesamplevariancetest' class=toc>onesamplevariancetest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_ftest'></a><h3 class=pageheader><code>ftest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Two-sample F-test

This test checks three hypotheses about dispersions of the given  samples.
The following tests are performed:
    * two-tailed test (null hypothesis - the dispersions are equal)
    * left-tailed test (null hypothesis  -  the  dispersion  of  the first
      sample is greater than or equal to  the  dispersion  of  the  second
      sample).
    * right-tailed test (null hypothesis - the  dispersion  of  the  first
      sample is less than or equal to the dispersion of the second sample)

The test is based on the following assumptions:
    * the given samples have normal distributions
    * the samples are independent.

Input parameters:
    X   -   sample 1. Array whose index goes from 0 to N-1.
    N   -   sample size.
    Y   -   sample 2. Array whose index goes from 0 to M-1.
    M   -   sample size.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

  -- ALGLIB --
     Copyright 19.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::ftest(
    real_1d_array x,
    ae_int_t n,
    real_1d_array y,
    ae_int_t m,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name='sub_onesamplevariancetest'></a><h3 class=pageheader><code>onesamplevariancetest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
One-sample chi-square test

This test checks three hypotheses about the dispersion of the given sample
The following tests are performed:
    * two-tailed test (null hypothesis - the dispersion equals  the  given
      number)
    * left-tailed test (null hypothesis - the dispersion is  greater  than
      or equal to the given number)
    * right-tailed test (null hypothesis  -  dispersion is  less  than  or
      equal to the given number).

Test is based on the following assumptions:
    * the given sample has a normal distribution.

Input parameters:
    X           -   sample 1. Array whose index goes from 0 to N-1.
    N           -   size of the sample.
    Variance    -   dispersion value to compare with.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

  -- ALGLIB --
     Copyright 19.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::onesamplevariancetest(
    real_1d_array x,
    ae_int_t n,
    <b>double</b> variance,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>
<a name=unit_wsr></a><h2 class=pageheader><code>wsr</code> subpackage</h2>
<div class=pagecontent>
<h3 class=pageheader>Functions</h3>
<a href='#sub_wilcoxonsignedranktest' class=toc>wilcoxonsignedranktest</a><br>
<h3 class=pageheader>Examples</h3>
<table border=0 cellspacing=0 class='pagecontent'>
</table></div>
<a name='sub_wilcoxonsignedranktest'></a><h3 class=pageheader><code>wilcoxonsignedranktest</code> function</h3>
<pre class=source>
<div style='color: navy; margin-top: 0; margin-bottom: 0;'>/*************************************************************************
Wilcoxon signed-rank test

This test checks three hypotheses about the median  of  the  given sample.
The following tests are performed:
    * two-tailed test (null hypothesis - the median is equal to the  given
      value)
    * left-tailed test (null hypothesis - the median is  greater  than  or
      equal to the given value)
    * right-tailed test (null hypothesis  -  the  median  is  less than or
      equal to the given value)

Requirements:
    * the scale of measurement should be ordinal, interval or  ratio (i.e.
      the test could not be applied to nominal variables).
    * the distribution should be continuous and symmetric relative to  its
      median.
    * number of distinct values in the X array should be greater than 4

The test is non-parametric and doesn't require distribution X to be normal

Input parameters:
    X       -   sample. Array whose index goes from 0 to N-1.
    N       -   size of the sample.
    Median  -   assumed median value.

Output parameters:
    BothTails   -   p-value for two-tailed test.
                    If BothTails is less than the given significance level
                    the null hypothesis is rejected.
    LeftTail    -   p-value for left-tailed test.
                    If LeftTail is less than the given significance level,
                    the null hypothesis is rejected.
    RightTail   -   p-value for right-tailed test.
                    If RightTail is less than the given significance level
                    the null hypothesis is rejected.

To calculate p-values, special approximation is used. This method lets  us
calculate p-values with two decimal places in interval [0.0001, 1].

&quot;Two decimal places&quot; does not sound very impressive, but in  practice  the
relative error of less than 1% is enough to make a decision.

There is no approximation outside the [0.0001, 1] interval. Therefore,  if
the significance level outlies this interval, the test returns 0.0001.

  -- ALGLIB --
     Copyright 08.09.2006 by Bochkanov Sergey
*************************************************************************/
</div><div style='margin-top: 0; margin-bottom: 0;'><b>void</b> alglib::wilcoxonsignedranktest(
    real_1d_array x,
    ae_int_t n,
    <b>double</b> e,
    <b>double</b>&amp; bothtails,
    <b>double</b>&amp; lefttail,
    <b>double</b>&amp; righttail);

</div></pre>

</body>
</html>